[
  {
    "objectID": "check-links.html",
    "href": "check-links.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "# check all the links - get a list of all internal links\n# find all the files that are not used\n\n\nimport os\n\ndef get_all_files(base):\n    \"\"\"Returns a set of all paths to all files below base.\"\"\"\n    all_files = set()\n    skips = ['.git', '_site', \".quarto\"]\n    for root, dirs, files in os.walk(base):\n        for skip in skips:\n            if skip in dirs:\n                dirs.remove(skip)\n        for file in files:\n            all_files.add(os.path.join(root, file)[2:])\n    return all_files\n\n\nextra_files = get_all_files(\".\")\n\nprint(extra_files)\n\n{'lectures/images/StaticSingleAssignment_Part48.jpg', 'lectures/images/StaticSingleAssignment_Part73.jpg', 'issues', 'runfirst.py', 'lectures/images/StaticSingleAssignment_Part71.jpg', 'lectures/12_memory.qmd', 'Class_Overview/sylibus.qmd', 'lectures/03b_local_value_numbering.qmd', 'lectures/02b_bril.qmd.saved', 'lectures/100_mlir.qmd', 'lectures/03_local.qmd', 'lectures/05_global.qmd', 'description.txt', 'Class_Overview/about.qmd', 'lectures/04_data_flow.qmd', 'lectures/images/StaticSingleAssignment_Part69.jpg', 'index.qmd', 'notebooks/representation.ipynb', 'lectures/13_dynamic_compilers.qmd', 'lectures/images/my_ast', 'lectures/images/StaticSingleAssignment_Part40.jpg', 'lectures/images/add.json', 'lectures/images/Grace_Hopper_and_UNIVAC.jpg', 'lectures/08_classic_loop_ops.qmd', 'weekly.qmd', 'found_links.csv', 'lectures/02b_bril.qmd', 'lectures/14_gpu_compilers.qmd', 'Links-21-6-2024 83848.csv', 'lectures/junk.qmd', 'lectures/images/StaticSingleAssignment_Part40.pdf', 'Links-21-6-2024 84630.csv', 'notebooks/possible_papers.qmd', 'about.qmd', 'notebooks/02aa_reps.ipynb', 'lectures/images/Digraph.gv', 'Links-21-6-2024 84311.csv', 'lectures/images/StaticSingleAssignment_Part41.jpg', 'lectures/bril.qmd', 'lectures/images/StaticSingleAssignment_Part70.jpg', 'notebooks/llvm.ipynb', '.github/workflows/publish.yml', 'lectures/110_whole_program.qmd', 'lectures/images/Digraph.gv.png', 'requirements.txt', 'lectures/02a_representation.qmd.saved', 'lectures/02a_representation.qmd', 'lectures/06_ssa.qmd', 'lectures/images/StaticSingleAssignment_Part46.jpg', 'lectures/01a_performance_measurement.qmd', '.gitignore', 'lectures/images/toy.ts', '.vscode/settings.json', 'setenv.sh', 'lectures/images/StaticSingleAssignment_Part43.jpg', 'lectures/images/my_ast.png', 'styles.css', 'notebooks/02_reps.ipynb', 'Links-21-6-2024 84544.csv', 'check-links.ipynb', 'Links-21-6-2024 8400.csv', 'Class_Overview/schedule.qmd', 'lectures/02b_bril.ipynb', 'lectures/05b_licm.qmd', 'Links-21-6-2024 84235.csv', '_quarto.yml', 'lectures/09_poly.qmd', 'Class_Overview/What_to_do.qmd', 'lectures/07_llvm.ipynb', 'lectures/images/cfg.png', 'lectures/010_compiler_overview.qmd', 'notebooks/bril.ipynb', 'lectures/02a_representation.ipynb'}\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\nclass ctx():\n    def __init__(self, top):\n        self.top = top\n        self.external_links = set()\n        self.missing_files = set()\n        self.extra_files = set()\n        self.seen_urls = set()\n        self.seen_links = set()\n\n\n\n\ndef parseLinks(pageHtml, pageUrl, ctx):\n    soup = BeautifulSoup(pageHtml, 'html.parser')\n\n    #get all the &lt;a&gt; elements from the HTML page\n    allLinks = soup.find_all('a')\n\n    extIntLinks(allLinks, pageUrl, ctx)\n\n\ndef requestMaker(url, ctx):\n    if (url in ctx.seen_urls):\n        return\n    ctx.seen_urls.add(url)\n    try:\n        #make the get request to the url\n        response = requests.get(url)\n\n        #if the request is successful\n        if response.status_code in range(200, 300):\n            #extract the page html content for parsing the links\n            pageHtml = response.text\n            pageUrl = response.url\n\n            #call the parseLink function\n            parseLinks(pageHtml, pageUrl, ctx)\n        \n        else:\n            print(\"Sorry Could not fetch the result status code {response.status_code}!\")\n\n    except Exception as e:\n        print(f\"{e} Could Not Connect to url {url}\")\n\n\nfrom sympy import I\n\n\ndef extIntLinks(allLinks, pageUrl, ctx):\n\n    #go through all the &lt;a&gt; elements list \n    for anchor in allLinks:\n        link = anchor.get(\"href\")   #get the link from the &lt;a&gt; element\n\n        link_orig = link\n\n        if link is None:\n            continue\n        print(f\"link {link}\")\n\n        if link.startswith(\".\"):\n            if link == \"./\":\n                continue\n\n            if link in ctx.seen_links:\n                continue\n            ctx.seen_links.add(link)\n            file = link[2:] # remove ./\n            ## deal with the possible enddings \n\n            if file.startswith(\"revealjs-\"):\n                file = file[10:]\n\n            if file.endswith(\".html\"):\n                file_qmd =  file[:-4]+ \"qmd\"\n                if file_qmd in extra_files:\n                    extra_files.remove(file_qmd)\n                    newurl = ctx.top + '/' + file\n                    requestMaker(newurl, ctx)\n                    continue\n\n        elif link.startswith(ctx.top):\n            print(\"starts with top\")\n            continue\n\n        \n        elif link.startswith(\"#\") :\n            print(\"ref link\")\n\n        elif link.startswith(\"https://capra\"):\n            ctx.external_links.add(link)\n\n        elif link.startswith(\"https://github.com\"):\n            ctx.external_links.add(link)\n\n        elif link.startswith(\"https://quarto.org\"):\n            ctx.external_links.add(link)\n        \n        else: \n            print(\"else \", link, link_orig)\n\n     \n\n\nurl = \"https://normrubin.github.io\"\nrequestMaker(url, ctx(url))\n\nlink ./\nlink ./weekly.html\nlink ./weekly.html\nlink ./weekly.html\nlink ./\nlink ./weekly.html\nlink ./Class_Overview/about.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/about.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/about.html\nlink ../weekly.html\nlink ../Class_Overview/schedule.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/about.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/schedule.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.ipynb\nlink ../lectures/02b_bril.ipynb\nlink ../lectures/03_local.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/schedule.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/sylibus.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.ipynb\nlink ../lectures/02b_bril.ipynb\nlink ../lectures/03_local.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/What_to_do.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/sylibus.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/What_to_do.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/What_to_do.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/What_to_do.html\nlink https://quarto.org/\nlink ../Class_Overview/sylibus.html\nlink ../lectures/010_compiler_overview.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/What_to_do.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./lectures/010_compiler_overview.html\nlink ../weekly.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/010_compiler_overview.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink revealjs-compiler_overview.html\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/02_reps.html",
    "href": "notebooks/02_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02_reps.html#a-more-regular-representation",
    "href": "notebooks/02_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/representation.html",
    "href": "notebooks/representation.html",
    "title": "Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/representation.html#a-more-regular-representation",
    "href": "notebooks/representation.html#a-more-regular-representation",
    "title": "Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "href": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "title": "Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/06_ssa.html",
    "href": "lectures/06_ssa.html",
    "title": "Static Single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#static-single-assignment-ssa",
    "href": "lectures/06_ssa.html#static-single-assignment-ssa",
    "title": "Static Single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#ssa",
    "href": "lectures/06_ssa.html#ssa",
    "title": "Static Single Assignment",
    "section": "ssa",
    "text": "ssa\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA means statically there is only a single assignment per variable.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#the-ssa-philosophy",
    "href": "lectures/06_ssa.html#the-ssa-philosophy",
    "title": "Static Single Assignment",
    "section": "The SSA Philosophy",
    "text": "The SSA Philosophy\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges\n\n\nIn LLVM, for example, instructions do not refer to argument variables by name—an argument is a pointer to defining instruction.\nStatic means in the text, not in the execution.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example",
    "href": "lectures/06_ssa.html#an-example",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 0 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#straight-line-code",
    "href": "lectures/06_ssa.html#straight-line-code",
    "title": "Static Single Assignment",
    "section": "straight line code",
    "text": "straight line code\nWe call a program without branches a piece of straight line code.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\n. . .\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#pseudo-code-for-one-basic-block",
    "href": "lectures/06_ssa.html#pseudo-code-for-one-basic-block",
    "title": "Static Single Assignment",
    "section": "pseudo code for one basic block",
    "text": "pseudo code for one basic block\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B:\n        for each use of a argument x in S: \n            i = top(Stack[x]) \n            replace the use of x with x_i\n            \n        for each variable a that S defines (a dest)\n            count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with a_i\nWe don’t need the stack here but we will need it later.\n\nOf course, things will get a little more complicated when there is control flow. And because real machines are not SSA, using separate variables (i.e., memory locations and registers) for everything is bound to be inefficient.\nThe idea in SSA is to convert general programs into SSA form, do all our optimization there, and then convert back to a standard mutating form before we generate backend code.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes",
    "href": "lectures/06_ssa.html#phi-nodes",
    "title": "Static Single Assignment",
    "section": "phi-Nodes",
    "text": "phi-Nodes\nJust renaming assignments will quickly run into problems. Consider this program:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nWhich “version” of a should we use in the print statement?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes-1",
    "href": "lectures/06_ssa.html#phi-nodes-1",
    "title": "Static Single Assignment",
    "section": "phi nodes",
    "text": "phi nodes\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a phi-node.\nphi-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes-in-bril",
    "href": "lectures/06_ssa.html#phi-nodes-in-bril",
    "title": "Static Single Assignment",
    "section": "phi nodes in Bril",
    "text": "phi nodes in Bril\nIn Bril, a phi-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#back-to-the-example",
    "href": "lectures/06_ssa.html#back-to-the-example",
    "title": "Static Single Assignment",
    "section": "back to the example",
    "text": "back to the example\nYou can write the above program in SSA like this:\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\n\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#bril-in-ssa",
    "href": "lectures/06_ssa.html#bril-in-ssa",
    "title": "Static Single Assignment",
    "section": "Bril in SSA",
    "text": "Bril in SSA\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#converting-to-ssa---very-simple-scheme",
    "href": "lectures/06_ssa.html#converting-to-ssa---very-simple-scheme",
    "title": "Static Single Assignment",
    "section": "Converting to SSA - Very simple scheme",
    "text": "Converting to SSA - Very simple scheme\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nWhere do we need phi-functions?\nWhich variables\n. . .\nphi At the merge (join) node\nvariable b",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#conditions",
    "href": "lectures/06_ssa.html#conditions",
    "title": "Static Single Assignment",
    "section": "conditions",
    "text": "conditions\nconditions: phi-function for variable b at node z\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#scheme-part-2",
    "href": "lectures/06_ssa.html#scheme-part-2",
    "title": "Static Single Assignment",
    "section": "scheme part 2",
    "text": "scheme part 2\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#diagram",
    "href": "lectures/06_ssa.html#diagram",
    "title": "Static Single Assignment",
    "section": "diagram",
    "text": "diagram\nusing dash for path\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d \n\n\n\n\n\n\nWe could have complex flow - including loops on the paths",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#reminder-dominators",
    "href": "lectures/06_ssa.html#reminder-dominators",
    "title": "Static Single Assignment",
    "section": "reminder dominators",
    "text": "reminder dominators\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] =\n\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] =  {vertex} + ...\n\nif b has multiple preds, and a dominates all of them, a dom b\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] =  {vertex} + Intersection( dom(p) for p a pred of vertex)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#fast-methods-for-inserting-phis",
    "href": "lectures/06_ssa.html#fast-methods-for-inserting-phis",
    "title": "Static Single Assignment",
    "section": "fast methods for inserting phi’s",
    "text": "fast methods for inserting phi’s\nThe method for this has two steps\n\ninsert phi instructions where needed (do not add subscripts yet)\nin a second pass insert all the numbers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#to-ssa",
    "href": "lectures/06_ssa.html#to-ssa",
    "title": "Static Single Assignment",
    "section": "to ssa",
    "text": "to ssa\nTo convert to SSA, we want to insert phi-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need phi-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition?\nThe dominance frontier!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#recall-the-dominance-frontier",
    "href": "lectures/06_ssa.html#recall-the-dominance-frontier",
    "title": "Static Single Assignment",
    "section": "recall the dominance frontier",
    "text": "recall the dominance frontier\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n\n\n\n\n\n\n\nblock\nA\nB\nC\nD\nE\n\n\nfrontier\nempty\nF\nE\nE\nF",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#a-block-can-be-in-its-own-dom-frontier",
    "href": "lectures/06_ssa.html#a-block-can-be-in-its-own-dom-frontier",
    "title": "Static Single Assignment",
    "section": "a block can be in its own dom frontier",
    "text": "a block can be in its own dom frontier\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n\n\nwhy: A dom B, but B does not dom A. so A is in the dom frontier of A",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-almost-linear-method",
    "href": "lectures/06_ssa.html#an-almost-linear-method",
    "title": "Static Single Assignment",
    "section": "an almost linear method",
    "text": "an almost linear method\nWe do it in two steps.\n\ninsert phi-nodes:\nrename variables:",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#placing-phi-functions",
    "href": "lectures/06_ssa.html#placing-phi-functions",
    "title": "Static Single Assignment",
    "section": "placing Phi functions",
    "text": "placing Phi functions\nlet b be a block with a def of a variable v, if b has multiple defs of v, use the last one\nWhat is the first block following v that can be reached by a different def of v\nin blocks dominated by b, b’s def must have been executed, (other defs of v in a dominated block may overwrite it)\nwe need to place a phi function for b at the start of all blocks in the dom frontier of b.\nafter we add phi functions to S where S = df(b) we have more defs, so we need to add phi’s in the dom frontier of all the blocks in S",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#example-1",
    "href": "lectures/06_ssa.html#example-1",
    "title": "Static Single Assignment",
    "section": "example 1",
    "text": "example 1\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#a-loop",
    "href": "lectures/06_ssa.html#a-loop",
    "title": "Static Single Assignment",
    "section": "a loop",
    "text": "a loop\n::: {.columns}\n::: {.column}\n\ngraph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n graph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n::: {.column}\n\ngraph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n graph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n:::",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#iterative-placement",
    "href": "lectures/06_ssa.html#iterative-placement",
    "title": "Static Single Assignment",
    "section": "iterative placement",
    "text": "iterative placement\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-placement",
    "href": "lectures/06_ssa.html#phi-placement",
    "title": "Static Single Assignment",
    "section": "phi placement",
    "text": "phi placement\nfor each block b in the cfg \n  for each var v defined in b\n    add block to the set defs(v)  ## blocks that contain an assignment to v \n\n  W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[n]:  # Dominance frontier.\n           Add a phi-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v),\n             unless it's already in there.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-1",
    "href": "lectures/06_ssa.html#an-example-1",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n\n\n\n\ninitially w = {1,3,5,6}\nprocess DF(1) = empty\nprocess DF(3) = 4, add 4 to w and add a phi function for x to 4\nprocess DF(5) = 4,5 no need to add 5 to w, add phi for x to 5\nprocess DF(6) = 5\nprocess DF(4) = 4\n\n\n\nadd phi’s to blocks 4 and 5",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#rename-variables",
    "href": "lectures/06_ssa.html#rename-variables",
    "title": "Static Single Assignment",
    "section": "rename variables:",
    "text": "rename variables:\n# allocate a stack and a counter for each variable\nfor each V a variable \n  c[v] = 0\n  s[v] = empty stack\n  search(entry)\n\nsearch(n):\n  for each instr i in n:\n     if instr is not a phi\n         replace every variable in the rhs of instr by vi where i = top(s[v])\n         if instr has a dest v\n           i = C(v)\n            replace v by new vi, push i onto s[v]\n            increment c[v]\n\n  for each y a successor of n\n     j = which pred (y,n)\n     for each phi function pinstr in Y replace the jth opernmad of pinstr by vi where \n        i = top(s(v)\n  \n  for each Y a child of n in the dominator tree \n      call search(Y)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-2",
    "href": "lectures/06_ssa.html#an-example-2",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#what-is-the-dominator-tree",
    "href": "lectures/06_ssa.html#what-is-the-dominator-tree",
    "title": "Static Single Assignment",
    "section": "What is the dominator tree?",
    "text": "What is the dominator tree?\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#dominance-frontiers",
    "href": "lectures/06_ssa.html#dominance-frontiers",
    "title": "Static Single Assignment",
    "section": "dominance frontiers",
    "text": "dominance frontiers\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#add-phi-nodes",
    "href": "lectures/06_ssa.html#add-phi-nodes",
    "title": "Static Single Assignment",
    "section": "add phi nodes",
    "text": "add phi nodes\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#the-arity-of-phi-functions",
    "href": "lectures/06_ssa.html#the-arity-of-phi-functions",
    "title": "Static Single Assignment",
    "section": "The arity of phi-functions",
    "text": "The arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\ndoing dead code elimination pruned ssa form",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#getting-out-of-ssa",
    "href": "lectures/06_ssa.html#getting-out-of-ssa",
    "title": "Static Single Assignment",
    "section": "Getting out of ssa",
    "text": "Getting out of ssa\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-3",
    "href": "lectures/06_ssa.html#an-example-3",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n\n\n\nwe cannot put instructions on edges, but we can add to prev block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#critical-edges",
    "href": "lectures/06_ssa.html#critical-edges",
    "title": "Static Single Assignment",
    "section": "critical edges",
    "text": "critical edges\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\n\nb2 = b0?\n\n\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors. This should remind you of adding a preheader to a loop",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#critical-edge-splitting",
    "href": "lectures/06_ssa.html#critical-edge-splitting",
    "title": "Static Single Assignment",
    "section": "critical edge splitting",
    "text": "critical edge splitting\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#making-use-of-ssa-form",
    "href": "lectures/06_ssa.html#making-use-of-ssa-form",
    "title": "Static Single Assignment",
    "section": "making use of ssa form",
    "text": "making use of ssa form\nOur previous analyses always used a (variable, program point), but in ssa these are the same",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "href": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "title": "Static Single Assignment",
    "section": "dead code elimination in ssa",
    "text": "dead code elimination in ssa\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#sparse-constant-prop",
    "href": "lectures/06_ssa.html#sparse-constant-prop",
    "title": "Static Single Assignment",
    "section": "sparse constant prop",
    "text": "sparse constant prop\nwe define a partial order on constats, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is any\n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#what-order-do-we-process-nodes",
    "href": "lectures/06_ssa.html#what-order-do-we-process-nodes",
    "title": "Static Single Assignment",
    "section": "What order do we process nodes?",
    "text": "What order do we process nodes?\nbecause the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a1,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#walking-the-dominator-tree-b0---b1",
    "href": "lectures/06_ssa.html#walking-the-dominator-tree-b0---b1",
    "title": "Static Single Assignment",
    "section": "walking the dominator tree b0 -> b1",
    "text": "walking the dominator tree b0 -&gt; b1\n\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a0,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 -  1 (only one input defined)\nb0  - any\na2 -  2\nupdate the uses of a2 - the phi\na1 -  any \n\nupdate the uses of a1 \nno change",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#converting-from-ssa",
    "href": "lectures/06_ssa.html#converting-from-ssa",
    "title": "Static Single Assignment",
    "section": "Converting from SSA",
    "text": "Converting from SSA\nEventually, we need to convert out of SSA form to generate efficient code for real machines that don’t have phi-nodes and do have finite space for variable storage.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#basic-algorithm",
    "href": "lectures/06_ssa.html#basic-algorithm",
    "title": "Static Single Assignment",
    "section": "basic algorithm",
    "text": "basic algorithm\nThe basic algorithm is pretty straightforward. If you have a phi-node:\nv = phi .l1 x .l2 y;\nThen there must be assignments to x and y (recursively) preceding this statement in the CFG.\nThe paths from x to the phi-containing block and from y to the same block must “converge” at that block. So insert code into the phi-containing block’s immediate predecessors along each of those two paths: one that does v = id x and one that does v = id y. Then you can delete the phi instruction.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#extra-copies",
    "href": "lectures/06_ssa.html#extra-copies",
    "title": "Static Single Assignment",
    "section": "extra copies",
    "text": "extra copies\nThis basic approach can introduce some redundant copying. (Take a look at the code it generates after you implement it!) Non-SSA copy propagation optimization can work well as a post-processing step. For a more extensive take on how to translate out of SSA efficiently, see “Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#overlap",
    "href": "lectures/06_ssa.html#overlap",
    "title": "Static Single Assignment",
    "section": "overlap",
    "text": "overlap\nits possible that an optimization can give overlapping phi-functions\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1,x3)\ny2 = phi(y1, y3)\n  z = x2\n  x3 = y2\n  y3= z\n  if() go to b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#optimize-it",
    "href": "lectures/06_ssa.html#optimize-it",
    "title": "Static Single Assignment",
    "section": "optimize it",
    "text": "optimize it\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1, y2)\ny2 = phi(y1, x2)\n  if() go to b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#lost-the-temp-this-is-called-the-swap-problem",
    "href": "lectures/06_ssa.html#lost-the-temp-this-is-called-the-swap-problem",
    "title": "Static Single Assignment",
    "section": "lost the temp (this is called the swap problem)",
    "text": "lost the temp (this is called the swap problem)\nif we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nphi nodes execute all at once - not one at a time\nSome SSA slides from Todd Mowry at CMU",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#static-single-assignment-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#static-single-assignment-ssa",
    "title": "Static Single Assignment",
    "section": "Static single assignment (SSA)",
    "text": "Static single assignment (SSA)\nA variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#ssa",
    "title": "Static Single Assignment",
    "section": "ssa",
    "text": "ssa\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA means statically there is only a single assignment per variable."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#the-ssa-philosophy",
    "href": "lectures/revealjs_06_ssa.qmd.html#the-ssa-philosophy",
    "title": "Static Single Assignment",
    "section": "The SSA Philosophy",
    "text": "The SSA Philosophy\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 0 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#straight-line-code",
    "href": "lectures/revealjs_06_ssa.qmd.html#straight-line-code",
    "title": "Static Single Assignment",
    "section": "straight line code",
    "text": "straight line code\nWe call a program without branches a piece of straight line code.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\n\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#pseudo-code-for-one-basic-block",
    "href": "lectures/revealjs_06_ssa.qmd.html#pseudo-code-for-one-basic-block",
    "title": "Static Single Assignment",
    "section": "pseudo code for one basic block",
    "text": "pseudo code for one basic block\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B:\n        for each use of a argument x in S: \n            i = top(Stack[x]) \n            replace the use of x with x_i\n            \n        for each variable a that S defines (a dest)\n            count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with a_i\nWe don’t need the stack here but we will need it later."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes",
    "title": "Static Single Assignment",
    "section": "phi-Nodes",
    "text": "phi-Nodes\nJust renaming assignments will quickly run into problems. Consider this program:\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nWhich “version” of a should we use in the print statement?"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-1",
    "title": "Static Single Assignment",
    "section": "phi nodes",
    "text": "phi nodes\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a phi-node.\nphi-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-in-bril",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-in-bril",
    "title": "Static Single Assignment",
    "section": "phi nodes in Bril",
    "text": "phi nodes in Bril\nIn Bril, a phi-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#back-to-the-example",
    "href": "lectures/revealjs_06_ssa.qmd.html#back-to-the-example",
    "title": "Static Single Assignment",
    "section": "back to the example",
    "text": "back to the example\nYou can write the above program in SSA like this:\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\n\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#bril-in-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#bril-in-ssa",
    "title": "Static Single Assignment",
    "section": "Bril in SSA",
    "text": "Bril in SSA\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#converting-to-ssa---very-simple-scheme",
    "href": "lectures/revealjs_06_ssa.qmd.html#converting-to-ssa---very-simple-scheme",
    "title": "Static Single Assignment",
    "section": "Converting to SSA - Very simple scheme",
    "text": "Converting to SSA - Very simple scheme\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nWhere do we need phi-functions?\nWhich variables\n\nphi At the merge (join) node\nvariable b"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#conditions",
    "href": "lectures/revealjs_06_ssa.qmd.html#conditions",
    "title": "Static Single Assignment",
    "section": "conditions",
    "text": "conditions\nconditions: phi-function for variable b at node z\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#scheme-part-2",
    "href": "lectures/revealjs_06_ssa.qmd.html#scheme-part-2",
    "title": "Static Single Assignment",
    "section": "scheme part 2",
    "text": "scheme part 2\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#diagram",
    "href": "lectures/revealjs_06_ssa.qmd.html#diagram",
    "title": "Static Single Assignment",
    "section": "diagram",
    "text": "diagram\nusing dash for path\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d \n\n\n\n\n\n\nWe could have complex flow - including loops on the paths"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#reminder-dominators",
    "href": "lectures/revealjs_06_ssa.qmd.html#reminder-dominators",
    "title": "Static Single Assignment",
    "section": "reminder dominators",
    "text": "reminder dominators\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] ="
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#fast-methods-for-inserting-phis",
    "href": "lectures/revealjs_06_ssa.qmd.html#fast-methods-for-inserting-phis",
    "title": "Static Single Assignment",
    "section": "fast methods for inserting phi’s",
    "text": "fast methods for inserting phi’s\nThe method for this has two steps\n\ninsert phi instructions where needed (do not add subscripts yet)\nin a second pass insert all the numbers"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#to-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#to-ssa",
    "title": "Static Single Assignment",
    "section": "to ssa",
    "text": "to ssa\nTo convert to SSA, we want to insert phi-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need phi-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition?\nThe dominance frontier!"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#recall-the-dominance-frontier",
    "href": "lectures/revealjs_06_ssa.qmd.html#recall-the-dominance-frontier",
    "title": "Static Single Assignment",
    "section": "recall the dominance frontier",
    "text": "recall the dominance frontier\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n\n\n\n\n\n\nblock\nA\nB\nC\nD\nE\n\n\nfrontier\nempty\nF\nE\nE\nF"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#a-block-can-be-in-its-own-dom-frontier",
    "href": "lectures/revealjs_06_ssa.qmd.html#a-block-can-be-in-its-own-dom-frontier",
    "title": "Static Single Assignment",
    "section": "a block can be in its own dom frontier",
    "text": "a block can be in its own dom frontier\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n\n\nwhy: A dom B, but B does not dom A. so A is in the dom frontier of A"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-almost-linear-method",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-almost-linear-method",
    "title": "Static Single Assignment",
    "section": "an almost linear method",
    "text": "an almost linear method\nWe do it in two steps.\n\ninsert phi-nodes:\nrename variables:"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#placing-phi-functions",
    "href": "lectures/revealjs_06_ssa.qmd.html#placing-phi-functions",
    "title": "Static Single Assignment",
    "section": "placing Phi functions",
    "text": "placing Phi functions\nlet b be a block with a def of a variable v, if b has multiple defs of v, use the last one\nWhat is the first block following v that can be reached by a different def of v\nin blocks dominated by b, b’s def must have been executed, (other defs of v in a dominated block may overwrite it)\nwe need to place a phi function for b at the start of all blocks in the dom frontier of b.\nafter we add phi functions to S where S = df(b) we have more defs, so we need to add phi’s in the dom frontier of all the blocks in S"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#example-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#example-1",
    "title": "Static Single Assignment",
    "section": "example 1",
    "text": "example 1\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#a-loop",
    "href": "lectures/revealjs_06_ssa.qmd.html#a-loop",
    "title": "Static Single Assignment",
    "section": "a loop",
    "text": "a loop\n::: {.columns}\n::: {.column}\n\n\nCode\ngraph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n graph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n::: {.column}\n\n\nCode\ngraph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n graph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n:::"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#iterative-placement",
    "href": "lectures/revealjs_06_ssa.qmd.html#iterative-placement",
    "title": "Static Single Assignment",
    "section": "iterative placement",
    "text": "iterative placement\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-placement",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-placement",
    "title": "Static Single Assignment",
    "section": "phi placement",
    "text": "phi placement\nfor each block b in the cfg \n  for each var v defined in b\n    add block to the set defs(v)  ## blocks that contain an assignment to v \n\n  W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[n]:  # Dominance frontier.\n           Add a phi-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v),\n             unless it's already in there."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-1",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n\n\n\n\ninitially w = {1,3,5,6}\nprocess DF(1) = empty\nprocess DF(3) = 4, add 4 to w and add a phi function for x to 4\nprocess DF(5) = 4,5 no need to add 5 to w, add phi for x to 5\nprocess DF(6) = 5\nprocess DF(4) = 4\n\n\nadd phi’s to blocks 4 and 5"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#rename-variables",
    "href": "lectures/revealjs_06_ssa.qmd.html#rename-variables",
    "title": "Static Single Assignment",
    "section": "rename variables:",
    "text": "rename variables:\n# allocate a stack and a counter for each variable\nfor each V a variable \n  c[v] = 0\n  s[v] = empty stack\n  search(entry)\n\nsearch(n):\n  for each instr i in n:\n     if instr is not a phi\n         replace every variable in the rhs of instr by vi where i = top(s[v])\n         if instr has a dest v\n           i = C(v)\n            replace v by new vi, push i onto s[v]\n            increment c[v]\n\n  for each y a successor of n\n     j = which pred (y,n)\n     for each phi function pinstr in Y replace the jth opernmad of pinstr by vi where \n        i = top(s(v)\n  \n  for each Y a child of n in the dominator tree \n      call search(Y)"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-2",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-2",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#what-is-the-dominator-tree",
    "href": "lectures/revealjs_06_ssa.qmd.html#what-is-the-dominator-tree",
    "title": "Static Single Assignment",
    "section": "What is the dominator tree?",
    "text": "What is the dominator tree?\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#dominance-frontiers",
    "href": "lectures/revealjs_06_ssa.qmd.html#dominance-frontiers",
    "title": "Static Single Assignment",
    "section": "dominance frontiers",
    "text": "dominance frontiers\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#add-phi-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#add-phi-nodes",
    "title": "Static Single Assignment",
    "section": "add phi nodes",
    "text": "add phi nodes\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#the-arity-of-phi-functions",
    "href": "lectures/revealjs_06_ssa.qmd.html#the-arity-of-phi-functions",
    "title": "Static Single Assignment",
    "section": "The arity of phi-functions",
    "text": "The arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\ndoing dead code elimination pruned ssa form"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#getting-out-of-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#getting-out-of-ssa",
    "title": "Static Single Assignment",
    "section": "Getting out of ssa",
    "text": "Getting out of ssa\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-3",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-3",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n\n\nwe cannot put instructions on edges, but we can add to prev block"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#critical-edges",
    "href": "lectures/revealjs_06_ssa.qmd.html#critical-edges",
    "title": "Static Single Assignment",
    "section": "critical edges",
    "text": "critical edges\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\n\nb2 = b0?\n\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors. This should remind you of adding a preheader to a loop"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#critical-edge-splitting",
    "href": "lectures/revealjs_06_ssa.qmd.html#critical-edge-splitting",
    "title": "Static Single Assignment",
    "section": "critical edge splitting",
    "text": "critical edge splitting\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#making-use-of-ssa-form",
    "href": "lectures/revealjs_06_ssa.qmd.html#making-use-of-ssa-form",
    "title": "Static Single Assignment",
    "section": "making use of ssa form",
    "text": "making use of ssa form\nOur previous analyses always used a (variable, program point), but in ssa these are the same"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#dead-code-elimination-in-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#dead-code-elimination-in-ssa",
    "title": "Static Single Assignment",
    "section": "dead code elimination in ssa",
    "text": "dead code elimination in ssa\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#sparse-constant-prop",
    "href": "lectures/revealjs_06_ssa.qmd.html#sparse-constant-prop",
    "title": "Static Single Assignment",
    "section": "sparse constant prop",
    "text": "sparse constant prop\nwe define a partial order on constats, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is any\n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#what-order-do-we-process-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#what-order-do-we-process-nodes",
    "title": "Static Single Assignment",
    "section": "What order do we process nodes?",
    "text": "What order do we process nodes?\nbecause the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#walking-the-dominator-tree-b0---b1",
    "href": "lectures/revealjs_06_ssa.qmd.html#walking-the-dominator-tree-b0---b1",
    "title": "Static Single Assignment",
    "section": "walking the dominator tree b0 -> b1",
    "text": "walking the dominator tree b0 -&gt; b1\n\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a0,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 -  1 (only one input defined)\nb0  - any\na2 -  2\nupdate the uses of a2 - the phi\na1 -  any \n\nupdate the uses of a1 \nno change"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#converting-from-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#converting-from-ssa",
    "title": "Static Single Assignment",
    "section": "Converting from SSA",
    "text": "Converting from SSA\nEventually, we need to convert out of SSA form to generate efficient code for real machines that don’t have phi-nodes and do have finite space for variable storage."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#basic-algorithm",
    "href": "lectures/revealjs_06_ssa.qmd.html#basic-algorithm",
    "title": "Static Single Assignment",
    "section": "basic algorithm",
    "text": "basic algorithm\nThe basic algorithm is pretty straightforward. If you have a phi-node:\nv = phi .l1 x .l2 y;\nThen there must be assignments to x and y (recursively) preceding this statement in the CFG.\nThe paths from x to the phi-containing block and from y to the same block must “converge” at that block. So insert code into the phi-containing block’s immediate predecessors along each of those two paths: one that does v = id x and one that does v = id y. Then you can delete the phi instruction."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#extra-copies",
    "href": "lectures/revealjs_06_ssa.qmd.html#extra-copies",
    "title": "Static Single Assignment",
    "section": "extra copies",
    "text": "extra copies\nThis basic approach can introduce some redundant copying. (Take a look at the code it generates after you implement it!) Non-SSA copy propagation optimization can work well as a post-processing step. For a more extensive take on how to translate out of SSA efficiently, see “Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#overlap",
    "href": "lectures/revealjs_06_ssa.qmd.html#overlap",
    "title": "Static Single Assignment",
    "section": "overlap",
    "text": "overlap\nits possible that an optimization can give overlapping phi-functions\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1,x3)\ny2 = phi(y1, y3)\n  z = x2\n  x3 = y2\n  y3= z\n  if() go to b1"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#optimize-it",
    "href": "lectures/revealjs_06_ssa.qmd.html#optimize-it",
    "title": "Static Single Assignment",
    "section": "optimize it",
    "text": "optimize it\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1, y2)\ny2 = phi(y1, x2)\n  if() go to b1"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#lost-the-temp-this-is-called-the-swap-problem",
    "href": "lectures/revealjs_06_ssa.qmd.html#lost-the-temp-this-is-called-the-swap-problem",
    "title": "Static Single Assignment",
    "section": "lost the temp (this is called the swap problem)",
    "text": "lost the temp (this is called the swap problem)\nif we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nphi nodes execute all at once - not one at a time\nSome SSA slides from Todd Mowry at CMU"
  },
  {
    "objectID": "lectures/09_poly.html",
    "href": "lectures/09_poly.html",
    "title": "Polyhedral Analysis",
    "section": "",
    "text": "There are two kinds of polyhedral problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid?\npolyhedral scheduling - find a transform that maximizes/minimizes some property",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#intro-to-polyhedral-techniques",
    "href": "lectures/09_poly.html#intro-to-polyhedral-techniques",
    "title": "Polyhedral Analysis",
    "section": "",
    "text": "There are two kinds of polyhedral problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid?\npolyhedral scheduling - find a transform that maximizes/minimizes some property",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#base-idea",
    "href": "lectures/09_poly.html#base-idea",
    "title": "Polyhedral Analysis",
    "section": "Base Idea",
    "text": "Base Idea\nThe base ideas -\n\nA statement in a loop might execute a lot of times. Each time it executes there is one instance of the statement. Polyhedral methods keep track of instances.\nWe can think of a program as having two parts: An algorithm, like \\[ a[i] = 3, i \\in \\{1,2,3\\}\\] and a schedule like: execute the instances in reverse order.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#poly-steps",
    "href": "lectures/09_poly.html#poly-steps",
    "title": "Polyhedral Analysis",
    "section": "poly steps",
    "text": "poly steps\n\nchange the program into a polyhedral notations (a set like notation)\nApply some kind of transformations to add a schedule\nGenerate code that lets the result execute on a computer",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#polyhedral-methods",
    "href": "lectures/09_poly.html#polyhedral-methods",
    "title": "Polyhedral Analysis",
    "section": "Polyhedral Methods",
    "text": "Polyhedral Methods\n\nUse equations as an intermediate representation (IR)\nAllow reasoning about each instance\nEnsure finiteness (even if the number of instances is not)\nReduce phase ordering issues by applying multiple transformations simultaneously\nIdeal for tiling, parallelism, and cache management",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#negatives-of-polyhedral-analysis",
    "href": "lectures/09_poly.html#negatives-of-polyhedral-analysis",
    "title": "Polyhedral Analysis",
    "section": "Negatives of Polyhedral Analysis",
    "text": "Negatives of Polyhedral Analysis\n\nOnly applies to loop nests, but we can wrap a for (i= 0; i &lt;1; i++) around a group of statements\nRequires affine array indexes, bounds, and statements\nNot applicable to loops hidden by recursion",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#an-example-changing-the-order-of-iterations",
    "href": "lectures/09_poly.html#an-example-changing-the-order-of-iterations",
    "title": "Polyhedral Analysis",
    "section": "an example changing the order of iterations",
    "text": "an example changing the order of iterations\ncan we reverse this loop: (change the schedule so that i takes values 4,3,2,1). Does it get the same answer\nfor i = [1,2,3,4]\ns:   a[i] = a[i-1]\n\nDo these loops do the same thing\nfor i = [1,2,3,4]               for i = [4,3,2,1]\ns:   a[i] = a[i-1]               s:   a[i] = a[i-1] \n. . .\nprogram trace (instances)\n   s(1)                               s(4)\n   s(2)                               s(3)\n   s(3)                               s(2)\n   s(4)                               s(1)\nand the data that is accessed\n          reads  writes                       reads writes\n   s(1)    a[0]   a[1]               s(4)     a[3]   a[4]\n   s(2)    a[1]   a[2]               s(3)     a[2]   a[3]\n   s(3)    a[2]   a[3]               s(2)     a[1]   a[2]\n   s(4)    a[3]   a[4]               s(1)     a[0]   a[1]\n\nA transformation is valid (legal) if it preserves the dependence relations: producers have to execute before consumers\nit is not valid if there is a pair s[i] and s[j], s[i] produces a value s[j] reads that value, s[j] is first in the new schedule",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#a-graphical-view",
    "href": "lectures/09_poly.html#a-graphical-view",
    "title": "Polyhedral Analysis",
    "section": "a graphical view",
    "text": "a graphical view\n(not legal if there is a pair where the arrows go in opposite directions)\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  i_values.append(i)\n  j_values.append(1)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 3))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n    plt.annotate('',\n      xy=(i,1), xytext=(i-1,1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\nplt.annotate(\"time left schedule\", xy=(n, 1.02), xytext=(1,1.02), arrowprops=dict(facecolor='green', shrink=0.05))\n\nplt.annotate(\"time right schedule\", xy=(1, 1.04), xytext=(n-1,1.04), arrowprops=dict(facecolor='red', shrink=0.05))\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nThere are 3 pairs that make this invalid",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#a-second-example",
    "href": "lectures/09_poly.html#a-second-example",
    "title": "Polyhedral Analysis",
    "section": "a second example",
    "text": "a second example\nfor i in [1,2,3,4]\n  for j in [1,2,3,4]\n    a[i,j] = a[i,j-1]+ a[i-1,j]\ncan we execute this is parallel\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  for j in range(1, n + 1):\n    i_values.append(i)\n    j_values.append(j)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 4))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.ylabel('j loop index')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n  for j in range(2, n +1):\n    plt.annotate('',\n       xy=(i,j), xytext=(i-1,j),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\n    plt.annotate('',\n       xy=(i,j), xytext=(i,j-1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\n# plt.annotate(\"time left schedule\", xy=(n, 1.02), xytext=(1,1.02), arrowprops=dict(facecolor='green', shrink=0.05))\n\n# plt.annotate(\"time right schedule\", xy=(1, 1.04), xytext=(n-1,1.04), arrowprops=dict(facecolor='red', shrink=0.05))\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\noriginal code: time goes down each column\n. . .\nrun diagonal order and could tile the loops",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#definitions",
    "href": "lectures/09_poly.html#definitions",
    "title": "Polyhedral Analysis",
    "section": "definitions",
    "text": "definitions\nan affine function\n\\[\n\\text { affine function } f(\\vec{v})=M_{f} \\vec{v}+\\vec{f}_{0}\n\\]\nwhere \\(\\vec{v}=\\left(\\begin{array}{c}v_{1} \\\\ \\vdots \\\\ v_{d}\\end{array}\\right)\\) and \\(M_{f} \\in \\mathbb{R}^{k \\times d}\\) is a matrix with \\(k\\) rows and \\(d\\) columns, \\(f_{0} \\in \\mathbb{R}^{k}\\) is a \\(k\\)-dimensional vector. In all cases, we deal with affine functions with \\(M_{f} \\in \\mathbb{Z}^{k \\times d}\\) and \\(f_{0} \\in \\mathbb{Z}^{k}\\). The domain is also a set of integers: \\(\\vec{v} \\in \\mathbb{Z}^{d}\\).\nPerfect loop nest, Imperfect loop nest. A set of nested loops is called a perfect loop nest iff all statements appearing in the nest appear inside the body of the innermost loop. Otherwise, the loop nest is called an imperfect loop nest.\nAffine loop nest. Affine loop nests are sequences of imperfectly nested loops with loop bounds and array accesses that are affine functions of outer loop variables and program parameters.\nProgram parameters or structure parameters are symbolic constants that appear in loop bounds or access functions. They very often represent the problem size. \\(N\\) and beta are the program parameters.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA portion of the GEMVER kernel\nAffine spaces. A set of vectors is an affine space iff it is closed under affine combination, i.e., if \\(\\vec{x}, \\vec{y}\\) are in the space, all points lying on the line joining \\(\\vec{x}\\) and \\(\\vec{y}\\) belong to the space.\nAffine hyperplane An affine hyperplane is an \\(n-1\\) dimensional affine sub-space of an \\(n\\) dimensional space.\nIn our context, the set of all vectors \\(v \\in \\mathbb{Z}^{n}\\) such that \\(\\mathbf{h} . \\vec{v}=k\\), for \\(k \\in \\mathbb{Z}\\), forms an affine hyperplane. The set of parallel hyperplane instances correspond to different values of \\(k\\) with the row vector \\(\\mathbf{h}\\) normal to the hyperplane. Two vectors \\(\\overrightarrow{v_{1}}\\) and \\(\\overrightarrow{v_{2}}\\) lie in the same hyperplane if \\(\\mathbf{h} \\cdot \\overrightarrow{v_{1}}=\\mathbf{h} \\cdot \\overrightarrow{v_{2}}\\).\n\nAn affine hyperplane\nPolyhedron, Polytope. A polyhedron is an intersection of a finite number of half-spaces. A polytope is a bounded polyhedron.\nEach of the half-spaces provides a face to the polyhedron. Hence, the set of affine inequalities, each representing a face, can be used to compactly represent the polyhedron. If there are \\(m\\) inequalities, then the polyhedron is\n\\[\n\\left\\{\\vec{x} \\in \\mathbb{R}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\]\nwhere \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{R}^{m}\\).\n\nIn our context, we are always interested in the integer points inside a polyhedron since loop iterators typically have integer data types and traverse an integer space. The matrix \\(A\\) and \\(\\vec{b}\\) for problems we will deal with also comprise only integers. So, we always have:\n\\[\n\\begin{equation*}\n\\left\\{\\vec{x} \\in \\mathbb{Z}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\end{equation*}\n\\]\nwhere \\(A \\in \\mathbb{Z}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{Z}^{m}\\).\nIteration vector. The iteration vector of a statement is the vector consisting of values of the indices of all loops surrounding the statement.\nLet \\(S\\) be a statement of a program. The iteration vector is denoted by \\(\\vec{i}_{S}\\). An iteration vector represents a dynamic instance of a statement appearing in a loop nest that may be nested perfectly or imperfectly.\nDomain, Index set. The set of all iteration vectors for a given statement is the domain or the index set of the statement.\nA program comprises a sequence of statements, each statement surrounded by loops in a given order. We denote the domain of a statement \\(S\\) by \\(\\mathcal{D}^{S}\\). When the loop bounds and data accesses are affine functions of outer loop indices and other program parameters, and all conditionals are statically predictable, the domain of every statement is a polyhedron as defined in (. Again, conditionals that are affine functions of outer loop indices and program parameters are statically predictable.\nEach dynamic instance of a statement \\(S\\), in a program, is identified by its iteration vector \\(\\vec{i}_{S}\\) which contains values for the indices of the loops surrounding \\(S\\), from outermost to innermost. A statement \\(S\\) is associated with a polytope \\(\\mathcal{D}^{S}\\) of dimensionality \\(m_{S}\\). Each point in the polytope is an \\(m_{S}\\)-dimensional iteration vector.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\n\\[\n\\begin{aligned}\ni & \\geq 0 \\\\\nj & \\geq 0 \\\\\n-i+N-1 & \\geq 0 \\\\\n-j+N-1 & \\geq 0\n\\end{aligned} \\quad \\quad \\mathcal{D}^{S_{1}}:\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n-1 & 0 & 1 & -1 \\\\\n0 & -1 & 1 & -1\n\\end{array}\\right)\\left(\\begin{array}{c}\ni \\\\\nj \\\\\nN \\\\\n1\n\\end{array}\\right) \\geq 0\n\\]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#iteration-space-as-a-set-in-matrix-multiplication",
    "href": "lectures/09_poly.html#iteration-space-as-a-set-in-matrix-multiplication",
    "title": "Polyhedral Analysis",
    "section": "Iteration space as a set in matrix multiplication",
    "text": "Iteration space as a set in matrix multiplication\nfor (i =0 ;i &lt; M ; i++)\n for (j =0l j &lt; N; j++)\n   for (k= 0; k &lt; K, k++)\n     c[i,j] = c[i,j] + a[i,k]* B[k,j]\nIteration domain as a set:\n\\[ [M, N, K] -&gt; \\{ S[i, j, k] : 0 &lt;= i &lt; M \\and  0 &lt;= j &lt; N \\and 0 &lt;= k &lt; K; \\}\\]\n\\[ writes -&gt;  \\{ S[i, j, k] -&gt; C[i, j] \\}\\]\n\\[ reads := \\{S[i, j, k] -&gt; B[k, j], S[i, j, k] -&gt; A[i, k], S[i, j, k] -&gt; C[i, j] \\}\\]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#dependence",
    "href": "lectures/09_poly.html#dependence",
    "title": "Polyhedral Analysis",
    "section": "Dependence",
    "text": "Dependence\nTwo instances are dependent if they access the same location and one of them is a write.\ntrue dependence producer is a write, consumer is a read. Also called read after write to RAW, also called a flow dependence\nanti dependence write after read. WAR\n*output dependence both writes WAW",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#dependence-in-example",
    "href": "lectures/09_poly.html#dependence-in-example",
    "title": "Polyhedral Analysis",
    "section": "dependence in example",
    "text": "dependence in example\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor (k=0 ;k&lt;N; k++ )\n    for (l=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA[i,j] same location as A[l,k]\ni between 0 and N\nj between 0 and N\nk between 0 and N\nl between 0 and N\ni - l == 0\nj - k == 0\nDomain for statement S1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#loop-interchange-example",
    "href": "lectures/09_poly.html#loop-interchange-example",
    "title": "Polyhedral Analysis",
    "section": "loop interchange example",
    "text": "loop interchange example\nfor (i = 0, i &lt; 9; i++)\n  for (j = i; j &lt; 7 && j &lt; i+4; j++)\n     a[i,j] = \n\nThere is no dependence so we can reorder the loops but what are the new bounds\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Initialize the coordinates for the domain\ndomain_i = []\ndomain_j = []\n\n# Loop through the values as described in the pseudocode\nfor i in range(9):  # i = 0 to 8\n    for j in range(i, min(7, i + 4)):  # j starts from i, and is less than both 7 and i+4\n        domain_i.append(i)\n        domain_j.append(j)\n\n# Plot the domain points\nplt.scatter(domain_i, domain_j, color='blue', label='Domain Points')\n\n# Define the range for i and j for the hyperplanes\ni_values = np.arange(0, 9)\nj_values_i = i_values  # j = i\nj_values_7 = np.full_like(i_values, 7)  # j = 7\nj_values_i_plus_4 = i_values + 4  # j = i + 4\n\n# Plot the hyperplanes\nplt.plot(i_values, j_values_i, label='j = i', color='red')\nplt.plot(i_values, j_values_7, label='j = 7', color='green')\nplt.plot(i_values, j_values_i_plus_4, label='j = i + 4', color='orange')\n\n# Set plot properties\nplt.title('Domain of (i, j) with Hyperplanes')\nplt.xlabel('i')\nplt.ylabel('j')\nplt.grid(True)\nplt.xticks(range(9))\nplt.yticks(range(7))\nplt.gca().invert_yaxis()  # Invert y-axis to match matrix notation\nplt.legend()\nplt.show()",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#reodered-loops",
    "href": "lectures/09_poly.html#reodered-loops",
    "title": "Polyhedral Analysis",
    "section": "reodered loops",
    "text": "reodered loops\nfor (j = 0; j &lt;=6; j++)\n for (i = max(j-3,0); i &lt;= j; i++)\n   a[i,j] = 0\noutloop bounds cannot depend on i\ninner loop bounds can depend on j\nWe can read off j as a proection, for each value of j, i is a convex polygon (if the bounds were not convex this would be false)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#fourier-motzkin-method",
    "href": "lectures/09_poly.html#fourier-motzkin-method",
    "title": "Polyhedral Analysis",
    "section": "fourier-motzkin method",
    "text": "fourier-motzkin method\ninput:\n\nA convex polygon S on \\(x_1, x_2, ... x_n\\)\nA variable \\(X_m\\) to be eliminated\n\noutput: \\(S^1\\) a projection of S with out dimiension \\(m\\)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#alogorithm",
    "href": "lectures/09_poly.html#alogorithm",
    "title": "Polyhedral Analysis",
    "section": "alogorithm",
    "text": "alogorithm\n\\[ S = \\{ vec(x) | B vec(x) + vec(f) \\ge 0 \\}\\] \\[C\\] = constraints in S that involve \\(S_m\\) (coef is not zero)\n-=======================",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#how-much-of-a-limitation-is-affine-only",
    "href": "lectures/09_poly.html#how-much-of-a-limitation-is-affine-only",
    "title": "Polyhedral Analysis",
    "section": "How much of a limitation is affine only",
    "text": "How much of a limitation is affine only\n99% of hpc loops are affine C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam. Putting polyhedral loop transformations to work. In LCPC, 2003.\nover 95% of loops in deep learning are affine Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, RaminderBajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA). IEEE, 1–12.\n\nOver the course of this, I’ll use 3 pieces of math\n\nILP integer linear programming find a set of integers that satisfies a set of inequalities and maximize something\nfourier-motzkin method\nThe affine form of Farkas Lemma (maybe)\n\n\nHere is a graph showing the data flow \n\n::: {#cb405be1 .cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  i_values.append(i)\n  j_values.append(1)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 3))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n    plt.annotate('',\n      xy=(i,1), xytext=(i-1,1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n:::\n\nWe need to preserve order where an instance produces a value, some other instance consumes the value\nmore formally:\nThe order that statements execute is called a *schedule\neach s(i) is an instance of a single statement\ndata dependence is a mapping: \\(s(i) =&gt; s(i+1)\\)\na valid schedule does not violate data dependence\n\nobservation 1- same set of instances\nif we track each instance, we have more info but could run out of space\nwe need a more compressed ir format, polyhedral methods use sets and math",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#some-notation",
    "href": "lectures/09_poly.html#some-notation",
    "title": "Polyhedral Analysis",
    "section": "some notation",
    "text": "some notation\n\\[\n\\begin{align*}\ndomain &= \\left\\{ i \\in \\mathbf{Z}^1  \\mid 1 &lt;= i &lt;= 4\\right\\} \\\\\ninstances\\  of   \\ s &= \\left\\{ s(i) \\mid 1 &lt;=i &lt;= 4\\right\\}\n\\end{align*}\n\\]\nThe domain is the set of integer values of the loop index. left and right have the same domain\nWe call the order that instances execute the schedule The schedule is the ordering of instances. this is a map of instance to time.\n\nobservation 2- different schedules. instance -&gt; time\n\\[\n\\begin{align*}\nleft \\ schedule &= \\left\\{ s[i] \\rightarrow i \\right\\} \\\\\nright \\ schedule &= \\left\\{ s[i] \\rightarrow 5-i \\right\\}\n\\end{align*}\n\\]\ndata dependences (just the same as before but with bounds) \\[\ndependence = \\left \\{(s(i), s(i+1)) \\mid 1&lt;= i &lt;= 3 \\right \\}\n\\]\nNew schedule is legal, if it respects all data dependences, or set of violated data dependences is empty",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#what-is-a-violated-data-dependence",
    "href": "lectures/09_poly.html#what-is-a-violated-data-dependence",
    "title": "Polyhedral Analysis",
    "section": "what is a violated data dependence",
    "text": "what is a violated data dependence\na pair (p, c) where p produces data that c consumes and c comes before p in the new schedule\ndata dependence \\[\n\\left \\{(s(i), s(i+1)) \\mid 1 \\le i \\le 3 \\right \\}\n\\]\nset of violated data dependences \\[\n\\left \\{(s(i), s(j)) \\mid \\ newSch(j) \\ge newSch(i) \\right \\}\n\\]\n\nDependence is \\(s[i] -&gt; s[i+1]\\)\nset of violated data dependences \\[\n\\left \\{(s(i), s(j)) \\mid \\ newSch(j) \\ge newSch(i) \\right \\}\n\\]\n\\[\n\\left \\{ (s(i), s(i+1)) \\mid 1 \\le i \\le 3 \\land 5-i+1 \\ge 5-i  \\right \\}\n\\]\nconstrants are : \\[\n\\begin{align*}\n1&lt;= i &lt;= 3 \\\\\n5-i +1  &gt;= 5-i\n\\end{align*}\n\\]\n\nUse an ilp solver to find a solution one solution is i = 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#ilp-solver-info",
    "href": "lectures/09_poly.html#ilp-solver-info",
    "title": "Polyhedral Analysis",
    "section": "ilp solver info",
    "text": "ilp solver info\ncan an ilp solver always work?\nHilbert’s tenth problem is the tenth on the list of mathematical problems that the German mathematician David Hilbert posed in 1900. It is the challenge to provide a general algorithm that, for any given Diophantine equation (a polynomial equation with integer coefficients and a finite number of unknowns), can decide whether the equation has a solution with all unknowns taking integer values.\nsadly answer is no (found in 1970)\nBut we can do this if we limit the kinds of inequalities",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#affine-limitations",
    "href": "lectures/09_poly.html#affine-limitations",
    "title": "Polyhedral Analysis",
    "section": "Affine limitations",
    "text": "Affine limitations\naffine functions, no multiplying unknowns, no quantifiers (for all, or exists) and is ok, or ok (if we change to two problems) just add/subtract/ multiply by a constant, can add minimize/maximize a function. division and remainder by a constant, max/min/ absolute\nMost scientific programs and ai programs fit, because array subscripts are often affine\nBut lots of other kinds of programs do not.\nThere is a lot of formal math background here, decidability in logic.\n\nilp is np-complete so it is slow, but often tractable for problems with up to several hundred variables.\nSome compiler writers feel that means can only do this for toy programs? What do you think?\n\n2 multiple dimensions\nfor (i=1; i&lt;=n; i++)\nfor (j=1; j&lt;=n; j++)\nS: A[i][j] = (A[i-1][j] + A[i][j-1]) * 0.5;\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # You can change n to any desired value\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n    for j in range(1, n + 1):\n        i_values.append(i)\n        j_values.append(j)\n\n# Plotting the iteration space\nplt.figure(figsize=(5, 5))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i (outer loop index)')\nplt.ylabel('j (inner loop index)')\nplt.title('Data Dependence for A[i][j] = (A[i-1][j] + A[i][j-1]) * 0.5')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\n# Annotate the iteration order and add arrows for data dependencies\nfor i in range(1, n + 1):\n    for j in range(1, n + 1):\n        if i &gt; 1:  # Dependency on A[i-1][j]\n            plt.annotate('',\n                         xy=(i, j), xytext=(i-1, j),\n                         arrowprops=dict(facecolor='black', shrink=0.05))\n        if j &gt; 1:  # Dependency on A[i][j-1]\n            plt.annotate('',\n                         xy=(i, j), xytext=(i, j-1),\n                         arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Force the x-axis to use integer labels and remove y-axis labels\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])  # Turn off y-axis labels\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nThe schedule actually goes up each column (the j values) going over the columns left to right (the i column)\nnotice that this does not execute in parallel, but it could if pick a different schedule\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.ticker as ticker\n\nplt.figure(figsize=(8, 8))\ntile_size = 1\n\n# # Define parameters\n# n = 12 # Size of the matrix\n# tile_size = 2  # Size of the tile\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Calculate iteration points for tiles\nfor t in range(8):\n  for p in range(8):\n    i = p + t\n    j = p\n    if i &gt;= 8:\n      continue\n    if (i &gt;= 0 and  j &gt;= 0) :\n      i_values.append(i)\n      j_values.append(j)\n      if i &lt;= j:\n        continue\n      if ((t % 2) == 0) and (p % 2 ) == 0:\n          plt.gca().add_patch(   \\\n          patches.Rectangle((t,p), tile_size, tile_size,  \\\n                              linewidth=1, edgecolor='red', facecolor='none'))\n#         for i in range(ti, min(ti + tile_size, n + 1)):\n#             for j in range(tj, min(tj + tile_size, n + 1)):\n#                 if (i &gt; 1 and  j &gt; 1) :\n#                   i_values.append(i)\n#                   j_values.append(j)\n\n# # Plotting the iteration space\n\nplt.scatter(i_values, j_values, c='blue', marker='o', label='Iterations')\nplt.xlabel('i')\nplt.ylabel('j')\nplt.title('Iteration Space with Tiling and Dependencies')\n# plt.grid(True)\n#lt.gca().invert_yaxis()\n\n# # Draw a box around each tile\n# for ti in range(1, n + 1, tile_size):\n#     for tj in range(1, n + 1, tile_size):\n#         plt.gca().add_patch(\n#             patches.Rectangle((ti, tj), tile_size, tile_size,\n#                                linewidth=1, edgecolor='red', facecolor='none')\n#         )\n\n# # Draw dependencies\n# for i in range(1, n + 1):\n#     for j in range(1, n + 1):\n#         if i &gt; 1:  # Dependency on A[i-1][j]\n#             plt.annotate('',\n#                          xy=(i, j), xytext=(i-1, j),\n#                          arrowprops=dict(facecolor='black', shrink=0.05))\n#         if j &gt; 1:  # Dependency on A[i][j-1]\n#             plt.annotate('',\n#                          xy=(i, j), xytext=(i, j-1),\n#                          arrowprops=dict(facecolor='red', shrink=0.05))\n\n# # Force the x-axis and y-axis to use integer labels\n# plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n# plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n\n# # Show the plot\n# plt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nt p i j 0 0 0 0 1 0 1 0 1 1 0 1 t-p p 2 1 1 1 2 2 0 2\n\n## formalizing the schedule, Lexicographic ordering\n\nschedule s(i,j) -&gt; (i,j)\nstatements -&gt; vector (should be a time)\n\nHow do we interpret a vector as a time, e.g. hours, min, seconds. \n\nUsually written  as $\\gg $ Generalization of alphabetical order\n\n$$\n(i,j) \\gg (m,n) \\iff i &gt;  m \\lor (i=m \\land j&gt; n)\n$$\n\nCompare left to right if terms are equal, go to next term, or different so compare the terms\n\nNotice the or we will need to call the ilp solver more than once \n\nChecking for loop interchange \n\nfor i in [1,2,3,4] for j in [1,2,3] for j in [1,2,3] for i in [1,2,3,4] s: a(i,j) = a(i-1,j+1) a(i,j) = a(i-1,j+1)\ns(i, j) -&gt; (i,j) s(i,j)=(j,i)\n\ndata flow \n\n\n        read write\ns(1,1)  a(0,2)  a(1,1)\ns(1,2)  a(0,3)  a(1,2)\ns(1,3)  a(0,4)  a(1,3)\ns(1,4)  a(0,5)  a(1,4)\ns(2,1)  a(1,2)  a(2,1)   s(1,2)-&gt; s(2,1)\ns(2,2)  a(1,3)  a(2,2)   s(1,3)-&gt; s(2.2)\n...\n\ns(i,j) writes a value that is consumed in s(i+1, j-1)\n\n\n$$\ns(i,j) \\rightarrow s(i+1, j-1)\n$$\nconstants:\n\nDoes there exist a statement s(i,j) and a statement $s(i',j')$\nwhere in the new schedule $s(i',j')$ executes first and  data flows backward in time \n$$\n\\begin{align*}\n(i', j') \\gg (j,i)   &\\text{ $i',j'$ is first} \\\\\ni' = 1+ i            &\\text{ data\\  from \\ i+1 to $i'$}\\\\\nj' = -1 +j           &\\text{ data\\  from \\ j-1 to $j'$}\\\\\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 3  \\\\\n1 \\le i' le 4 \\\\\n1 \\le j' \\leftrightarrows 3\n\\end{align*}\n$$\n\nbecause of the lexicographic order ( or) we have two ilp problems\none where $i'$ is greater then j, and one where $i'$ = j, and the other where $j'$ &gt; j\n\ni ran it through:\n\nhttps://online-optimizer.appspot.com\n\nwhich gave me a solution \n\ns(4,2) reads  s(3,3) but s(4,2) executes first \n\n## ir\n\nHow do we represent these sets in the  ir?\n\n~~~\nfor i in [0,1,2,3,4,5]\n  for j from  i to 7\n     a(i,j) = 0\n\n~~~\n\nchange the equations around so that they are ... $\\ge 0$\n\n$$\n\\begin{align*}\ni \\ge 0  &\\rightarrow  i \\ge 0 \\\\\ni \\le 5 &\\rightarrow -i + 5 \\ge 0 \\\\\nj \\ge i &\\rightarrow -i + j \\ge 0 \\\\\nj \\le 7 &\\rightarrow =j+7 \\ge 0\n\\end{align*}\n$$\n\n\nWe can split off the constraints:\n$$\nconstraints  = \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\} \n$$\n\nWhere:\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0 \\\\\n 5  \\\\\n 0   \\\\\n7\n\\end{bmatrix}\n\\vec{x} =\n\\begin{bmatrix}\ni \\\\\nj \n\\end{bmatrix}\n\\end{equation*}\n$$\n\nThis also works if the loop bounds are symbolic\nfor i in [L.. U] for j from i to 7 a(i,j) = 0\n\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n L \\\\\n U\\\\\n0\\\\\n7\n\\end{bmatrix}\n\\end{equation*}\n$$\n\n\n## suppose we have complex loop bounds?\n\nfor i=0; i &lt; 7, i++ for j =i, j &lt; min(7, i+4), j++ a(i,j) = 0\n![alt text](plot1-7.png)\n\nshaded area is the polygon\nwhat are the loop bounds if we interchange the loops?\n\nWhat are the upper and lower bounds if we interchange the loops?\n\ninequalities\n$$\n\\begin{align*}\ni \\ge 0   & \\rightarrow  i  \\ge 0 \\\\\ni \\le 6   & \\rightarrow  -i+6 \\ge 0 \\\\\nj \\ge i   & \\rightarrow j-i \\ge 0 \\\\\nj \\le 6    & \\rightarrow  6  -j  \\ge 0 \\\\\nj \\le i+3 & \\rightarrow -j+i+3 \\ge 0 \n\\end{align*}\n$$\n\nfor j (must be constants) for j (constants and j )\n\nwe can get the j bounds by projecting onto the j axis,  next we want to remove j from the inequalities \n\n\nir constants\n\n\n\n\n\n$$\n\\begin{align*}\n\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n 1 & 0 \\\\\n-1 & 0 \\\\\n-1 & 1 \\\\\n0 & -1 \\\\\n 1 & -1 \n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0\\\\\n 6 \\\\\n0\\\\\n6\\\\\n3\n\\end{bmatrix}\n\n\n\\end{align*}\n$$\n\n\nwritten for i\n$$\n\\begin{align}\n0  \\le  & i & \\\\\n        & i &\\le 6 \\\\\n        & i & \\le j \\\\\n        & &  6  -j  \\ge 0 \\\\\nj -3 \\le & i &\n\\end{align}\n$$\n\n$ i \\le max(0, j-3) \\land  i \\le min(6,j) $\n\nwritten for j\n$$\n\\begin{align}\n       & & i \\ge 0 \\\\\n       & & i \\le 6  \\\\\ni \\le  &j & \\\\\n    &  j  & \\le 6 \\\\\n&j& \\le i+3 \n\\end{align}\n$$\n\n\nbounds for j depend on i -  We need to remove i \n\n\nmath thing #2 fourier-motzkin method\n\nhttps://people.math.carleton.ca/~kcheung/math/notes/MATH5801/02/2_1_fourier_motzkin.html\n\nGiven a set of inequalities remove one variable, (for higher dim d, need to do this multiple times)\n\nin general \nSuppose we want to remove $x_m$ we find a pair $L \\le c_1 * x_m $  and  upper bound $x_2 * x_m \\ge U$ and both c's are &gt;= 0\n\nremove x_m and add $c_2* L \\ge c_1 *U $\n\nWe start with each pair of constants\n$$\nc_1 * i &lt; U \\land\nc_2 *i &gt; L\n$$\n\nthere are 4 pairs (1,2), (1,3) , (2,5),  (3,5) \nall the c's are 1 \nfrom the ir column 1 (i column) ignore zeros, pair up plus and minus values \n\n\nWe need to eliminate i (to get the bounds for the outer loop in j)\n\nwe have 4 inequalities where i is not multiplied by zero $ j \\le 6$ \n\nwe consider each pair\n\n$$\n\\begin{align*}\n(1,2) \\rightarrow  0 &\\le 6 \\ done \\\\\n(1,3) \\rightarrow  0 &\\le j\\\\\n(2,5) \\rightarrow j-3  &\\le 6\\\\\n(3,5) \\rightarrow j-3  &\\le j \\ done \n\\end{align*}\n$$\n\nbounds for j are 0 to 6\n\n\nfor j =0 ; j &lt;= 6 , j++ for i = max(j-3,6), i &lt; j; i++&gt;\na[i,j] = 0\n\n\n## suppose we want to run the an example  in parallel\n~~~\nfor i in [1,2,3,4]\n  for j in [1,2,3, 4]\n    s: a(i,j) = a(i-1, j+1) \n~~~\n\n\n\nreorder to run in parallel get new bounds, we want to run diagonally $k= i-j$, we know the transformation that we want \nWe replace $i = k+j $\n\nfor k = ??\n   for j = ?? \n     s: a(j-k,j) = a(j-k-1, j+1)\n\n\n$$\n\\begin{align*}\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 4 \\\\\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n1 \\le & k+j &\\le 4 \\\\\n1 \\le & j &\\le 4 \\\\\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n1-k \\le j \\le 4-k \\\\\n1 \\le j &lt;= 4\n\\end{align*}\n$$\n\nnow for mf\n$$\n\\begin{align*}\n1-k \\le  4-k \\\\\n1-k  \\le 4\\\\\n1 \\le 4-k \\\\\n1 \\le 4\n\\end{align*}\n$$\n\ngiving k bounds -3 to 3 \nj bound are max(1,1,k) yo min(4, 4-k)\n\n\n#  4 Scheduling \n\nUp till now we assumed we know the transformation but now we consider \ncan we find a schedule that is good in some way\n\nan example \nfor i in [0,1,2,3,4,5] P: a(i) = input(i) +1 for j in [0,12,3,4,5] c: b(j) = a(j) +2\n\nThis is not quite a loop nest - unless we picture an outer loop running one time.\n\n\n\nThe new schedule has to be affine (restriction)\nschedule is a map from instances to time \n$$\nP(i) = sp*i + dp \\\\ \nC(j) = sc*j + dc \n$$\n\noptimization pick sp, dp, sc, dc that optimizes the locality.\n\n\nconstraint is for all i,j, p(i) writes data that c(j) reads, and i,j are in bounds\n\n\nFor any legal schedule:\n\n\n$$\n\\forall i,j \\mid 0 \\le i \\le 5 \\land 0 \\le j \\le 5 \\land i = j \n\\land sp * i + dp  \\le sc * j + dc\n$$\n\n\ndifferent values of sp, dp, sc, and dc give different schedules.  \nSince all these schedules are affine - None on them is the \"best\".\nSome non-affine schedule might be better.\n\nThis is not suitable for ilp, because of the  $ sp * i $\n\nSuppose we want to select one of the schedules that minimizes a cost function:\n$$\nw(i,j)  = sc * j + dc - sp * i + dp \n$$\n\nw is the time the value is needed\n\nHow we select a legal schedule that has the smallest w?\n\n\n\nmath fact 3 \n\nThe affine form of Farkas Lemma\nAn affine function non-negative everywhere inside a polygon \niff its non-negative at all the vertices \n\n$$\ngiven: \n\\forall \\vec{x} \\mid \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\} \nS^T \\vec{x}+\\vec{d} \\ge 0\n$$\nif and only if \n$$\n\\exists p_0, \\vec{p} \\ge 0 \\mid \\forall \\vec{x}\\mid S^T \\vec{x} + \\vec{d} = (\\vec{p})^t(B\\vec{x}+\\vec{d}) + p_0\n$$\n\nWhat does this mean and how does it help?\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Arc\n\nfig, ax = plt.subplots(figsize=(5,5))\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n    i_values.append(i)\n    j_values.append(1)\n\n    arc = Arc(xy=(i+.5, 1), width=1, height=1, angle=0, theta1=0, theta2=180, color='red', lw=2)\n    ax.add_patch(arc)\n\nax.set_ylim(0,2)\n\n# Plotting the iteration space\n\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i (outer loop index)')\nplt.ylabel('j (inner loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\n# # Annotate the iteration order and add arrows for data flow\n# for i in range(1, n + 1):\n#     for j in range(2, m + 1):  # Start from j=2 since j-1 needs to exist\n#         plt.annotate('',\n#                      xy=(i, j), xytext=(i, j-1),\n#                      arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#intro-to-polyhedral-techniques",
    "href": "lectures/revealjs_09_poly.qmd.html#intro-to-polyhedral-techniques",
    "title": "Polyhedral Analysis",
    "section": "intro to polyhedral techniques",
    "text": "intro to polyhedral techniques\nThere are two kinds of polyhedral problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid?\npolyhedral scheduling - find a transform that maximizes/minimizes some property"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#base-idea",
    "href": "lectures/revealjs_09_poly.qmd.html#base-idea",
    "title": "Polyhedral Analysis",
    "section": "Base Idea",
    "text": "Base Idea\nThe base ideas -\n\nA statement in a loop might execute a lot of times. Each time it executes there is one instance of the statement. Polyhedral methods keep track of instances.\nWe can think of a program as having two parts: An algorithm, like \\[ a[i] = 3, i \\in \\{1,2,3\\}\\] and a schedule like: execute the instances in reverse order."
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#poly-steps",
    "href": "lectures/revealjs_09_poly.qmd.html#poly-steps",
    "title": "Polyhedral Analysis",
    "section": "poly steps",
    "text": "poly steps\n\nchange the program into a polyhedral notations (a set like notation)\nApply some kind of transformations to add a schedule\nGenerate code that lets the result execute on a computer"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#polyhedral-methods",
    "href": "lectures/revealjs_09_poly.qmd.html#polyhedral-methods",
    "title": "Polyhedral Analysis",
    "section": "Polyhedral Methods",
    "text": "Polyhedral Methods\n\nUse equations as an intermediate representation (IR)\nAllow reasoning about each instance\nEnsure finiteness (even if the number of instances is not)\nReduce phase ordering issues by applying multiple transformations simultaneously\nIdeal for tiling, parallelism, and cache management"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#negatives-of-polyhedral-analysis",
    "href": "lectures/revealjs_09_poly.qmd.html#negatives-of-polyhedral-analysis",
    "title": "Polyhedral Analysis",
    "section": "Negatives of Polyhedral Analysis",
    "text": "Negatives of Polyhedral Analysis\n\nOnly applies to loop nests, but we can wrap a for (i= 0; i &lt;1; i++) around a group of statements\nRequires affine array indexes, bounds, and statements\nNot applicable to loops hidden by recursion"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#an-example-changing-the-order-of-iterations",
    "href": "lectures/revealjs_09_poly.qmd.html#an-example-changing-the-order-of-iterations",
    "title": "Polyhedral Analysis",
    "section": "an example changing the order of iterations",
    "text": "an example changing the order of iterations\ncan we reverse this loop: (change the schedule so that i takes values 4,3,2,1). Does it get the same answer\nfor i = [1,2,3,4]\ns:   a[i] = a[i-1]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#a-graphical-view",
    "href": "lectures/revealjs_09_poly.qmd.html#a-graphical-view",
    "title": "Polyhedral Analysis",
    "section": "a graphical view",
    "text": "a graphical view\n(not legal if there is a pair where the arrows go in opposite directions)\n\n\nCode\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  i_values.append(i)\n  j_values.append(1)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 3))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n    plt.annotate('',\n      xy=(i,1), xytext=(i-1,1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\nplt.annotate(\"time left schedule\", xy=(n, 1.02), xytext=(1,1.02), arrowprops=dict(facecolor='green', shrink=0.05))\n\nplt.annotate(\"time right schedule\", xy=(1, 1.04), xytext=(n-1,1.04), arrowprops=dict(facecolor='red', shrink=0.05))\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nThere are 3 pairs that make this invalid"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#a-second-example",
    "href": "lectures/revealjs_09_poly.qmd.html#a-second-example",
    "title": "Polyhedral Analysis",
    "section": "a second example",
    "text": "a second example\nfor i in [1,2,3,4]\n  for j in [1,2,3,4]\n    a[i,j] = a[i,j-1]+ a[i-1,j]\ncan we execute this is parallel"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#definitions",
    "href": "lectures/revealjs_09_poly.qmd.html#definitions",
    "title": "Polyhedral Analysis",
    "section": "definitions",
    "text": "definitions\nan affine function\n\\[\n\\text { affine function } f(\\vec{v})=M_{f} \\vec{v}+\\vec{f}_{0}\n\\]\nwhere \\(\\vec{v}=\\left(\\begin{array}{c}v_{1} \\\\ \\vdots \\\\ v_{d}\\end{array}\\right)\\) and \\(M_{f} \\in \\mathbb{R}^{k \\times d}\\) is a matrix with \\(k\\) rows and \\(d\\) columns, \\(f_{0} \\in \\mathbb{R}^{k}\\) is a \\(k\\)-dimensional vector. In all cases, we deal with affine functions with \\(M_{f} \\in \\mathbb{Z}^{k \\times d}\\) and \\(f_{0} \\in \\mathbb{Z}^{k}\\). The domain is also a set of integers: \\(\\vec{v} \\in \\mathbb{Z}^{d}\\).\nPerfect loop nest, Imperfect loop nest. A set of nested loops is called a perfect loop nest iff all statements appearing in the nest appear inside the body of the innermost loop. Otherwise, the loop nest is called an imperfect loop nest.\nAffine loop nest. Affine loop nests are sequences of imperfectly nested loops with loop bounds and array accesses that are affine functions of outer loop variables and program parameters.\nProgram parameters or structure parameters are symbolic constants that appear in loop bounds or access functions. They very often represent the problem size. \\(N\\) and beta are the program parameters.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA portion of the GEMVER kernel\nAffine spaces. A set of vectors is an affine space iff it is closed under affine combination, i.e., if \\(\\vec{x}, \\vec{y}\\) are in the space, all points lying on the line joining \\(\\vec{x}\\) and \\(\\vec{y}\\) belong to the space.\nAffine hyperplane An affine hyperplane is an \\(n-1\\) dimensional affine sub-space of an \\(n\\) dimensional space.\nIn our context, the set of all vectors \\(v \\in \\mathbb{Z}^{n}\\) such that \\(\\mathbf{h} . \\vec{v}=k\\), for \\(k \\in \\mathbb{Z}\\), forms an affine hyperplane. The set of parallel hyperplane instances correspond to different values of \\(k\\) with the row vector \\(\\mathbf{h}\\) normal to the hyperplane. Two vectors \\(\\overrightarrow{v_{1}}\\) and \\(\\overrightarrow{v_{2}}\\) lie in the same hyperplane if \\(\\mathbf{h} \\cdot \\overrightarrow{v_{1}}=\\mathbf{h} \\cdot \\overrightarrow{v_{2}}\\).\n\nAn affine hyperplane\nPolyhedron, Polytope. A polyhedron is an intersection of a finite number of half-spaces. A polytope is a bounded polyhedron.\nEach of the half-spaces provides a face to the polyhedron. Hence, the set of affine inequalities, each representing a face, can be used to compactly represent the polyhedron. If there are \\(m\\) inequalities, then the polyhedron is\n\\[\n\\left\\{\\vec{x} \\in \\mathbb{R}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\]\nwhere \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{R}^{m}\\).\n\nIn our context, we are always interested in the integer points inside a polyhedron since loop iterators typically have integer data types and traverse an integer space. The matrix \\(A\\) and \\(\\vec{b}\\) for problems we will deal with also comprise only integers. So, we always have:\n\\[\n\\begin{equation*}\n\\left\\{\\vec{x} \\in \\mathbb{Z}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\end{equation*}\n\\]\nwhere \\(A \\in \\mathbb{Z}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{Z}^{m}\\).\nIteration vector. The iteration vector of a statement is the vector consisting of values of the indices of all loops surrounding the statement.\nLet \\(S\\) be a statement of a program. The iteration vector is denoted by \\(\\vec{i}_{S}\\). An iteration vector represents a dynamic instance of a statement appearing in a loop nest that may be nested perfectly or imperfectly.\nDomain, Index set. The set of all iteration vectors for a given statement is the domain or the index set of the statement.\nA program comprises a sequence of statements, each statement surrounded by loops in a given order. We denote the domain of a statement \\(S\\) by \\(\\mathcal{D}^{S}\\). When the loop bounds and data accesses are affine functions of outer loop indices and other program parameters, and all conditionals are statically predictable, the domain of every statement is a polyhedron as defined in (. Again, conditionals that are affine functions of outer loop indices and program parameters are statically predictable.\nEach dynamic instance of a statement \\(S\\), in a program, is identified by its iteration vector \\(\\vec{i}_{S}\\) which contains values for the indices of the loops surrounding \\(S\\), from outermost to innermost. A statement \\(S\\) is associated with a polytope \\(\\mathcal{D}^{S}\\) of dimensionality \\(m_{S}\\). Each point in the polytope is an \\(m_{S}\\)-dimensional iteration vector.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\n\\[\n\\begin{aligned}\ni & \\geq 0 \\\\\nj & \\geq 0 \\\\\n-i+N-1 & \\geq 0 \\\\\n-j+N-1 & \\geq 0\n\\end{aligned} \\quad \\quad \\mathcal{D}^{S_{1}}:\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n-1 & 0 & 1 & -1 \\\\\n0 & -1 & 1 & -1\n\\end{array}\\right)\\left(\\begin{array}{c}\ni \\\\\nj \\\\\nN \\\\\n1\n\\end{array}\\right) \\geq 0\n\\]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#iteration-space-as-a-set-in-matrix-multiplication",
    "href": "lectures/revealjs_09_poly.qmd.html#iteration-space-as-a-set-in-matrix-multiplication",
    "title": "Polyhedral Analysis",
    "section": "Iteration space as a set in matrix multiplication",
    "text": "Iteration space as a set in matrix multiplication\nfor (i =0 ;i &lt; M ; i++)\n for (j =0l j &lt; N; j++)\n   for (k= 0; k &lt; K, k++)\n     c[i,j] = c[i,j] + a[i,k]* B[k,j]\nIteration domain as a set:\n\\[ [M, N, K] -&gt; \\{ S[i, j, k] : 0 &lt;= i &lt; M \\and  0 &lt;= j &lt; N \\and 0 &lt;= k &lt; K; \\}\\]\n\\[ writes -&gt;  \\{ S[i, j, k] -&gt; C[i, j] \\}\\]\n\\[ reads := \\{S[i, j, k] -&gt; B[k, j], S[i, j, k] -&gt; A[i, k], S[i, j, k] -&gt; C[i, j] \\}\\]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#dependence",
    "href": "lectures/revealjs_09_poly.qmd.html#dependence",
    "title": "Polyhedral Analysis",
    "section": "Dependence",
    "text": "Dependence\nTwo instances are dependent if they access the same location and one of them is a write.\ntrue dependence producer is a write, consumer is a read. Also called read after write to RAW, also called a flow dependence\nanti dependence write after read. WAR\n*output dependence both writes WAW"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#dependence-in-example",
    "href": "lectures/revealjs_09_poly.qmd.html#dependence-in-example",
    "title": "Polyhedral Analysis",
    "section": "dependence in example",
    "text": "dependence in example\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor (k=0 ;k&lt;N; k++ )\n    for (l=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA[i,j] same location as A[l,k]\ni between 0 and N\nj between 0 and N\nk between 0 and N\nl between 0 and N\ni - l == 0\nj - k == 0\nDomain for statement S1"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#loop-interchange-example",
    "href": "lectures/revealjs_09_poly.qmd.html#loop-interchange-example",
    "title": "Polyhedral Analysis",
    "section": "loop interchange example",
    "text": "loop interchange example\nfor (i = 0, i &lt; 9; i++)\n  for (j = i; j &lt; 7 && j &lt; i+4; j++)\n     a[i,j] = \n\nThere is no dependence so we can reorder the loops but what are the new bounds\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Initialize the coordinates for the domain\ndomain_i = []\ndomain_j = []\n\n# Loop through the values as described in the pseudocode\nfor i in range(9):  # i = 0 to 8\n    for j in range(i, min(7, i + 4)):  # j starts from i, and is less than both 7 and i+4\n        domain_i.append(i)\n        domain_j.append(j)\n\n# Plot the domain points\nplt.scatter(domain_i, domain_j, color='blue', label='Domain Points')\n\n# Define the range for i and j for the hyperplanes\ni_values = np.arange(0, 9)\nj_values_i = i_values  # j = i\nj_values_7 = np.full_like(i_values, 7)  # j = 7\nj_values_i_plus_4 = i_values + 4  # j = i + 4\n\n# Plot the hyperplanes\nplt.plot(i_values, j_values_i, label='j = i', color='red')\nplt.plot(i_values, j_values_7, label='j = 7', color='green')\nplt.plot(i_values, j_values_i_plus_4, label='j = i + 4', color='orange')\n\n# Set plot properties\nplt.title('Domain of (i, j) with Hyperplanes')\nplt.xlabel('i')\nplt.ylabel('j')\nplt.grid(True)\nplt.xticks(range(9))\nplt.yticks(range(7))\nplt.gca().invert_yaxis()  # Invert y-axis to match matrix notation\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#reodered-loops",
    "href": "lectures/revealjs_09_poly.qmd.html#reodered-loops",
    "title": "Polyhedral Analysis",
    "section": "reodered loops",
    "text": "reodered loops\nfor (j = 0; j &lt;=6; j++)\n for (i = max(j-3,0); i &lt;= j; i++)\n   a[i,j] = 0\noutloop bounds cannot depend on i\ninner loop bounds can depend on j\nWe can read off j as a proection, for each value of j, i is a convex polygon (if the bounds were not convex this would be false)"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#fourier-motzkin-method",
    "href": "lectures/revealjs_09_poly.qmd.html#fourier-motzkin-method",
    "title": "Polyhedral Analysis",
    "section": "fourier-motzkin method",
    "text": "fourier-motzkin method\ninput:\n\nA convex polygon S on \\(x_1, x_2, ... x_n\\)\nA variable \\(X_m\\) to be eliminated\n\noutput: \\(S^1\\) a projection of S with out dimiension \\(m\\)"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#alogorithm",
    "href": "lectures/revealjs_09_poly.qmd.html#alogorithm",
    "title": "Polyhedral Analysis",
    "section": "alogorithm",
    "text": "alogorithm\n\\[ S = \\{ vec(x) | B vec(x) + vec(f) \\ge 0 \\}\\] \\[C\\] = constraints in S that involve \\(S_m\\) (coef is not zero)\n-======================="
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#how-much-of-a-limitation-is-affine-only",
    "href": "lectures/revealjs_09_poly.qmd.html#how-much-of-a-limitation-is-affine-only",
    "title": "Polyhedral Analysis",
    "section": "How much of a limitation is affine only",
    "text": "How much of a limitation is affine only\n99% of hpc loops are affine C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam. Putting polyhedral loop transformations to work. In LCPC, 2003.\nover 95% of loops in deep learning are affine Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, RaminderBajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA). IEEE, 1–12."
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#some-notation",
    "href": "lectures/revealjs_09_poly.qmd.html#some-notation",
    "title": "Polyhedral Analysis",
    "section": "some notation",
    "text": "some notation\n\\[\n\\begin{align*}\ndomain &= \\left\\{ i \\in \\mathbf{Z}^1  \\mid 1 &lt;= i &lt;= 4\\right\\} \\\\\ninstances\\  of   \\ s &= \\left\\{ s(i) \\mid 1 &lt;=i &lt;= 4\\right\\}\n\\end{align*}\n\\]\nThe domain is the set of integer values of the loop index. left and right have the same domain\nWe call the order that instances execute the schedule The schedule is the ordering of instances. this is a map of instance to time."
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#what-is-a-violated-data-dependence",
    "href": "lectures/revealjs_09_poly.qmd.html#what-is-a-violated-data-dependence",
    "title": "Polyhedral Analysis",
    "section": "what is a violated data dependence",
    "text": "what is a violated data dependence\na pair (p, c) where p produces data that c consumes and c comes before p in the new schedule\ndata dependence \\[\n\\left \\{(s(i), s(i+1)) \\mid 1 \\le i \\le 3 \\right \\}\n\\]\nset of violated data dependences \\[\n\\left \\{(s(i), s(j)) \\mid \\ newSch(j) \\ge newSch(i) \\right \\}\n\\]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#ilp-solver-info",
    "href": "lectures/revealjs_09_poly.qmd.html#ilp-solver-info",
    "title": "Polyhedral Analysis",
    "section": "ilp solver info",
    "text": "ilp solver info\ncan an ilp solver always work?\nHilbert’s tenth problem is the tenth on the list of mathematical problems that the German mathematician David Hilbert posed in 1900. It is the challenge to provide a general algorithm that, for any given Diophantine equation (a polynomial equation with integer coefficients and a finite number of unknowns), can decide whether the equation has a solution with all unknowns taking integer values.\nsadly answer is no (found in 1970)\nBut we can do this if we limit the kinds of inequalities"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#affine-limitations",
    "href": "lectures/revealjs_09_poly.qmd.html#affine-limitations",
    "title": "Polyhedral Analysis",
    "section": "Affine limitations",
    "text": "Affine limitations\naffine functions, no multiplying unknowns, no quantifiers (for all, or exists) and is ok, or ok (if we change to two problems) just add/subtract/ multiply by a constant, can add minimize/maximize a function. division and remainder by a constant, max/min/ absolute\nMost scientific programs and ai programs fit, because array subscripts are often affine\nBut lots of other kinds of programs do not.\nThere is a lot of formal math background here, decidability in logic."
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html",
    "href": "lectures/13_dynamic_compilers.html",
    "title": "Dynamic Compilers",
    "section": "",
    "text": "a jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "href": "lectures/13_dynamic_compilers.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "title": "Dynamic Compilers",
    "section": "",
    "text": "a jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#can-jit-compiled-code-run-faster-then-aot-code",
    "href": "lectures/13_dynamic_compilers.html#can-jit-compiled-code-run-faster-then-aot-code",
    "title": "Dynamic Compilers",
    "section": "Can jit compiled code run faster then aot code?",
    "text": "Can jit compiled code run faster then aot code?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#comparison",
    "href": "lectures/13_dynamic_compilers.html#comparison",
    "title": "Dynamic Compilers",
    "section": "Comparison",
    "text": "Comparison\n\n\n\naot\njit\n\n\n\n\ncannot inline libraries\ncan inline (even class methods)\n\n\nno runtime code gen\ncan use run time code gen\n\n\nno speculative opts\ncan use spec opts\n\n\nless information\nmore information\n\n\noverall performance lower\noverall performance often higher\n\n\nfull speed from the start\nrequires warmup\n\n\nno compile cost at run time\noverhead to run compiler",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tradeoffs",
    "href": "lectures/13_dynamic_compilers.html#tradeoffs",
    "title": "Dynamic Compilers",
    "section": "Tradeoffs",
    "text": "Tradeoffs\n\nThe time to compile is part of the total execution time\nmight run less optimizations to speed up execution time\nmight look at run time info\nsame code might be compiled many times\n\nWt would the same code be compiled more than once?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tiered-compilers",
    "href": "lectures/13_dynamic_compilers.html#tiered-compilers",
    "title": "Dynamic Compilers",
    "section": "tiered compilers",
    "text": "tiered compilers\nSince compilation is costly, do not compile functions that are only called once and do not contain a long running loop\nwe have a series of compilers, each with more aggressive optimization and each allowed to take longer\n\nthe lowest tier is the interpreter\nthe next is the base line compiler\n\n\n\nstart interpreting the code\nif some part of the code takes a long time, compile it with the next higher tier\nis some runtime info changes, compile it again",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#magic-numbers",
    "href": "lectures/13_dynamic_compilers.html#magic-numbers",
    "title": "Dynamic Compilers",
    "section": "magic numbers",
    "text": "magic numbers\nassociate a counter with branches and functions if the counter reaches some magic number use one of the compilers\nif the counter for a backward branch, you recompile, but the code is executing in the middle of a loop, so how do you insert the newly compiled code?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#questions-when-building-a-jit",
    "href": "lectures/13_dynamic_compilers.html#questions-when-building-a-jit",
    "title": "Dynamic Compilers",
    "section": "questions when building a JIT",
    "text": "questions when building a JIT\n\nwhat strategy do you use to invoke the jit\ndo you have to execute for a while before calling the jit\nhow much info do you need\nwhat is the price of wrong info\nare there easy and hard programs\ndo the easy programs match up with users common programs",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#speculation",
    "href": "lectures/13_dynamic_compilers.html#speculation",
    "title": "Dynamic Compilers",
    "section": "Speculation",
    "text": "Speculation\n\nassume some property is true, compile using that info this is always a gamble, so you need to recover if the assumption was wrong\nassume a variable is an int, and does not overflow\nassume properties of an object is fixed\nassume the target of call is always the same\nassume past behavior predicts future behavior",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#flow",
    "href": "lectures/13_dynamic_compilers.html#flow",
    "title": "Dynamic Compilers",
    "section": "flow",
    "text": "flow\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#boxed-values",
    "href": "lectures/13_dynamic_compilers.html#boxed-values",
    "title": "Dynamic Compilers",
    "section": "boxed values",
    "text": "boxed values\nMany languages do not use strong static typeing\nfor example in python\nx = x + 1\nx could be an int/float/object\nthe value of x needs to carry a type. Represent x as a pair (type, pointer or bits) The pair is called a boxed value\nthen to generate code for the plus we have to figure out what kind of add, based on the type",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches",
    "href": "lectures/13_dynamic_compilers.html#inline-caches",
    "title": "Dynamic Compilers",
    "section": "inline caches",
    "text": "inline caches\nin languages like python, calls to a method are more expensive then calls to a method in c++ why?\n. . .\nPython objects are implemented as hash tables. While C++ uses virtual tables\nhow does that effect the cost?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#first-c-virtual-tables",
    "href": "lectures/13_dynamic_compilers.html#first-c-virtual-tables",
    "title": "Dynamic Compilers",
    "section": "first C++ virtual tables",
    "text": "first C++ virtual tables\nin C++ a method call takes two dereferences\n\nfirst find the v-table\nsecond used a fixed offset from the table start to find the address",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#what-do-we-need-to-keep-the-offset-fixed",
    "href": "lectures/13_dynamic_compilers.html#what-do-we-need-to-keep-the-offset-fixed",
    "title": "Dynamic Compilers",
    "section": "What do we need to keep the offset fixed?",
    "text": "What do we need to keep the offset fixed?\nif derived inherits from base, and both have a function f. the offset to f has to be the same.\nin languages where objects are hash tables, the c++ dereference becomes a hash table lookup, which is slower",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tradeoffs-1",
    "href": "lectures/13_dynamic_compilers.html#tradeoffs-1",
    "title": "Dynamic Compilers",
    "section": "tradeoffs",
    "text": "tradeoffs\nIn a dynamically typed language like python we can add or remove methods easily\nbut method calls are expensive\nwe want to make these calls cheaper",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches-at-te-call-site",
    "href": "lectures/13_dynamic_compilers.html#inline-caches-at-te-call-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at te call site",
    "text": "inline caches at te call site\nthe first time we call a method, we know the type (because we are generating code at runtime)\n\n\ndef func(a,b,c):\n  for i in range(10):\n     foo(a,b,c)\n\ndef func(a,b,c):\n  for i in range(1):\n    if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in the hash\n      call other(a,b,c\n      )",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches-at-the-function-site",
    "href": "lectures/13_dynamic_compilers.html#inline-caches-at-the-function-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at the function site",
    "text": "inline caches at the function site\n\n\ndef func(a,b,c):\n  for i in range(10):\n     _foo(a,b,c\n\ndef _foo(a,b,c)\n  if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in a\n      call other(a,b,c)\n\n\nis it better to do this at the call site or at the function site?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#polymorphic-calls",
    "href": "lectures/13_dynamic_compilers.html#polymorphic-calls",
    "title": "Dynamic Compilers",
    "section": "polymorphic calls",
    "text": "polymorphic calls\nif the type changes at runtime (the call to other is taken) does the optimization help?\ncould invalidate the table and rebuild it with another case",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#what-are-the-costs",
    "href": "lectures/13_dynamic_compilers.html#what-are-the-costs",
    "title": "Dynamic Compilers",
    "section": "what are the costs",
    "text": "what are the costs\nfor example v8 compiler\nmonomorphic inline hit - 10 instructions\npolymorphic hit - 35 instructions for 10 types, 60 instructions for 20 types\ncache miss 1000-4000 instructions",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#value-specialization",
    "href": "lectures/13_dynamic_compilers.html#value-specialization",
    "title": "Dynamic Compilers",
    "section": "value specialization",
    "text": "value specialization\nOddly many functions are called with the same arguments",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#an-example",
    "href": "lectures/13_dynamic_compilers.html#an-example",
    "title": "Dynamic Compilers",
    "section": "an example",
    "text": "an example\ngiven a vector v of size n, and a parameter q find the element of v that is closest to q\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n        var i = 0;\n        var d = 0ffffffff;\n        while (i &lt; n) {\n           var nd = abs(v[i] - q);\n           if (nd &lt;= d) d = nd; \n           i++;\n        }    \n        return d;  \n      } \n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#the-cfg",
    "href": "lectures/13_dynamic_compilers.html#the-cfg",
    "title": "Dynamic Compilers",
    "section": "the cfg",
    "text": "the cfg\nwe want to recompile this for specific v,q, and n, where we restart at the while test\n\n\n\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n      var i = 0;\n      var d = 0ffffffff;\n      while (i &lt; n) {\n         var nd = abs(v[i] - q);\n         if (nd &lt;= d) d = nd; \n         i++;\n        }    \n        return d;  \n      } \n}\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#two-entries",
    "href": "lectures/13_dynamic_compilers.html#two-entries",
    "title": "Dynamic Compilers",
    "section": "two entries",
    "text": "two entries\nFirst entry is the regular starting point, second is the entry if we are currently running the loop in the interpreter\nSince we are compiling the function while in the loop we can ask the interpreter for values\n\nv == load[0]\nq = 42\nn = 100\ni = 40\nd = 0fffffff\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#dead-code-elimination",
    "href": "lectures/13_dynamic_compilers.html#dead-code-elimination",
    "title": "Dynamic Compilers",
    "section": "dead code elimination",
    "text": "dead code elimination\nAfter this the all calls to the function assume these arguments so no need to keep the regular entry\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#array-in-bounds-check",
    "href": "lectures/13_dynamic_compilers.html#array-in-bounds-check",
    "title": "Dynamic Compilers",
    "section": "array in bounds check",
    "text": "array in bounds check\nwe can pattern match loops with bounds checks if we know the limit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     \"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     \"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#loop-inversion",
    "href": "lectures/13_dynamic_compilers.html#loop-inversion",
    "title": "Dynamic Compilers",
    "section": "loop inversion",
    "text": "loop inversion\na general while loop\nwhile(cond){\n  ...\n}\ncan be changed into\nif (cond){\n  do {\n    ...\n  } while(cond)\n}\nfor this loop the first time around i = 40, n = 100 so the first condition is true",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#after-loop-inversion",
    "href": "lectures/13_dynamic_compilers.html#after-loop-inversion",
    "title": "Dynamic Compilers",
    "section": "after loop inversion",
    "text": "after loop inversion\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#results",
    "href": "lectures/13_dynamic_compilers.html#results",
    "title": "Dynamic Compilers",
    "section": "results",
    "text": "results\nspecialized code is shorter and compiles faster\nsince we know that the loop goes from 42 to 100, we could unroll the loop",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#trace-compilation",
    "href": "lectures/13_dynamic_compilers.html#trace-compilation",
    "title": "Dynamic Compilers",
    "section": "trace compilation",
    "text": "trace compilation\ntracing jit: extract a hot path (not a function)\nHot paths are compiled as a single basic block, but the path might go through a call\ngamble: next execution starting at this point, go the same way, no branches leave the path\ngenerate machine code for hot paths interpret the rest of the program\nunlike specialization, tracing assumes the same path but not the same values",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#an-example-x-42",
    "href": "lectures/13_dynamic_compilers.html#an-example-x-42",
    "title": "Dynamic Compilers",
    "section": "an example (x = 42)",
    "text": "an example (x = 42)\n\n\nfunction main(x){\n   y = x +1 \n   if x &lt;100 {\n      z = f(y)\n   } else {\n      z = g(y)\n   }\n   return z\n}\n\nfunction f(a){\n   return a -1 \n}\n\n\n\ny = x +1\nguard(x &lt; 100)\na = y\nz = a - 1\nreturn z\n\n\n\n\nguards at divergence, guards never return\noptimize assuming guards are true, ok to be slow if guard is false",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#move-guards-up",
    "href": "lectures/13_dynamic_compilers.html#move-guards-up",
    "title": "Dynamic Compilers",
    "section": "move guards up",
    "text": "move guards up\nwhy is this a good idea?\n. . .\n\nfail fast\nlonger region to optimize",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#use-local-value-numbering",
    "href": "lectures/13_dynamic_compilers.html#use-local-value-numbering",
    "title": "Dynamic Compilers",
    "section": "use local value numbering",
    "text": "use local value numbering\n\n\n\nguard(x &lt; 100)\ny = x + 1\na = y\nz = a - 1\nreturn z\n\n\n\nguard(x &lt; 100)\nreturn x",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#how-do-this-in-bril",
    "href": "lectures/13_dynamic_compilers.html#how-do-this-in-bril",
    "title": "Dynamic Compilers",
    "section": "how do this in Bril?",
    "text": "how do this in Bril?\n3 new operations (sort of like out-of-order instructions)\n\nspeculate\ncommit\nguard\n\nspeculative execution extension\nyou can nest speculate\nit does not role back stores\nwe can approximate trace compilation by running the program twice\nHow to modify the reference interpreter (warning typescript!)\nbrili\nthere are two functions to consider\n\nevalFunc interprets a function by calling evalInstr on each instruction\nevalInstr interprets one instruction, large case statement for each instruction\n\nyou will need to print instructions as they execute\n\nfigure out when to start and when to stop\nhow to print instructions (modify evalInstr by printing instructions) console.log(instr)\n\nyou have to optimize the trace and put it back",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "title": "Dynamic Compilers",
    "section": "jit (just in time) compilers vs aot(ahead of time) compilers",
    "text": "jit (just in time) compilers vs aot(ahead of time) compilers\na jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#can-jit-compiled-code-run-faster-then-aot-code",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#can-jit-compiled-code-run-faster-then-aot-code",
    "title": "Dynamic Compilers",
    "section": "Can jit compiled code run faster then aot code?",
    "text": "Can jit compiled code run faster then aot code?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#comparison",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#comparison",
    "title": "Dynamic Compilers",
    "section": "Comparison",
    "text": "Comparison\n\n\n\naot\njit\n\n\n\n\ncannot inline libraries\ncan inline (even class methods)\n\n\nno runtime code gen\ncan use run time code gen\n\n\nno speculative opts\ncan use spec opts\n\n\nless information\nmore information\n\n\noverall performance lower\noverall performance often higher\n\n\nfull speed from the start\nrequires warmup\n\n\nno compile cost at run time\noverhead to run compiler"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs",
    "title": "Dynamic Compilers",
    "section": "Tradeoffs",
    "text": "Tradeoffs\n\nThe time to compile is part of the total execution time\nmight run less optimizations to speed up execution time\nmight look at run time info\nsame code might be compiled many times\n\nWt would the same code be compiled more than once?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tiered-compilers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tiered-compilers",
    "title": "Dynamic Compilers",
    "section": "tiered compilers",
    "text": "tiered compilers\nSince compilation is costly, do not compile functions that are only called once and do not contain a long running loop\nwe have a series of compilers, each with more aggressive optimization and each allowed to take longer\n\nthe lowest tier is the interpreter\nthe next is the base line compiler"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#magic-numbers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#magic-numbers",
    "title": "Dynamic Compilers",
    "section": "magic numbers",
    "text": "magic numbers\nassociate a counter with branches and functions if the counter reaches some magic number use one of the compilers\nif the counter for a backward branch, you recompile, but the code is executing in the middle of a loop, so how do you insert the newly compiled code?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#questions-when-building-a-jit",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#questions-when-building-a-jit",
    "title": "Dynamic Compilers",
    "section": "questions when building a JIT",
    "text": "questions when building a JIT\n\nwhat strategy do you use to invoke the jit\ndo you have to execute for a while before calling the jit\nhow much info do you need\nwhat is the price of wrong info\nare there easy and hard programs\ndo the easy programs match up with users common programs"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#speculation",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#speculation",
    "title": "Dynamic Compilers",
    "section": "Speculation",
    "text": "Speculation\n\nassume some property is true, compile using that info this is always a gamble, so you need to recover if the assumption was wrong\nassume a variable is an int, and does not overflow\nassume properties of an object is fixed\nassume the target of call is always the same\nassume past behavior predicts future behavior"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#flow",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#flow",
    "title": "Dynamic Compilers",
    "section": "flow",
    "text": "flow\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#boxed-values",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#boxed-values",
    "title": "Dynamic Compilers",
    "section": "boxed values",
    "text": "boxed values\nMany languages do not use strong static typeing\nfor example in python\nx = x + 1\nx could be an int/float/object\nthe value of x needs to carry a type. Represent x as a pair (type, pointer or bits) The pair is called a boxed value\nthen to generate code for the plus we have to figure out what kind of add, based on the type"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches",
    "title": "Dynamic Compilers",
    "section": "inline caches",
    "text": "inline caches\nin languages like python, calls to a method are more expensive then calls to a method in c++ why?\n\nPython objects are implemented as hash tables. While C++ uses virtual tables\nhow does that effect the cost?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#first-c-virtual-tables",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#first-c-virtual-tables",
    "title": "Dynamic Compilers",
    "section": "first C++ virtual tables",
    "text": "first C++ virtual tables\nin C++ a method call takes two dereferences\n\nfirst find the v-table\nsecond used a fixed offset from the table start to find the address"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-do-we-need-to-keep-the-offset-fixed",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-do-we-need-to-keep-the-offset-fixed",
    "title": "Dynamic Compilers",
    "section": "What do we need to keep the offset fixed?",
    "text": "What do we need to keep the offset fixed?\nif derived inherits from base, and both have a function f. the offset to f has to be the same.\nin languages where objects are hash tables, the c++ dereference becomes a hash table lookup, which is slower"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs-1",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs-1",
    "title": "Dynamic Compilers",
    "section": "tradeoffs",
    "text": "tradeoffs\nIn a dynamically typed language like python we can add or remove methods easily\nbut method calls are expensive\nwe want to make these calls cheaper"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-te-call-site",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-te-call-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at te call site",
    "text": "inline caches at te call site\nthe first time we call a method, we know the type (because we are generating code at runtime)\n\n\ndef func(a,b,c):\n  for i in range(10):\n     foo(a,b,c)\n\ndef func(a,b,c):\n  for i in range(1):\n    if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in the hash\n      call other(a,b,c\n      )"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-the-function-site",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-the-function-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at the function site",
    "text": "inline caches at the function site\n\n\ndef func(a,b,c):\n  for i in range(10):\n     _foo(a,b,c\n\ndef _foo(a,b,c)\n  if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in a\n      call other(a,b,c)\n\nis it better to do this at the call site or at the function site?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#polymorphic-calls",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#polymorphic-calls",
    "title": "Dynamic Compilers",
    "section": "polymorphic calls",
    "text": "polymorphic calls\nif the type changes at runtime (the call to other is taken) does the optimization help?\ncould invalidate the table and rebuild it with another case"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-are-the-costs",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-are-the-costs",
    "title": "Dynamic Compilers",
    "section": "what are the costs",
    "text": "what are the costs\nfor example v8 compiler\nmonomorphic inline hit - 10 instructions\npolymorphic hit - 35 instructions for 10 types, 60 instructions for 20 types\ncache miss 1000-4000 instructions"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#value-specialization",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#value-specialization",
    "title": "Dynamic Compilers",
    "section": "value specialization",
    "text": "value specialization\nOddly many functions are called with the same arguments"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example",
    "title": "Dynamic Compilers",
    "section": "an example",
    "text": "an example\ngiven a vector v of size n, and a parameter q find the element of v that is closest to q\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n        var i = 0;\n        var d = 0ffffffff;\n        while (i &lt; n) {\n           var nd = abs(v[i] - q);\n           if (nd &lt;= d) d = nd; \n           i++;\n        }    \n        return d;  \n      } \n}"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#the-cfg",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#the-cfg",
    "title": "Dynamic Compilers",
    "section": "the cfg",
    "text": "the cfg\nwe want to recompile this for specific v,q, and n, where we restart at the while test"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#two-entries",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#two-entries",
    "title": "Dynamic Compilers",
    "section": "two entries",
    "text": "two entries\nFirst entry is the regular starting point, second is the entry if we are currently running the loop in the interpreter\nSince we are compiling the function while in the loop we can ask the interpreter for values\n\nv == load[0]\nq = 42\nn = 100\ni = 40\nd = 0fffffff"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#dead-code-elimination",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#dead-code-elimination",
    "title": "Dynamic Compilers",
    "section": "dead code elimination",
    "text": "dead code elimination\nAfter this the all calls to the function assume these arguments so no need to keep the regular entry\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#array-in-bounds-check",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#array-in-bounds-check",
    "title": "Dynamic Compilers",
    "section": "array in bounds check",
    "text": "array in bounds check\nwe can pattern match loops with bounds checks if we know the limit"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#loop-inversion",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#loop-inversion",
    "title": "Dynamic Compilers",
    "section": "loop inversion",
    "text": "loop inversion\na general while loop\nwhile(cond){\n  ...\n}\ncan be changed into\nif (cond){\n  do {\n    ...\n  } while(cond)\n}\nfor this loop the first time around i = 40, n = 100 so the first condition is true"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#after-loop-inversion",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#after-loop-inversion",
    "title": "Dynamic Compilers",
    "section": "after loop inversion",
    "text": "after loop inversion\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#results",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#results",
    "title": "Dynamic Compilers",
    "section": "results",
    "text": "results\nspecialized code is shorter and compiles faster\nsince we know that the loop goes from 42 to 100, we could unroll the loop"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#trace-compilation",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#trace-compilation",
    "title": "Dynamic Compilers",
    "section": "trace compilation",
    "text": "trace compilation\ntracing jit: extract a hot path (not a function)\nHot paths are compiled as a single basic block, but the path might go through a call\ngamble: next execution starting at this point, go the same way, no branches leave the path\ngenerate machine code for hot paths interpret the rest of the program\nunlike specialization, tracing assumes the same path but not the same values"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example-x-42",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example-x-42",
    "title": "Dynamic Compilers",
    "section": "an example (x = 42)",
    "text": "an example (x = 42)\n\n\nfunction main(x){\n   y = x +1 \n   if x &lt;100 {\n      z = f(y)\n   } else {\n      z = g(y)\n   }\n   return z\n}\n\nfunction f(a){\n   return a -1 \n}\n\n\n\ny = x +1\nguard(x &lt; 100)\na = y\nz = a - 1\nreturn z\n\n\n\nguards at divergence, guards never return\noptimize assuming guards are true, ok to be slow if guard is false"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#move-guards-up",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#move-guards-up",
    "title": "Dynamic Compilers",
    "section": "move guards up",
    "text": "move guards up\nwhy is this a good idea?\n\n\nfail fast\nlonger region to optimize"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#use-local-value-numbering",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#use-local-value-numbering",
    "title": "Dynamic Compilers",
    "section": "use local value numbering",
    "text": "use local value numbering\n\n\n\nguard(x &lt; 100)\ny = x + 1\na = y\nz = a - 1\nreturn z\n\n\n\nguard(x &lt; 100)\nreturn x"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#how-do-this-in-bril",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#how-do-this-in-bril",
    "title": "Dynamic Compilers",
    "section": "how do this in Bril?",
    "text": "how do this in Bril?\n3 new operations (sort of like out-of-order instructions)\n\nspeculate\ncommit\nguard\n\nspeculative execution extension\nyou can nest speculate\nit does not role back stores\nwe can approximate trace compilation by running the program twice\nHow to modify the reference interpreter (warning typescript!)\nbrili\nthere are two functions to consider\n\nevalFunc interprets a function by calling evalInstr on each instruction\nevalInstr interprets one instruction, large case statement for each instruction\n\nyou will need to print instructions as they execute\n\nfigure out when to start and when to stop\nhow to print instructions (modify evalInstr by printing instructions) console.log(instr)\n\nyou have to optimize the trace and put it back"
  },
  {
    "objectID": "lectures/02a_representation.html",
    "href": "lectures/02a_representation.html",
    "title": "Representation of programs",
    "section": "",
    "text": "The representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#how-do-we-represent-programs",
    "href": "lectures/02a_representation.html#how-do-we-represent-programs",
    "title": "Representation of programs",
    "section": "",
    "text": "The representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#concrete-syntax",
    "href": "lectures/02a_representation.html#concrete-syntax",
    "title": "Representation of programs",
    "section": "Concrete Syntax",
    "text": "Concrete Syntax\nConcrete syntax, or surface syntax, represents programs as they are written\nPrograms are text or surface syntax- just what you would type into an editor.\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction?\nHow do you understand the semantics.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#abstract-syntax",
    "href": "lectures/02a_representation.html#abstract-syntax",
    "title": "Representation of programs",
    "section": "Abstract syntax",
    "text": "Abstract syntax\nAbstract syntax represents programs as tree structures, focusing on the nodes and their connections.\n\nNodes are parts of the program,\nEdges show how they are connected.\n\nWe can write this as a list or a graph\n\n\ndef pgm():\n    value = 8\n    result = 1\n    for i in range(value):\n        result = result * i\n    print(result)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#ast-tree-representation",
    "href": "lectures/02a_representation.html#ast-tree-representation",
    "title": "Representation of programs",
    "section": "AST tree representation",
    "text": "AST tree representation\nAn AST is a tree structure, nodes like ‘if’, ‘test’, ‘body’, assign’.\nEach node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter.\nSimple (non optimizing) compilers often use this format.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#a-more-regular-representation",
    "href": "lectures/02a_representation.html#a-more-regular-representation",
    "title": "Representation of programs",
    "section": "A more regular representation",
    "text": "A more regular representation\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\nts2bril images/toy.ts | bril2txt\n\n\n    //typescript program \n    let value = 8\n    let result = 1\n    for (let i = 0; i &lt; value;\n         i = i+1)\n    {\n        result = result * i\n    }\n    console.log(result)\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#bril",
    "href": "lectures/02a_representation.html#bril",
    "title": "Representation of programs",
    "section": "bril",
    "text": "bril\n\nLooks like assembly\nno limit on registers,\nno condition codes.\nfully typed,\nno complex addressing modes.\neasy to extend",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#bril-syntax",
    "href": "lectures/02a_representation.html#bril-syntax",
    "title": "Representation of programs",
    "section": "Bril syntax",
    "text": "Bril syntax\nDeclare functions, labels, instructions\ninstruction:\n\nvariable type = opcode arguments\nopcode list of arguments\n\nForm 1, variable is the destination, like a: int = add b, c\nForm 2, no destination, like print a\nwhat is good and what is about this representation?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#control-flow-graph-cfg-version-1",
    "href": "lectures/02a_representation.html#control-flow-graph-cfg-version-1",
    "title": "Representation of programs",
    "section": "control flow graph (CFG) (version 1)",
    "text": "control flow graph (CFG) (version 1)\nRepresentation is a directed graph.\n\nNodes are instructions,\nedges indicate possible flow of control,\none entry and one exit node.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#example-one",
    "href": "lectures/02a_representation.html#example-one",
    "title": "Representation of programs",
    "section": "Example one",
    "text": "Example one\n@main {\n    v: int = const 5;\n    print v;\n}\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#second-example",
    "href": "lectures/02a_representation.html#second-example",
    "title": "Representation of programs",
    "section": "second example",
    "text": "second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\n. . .\nnotice label does not produce a node\nEasy to see a dead instruction.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#third-example",
    "href": "lectures/02a_representation.html#third-example",
    "title": "Representation of programs",
    "section": "Third example:",
    "text": "Third example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\n. . .\nwhich is the true edge and which is the false edge , could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#cfg-cfg-form-2",
    "href": "lectures/02a_representation.html#cfg-cfg-form-2",
    "title": "Representation of programs",
    "section": "CFG (cfg form 2)",
    "text": "CFG (cfg form 2)\n\nnodes ares sequences of instructions.\njumps and branches can only be at the end of a sequence\nonly label has to be at the start\nevery instruction in the sequence executes the same number of times",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#construct-cfg",
    "href": "lectures/02a_representation.html#construct-cfg",
    "title": "Representation of programs",
    "section": "construct cfg",
    "text": "construct cfg\nwalk over the instructions:\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of \\(b\\) are the blocks \\(b_{in}\\) where there is an edge \\(b_{in}-&gt;b\\). And the successors of \\(b\\) are the \\(b_{out}\\) where \\(b-&gt;b_{out}\\) is an edge.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "lectures/02a_representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation of programs",
    "section": "What is an algorithm that forms a cfg",
    "text": "What is an algorithm that forms a cfg\n. . .\n\njust find all the basic blocks\nadd the control flow edges",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#pseudo-code-to-construct-cfg",
    "href": "lectures/02a_representation.html#pseudo-code-to-construct-cfg",
    "title": "Representation of programs",
    "section": "pseudo code to construct cfg",
    "text": "pseudo code to construct cfg\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#how-do-we-represent-programs",
    "href": "lectures/revealjs_02a_representation.qmd.html#how-do-we-represent-programs",
    "title": "Representation of programs",
    "section": "How do we represent programs",
    "text": "How do we represent programs\nThe representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\n\nCode\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#concrete-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#concrete-syntax",
    "title": "Representation of programs",
    "section": "Concrete Syntax",
    "text": "Concrete Syntax\nConcrete syntax, or surface syntax, represents programs as they are written\nPrograms are text or surface syntax- just what you would type into an editor.\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction?\nHow do you understand the semantics."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#abstract-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#abstract-syntax",
    "title": "Representation of programs",
    "section": "Abstract syntax",
    "text": "Abstract syntax\nAbstract syntax represents programs as tree structures, focusing on the nodes and their connections.\n\nNodes are parts of the program,\nEdges show how they are connected.\n\nWe can write this as a list or a graph\n\n\ndef pgm():\n    value = 8\n    result = 1\n    for i in range(value):\n        result = result * i\n    print(result)"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#ast-tree-representation",
    "href": "lectures/revealjs_02a_representation.qmd.html#ast-tree-representation",
    "title": "Representation of programs",
    "section": "AST tree representation",
    "text": "AST tree representation\nAn AST is a tree structure, nodes like ‘if’, ‘test’, ‘body’, assign’.\nEach node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter.\nSimple (non optimizing) compilers often use this format."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#a-more-regular-representation",
    "href": "lectures/revealjs_02a_representation.qmd.html#a-more-regular-representation",
    "title": "Representation of programs",
    "section": "A more regular representation",
    "text": "A more regular representation\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\nts2bril images/toy.ts | bril2txt\n\n\n    //typescript program \n    let value = 8\n    let result = 1\n    for (let i = 0; i &lt; value;\n         i = i+1)\n    {\n        result = result * i\n    }\n    console.log(result)\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#bril",
    "href": "lectures/revealjs_02a_representation.qmd.html#bril",
    "title": "Representation of programs",
    "section": "bril",
    "text": "bril\n\nLooks like assembly\nno limit on registers,\nno condition codes.\nfully typed,\nno complex addressing modes.\neasy to extend"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#bril-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#bril-syntax",
    "title": "Representation of programs",
    "section": "Bril syntax",
    "text": "Bril syntax\nDeclare functions, labels, instructions\ninstruction:\n\nvariable type = opcode arguments\nopcode list of arguments\n\nForm 1, variable is the destination, like a: int = add b, c\nForm 2, no destination, like print a\nwhat is good and what is about this representation?"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#control-flow-graph-cfg-version-1",
    "href": "lectures/revealjs_02a_representation.qmd.html#control-flow-graph-cfg-version-1",
    "title": "Representation of programs",
    "section": "control flow graph (CFG) (version 1)",
    "text": "control flow graph (CFG) (version 1)\nRepresentation is a directed graph.\n\nNodes are instructions,\nedges indicate possible flow of control,\none entry and one exit node."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#example-one",
    "href": "lectures/revealjs_02a_representation.qmd.html#example-one",
    "title": "Representation of programs",
    "section": "Example one",
    "text": "Example one\n@main {\n    v: int = const 5;\n    print v;\n}\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#second-example",
    "href": "lectures/revealjs_02a_representation.qmd.html#second-example",
    "title": "Representation of programs",
    "section": "second example",
    "text": "second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#third-example",
    "href": "lectures/revealjs_02a_representation.qmd.html#third-example",
    "title": "Representation of programs",
    "section": "Third example:",
    "text": "Third example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\n\n\nwhich is the true edge and which is the false edge , could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#cfg-cfg-form-2",
    "href": "lectures/revealjs_02a_representation.qmd.html#cfg-cfg-form-2",
    "title": "Representation of programs",
    "section": "CFG (cfg form 2)",
    "text": "CFG (cfg form 2)\n\nnodes ares sequences of instructions.\njumps and branches can only be at the end of a sequence\nonly label has to be at the start\nevery instruction in the sequence executes the same number of times"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#construct-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#construct-cfg",
    "title": "Representation of programs",
    "section": "construct cfg",
    "text": "construct cfg\nwalk over the instructions:\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of \\(b\\) are the blocks \\(b_{in}\\) where there is an edge \\(b_{in}-&gt;b\\). And the successors of \\(b\\) are the \\(b_{out}\\) where \\(b-&gt;b_{out}\\) is an edge."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation of programs",
    "section": "What is an algorithm that forms a cfg",
    "text": "What is an algorithm that forms a cfg\n\n\njust find all the basic blocks\nadd the control flow edges"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#pseudo-code-to-construct-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#pseudo-code-to-construct-cfg",
    "title": "Representation of programs",
    "section": "pseudo code to construct cfg",
    "text": "pseudo code to construct cfg\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []"
  },
  {
    "objectID": "lectures/diverg.html",
    "href": "lectures/diverg.html",
    "title": "divergent flow",
    "section": "",
    "text": "__global__ void dec2zero(int* v, int N) { \n    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   \n    if (xIndex &lt; N) {\n             while (v[xIndex] &gt; 0) { v[xIndex]--;     \n             }     \n        } \n} \nDepending on how we initialize the vector, we get different times and different subtracts\n\nSize of array 1048576\nThreads Per Block = 256\nBlocks In Grid = 4096",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#what-is-the-cost-of-divergence",
    "href": "lectures/diverg.html#what-is-the-cost-of-divergence",
    "title": "divergent flow",
    "section": "",
    "text": "__global__ void dec2zero(int* v, int N) { \n    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   \n    if (xIndex &lt; N) {\n             while (v[xIndex] &gt; 0) { v[xIndex]--;     \n             }     \n        } \n} \nDepending on how we initialize the vector, we get different times and different subtracts\n\nSize of array 1048576\nThreads Per Block = 256\nBlocks In Grid = 4096",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#some-initializers",
    "href": "lectures/diverg.html#some-initializers",
    "title": "divergent flow",
    "section": "some initializers",
    "text": "some initializers\n  // all 1\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 1; \n  }\n  // subtracts 1048576\n  // time      0.1 ms\n// decreasing values from n-1 to 0\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n - i - 1;  // count should be N*(n+1)/2 = 54975572...\n  }\n  // subtracts 549755289600\n  // time  45.7 ms\n// Fill function to set all elements of the array to the middle value of n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n / 2;  // count should be N*N/2 54975572...\n    // subtracts 549755813888\n    // time  45.6 ms\n// Fill function to set alternate elements to 0 or n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 0;\n    if (i%2){ A[i] = n;} \n    // subtacts 549755813888\n    // time 83.9 ms\n  }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#divergence-example",
    "href": "lectures/diverg.html#divergence-example",
    "title": "divergent flow",
    "section": "divergence example",
    "text": "divergence example\n```global void example(float* v){ if (v[tid]) &lt; 2.0){ v[tid] = /=2; } else { v[tid] = 0; } }\nand in ptx\n1. b0: r1 = addr v[tid]\n2. f1 = load r1\n3. p1 = set.lt f0, 0.0\n\n5. @p1? Bzr: f2 = div f1, 2\n6. @p1? jmp Bst\n\n7. !@p1? b1: f2 = 0.0\n\n8. Bst: store r1, f2\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nGraph TB\nB0--&gt; Bzr\nB0--&gt; B1\nBzr--&gt; Bst\nb1 --&gt; Bst",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#what-happens-to-implement-this",
    "href": "lectures/diverg.html#what-happens-to-implement-this",
    "title": "divergent flow",
    "section": "what happens to implement this?",
    "text": "what happens to implement this?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#harware-version-1-pre-volta-nvidia-chips",
    "href": "lectures/diverg.html#harware-version-1-pre-volta-nvidia-chips",
    "title": "divergent flow",
    "section": "harware version 1 (pre volta nvidia chips)",
    "text": "harware version 1 (pre volta nvidia chips)\nThere is a hardware stack called the simt-stack, each entry is a pc and a 32 bit active mask. When hardware reachs an if- push 3 entries pc then, mask for then pc else, mask for else pc reconvergence pt, mask for recovergence\n\n                          t0 t1 t2 t3    stack\na:                        r  r  r  r      a: 1111\n--------------------------------------------------------\n  if (tid% 4 &lt; 2) {       r  r  r  r      b  1100\n                                          c  0011\n                                          f  1111\n----------------------------------------------------------\n    b:                    r r   -  -      c 0011\n    c:                    r r   -  -      f  1111\n-------------------------------------------------\n  } else {                \n    d:                    - -   r r \n    e:                    - -   r r\n  }\n  f:                                    stack is empty    \nat else pc matches tos at f pc matches tos\nrules: 1. divergent paths execute serially 1. threads execute in lock step 1. recoverge at immed post dominator\neasy to find post dominator for reducible control flow\nsome code deadlocks:\n1: *mutex = 0; 2: 3 while(!atomicCAS(mutex,0,1)); 3: // Critical Section 4: atomicExch(mutex,0);",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#volta-and-newer",
    "href": "lectures/diverg.html#volta-and-newer",
    "title": "divergent flow",
    "section": "volta and newer",
    "text": "volta and newer\npossible structure\nHandles unstructured code nicely always makes forward progress\n\n                          t0 t1 t2 t3    \na:                        r  r  r  r      \n--------------------------------------------------------\n  if (tid% 4 &lt; 2) {       r  r  r  r    \n                                                                           \n----------------------------------------------------------\n    b:                    r r   -  -    \n    d:                    - -   r r  \n    c:                    r r   -  -  \n    e:                    - -   r r    \n-------------------------------------------------\n                \n  f:                      r r  --\n                          - -  r r \n   _syncthreads()         r r r r \n  g:             \nadds a new set of registers called barrier registers, which hold the indexes of threads that will synchronize\nnew instructions:\n\nbssy sets a barrier register to a mask of the threads that will need to reconverge (recovergence mask) and specfies the reconvergence point\nbmov copies between barrier registers and regular registers\nbsync forces threads in the mask to wait\nbbreak removes threads from mask",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#what-does-this-solve",
    "href": "lectures/diverg.html#what-does-this-solve",
    "title": "divergent flow",
    "section": "what does this solve",
    "text": "what does this solve\nThe Volta architecture introduces Independent Thread Scheduling among threads in a warp. This feature enables intra-warp synchronization patterns previously unavailable and simplifies code changes when porting CPU code. However, Independent Thread Scheduling can also lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity2 of previous hardware architectures.\nWhen porting existing codes to Volta, the following three code patterns need careful attention. For more details see the CUDA C++ Programming Guide.\nTo avoid data corruption, applications using warp intrinsics (__shfl*, __any, __all, and __ballot) should transition to the new, safe, synchronizing counterparts, with the *_sync suffix. The new warp intrinsics take in a mask of threads that explicitly define which lanes (threads of a warp) must participate in the warp intrinsic.\nApplications that assume reads and writes are implicitly visible to other threads in the same warp need to insert the new __syncwarp() warp-wide barrier synchronization instruction between steps where data is exchanged between threads via global or shared memory. Assumptions that code is executed in lockstep or that reads/writes from separate threads are visible across a warp without synchronization are invalid.\nApplications using __syncthreads() or the PTX bar.sync (and their derivatives) in such a way that a barrier will not be reached by some non-exited thread in the thread block must be modified to ensure that all non-exited threads reach the barrier.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#amd",
    "href": "lectures/diverg.html#amd",
    "title": "divergent flow",
    "section": "AMD",
    "text": "AMD\nAMD implemented the early version. scalar registers are used as an ‘exec mask’ to indicate which vector lanes execute. The simt-stack can be done in software using scalar instructions\nsave the exec mask set exect mask to running threads do the then invert the exec mask if there is an else do the else restore the exec mask",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#static-detection-of-divergences",
    "href": "lectures/diverg.html#static-detection-of-divergences",
    "title": "divergent flow",
    "section": "static detection of divergences",
    "text": "static detection of divergences\ncan we determine which branches may cause divergences and which branches are uniform?\nat a dirergent branch some threads go one way, some the other, we will need to insert instructions for reconvergence at a uniform branch all threads go the same way",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#divergent-and-uniform-variables",
    "href": "lectures/diverg.html#divergent-and-uniform-variables",
    "title": "divergent flow",
    "section": "divergent and uniform variables",
    "text": "divergent and uniform variables\nA program variable is divergent if different threads see different values.\nIf different threads always see that variable with the same value, then the variable is uniform\ndivergent variables\n\nv = tid\natomic()\nv is data dependent on a divergent variable\nv is control dependent on a divergent variable\n\n## thread id is always divergent\n __global__ \n void saxpy (int n, float alpha, float *x, float *y) {\n   int i = blockIdx.x * blockDim.x + threadIdx.x;  \n  if (i &lt; n) y[i] = alpha * x[i] + y[i]; } \nEach thread sees a different value\nThreads in different blocks see the same threadid - is that a problem",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#variables-defined-by-atomic-operations",
    "href": "lectures/diverg.html#variables-defined-by-atomic-operations",
    "title": "divergent flow",
    "section": "variables defined by atomic operations",
    "text": "variables defined by atomic operations\n__global__ void ex_atomic (int index, float* v) {\n   int i = 0; \n   i = ATOMINC( v[index] ); }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#dependences",
    "href": "lectures/diverg.html#dependences",
    "title": "divergent flow",
    "section": "dependences",
    "text": "dependences\nTwo types of dependences: data and control.\nIf the program contains an assignment such as v = f(v1, v2, …, vn), then v is data dependent on the arguments v1,v2 …\nIf the value assigned to variable v depends on a branch controlled by p, then we say that v is control dependent on p. \nDivergences propagate transitively on the graph determined by the dependence relation.\nA variable might be divergent at one program point and uniform at another",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#an-example",
    "href": "lectures/diverg.html#an-example",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#section",
    "href": "lectures/diverg.html#section",
    "title": "divergent flow",
    "section": "",
    "text": "##",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#finding-control-dependences",
    "href": "lectures/diverg.html#finding-control-dependences",
    "title": "divergent flow",
    "section": "finding control dependences",
    "text": "finding control dependences\nlet branch p, label be a branch instruction and \\(I_p\\) be its post dominator. A varable v is control dependent on p if\n\nv is defined inside the influence region of p\nv reaches \\(I_p\\)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#some-optimizations",
    "href": "lectures/diverg.html#some-optimizations",
    "title": "divergent flow",
    "section": "some optimizations",
    "text": "some optimizations\n\non AMD use scalar processor\nif a branch condition is uniform no need for a sync in the post dominator\nplace uniform spills in shared memory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#what-is-the-cost-of-divergence",
    "href": "lectures/revealjs_diverg.qmd.html#what-is-the-cost-of-divergence",
    "title": "divergent flow",
    "section": "What is the cost of divergence",
    "text": "What is the cost of divergence\n__global__ void dec2zero(int* v, int N) { \n    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   \n    if (xIndex &lt; N) {\n             while (v[xIndex] &gt; 0) { v[xIndex]--;     \n             }     \n        } \n} \nDepending on how we initialize the vector, we get different times and different subtracts\n\nSize of array 1048576\nThreads Per Block = 256\nBlocks In Grid = 4096"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#some-initializers",
    "href": "lectures/revealjs_diverg.qmd.html#some-initializers",
    "title": "divergent flow",
    "section": "some initializers",
    "text": "some initializers\n  // all 1\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 1; \n  }\n  // subtracts 1048576\n  // time      0.1 ms\n// decreasing values from n-1 to 0\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n - i - 1;  // count should be N*(n+1)/2 = 54975572...\n  }\n  // subtracts 549755289600\n  // time  45.7 ms\n// Fill function to set all elements of the array to the middle value of n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n / 2;  // count should be N*N/2 54975572...\n    // subtracts 549755813888\n    // time  45.6 ms\n// Fill function to set alternate elements to 0 or n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 0;\n    if (i%2){ A[i] = n;} \n    // subtacts 549755813888\n    // time 83.9 ms\n  }"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#divergence-example",
    "href": "lectures/revealjs_diverg.qmd.html#divergence-example",
    "title": "divergent flow",
    "section": "divergence example",
    "text": "divergence example\n```global void example(float* v){ if (v[tid]) &lt; 2.0){ v[tid] = /=2; } else { v[tid] = 0; } }\nand in ptx\n1. b0: r1 = addr v[tid]\n2. f1 = load r1\n3. p1 = set.lt f0, 0.0\n\n5. @p1? Bzr: f2 = div f1, 2\n6. @p1? jmp Bst\n\n7. !@p1? b1: f2 = 0.0\n\n8. Bst: store r1, f2\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nGraph TB\nB0--&gt; Bzr\nB0--&gt; B1\nBzr--&gt; Bst\nb1 --&gt; Bst"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#what-happens-to-implement-this",
    "href": "lectures/revealjs_diverg.qmd.html#what-happens-to-implement-this",
    "title": "divergent flow",
    "section": "what happens to implement this?",
    "text": "what happens to implement this?"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#harware-version-1-pre-volta-nvidia-chips",
    "href": "lectures/revealjs_diverg.qmd.html#harware-version-1-pre-volta-nvidia-chips",
    "title": "divergent flow",
    "section": "harware version 1 (pre volta nvidia chips)",
    "text": "harware version 1 (pre volta nvidia chips)\nThere is a hardware stack called the simt-stack, each entry is a pc and a 32 bit active mask. When hardware reachs an if- push 3 entries pc then, mask for then pc else, mask for else pc reconvergence pt, mask for recovergence\n\n                          t0 t1 t2 t3    stack\na:                        r  r  r  r      a: 1111\n--------------------------------------------------------\n  if (tid% 4 &lt; 2) {       r  r  r  r      b  1100\n                                          c  0011\n                                          f  1111\n----------------------------------------------------------\n    b:                    r r   -  -      c 0011\n    c:                    r r   -  -      f  1111\n-------------------------------------------------\n  } else {                \n    d:                    - -   r r \n    e:                    - -   r r\n  }\n  f:                                    stack is empty    \nat else pc matches tos at f pc matches tos\nrules: 1. divergent paths execute serially 1. threads execute in lock step 1. recoverge at immed post dominator\neasy to find post dominator for reducible control flow\nsome code deadlocks:\n1: *mutex = 0; 2: 3 while(!atomicCAS(mutex,0,1)); 3: // Critical Section 4: atomicExch(mutex,0);"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#volta-and-newer",
    "href": "lectures/revealjs_diverg.qmd.html#volta-and-newer",
    "title": "divergent flow",
    "section": "volta and newer",
    "text": "volta and newer\npossible structure\nHandles unstructured code nicely always makes forward progress\n\n                          t0 t1 t2 t3    \na:                        r  r  r  r      \n--------------------------------------------------------\n  if (tid% 4 &lt; 2) {       r  r  r  r    \n                                                                           \n----------------------------------------------------------\n    b:                    r r   -  -    \n    d:                    - -   r r  \n    c:                    r r   -  -  \n    e:                    - -   r r    \n-------------------------------------------------\n                \n  f:                      r r  --\n                          - -  r r \n   _syncthreads()         r r r r \n  g:             \nadds a new set of registers called barrier registers, which hold the indexes of threads that will synchronize\nnew instructions:\n\nbssy sets a barrier register to a mask of the threads that will need to reconverge (recovergence mask) and specfies the reconvergence point\nbmov copies between barrier registers and regular registers\nbsync forces threads in the mask to wait\nbbreak removes threads from mask"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#what-does-this-solve",
    "href": "lectures/revealjs_diverg.qmd.html#what-does-this-solve",
    "title": "divergent flow",
    "section": "what does this solve",
    "text": "what does this solve\nThe Volta architecture introduces Independent Thread Scheduling among threads in a warp. This feature enables intra-warp synchronization patterns previously unavailable and simplifies code changes when porting CPU code. However, Independent Thread Scheduling can also lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity2 of previous hardware architectures.\nWhen porting existing codes to Volta, the following three code patterns need careful attention. For more details see the CUDA C++ Programming Guide.\nTo avoid data corruption, applications using warp intrinsics (__shfl*, __any, __all, and __ballot) should transition to the new, safe, synchronizing counterparts, with the *_sync suffix. The new warp intrinsics take in a mask of threads that explicitly define which lanes (threads of a warp) must participate in the warp intrinsic.\nApplications that assume reads and writes are implicitly visible to other threads in the same warp need to insert the new __syncwarp() warp-wide barrier synchronization instruction between steps where data is exchanged between threads via global or shared memory. Assumptions that code is executed in lockstep or that reads/writes from separate threads are visible across a warp without synchronization are invalid.\nApplications using __syncthreads() or the PTX bar.sync (and their derivatives) in such a way that a barrier will not be reached by some non-exited thread in the thread block must be modified to ensure that all non-exited threads reach the barrier."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#amd",
    "href": "lectures/revealjs_diverg.qmd.html#amd",
    "title": "divergent flow",
    "section": "AMD",
    "text": "AMD\nAMD implemented the early version. scalar registers are used as an ‘exec mask’ to indicate which vector lanes execute. The simt-stack can be done in software using scalar instructions\nsave the exec mask set exect mask to running threads do the then invert the exec mask if there is an else do the else restore the exec mask"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#static-detection-of-divergences",
    "href": "lectures/revealjs_diverg.qmd.html#static-detection-of-divergences",
    "title": "divergent flow",
    "section": "static detection of divergences",
    "text": "static detection of divergences\ncan we determine which branches may cause divergences and which branches are uniform?\nat a dirergent branch some threads go one way, some the other, we will need to insert instructions for reconvergence at a uniform branch all threads go the same way"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#divergent-and-uniform-variables",
    "href": "lectures/revealjs_diverg.qmd.html#divergent-and-uniform-variables",
    "title": "divergent flow",
    "section": "divergent and uniform variables",
    "text": "divergent and uniform variables\nA program variable is divergent if different threads see different values.\nIf different threads always see that variable with the same value, then the variable is uniform\ndivergent variables\n\nv = tid\natomic()\nv is data dependent on a divergent variable\nv is control dependent on a divergent variable\n\n## thread id is always divergent\n __global__ \n void saxpy (int n, float alpha, float *x, float *y) {\n   int i = blockIdx.x * blockDim.x + threadIdx.x;  \n  if (i &lt; n) y[i] = alpha * x[i] + y[i]; } \nEach thread sees a different value\nThreads in different blocks see the same threadid - is that a problem"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#variables-defined-by-atomic-operations",
    "href": "lectures/revealjs_diverg.qmd.html#variables-defined-by-atomic-operations",
    "title": "divergent flow",
    "section": "variables defined by atomic operations",
    "text": "variables defined by atomic operations\n__global__ void ex_atomic (int index, float* v) {\n   int i = 0; \n   i = ATOMINC( v[index] ); }"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#dependences",
    "href": "lectures/revealjs_diverg.qmd.html#dependences",
    "title": "divergent flow",
    "section": "dependences",
    "text": "dependences\nTwo types of dependences: data and control.\nIf the program contains an assignment such as v = f(v1, v2, …, vn), then v is data dependent on the arguments v1,v2 …\nIf the value assigned to variable v depends on a branch controlled by p, then we say that v is control dependent on p. \nDivergences propagate transitively on the graph determined by the dependence relation.\nA variable might be divergent at one program point and uniform at another"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#an-example",
    "href": "lectures/revealjs_diverg.qmd.html#an-example",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#section",
    "href": "lectures/revealjs_diverg.qmd.html#section",
    "title": "divergent flow",
    "section": "",
    "text": "##"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#finding-control-dependences",
    "href": "lectures/revealjs_diverg.qmd.html#finding-control-dependences",
    "title": "divergent flow",
    "section": "finding control dependences",
    "text": "finding control dependences\nlet branch p, label be a branch instruction and \\(I_p\\) be its post dominator. A varable v is control dependent on p if\n\nv is defined inside the influence region of p\nv reaches \\(I_p\\)"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#some-optimizations",
    "href": "lectures/revealjs_diverg.qmd.html#some-optimizations",
    "title": "divergent flow",
    "section": "some optimizations",
    "text": "some optimizations\n\non AMD use scalar processor\nif a branch condition is uniform no need for a sync in the post dominator\nplace uniform spills in shared memory"
  },
  {
    "objectID": "lectures/04_data_flow.html",
    "href": "lectures/04_data_flow.html",
    "title": "Data Flow",
    "section": "",
    "text": "The material in these slides have been taken from Lecture Notes in Static Analysis” (Sec.6), by Michael I. Schwartzbach, “Principles of Program Analysis”, Chapter 6, by Niesen et al, and from Miachel Schwartzbach’s “Lecture notes in Static Analysis”, Chapter 6, First Section.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#in-and-out",
    "href": "lectures/04_data_flow.html#in-and-out",
    "title": "Data Flow",
    "section": "IN and OUT",
    "text": "IN and OUT",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#equations",
    "href": "lectures/04_data_flow.html#equations",
    "title": "Data Flow",
    "section": "EQUATIONS",
    "text": "EQUATIONS",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#liveness-example",
    "href": "lectures/04_data_flow.html#liveness-example",
    "title": "Data Flow",
    "section": "Liveness Example",
    "text": "Liveness Example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#summary-by-basic-blocks",
    "href": "lectures/04_data_flow.html#summary-by-basic-blocks",
    "title": "Data Flow",
    "section": "Summary by basic blocks",
    "text": "Summary by basic blocks\nThe dataflow equations used for a given basic block b and exiting block final in live variable analysis:\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b\nThe in-state of a block is the set of variables that are live at the start of the block. Its out-state is the set of variables that are live at the end of it. The out-state is the union of the in-states of the block’s successors. The transfer function of a statement is applied by making the variables that are written dead, then making the variables that are read live.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#equations-1",
    "href": "lectures/04_data_flow.html#equations-1",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n$\n\\[\\begin{aligned}\n  & \\operatorname{IN}[b]=\\operatorname{GEN}[b] \\cup\\left(\\operatorname{OUT}[b]-\\operatorname{KILL}[s]\\right) \\\\\n  & \\operatorname{OUT}[\\text { final }]=\\emptyset \\\\\n  & \\operatorname{OUT}[b]=\\bigcup_{p \\in s u c c[b]} \\operatorname{IN}[p] \\\\\n  & \\operatorname{GEN}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\left\\{x_1, \\ldots, x_n\\right\\} \\\\\n  & \\operatorname{KILL}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\{y\\}\n\n\\end{aligned}\\]\n$",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#an-example",
    "href": "lectures/04_data_flow.html#an-example",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nb1: \na = 3\nb = 5\nd = 4\nx = 100\nif a &gt; b then \n\n   b2: \n    c = a + b\n    d = 2 \n\nb3: \n   c = 4\n   return b*d +c\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b\n\nGEN[b1] = []         kill[b1] = [a,b,d,x]\nGEN[b2] = [a,b]      kill[b2] = [c,d]\nGEN[b3] = [b,d]      Kill[b3] = [c]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#processing",
    "href": "lectures/04_data_flow.html#processing",
    "title": "Data Flow",
    "section": "processing",
    "text": "processing\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\nGEN[b1] = []         kill[b1] = [a,b,d,x]\nGEN[b2] = [a,b]      kill[b2] = [c,d]\nGEN[b3] = [b,d]      Kill[b3] = [c]\nblock OUT       IN   Next IN        worklist  \nb3    []        []    [b,d]           b1,b2\nb1    [b,d]     []    []              b2\nb2    [b,d]     []    [a,b]           b1\nb1    [a,b,d]   []    []              empty",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#frameworks",
    "href": "lectures/04_data_flow.html#frameworks",
    "title": "Data Flow",
    "section": "frameworks",
    "text": "frameworks",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#common-properties-direction",
    "href": "lectures/04_data_flow.html#common-properties-direction",
    "title": "Data Flow",
    "section": "common properties Direction",
    "text": "common properties Direction\nDirection\n\n\nbackward\n\nliveness\nvery busy expressions\n\nOUT is a function of the IN of successors\n\nforward\n\nreaching Defs\nAvailable Expressions\n\nIN is a function of the OUT of Preds",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#common-properties-operation",
    "href": "lectures/04_data_flow.html#common-properties-operation",
    "title": "Data Flow",
    "section": "common properties Operation",
    "text": "common properties Operation\n\n\nMay union\n\nLiveness\nReaching defs\n\nmerge using intersection\n\nmust\n\nvery busy expressions\nAvailable Expressions\n\nmerge using union",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#transfer-functions-with-a-block-or-for-one-statement",
    "href": "lectures/04_data_flow.html#transfer-functions-with-a-block-or-for-one-statement",
    "title": "Data Flow",
    "section": "transfer functions with a block or for one statement",
    "text": "transfer functions with a block or for one statement\nForward\n\\[ \\text{OUT}_b = f_b(\\text{IN}_b) \\]\nBackward\n\\[ \\text{IN}_b = f_b(\\text{OUT}_b) \\]\nliveness IN = (OUT-def) union (args)\nVery busy expressions IN = (OUT - exprs(def)) union (this expr)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#an-example-1",
    "href": "lectures/04_data_flow.html#an-example-1",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nif b1 \n    while b2 { x = a1}\nelse \n    while b3 { x = a2}\nx = a3\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\nreaching defs - a definition of a variable v at pv reaches a point p if there is a path from pv tp p and v is not redefined along the path",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#equations-2",
    "href": "lectures/04_data_flow.html#equations-2",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\n\n\n\\[ \\small \\text{IN}_p = \\bigcup \\text{OUT}_{ps}, ps \\in pred(p)\\]\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\n\n\n\\[ \\small \\text{OUT}_p = (\\text{IN)}_p - defs(v)) \\cup \\{ (p,v) \\}  \\]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#complexity",
    "href": "lectures/04_data_flow.html#complexity",
    "title": "Data Flow",
    "section": "complexity",
    "text": "complexity",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#graph-of-equations",
    "href": "lectures/04_data_flow.html#graph-of-equations",
    "title": "Data Flow",
    "section": "graph of equations",
    "text": "graph of equations\n\n\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#reverse-postorder",
    "href": "lectures/04_data_flow.html#reverse-postorder",
    "title": "Data Flow",
    "section": "Reverse Postorder",
    "text": "Reverse Postorder\nvisit successors first (need an ordering)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#order",
    "href": "lectures/04_data_flow.html#order",
    "title": "Data Flow",
    "section": "order",
    "text": "order\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n\n\n\norder b5 b6 b3 b3 b2 b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#implement",
    "href": "lectures/04_data_flow.html#implement",
    "title": "Data Flow",
    "section": "implement",
    "text": "implement\nkeep two data structures\n\nC current list\nP set of pending lists\n\ninitially C is a reverse post order sort of the nodes\nprocess each element of C\nwhen we find a changed add it to P\nWhen C is empty, sort P in reverse post order and move to C",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#representing-sets",
    "href": "lectures/04_data_flow.html#representing-sets",
    "title": "Data Flow",
    "section": "representing sets",
    "text": "representing sets\nwe keep doing union and intersection for sets, which are sparse\ncompilers generally use bit vectors",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#pseudo-code",
    "href": "lectures/04_data_flow.html#pseudo-code",
    "title": "Data Flow",
    "section": "pseudo code",
    "text": "pseudo code\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#loops",
    "href": "lectures/04_data_flow.html#loops",
    "title": "Data Flow",
    "section": "loops",
    "text": "loops\nThis algorithm has no problems with loops!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#homework-3",
    "href": "lectures/04_data_flow.html#homework-3",
    "title": "Data Flow",
    "section": "homework 3",
    "text": "homework 3\nImplement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it. use a simple ordering- Not necessary to use reverse post order\nas always think about testing",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#in-and-out",
    "href": "lectures/revealjs_04_data_flow.qmd.html#in-and-out",
    "title": "Data Flow",
    "section": "IN and OUT",
    "text": "IN and OUT"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#equations",
    "href": "lectures/revealjs_04_data_flow.qmd.html#equations",
    "title": "Data Flow",
    "section": "EQUATIONS",
    "text": "EQUATIONS"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#liveness-example",
    "href": "lectures/revealjs_04_data_flow.qmd.html#liveness-example",
    "title": "Data Flow",
    "section": "Liveness Example",
    "text": "Liveness Example"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#summary-by-basic-blocks",
    "href": "lectures/revealjs_04_data_flow.qmd.html#summary-by-basic-blocks",
    "title": "Data Flow",
    "section": "Summary by basic blocks",
    "text": "Summary by basic blocks\nThe dataflow equations used for a given basic block b and exiting block final in live variable analysis:\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b\nThe in-state of a block is the set of variables that are live at the start of the block. Its out-state is the set of variables that are live at the end of it. The out-state is the union of the in-states of the block’s successors. The transfer function of a statement is applied by making the variables that are written dead, then making the variables that are read live."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#equations-1",
    "href": "lectures/revealjs_04_data_flow.qmd.html#equations-1",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n$\n\\[\\begin{aligned}\n  & \\operatorname{IN}[b]=\\operatorname{GEN}[b] \\cup\\left(\\operatorname{OUT}[b]-\\operatorname{KILL}[s]\\right) \\\\\n  & \\operatorname{OUT}[\\text { final }]=\\emptyset \\\\\n  & \\operatorname{OUT}[b]=\\bigcup_{p \\in s u c c[b]} \\operatorname{IN}[p] \\\\\n  & \\operatorname{GEN}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\left\\{x_1, \\ldots, x_n\\right\\} \\\\\n  & \\operatorname{KILL}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\{y\\}\n\n\\end{aligned}\\]\n$"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#an-example",
    "href": "lectures/revealjs_04_data_flow.qmd.html#an-example",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nb1: \na = 3\nb = 5\nd = 4\nx = 100\nif a &gt; b then \n\n   b2: \n    c = a + b\n    d = 2 \n\nb3: \n   c = 4\n   return b*d +c\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#processing",
    "href": "lectures/revealjs_04_data_flow.qmd.html#processing",
    "title": "Data Flow",
    "section": "processing",
    "text": "processing\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\nGEN[b1] = []         kill[b1] = [a,b,d,x]\nGEN[b2] = [a,b]      kill[b2] = [c,d]\nGEN[b3] = [b,d]      Kill[b3] = [c]\nblock OUT       IN   Next IN        worklist  \nb3    []        []    [b,d]           b1,b2\nb1    [b,d]     []    []              b2\nb2    [b,d]     []    [a,b]           b1\nb1    [a,b,d]   []    []              empty"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#frameworks",
    "href": "lectures/revealjs_04_data_flow.qmd.html#frameworks",
    "title": "Data Flow",
    "section": "frameworks",
    "text": "frameworks"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#common-properties-direction",
    "href": "lectures/revealjs_04_data_flow.qmd.html#common-properties-direction",
    "title": "Data Flow",
    "section": "common properties Direction",
    "text": "common properties Direction\nDirection\n\n\nbackward\n\nliveness\nvery busy expressions\n\nOUT is a function of the IN of successors\n\nforward\n\nreaching Defs\nAvailable Expressions\n\nIN is a function of the OUT of Preds"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#common-properties-operation",
    "href": "lectures/revealjs_04_data_flow.qmd.html#common-properties-operation",
    "title": "Data Flow",
    "section": "common properties Operation",
    "text": "common properties Operation\n\n\nMay union\n\nLiveness\nReaching defs\n\nmerge using intersection\n\nmust\n\nvery busy expressions\nAvailable Expressions\n\nmerge using union"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#transfer-functions-with-a-block-or-for-one-statement",
    "href": "lectures/revealjs_04_data_flow.qmd.html#transfer-functions-with-a-block-or-for-one-statement",
    "title": "Data Flow",
    "section": "transfer functions with a block or for one statement",
    "text": "transfer functions with a block or for one statement\nForward\n\\[ \\text{OUT}_b = f_b(\\text{IN}_b) \\]\nBackward\n\\[ \\text{IN}_b = f_b(\\text{OUT}_b) \\]\nliveness IN = (OUT-def) union (args)\nVery busy expressions IN = (OUT - exprs(def)) union (this expr)"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#an-example-1",
    "href": "lectures/revealjs_04_data_flow.qmd.html#an-example-1",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nif b1 \n    while b2 { x = a1}\nelse \n    while b3 { x = a2}\nx = a3\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\nreaching defs - a definition of a variable v at pv reaches a point p if there is a path from pv tp p and v is not redefined along the path"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#equations-2",
    "href": "lectures/revealjs_04_data_flow.qmd.html#equations-2",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\n\n\n\\[ \\small \\text{IN}_p = \\bigcup \\text{OUT}_{ps}, ps \\in pred(p)\\]\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\n\n\n\\[ \\small \\text{OUT}_p = (\\text{IN)}_p - defs(v)) \\cup \\{ (p,v) \\}  \\]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#complexity",
    "href": "lectures/revealjs_04_data_flow.qmd.html#complexity",
    "title": "Data Flow",
    "section": "complexity",
    "text": "complexity"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#graph-of-equations",
    "href": "lectures/revealjs_04_data_flow.qmd.html#graph-of-equations",
    "title": "Data Flow",
    "section": "graph of equations",
    "text": "graph of equations\n\n\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#reverse-postorder",
    "href": "lectures/revealjs_04_data_flow.qmd.html#reverse-postorder",
    "title": "Data Flow",
    "section": "Reverse Postorder",
    "text": "Reverse Postorder\nvisit successors first (need an ordering)"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#order",
    "href": "lectures/revealjs_04_data_flow.qmd.html#order",
    "title": "Data Flow",
    "section": "order",
    "text": "order\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n\n\n\norder b5 b6 b3 b3 b2 b1"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#implement",
    "href": "lectures/revealjs_04_data_flow.qmd.html#implement",
    "title": "Data Flow",
    "section": "implement",
    "text": "implement\nkeep two data structures\n\nC current list\nP set of pending lists\n\ninitially C is a reverse post order sort of the nodes\nprocess each element of C\nwhen we find a changed add it to P\nWhen C is empty, sort P in reverse post order and move to C"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#representing-sets",
    "href": "lectures/revealjs_04_data_flow.qmd.html#representing-sets",
    "title": "Data Flow",
    "section": "representing sets",
    "text": "representing sets\nwe keep doing union and intersection for sets, which are sparse\ncompilers generally use bit vectors"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#pseudo-code",
    "href": "lectures/revealjs_04_data_flow.qmd.html#pseudo-code",
    "title": "Data Flow",
    "section": "pseudo code",
    "text": "pseudo code\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#loops",
    "href": "lectures/revealjs_04_data_flow.qmd.html#loops",
    "title": "Data Flow",
    "section": "loops",
    "text": "loops\nThis algorithm has no problems with loops!"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#homework-3",
    "href": "lectures/revealjs_04_data_flow.qmd.html#homework-3",
    "title": "Data Flow",
    "section": "homework 3",
    "text": "homework 3\nImplement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it. use a simple ordering- Not necessary to use reverse post order\nas always think about testing"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html",
    "href": "lectures/03b_local_value_numbering.html",
    "title": "local value numbering",
    "section": "",
    "text": "slides from Phil Gibbons at CMU for more details and context on LVN\nValue numbering is a very powerful technique that removes redundancies, An instruction x + y is redundant inside a block if it has already been computed in the block, and no intervening operation redefines x or y. If the compiler finds a redundant expression, it can save that value at the first computation and replace any subsequent evaluations with references to the saved value.\n\nThe idea is simple - The algorithm executes the block, Each time it sees a new variable it gives it a value (represented as a number)\nEach time it sees an instruction it forms a hash of the op code and the value numbers of its operands and gives it a new value number.\nTwo instructions are redundant if they have same op code and operands, which means the same value number\n\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "href": "lectures/03b_local_value_numbering.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "title": "local value numbering",
    "section": "local value numbering covers lot of optimizations that look different",
    "text": "local value numbering covers lot of optimizations that look different\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#variables-vis-values",
    "href": "lectures/03b_local_value_numbering.html#variables-vis-values",
    "title": "local value numbering",
    "section": "variables vis values",
    "text": "variables vis values\nWe want to stop thinking about variables and think about values. Two instructions are redundant if they compute the same value.\n\nfor example in a JIT compiler we want computation to be fast so we can get rid of all the variables\nb: int const 1;\nc: int cont 2;\na:  int b c;  \nbecomes:\n[  int const 1\n   int const 2 \n   int 0 1\n]\nless storage, args are just pointers, instructions are smaller. faster because any use points to the corresponding def without any searching.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#value-numbering-continued",
    "href": "lectures/03b_local_value_numbering.html#value-numbering-continued",
    "title": "local value numbering",
    "section": "value numbering continued",
    "text": "value numbering continued",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#use-of-turnt",
    "href": "lectures/03b_local_value_numbering.html#use-of-turnt",
    "title": "local value numbering",
    "section": "use of turnt ",
    "text": "use of turnt \nturnt\nthere is a directory   bril/examples/test/tdce   which has some test programs \nand a file turnt.toml  that contains  one line \ncommand = “bril2json &lt; {filename} | python3 ../../tdce.py {args} | bril2txt”\nto execute \n(.venv) (base) norm@norm-ubuntu:~/bril/examples/test/tdce$ turnt *.bril 1..8 ok 1 - combo.bril ok 2 - diamond.bril ok 3 - double.bril ok 4 - double-pass.bril ok 5 - reassign.bril ok 6 - reassign-dkp.bril ok 7 - simple.bril ok 8 - skipped.bril",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#redundancy-elimination",
    "href": "lectures/03b_local_value_numbering.html#redundancy-elimination",
    "title": "local value numbering",
    "section": "redundancy elimination",
    "text": "redundancy elimination\nan expression x+y is redundant if and only if\n\nalong every path from the entry it has been evaluated and\nits subexpressions x and y have not been redefined\n\nif the compiler can prove an expression is redundant it can\n\npreserve the earlier evaluation\nreplace the redundant expression with a use of the preserved value",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#key-idea",
    "href": "lectures/03b_local_value_numbering.html#key-idea",
    "title": "local value numbering",
    "section": "key idea",
    "text": "key idea\nassign a number (value number) to each expression\n\ntwo expressions have the same value number if they always have the same value\nuse hashing to make this efficient",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#pseudo-code",
    "href": "lectures/03b_local_value_numbering.html#pseudo-code",
    "title": "local value numbering",
    "section": "pseudo code",
    "text": "pseudo code\nwalk each block, assign a distinct value number to each value the block computes.\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#pseudo-code-vn-version-1",
    "href": "lectures/03b_local_value_numbering.html#pseudo-code-vn-version-1",
    "title": "local value numbering",
    "section": "pseudo code vn version 1",
    "text": "pseudo code vn version 1\nwe have two tables - hash_table: expression to vn, variable holding the value variable to vn\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest \nAn example\na add b, c \nb sub a, d \nc add b, c\nd sub a, d  // d id b\nitem   vn       hash \nb      0/4\nc      1/5\n                add12  2    a \na      2 \nd      3\n\n                sub23 4     b\n                add41 5     c\n                \nPseudo code (similar to an interpreter)\n\nhash table constants and expressions of value numbers to value numbers and to a variable holding the value\nreverse map from variables to value numbers\n\n\n\n\n  main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mult sum1 sum2;\n    print prod\n\n  }\n\n\n\n\nkey\nvalue\ncanonical name\n\n\n\n\nconst 4\n1\na\n\n\nconst 2\n2\nb\n\n\nadd 1 2\n3\nsum1\n\n\nmul 3 3\n4\nprod\n\n\n\n\n\n\nname\nvalue\n\n\n\n\na\n1\n\n\nb\n2\n\n\nsum1\n3\n\n\nsum2\n3\n\n\nprod\n4\n\n\n\n\n\nextensions:\n\na: int id b\n\na gets the value number of b. No copy required\nCommutative operations Commutative operations that differ only in the order of their operands, such as a × b and b × a, should receive the same value numbers. As lvn constructs a hash key for the right-hand side of the current operation, it can sort the operands using some convenient scheme, such as ordering them by value number. This simple action will ensure that commutative variants receive the same value number.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#extension",
    "href": "lectures/03b_local_value_numbering.html#extension",
    "title": "local value numbering",
    "section": "extension",
    "text": "extension\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\nConstant folding If all the operands of an operation have known constant values, lvn can perform the operation and fold the answer directly into the code. lvn can store information about constants in the hash table, including their value. Before hash-key formation, it can test the operands and, if possible, evaluate them. If lvn discovers a constant expression, it can replace the operation with an immediate load of the result. Subsequent copy folding will clean up the code.\nAlgebraic identities: lvn can apply algebraic identities to simplify the code. For example, x + 0 and x should receive the same value number. Unfortunately, lvn needs special-case code for each identity. A series of tests, one per identity, can easily become long enough to produce an unacceptable slowdown in the algorithm. To ameliorate this problem, lvn should organize the tests into operator-specific decision trees.\na +0, a-0, a1 a0, a-a",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#vn-version-2",
    "href": "lectures/03b_local_value_numbering.html#vn-version-2",
    "title": "local value numbering",
    "section": "vn version 2",
    "text": "vn version 2\nadd a bit indicating that a variable is a constant\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  if all v's are constants, fold the operation \n  check for all the identities \n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#problem",
    "href": "lectures/03b_local_value_numbering.html#problem",
    "title": "local value numbering",
    "section": "problem:",
    "text": "problem:\na = x +y \nb = x + y\na = 17\nc = x +y \nkeep track of all variables that contain the value and select one\none option is to save the value, if x will be overwritten add a temp\nt = a+b\nx = t \nx = \n  = t",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#another-option-is-renaming",
    "href": "lectures/03b_local_value_numbering.html#another-option-is-renaming",
    "title": "local value numbering",
    "section": "another option is renaming",
    "text": "another option is renaming\n\n\na = x + y\nb = x + y\na = 17\nc = x +Y\n\na0 = x0 + y0\nb0 = x0+ y0\na1 = 17\nc0 = x0 +y0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#indirect-assignments",
    "href": "lectures/03b_local_value_numbering.html#indirect-assignments",
    "title": "local value numbering",
    "section": "indirect assignments",
    "text": "indirect assignments\nassignments via a pointer, or to an array element\na = b[i]\n...       no change to i \nc = b[i]\n\n\na = b[i]\ni=\nc = b[i]\n\n\na = b[i]\nb[k] =\n   =b[i]\n   =b[k]\nindexed stores\nwhen we see an assignment a[i] = exp\nwe have 3 value numbers a, i, exp\ngive the array a new value number give the array[i] operation the value number of the exp",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#local-value-numbering.",
    "href": "lectures/03b_local_value_numbering.html#local-value-numbering.",
    "title": "local value numbering",
    "section": "Local value numbering.",
    "text": "Local value numbering.\nYou can see one implementation in lvn.py in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#testing-your-optimizations",
    "href": "lectures/03b_local_value_numbering.html#testing-your-optimizations",
    "title": "local value numbering",
    "section": "Testing Your Optimizations",
    "text": "Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time.\n\n\nAs with every task in this class, part of the work is checking that you have done what you set out to do — in this case, that your optimizations do those two things.\nThink carefully about how to make a convincing case for each of those criteria.\n\nOne tempting methodology might be to hand write a few small test-case Bril programs (or, worse, borrow the woefully inadequate ones sitting around in the Bril git repository), run them through your optimizations, and look at them to check whether they look right. This does not amount to convincing evidence (maybe you can think of a few specific reasons why).\n\nWhile there are many ways to be convincing, a pretty good way might be to run your optimization on *every single available Bril benchmark, systematically check that it still produces the right output for at least one input, and collect aggregate statistics about some metric you’re interested in. This is a nice way to check for unexpected behavior in programs that you didn’t carefully write yourself to test the cases you’re thinking of.\n\nIf this is the route you choose, you can do it however you like, There is a simple tool that you can consider using, called Brench. Brench is not very fancy; it does three things:\n\nIt makes it easy to run a long list of inputs through several different commands. (For example, you can run a long list of Bril benchmarks through an “interpret” command and an “optimize-and-then-interpret” command.)\nIt checks that all the commands agree on their output. (So, in our use case, it checks that optimizing the benchmark doesn’t change its output when interpreted.)\nIt can collect a statistic from each command for comparison. (Like the number of dynamic instructions the interpreter executed, which is a pretty good metric for standard optimizations.)\n\nThose three things are probably what you want to do to make a convincing case for an optimization’s correctness and effectiveness, whether or not you use Brench. It’s there if you want it, but feel free to go your own way!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#homework-2",
    "href": "lectures/03b_local_value_numbering.html#homework-2",
    "title": "local value numbering",
    "section": "homework 2",
    "text": "homework 2\npart 1: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned.\npart2: Implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\nremember that the result is a blog post",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#crossing-blocks",
    "href": "lectures/03b_local_value_numbering.html#crossing-blocks",
    "title": "local value numbering",
    "section": "crossing blocks",
    "text": "crossing blocks\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#extended-basic-blocks",
    "href": "lectures/03b_local_value_numbering.html#extended-basic-blocks",
    "title": "local value numbering",
    "section": "extended basic blocks",
    "text": "extended basic blocks\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n\n\nhow do we extend the hash tables over the boundary\nwe need to do value numbering over each path\nworklist = {entry block}\nstack = {}\nwhile worklist is not empty \n   remove a block b from the worklist \n   evn(b)\n\nevn(b, stack)\n   t = new table for b  \n   link t above stack  \n   lvn(b,t) \n   for each s successor of b,\n     if s has one pred then evn(s, t)\n     else add s to worklist \n   dealocate t",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#safety",
    "href": "lectures/03b_local_value_numbering.html#safety",
    "title": "local value numbering",
    "section": "safety",
    "text": "safety\nif the result of evaluating E1 cannot be distinguished from evaluating E the compiler is free to replace E with E1\nSome compilers assume it is ok if E1 produces less errors than E\nsome compilers assume that safety is only required for “standard conforming” code and undefined behavior for other code.\nWhy is value numbering safe?\n\nif an expression is in the hash table, it must have occurred at least one in the block\nAlgorithm modified the code but does not invalidate the table",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#when-is-value-numbering-profitable",
    "href": "lectures/03b_local_value_numbering.html#when-is-value-numbering-profitable",
    "title": "local value numbering",
    "section": "when is value numbering profitable",
    "text": "when is value numbering profitable\nif reuse is cheaper then re-compute 1. does not cause a spill 1. if does not need a copy (does the copy take as long as the compute)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "title": "local value numbering",
    "section": "local value numbering covers lot of optimizations that look different",
    "text": "local value numbering covers lot of optimizations that look different\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#variables-vis-values",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#variables-vis-values",
    "title": "local value numbering",
    "section": "variables vis values",
    "text": "variables vis values\nWe want to stop thinking about variables and think about values. Two instructions are redundant if they compute the same value."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#value-numbering-continued",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#value-numbering-continued",
    "title": "local value numbering",
    "section": "value numbering continued",
    "text": "value numbering continued"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#use-of-turnt",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#use-of-turnt",
    "title": "local value numbering",
    "section": "use of turnt ",
    "text": "use of turnt \nturnt\nthere is a directory   bril/examples/test/tdce   which has some test programs \nand a file turnt.toml  that contains  one line \ncommand = “bril2json &lt; {filename} | python3 ../../tdce.py {args} | bril2txt”\nto execute \n(.venv) (base) norm@norm-ubuntu:~/bril/examples/test/tdce$ turnt *.bril 1..8 ok 1 - combo.bril ok 2 - diamond.bril ok 3 - double.bril ok 4 - double-pass.bril ok 5 - reassign.bril ok 6 - reassign-dkp.bril ok 7 - simple.bril ok 8 - skipped.bril"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#redundancy-elimination",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#redundancy-elimination",
    "title": "local value numbering",
    "section": "redundancy elimination",
    "text": "redundancy elimination\nan expression x+y is redundant if and only if\n\nalong every path from the entry it has been evaluated and\nits subexpressions x and y have not been redefined\n\nif the compiler can prove an expression is redundant it can\n\npreserve the earlier evaluation\nreplace the redundant expression with a use of the preserved value"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#key-idea",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#key-idea",
    "title": "local value numbering",
    "section": "key idea",
    "text": "key idea\nassign a number (value number) to each expression\n\ntwo expressions have the same value number if they always have the same value\nuse hashing to make this efficient"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code",
    "title": "local value numbering",
    "section": "pseudo code",
    "text": "pseudo code\nwalk each block, assign a distinct value number to each value the block computes.\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code-vn-version-1",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code-vn-version-1",
    "title": "local value numbering",
    "section": "pseudo code vn version 1",
    "text": "pseudo code vn version 1\nwe have two tables - hash_table: expression to vn, variable holding the value variable to vn\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest \nAn example\na add b, c \nb sub a, d \nc add b, c\nd sub a, d  // d id b\nitem   vn       hash \nb      0/4\nc      1/5\n                add12  2    a \na      2 \nd      3\n\n                sub23 4     b\n                add41 5     c\n                \nPseudo code (similar to an interpreter)\n\nhash table constants and expressions of value numbers to value numbers and to a variable holding the value\nreverse map from variables to value numbers"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#extension",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#extension",
    "title": "local value numbering",
    "section": "extension",
    "text": "extension\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\nConstant folding If all the operands of an operation have known constant values, lvn can perform the operation and fold the answer directly into the code. lvn can store information about constants in the hash table, including their value. Before hash-key formation, it can test the operands and, if possible, evaluate them. If lvn discovers a constant expression, it can replace the operation with an immediate load of the result. Subsequent copy folding will clean up the code.\nAlgebraic identities: lvn can apply algebraic identities to simplify the code. For example, x + 0 and x should receive the same value number. Unfortunately, lvn needs special-case code for each identity. A series of tests, one per identity, can easily become long enough to produce an unacceptable slowdown in the algorithm. To ameliorate this problem, lvn should organize the tests into operator-specific decision trees.\na +0, a-0, a1 a0, a-a"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#vn-version-2",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#vn-version-2",
    "title": "local value numbering",
    "section": "vn version 2",
    "text": "vn version 2\nadd a bit indicating that a variable is a constant\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  if all v's are constants, fold the operation \n  check for all the identities \n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#problem",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#problem",
    "title": "local value numbering",
    "section": "problem:",
    "text": "problem:\na = x +y \nb = x + y\na = 17\nc = x +y \nkeep track of all variables that contain the value and select one\none option is to save the value, if x will be overwritten add a temp\nt = a+b\nx = t \nx = \n  = t"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#another-option-is-renaming",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#another-option-is-renaming",
    "title": "local value numbering",
    "section": "another option is renaming",
    "text": "another option is renaming\n\n\na = x + y\nb = x + y\na = 17\nc = x +Y\n\na0 = x0 + y0\nb0 = x0+ y0\na1 = 17\nc0 = x0 +y0"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#indirect-assignments",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#indirect-assignments",
    "title": "local value numbering",
    "section": "indirect assignments",
    "text": "indirect assignments\nassignments via a pointer, or to an array element\na = b[i]\n...       no change to i \nc = b[i]\n\n\na = b[i]\ni=\nc = b[i]\n\n\na = b[i]\nb[k] =\n   =b[i]\n   =b[k]\nindexed stores\nwhen we see an assignment a[i] = exp\nwe have 3 value numbers a, i, exp\ngive the array a new value number give the array[i] operation the value number of the exp"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering.",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering.",
    "title": "local value numbering",
    "section": "Local value numbering.",
    "text": "Local value numbering.\nYou can see one implementation in lvn.py in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#testing-your-optimizations",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#testing-your-optimizations",
    "title": "local value numbering",
    "section": "Testing Your Optimizations",
    "text": "Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#homework-2",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#homework-2",
    "title": "local value numbering",
    "section": "homework 2",
    "text": "homework 2\npart 1: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned.\npart2: Implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\nremember that the result is a blog post"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#crossing-blocks",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#crossing-blocks",
    "title": "local value numbering",
    "section": "crossing blocks",
    "text": "crossing blocks\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#extended-basic-blocks",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#extended-basic-blocks",
    "title": "local value numbering",
    "section": "extended basic blocks",
    "text": "extended basic blocks\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n\n\nhow do we extend the hash tables over the boundary\nwe need to do value numbering over each path\nworklist = {entry block}\nstack = {}\nwhile worklist is not empty \n   remove a block b from the worklist \n   evn(b)\n\nevn(b, stack)\n   t = new table for b  \n   link t above stack  \n   lvn(b,t) \n   for each s successor of b,\n     if s has one pred then evn(s, t)\n     else add s to worklist \n   dealocate t"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#safety",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#safety",
    "title": "local value numbering",
    "section": "safety",
    "text": "safety\nif the result of evaluating E1 cannot be distinguished from evaluating E the compiler is free to replace E with E1\nSome compilers assume it is ok if E1 produces less errors than E\nsome compilers assume that safety is only required for “standard conforming” code and undefined behavior for other code.\nWhy is value numbering safe?\n\nif an expression is in the hash table, it must have occurred at least one in the block\nAlgorithm modified the code but does not invalidate the table"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#when-is-value-numbering-profitable",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#when-is-value-numbering-profitable",
    "title": "local value numbering",
    "section": "when is value numbering profitable",
    "text": "when is value numbering profitable\nif reuse is cheaper then re-compute 1. does not cause a spill 1. if does not need a copy (does the copy take as long as the compute)"
  },
  {
    "objectID": "lectures/07_llvm.html",
    "href": "lectures/07_llvm.html",
    "title": "7 LLVM",
    "section": "",
    "text": "intro to llvm\ndifference between bril and llvm\nhandy links\nllvm programmers guid\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n/bin/bash: line 1: /home/norm/pw: No such file or directory\n/bin/bash: line 1: /home/norm/pw: No such file or directory\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "7 LLVM"
    ]
  },
  {
    "objectID": "lectures/100_mlir.html",
    "href": "lectures/100_mlir.html",
    "title": "10 MLIR",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "10 MLIR"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html",
    "href": "lectures/mem_consistancy.html",
    "title": "memory consistancy",
    "section": "",
    "text": "Compilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#multi-threaded-programs",
    "href": "lectures/mem_consistancy.html#multi-threaded-programs",
    "title": "memory consistancy",
    "section": "",
    "text": "Compilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#shared-memory-multi-threading",
    "href": "lectures/mem_consistancy.html#shared-memory-multi-threading",
    "title": "memory consistancy",
    "section": "shared memory multi-threading",
    "text": "shared memory multi-threading\nThe most common parallel system is\n\nA single big memory\nmultiple threads address that memory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#what-is-sequential-consistency-sq",
    "href": "lectures/mem_consistancy.html#what-is-sequential-consistency-sq",
    "title": "memory consistancy",
    "section": "what is sequential consistency SQ",
    "text": "what is sequential consistency SQ\nProgram Order is Maintained Within Threads:\nOperations (reads and writes) appear to occur in the order they are issued by each individual thread. If a thread performs a write followed by a read, the read cannot appear to happen before the write in the execution.\nGlobal Order of Operations Across Threads:\nAll threads see the effects of memory operations in the same sequential order. Every thread agrees on the order of reads and writes, though the specific order is not predefined—it just needs to be consistent across all threads. Interleaving of Operations:\nThe execution can be viewed as an interleaving of instructions from all threads. However, the interleaving must follow the program order within each thread.\nno real machine/compiler implements this",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#compiler-effects",
    "href": "lectures/mem_consistancy.html#compiler-effects",
    "title": "memory consistancy",
    "section": "compiler effects",
    "text": "compiler effects\nCompiler transformations that break multi-thread sequential consistency (SC) often reorder or optimize instructions in ways that do not respect the original program order seen by other threads. These transformations can lead to subtle bugs in multithreaded programs where the expected interleaving of operations is violated.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#loadstore-reordering",
    "href": "lectures/mem_consistancy.html#loadstore-reordering",
    "title": "memory consistancy",
    "section": "Load/Store Reordering",
    "text": "Load/Store Reordering\nTransformation: Compilers might reorder loads and stores to improve performance. Violation: In a multi-threaded environment, this can lead to a situation where one thread sees stale or unexpected data. Example:\nCopy code\n// Thread 1\nx = 1;     // Store\nr1 = y;    // Load\n\n// Thread 2\ny = 1;     // Store\nr2 = x;    // Load\nUnder sequential consistency, if thread 1’s x = 1 happens before thread 2’s r2 = x, then thread 2 should observe r2 == 1. But reordering could result in thread 2 reading x as 0.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#common-subexpression-elimination-cse",
    "href": "lectures/mem_consistancy.html#common-subexpression-elimination-cse",
    "title": "memory consistancy",
    "section": "Common Subexpression Elimination (CSE)",
    "text": "Common Subexpression Elimination (CSE)\nTransformation: If a variable or expression is computed multiple times, the compiler may optimize by reusing the result of an earlier computation. Violation: This assumes that no other thread modifies shared variables between these uses. Example:\n// Original code\nr1 = x;\nr2 = x;\n\n// Transformed code (CSE applied)\ntemp = x;\nr1 = temp;\nr2 = temp;\nIf x is modified by another thread between the two reads, the transformed code will incorrectly assume the value of x hasn’t changed.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#dead-code-elimination-dce",
    "href": "lectures/mem_consistancy.html#dead-code-elimination-dce",
    "title": "memory consistancy",
    "section": "Dead Code Elimination (DCE)",
    "text": "Dead Code Elimination (DCE)\nTransformation: The compiler may remove stores to variables that are not subsequently read in the same thread. Violation: If the variable is shared and accessed by other threads, removing the store could lead to unexpected behavior. Example:\n// Original code\nx = 1;\n\n// Transformed code (DCE applied)\n// x = 1 is removed because x is not used locally If another thread reads x, it expects the store to have happened, but DCE breaks this assumption.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#speculative-execution-out-of-order-execution",
    "href": "lectures/mem_consistancy.html#speculative-execution-out-of-order-execution",
    "title": "memory consistancy",
    "section": "Speculative Execution (Out-of-Order Execution)",
    "text": "Speculative Execution (Out-of-Order Execution)\nTransformation: Compilers (or hardware) may execute instructions speculatively, assuming certain branches are likely to be taken. Violation: This can cause out-of-order writes or reads visible to other threads, breaking SC. Example:\nif (flag) {\n    r1 = x;\n}\nIf the compiler speculatively reads x before knowing the value of flag, another thread’s write to x might be missed or observed out-of-order.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#loop-invariant-code-motion",
    "href": "lectures/mem_consistancy.html#loop-invariant-code-motion",
    "title": "memory consistancy",
    "section": "Loop Invariant Code Motion",
    "text": "Loop Invariant Code Motion\nTransformation: The compiler moves computations that are invariant inside a loop to outside the loop. Violation: If these computations involve shared variables modified by other threads within the loop, moving them outside could make the code see stale values. Example:\n// Original code\nwhile (condition) {\n    r = shared_variable;\n}\n\n// Transformed code (Loop Invariant Code Motion)\ntemp = shared_variable;\nwhile (condition) {\n    r = temp;\n}\nIf shared_variable is updated by another thread, the transformed code might keep using the old value.\n\nRegister Allocation (Caching Shared Variables in Registers)\nTransformation: Compilers can keep a shared variable in a register for efficiency rather than repeatedly loading it from memory. Violation: If another thread modifies that shared variable in memory, the compiler’s register optimization would cause the thread to read stale data. Example:\nwhile (flag == 0) {\n    // busy-wait\n}\nIf flag is cached in a register, updates to flag by another thread in memory won’t be reflected, breaking SC.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#instruction-fusion-combining-loadsstores",
    "href": "lectures/mem_consistancy.html#instruction-fusion-combining-loadsstores",
    "title": "memory consistancy",
    "section": "Instruction Fusion (Combining Loads/Stores)",
    "text": "Instruction Fusion (Combining Loads/Stores)\nTransformation: The compiler may combine consecutive memory accesses into one, such as merging adjacent stores into a single store or combining two loads. Violation: If other threads expect these loads or stores to happen separately, they might see an inconsistent view of memory. Example:\n// Original code\nx = 1;\ny = 2;\n\n// Transformed code (store fusion)\n// x and y are stored together in a single transaction\nA thread expecting x and y to be updated separately might observe an inconsistent state if this transformation is applied.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#thread-libraries",
    "href": "lectures/mem_consistancy.html#thread-libraries",
    "title": "memory consistancy",
    "section": "thread libraries",
    "text": "thread libraries\nstart out assuming single threaded, add a threads library like pthreads\nmultiple threads could access shared memory simultaneously, leading to race conditions, inconsistent data, and undefined behavior.\nModern CPUs and compilers perform optimizations like instruction reordering, which can break assumptions about the order of memory operations in multithreaded programs.\nMultithreaded code is harder to test because race conditions and bugs might only manifest under certain timing conditions.\nDebugging multithreaded programs is more difficult due to the unpredictable nature of thread execution and interactions.\nSome optimizations might reorder instructions in a way that is incompatible with multithreading, introducing subtle bugs or performance regressions.\nCaching, prefetching, or other memory optimizations need to account for the fact that multiple threads may be accessing the same memory, which a simple thread library does not handle.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#using-libraries",
    "href": "lectures/mem_consistancy.html#using-libraries",
    "title": "memory consistancy",
    "section": "using libraries",
    "text": "using libraries\n\nFunctions such as pthread mutex lock() that are guaranteed by the standard to “synchronize memory” include hardware instructions (“memory barriers”) that prevent hardware reordering of memory operations around the call\nTo prevent the compiler from moving memory operations around calls to functions such as pthread mutex lock(), they are essentially treated as calls to opaque functions, about which the compiler has no information.\n\nThe compiler effectively assumes that pthread mutex lock() may read or write any global variable. Thus a memory reference cannot simply be moved across the call. This approach also ensures that transitive calls, e.g. a call to a function f() which then calls pthread mutex lock(), are handled in the same way more or less appropriately, i.e. memory operations are not moved across the call to f() either, whether or not the entire user program is being analyzed at once.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#adding-multi-threading-to-user-explaining-the-intent",
    "href": "lectures/mem_consistancy.html#adding-multi-threading-to-user-explaining-the-intent",
    "title": "memory consistancy",
    "section": "adding multi-threading to user explaining the intent",
    "text": "adding multi-threading to user explaining the intent\nc++/c added atomics\nAtomic operations are operations that are completed as a single, uninterruptible action. No other thread can observe a partial update or interfere with the operation.\nThese operations ensure that read-modify-write sequences are safe without needing explicit locks.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#an-example-1",
    "href": "lectures/mem_consistancy.html#an-example-1",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n// Global spinlock using atomic_flag\nstd::atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid enter_critical_section() {\n    // Busy-wait (spin) until the lock is acquired\n    while (lock.test_and_set(std::memory_order_acquire)) {\n        // Spin and wait for the lock to become available\n    }\n}\n\nvoid leave_critical_section() {\n    // Release the lock\n    lock.clear(std::memory_order_release);\n}\n\n// Shared resource\nint shared_counter = 0;\n\nvoid critical_section_task(int num_increments) {\n    for (int i = 0; i &lt; num_increments; ++i) {\n        enter_critical_section();\n        // Begin critical section\n        ++shared_counter;\n        // End critical section\n        leave_critical_section();\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#load-acquire-needs-special-hardware",
    "href": "lectures/mem_consistancy.html#load-acquire-needs-special-hardware",
    "title": "memory consistancy",
    "section": "load acquire (needs special hardware )",
    "text": "load acquire (needs special hardware )\nused by default with atomics not used for non-atomics\nall memory reads and writes after the load operation cannot be moved before the load. This ensures that after acquiring the value, any operations that depend on this value (like accessing shared data) will see consistent and up-to-date memory.\na one way fence - nothing can move up",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#write-release-needs-special-hardware",
    "href": "lectures/mem_consistancy.html#write-release-needs-special-hardware",
    "title": "memory consistancy",
    "section": "write release (needs special hardware )",
    "text": "write release (needs special hardware )\nprevents the compiler or processor from reordering any memory operations (reads or writes) that appear before the release store. This guarantees that all operations that modify shared data before the release are visible to other threads that subsequently perform an acquire operation.\nalso a one way fence - nothing can move down\nload.acquire - \nloads and stores on non-atomics  - compiler picks the order for these operations \nstore.release",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#using-atomics",
    "href": "lectures/mem_consistancy.html#using-atomics",
    "title": "memory consistancy",
    "section": "using atomics",
    "text": "using atomics\nAll operations appear to occur in a single total order that is consistent across all threads. This means that the results of operations are predictable and consistent as if all operations were executed in some sequential order.\nlimits the hardware and compiler because it prevents reordering",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#data-race-free",
    "href": "lectures/mem_consistancy.html#data-race-free",
    "title": "memory consistancy",
    "section": "Data Race Free",
    "text": "Data Race Free\nData Race Free (DRF) means that a program is free from data races, which occur when:\n\nTwo or more threads access the same variable concurrently.\nAt least one of the accesses is a write.\n\nThere is no synchronization mechanism (like mutexes or atomic operations) to control the access. In a data race-free program, every shared variable is accessed in a way that ensures predictable results. C++ provides various synchronization primitives (such as mutexes and atomic types) to help developers write DRF code.\nAll shared variables must be accessed using synchronization to prevent concurrent threads from modifying shared data simultaneously without coordination.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#an-example-2",
    "href": "lectures/mem_consistancy.html#an-example-2",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nint shared_counter1 = 0;                  // First non-atomic shared variable\nint shared_counter2 = 0;                  // Second non-atomic shared variable\nstd::atomic&lt;bool&gt; lock_flag(false);       // Atomic flag to control access\n\nvoid safe_increment() {\n    for (int i = 0; i &lt; 1000; ++i) {\n        // Spin until the lock is acquired\n        while (lock_flag.exchange(true)) {\n            // Busy-wait (spin) until the lock is free\n        }\n\n        // Critical section: update the non-atomic shared variables\n        ++shared_counter1;\n        ++shared_counter2;\n\n        // Release the lock\n        lock_flag.store(false);\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#language-rules",
    "href": "lectures/mem_consistancy.html#language-rules",
    "title": "memory consistancy",
    "section": "language rules",
    "text": "language rules\nC and C++\ndo not define what happens in the presence of data races. If a program has data races (e.g., multiple threads concurrently reading and writing to the same variable without synchronization), the behavior is considered undefined. This means that the program may produce unexpected results, crash, or behave inconsistently across different executions or platforms.\nJava\ntries to define what happens but definition is very complex and maybe inconsistent\nRust\nCompile-Time Guarantees: Rust’s ownership and borrowing system prevents data races at compile time. If a program is not DRF, the Rust compiler will typically refuse to compile it, enforcing memory safety guarantees.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#can-the-compiler-add-a-race-to-a-drf-program",
    "href": "lectures/mem_consistancy.html#can-the-compiler-add-a-race-to-a-drf-program",
    "title": "memory consistancy",
    "section": "can the compiler add a race to a drf program",
    "text": "can the compiler add a race to a drf program\nnew rule, compiler cannot add a write to a shared variable\nif (x ==1) y++\n\nto \ny++\nif (x!=1) y--",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#how-does-this-effect-hardware",
    "href": "lectures/mem_consistancy.html#how-does-this-effect-hardware",
    "title": "memory consistancy",
    "section": "how does this effect hardware?",
    "text": "how does this effect hardware?\nstruct { char a; char b; char c; char d;} s;\ns.a = 1\ns.c = 3\n\ncan a compiler do \nchar temp[4] = s // load 32 bits \ntemp[0] = 1\ntemp[2] = 3\ns = temp\nnot allowed - reads/writes b and d, so compiler incorrectly added writes\noptions are either have byte addressable hardware, or pad so that each char gets 32 bits\nVendors forced to add 8 byte loads/stores",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#multi-threaded-programs",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#multi-threaded-programs",
    "title": "memory consistancy",
    "section": "multi-threaded programs",
    "text": "multi-threaded programs\nCompilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#shared-memory-multi-threading",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#shared-memory-multi-threading",
    "title": "memory consistancy",
    "section": "shared memory multi-threading",
    "text": "shared memory multi-threading\nThe most common parallel system is\n\nA single big memory\nmultiple threads address that memory"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#what-is-sequential-consistency-sq",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#what-is-sequential-consistency-sq",
    "title": "memory consistancy",
    "section": "what is sequential consistency SQ",
    "text": "what is sequential consistency SQ\nProgram Order is Maintained Within Threads:\nOperations (reads and writes) appear to occur in the order they are issued by each individual thread. If a thread performs a write followed by a read, the read cannot appear to happen before the write in the execution.\nGlobal Order of Operations Across Threads:\nAll threads see the effects of memory operations in the same sequential order. Every thread agrees on the order of reads and writes, though the specific order is not predefined—it just needs to be consistent across all threads. Interleaving of Operations:\nThe execution can be viewed as an interleaving of instructions from all threads. However, the interleaving must follow the program order within each thread.\nno real machine/compiler implements this"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#compiler-effects",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#compiler-effects",
    "title": "memory consistancy",
    "section": "compiler effects",
    "text": "compiler effects\nCompiler transformations that break multi-thread sequential consistency (SC) often reorder or optimize instructions in ways that do not respect the original program order seen by other threads. These transformations can lead to subtle bugs in multithreaded programs where the expected interleaving of operations is violated."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#loadstore-reordering",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#loadstore-reordering",
    "title": "memory consistancy",
    "section": "Load/Store Reordering",
    "text": "Load/Store Reordering\nTransformation: Compilers might reorder loads and stores to improve performance. Violation: In a multi-threaded environment, this can lead to a situation where one thread sees stale or unexpected data. Example:\nCopy code\n// Thread 1\nx = 1;     // Store\nr1 = y;    // Load\n\n// Thread 2\ny = 1;     // Store\nr2 = x;    // Load\nUnder sequential consistency, if thread 1’s x = 1 happens before thread 2’s r2 = x, then thread 2 should observe r2 == 1. But reordering could result in thread 2 reading x as 0."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#common-subexpression-elimination-cse",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#common-subexpression-elimination-cse",
    "title": "memory consistancy",
    "section": "Common Subexpression Elimination (CSE)",
    "text": "Common Subexpression Elimination (CSE)\nTransformation: If a variable or expression is computed multiple times, the compiler may optimize by reusing the result of an earlier computation. Violation: This assumes that no other thread modifies shared variables between these uses. Example:\n// Original code\nr1 = x;\nr2 = x;\n\n// Transformed code (CSE applied)\ntemp = x;\nr1 = temp;\nr2 = temp;\nIf x is modified by another thread between the two reads, the transformed code will incorrectly assume the value of x hasn’t changed."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#dead-code-elimination-dce",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#dead-code-elimination-dce",
    "title": "memory consistancy",
    "section": "Dead Code Elimination (DCE)",
    "text": "Dead Code Elimination (DCE)\nTransformation: The compiler may remove stores to variables that are not subsequently read in the same thread. Violation: If the variable is shared and accessed by other threads, removing the store could lead to unexpected behavior. Example:\n// Original code\nx = 1;\n\n// Transformed code (DCE applied)\n// x = 1 is removed because x is not used locally If another thread reads x, it expects the store to have happened, but DCE breaks this assumption."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#speculative-execution-out-of-order-execution",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#speculative-execution-out-of-order-execution",
    "title": "memory consistancy",
    "section": "Speculative Execution (Out-of-Order Execution)",
    "text": "Speculative Execution (Out-of-Order Execution)\nTransformation: Compilers (or hardware) may execute instructions speculatively, assuming certain branches are likely to be taken. Violation: This can cause out-of-order writes or reads visible to other threads, breaking SC. Example:\nif (flag) {\n    r1 = x;\n}\nIf the compiler speculatively reads x before knowing the value of flag, another thread’s write to x might be missed or observed out-of-order."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#loop-invariant-code-motion",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#loop-invariant-code-motion",
    "title": "memory consistancy",
    "section": "Loop Invariant Code Motion",
    "text": "Loop Invariant Code Motion\nTransformation: The compiler moves computations that are invariant inside a loop to outside the loop. Violation: If these computations involve shared variables modified by other threads within the loop, moving them outside could make the code see stale values. Example:\n// Original code\nwhile (condition) {\n    r = shared_variable;\n}\n\n// Transformed code (Loop Invariant Code Motion)\ntemp = shared_variable;\nwhile (condition) {\n    r = temp;\n}\nIf shared_variable is updated by another thread, the transformed code might keep using the old value.\nRegister Allocation (Caching Shared Variables in Registers)\nTransformation: Compilers can keep a shared variable in a register for efficiency rather than repeatedly loading it from memory. Violation: If another thread modifies that shared variable in memory, the compiler’s register optimization would cause the thread to read stale data. Example:\nwhile (flag == 0) {\n    // busy-wait\n}\nIf flag is cached in a register, updates to flag by another thread in memory won’t be reflected, breaking SC."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#instruction-fusion-combining-loadsstores",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#instruction-fusion-combining-loadsstores",
    "title": "memory consistancy",
    "section": "Instruction Fusion (Combining Loads/Stores)",
    "text": "Instruction Fusion (Combining Loads/Stores)\nTransformation: The compiler may combine consecutive memory accesses into one, such as merging adjacent stores into a single store or combining two loads. Violation: If other threads expect these loads or stores to happen separately, they might see an inconsistent view of memory. Example:\n// Original code\nx = 1;\ny = 2;\n\n// Transformed code (store fusion)\n// x and y are stored together in a single transaction\nA thread expecting x and y to be updated separately might observe an inconsistent state if this transformation is applied."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#thread-libraries",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#thread-libraries",
    "title": "memory consistancy",
    "section": "thread libraries",
    "text": "thread libraries\nstart out assuming single threaded, add a threads library like pthreads\nmultiple threads could access shared memory simultaneously, leading to race conditions, inconsistent data, and undefined behavior.\nModern CPUs and compilers perform optimizations like instruction reordering, which can break assumptions about the order of memory operations in multithreaded programs.\nMultithreaded code is harder to test because race conditions and bugs might only manifest under certain timing conditions.\nDebugging multithreaded programs is more difficult due to the unpredictable nature of thread execution and interactions.\nSome optimizations might reorder instructions in a way that is incompatible with multithreading, introducing subtle bugs or performance regressions.\nCaching, prefetching, or other memory optimizations need to account for the fact that multiple threads may be accessing the same memory, which a simple thread library does not handle."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#using-libraries",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#using-libraries",
    "title": "memory consistancy",
    "section": "using libraries",
    "text": "using libraries\n\nFunctions such as pthread mutex lock() that are guaranteed by the standard to “synchronize memory” include hardware instructions (“memory barriers”) that prevent hardware reordering of memory operations around the call\nTo prevent the compiler from moving memory operations around calls to functions such as pthread mutex lock(), they are essentially treated as calls to opaque functions, about which the compiler has no information.\n\nThe compiler effectively assumes that pthread mutex lock() may read or write any global variable. Thus a memory reference cannot simply be moved across the call. This approach also ensures that transitive calls, e.g. a call to a function f() which then calls pthread mutex lock(), are handled in the same way more or less appropriately, i.e. memory operations are not moved across the call to f() either, whether or not the entire user program is being analyzed at once."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#adding-multi-threading-to-user-explaining-the-intent",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#adding-multi-threading-to-user-explaining-the-intent",
    "title": "memory consistancy",
    "section": "adding multi-threading to user explaining the intent",
    "text": "adding multi-threading to user explaining the intent\nc++/c added atomics\nAtomic operations are operations that are completed as a single, uninterruptible action. No other thread can observe a partial update or interfere with the operation.\nThese operations ensure that read-modify-write sequences are safe without needing explicit locks."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#an-example-1",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#an-example-1",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n// Global spinlock using atomic_flag\nstd::atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid enter_critical_section() {\n    // Busy-wait (spin) until the lock is acquired\n    while (lock.test_and_set(std::memory_order_acquire)) {\n        // Spin and wait for the lock to become available\n    }\n}\n\nvoid leave_critical_section() {\n    // Release the lock\n    lock.clear(std::memory_order_release);\n}\n\n// Shared resource\nint shared_counter = 0;\n\nvoid critical_section_task(int num_increments) {\n    for (int i = 0; i &lt; num_increments; ++i) {\n        enter_critical_section();\n        // Begin critical section\n        ++shared_counter;\n        // End critical section\n        leave_critical_section();\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#load-acquire-needs-special-hardware",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#load-acquire-needs-special-hardware",
    "title": "memory consistancy",
    "section": "load acquire (needs special hardware )",
    "text": "load acquire (needs special hardware )\nused by default with atomics not used for non-atomics\nall memory reads and writes after the load operation cannot be moved before the load. This ensures that after acquiring the value, any operations that depend on this value (like accessing shared data) will see consistent and up-to-date memory.\na one way fence - nothing can move up"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#write-release-needs-special-hardware",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#write-release-needs-special-hardware",
    "title": "memory consistancy",
    "section": "write release (needs special hardware )",
    "text": "write release (needs special hardware )\nprevents the compiler or processor from reordering any memory operations (reads or writes) that appear before the release store. This guarantees that all operations that modify shared data before the release are visible to other threads that subsequently perform an acquire operation.\nalso a one way fence - nothing can move down\nload.acquire - \nloads and stores on non-atomics  - compiler picks the order for these operations \nstore.release"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#using-atomics",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#using-atomics",
    "title": "memory consistancy",
    "section": "using atomics",
    "text": "using atomics\nAll operations appear to occur in a single total order that is consistent across all threads. This means that the results of operations are predictable and consistent as if all operations were executed in some sequential order.\nlimits the hardware and compiler because it prevents reordering"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#data-race-free",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#data-race-free",
    "title": "memory consistancy",
    "section": "Data Race Free",
    "text": "Data Race Free\nData Race Free (DRF) means that a program is free from data races, which occur when:\n\nTwo or more threads access the same variable concurrently.\nAt least one of the accesses is a write.\n\nThere is no synchronization mechanism (like mutexes or atomic operations) to control the access. In a data race-free program, every shared variable is accessed in a way that ensures predictable results. C++ provides various synchronization primitives (such as mutexes and atomic types) to help developers write DRF code.\nAll shared variables must be accessed using synchronization to prevent concurrent threads from modifying shared data simultaneously without coordination."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#an-example-2",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#an-example-2",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nint shared_counter1 = 0;                  // First non-atomic shared variable\nint shared_counter2 = 0;                  // Second non-atomic shared variable\nstd::atomic&lt;bool&gt; lock_flag(false);       // Atomic flag to control access\n\nvoid safe_increment() {\n    for (int i = 0; i &lt; 1000; ++i) {\n        // Spin until the lock is acquired\n        while (lock_flag.exchange(true)) {\n            // Busy-wait (spin) until the lock is free\n        }\n\n        // Critical section: update the non-atomic shared variables\n        ++shared_counter1;\n        ++shared_counter2;\n\n        // Release the lock\n        lock_flag.store(false);\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#language-rules",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#language-rules",
    "title": "memory consistancy",
    "section": "language rules",
    "text": "language rules\nC and C++\ndo not define what happens in the presence of data races. If a program has data races (e.g., multiple threads concurrently reading and writing to the same variable without synchronization), the behavior is considered undefined. This means that the program may produce unexpected results, crash, or behave inconsistently across different executions or platforms.\nJava\ntries to define what happens but definition is very complex and maybe inconsistent\nRust\nCompile-Time Guarantees: Rust’s ownership and borrowing system prevents data races at compile time. If a program is not DRF, the Rust compiler will typically refuse to compile it, enforcing memory safety guarantees."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#can-the-compiler-add-a-race-to-a-drf-program",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#can-the-compiler-add-a-race-to-a-drf-program",
    "title": "memory consistancy",
    "section": "can the compiler add a race to a drf program",
    "text": "can the compiler add a race to a drf program\nnew rule, compiler cannot add a write to a shared variable\nif (x ==1) y++\n\nto \ny++\nif (x!=1) y--"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#how-does-this-effect-hardware",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#how-does-this-effect-hardware",
    "title": "memory consistancy",
    "section": "how does this effect hardware?",
    "text": "how does this effect hardware?\nstruct { char a; char b; char c; char d;} s;\ns.a = 1\ns.c = 3\n\ncan a compiler do \nchar temp[4] = s // load 32 bits \ntemp[0] = 1\ntemp[2] = 3\ns = temp\nnot allowed - reads/writes b and d, so compiler incorrectly added writes\noptions are either have byte addressable hardware, or pad so that each char gets 32 bits\nVendors forced to add 8 byte loads/stores"
  },
  {
    "objectID": "lectures/ra-checking.html#what-is-register-allocation",
    "href": "lectures/ra-checking.html#what-is-register-allocation",
    "title": "Testing Register allocators",
    "section": "what is register allocation",
    "text": "what is register allocation\nIn Bril and LLVM a program can use an arbitrary number of registers,\nvoid f() {\n    int x0 = compute(0);\n    int x1 = compute(1);\n    // ...\n    int x99 = compute(99);\n    \n    // --- 100 possibly different values were computed \n    // --- where are those values stored?\n    \n    consume(x0);\n    consume(x1);\n    // ...\n    consume(x99);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#storing-variables",
    "href": "lectures/ra-checking.html#storing-variables",
    "title": "Testing Register allocators",
    "section": "storing variables",
    "text": "storing variables\none option\nAllocate a memory location for each local variable. All of the \\(x_N\\) variables above semantically live in memory. When the function is called, it allocates a nwe area on the stack called the stack frame and uses it to store local variables.\nThis means that adding two variables, takes two loads, one add, and one store so it is very slow\nCompiling code in this way is very fast because we need to make almost no decisions: a variable reference always becomes a memory load,\nOn computers we have a limited set of registers\nRegister allocation: is assigning a value in the program to a register for storage. The register allocator decides how to shuffle values between memory and registers, and between register.\nIn Bril and LLVM we have virtual registers - as many as you want. The register allocator has to rewrite the instructions to use physical registers. Since the number of physical registers is limited, The allocator might insert additional instructions:\n\nstores (called spills) to move a register to memory\nloads (called reloads) to move memory to a register\nmoves to copy from one register to another\n\nThe locations in memory are usually on the stack and are called spill-slots",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "href": "lectures/ra-checking.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "title": "Testing Register allocators",
    "section": "example of register allocation on a machine with two physical registers",
    "text": "example of register allocation on a machine with two physical registers\nvirtual register code          physical register code \n                               {v0 -&gt; r0, v1 -&gt; r1}\n                               store r1, [sp+0]  a spill\nadd v2, v0, v1                 add r1, r0, r1 \n                               {v0 -&gt; r0, v1-&gt; [sp+-0], v2-&gt; r1}\nsub v3, v2, v0                 sub r1, r1, r0\n                               load r0, [sp+0]  a reload \nmul  v4, v3, v1                mul r0, r1, r0\n                               {v4-&gt; r0}\nstore v4, [sp+48]              store r0, [sp+48]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#complexity",
    "href": "lectures/ra-checking.html#complexity",
    "title": "Testing Register allocators",
    "section": "complexity",
    "text": "complexity\nif you do register allocation for code that is not in SSA, this is NP-complete But if you do it on code that is in SSA, the time complexity is polynomial.\nThere are lots of approximate algorithms- all complicated, lots of machines have extra constraints for instance there is a GPU load instruction that read 128 bits from memory and puts the value into 4 consecutive registers\nI’m not going to talk about these algorithms here",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#how-to-verify-correctness-of-an-allocator",
    "href": "lectures/ra-checking.html#how-to-verify-correctness-of-an-allocator",
    "title": "Testing Register allocators",
    "section": "How to Verify Correctness of an allocator?",
    "text": "How to Verify Correctness of an allocator?\nBefore and after the allocator, we have the same instructions (except for those added by the allocator)\nassume we have a machine with an infinite register set and a second machine with a finite register set.\nCorrect means both programs executed on these two machines get the same answer for all possible inputs",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#how-do-we-test-this",
    "href": "lectures/ra-checking.html#how-do-we-test-this",
    "title": "Testing Register allocators",
    "section": "how do we test this?",
    "text": "how do we test this?\nHow do we test this equivalence?\npick a random program and a random input. interpret and see if the result is the same.\ncould try more random inputs, could generate more random programs (fuzzer tools)\nCould reasonably confident but not 100% and very expensive",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "href": "lectures/ra-checking.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "title": "Testing Register allocators",
    "section": "use value numbering check one program, one basic block, all possible inputs",
    "text": "use value numbering check one program, one basic block, all possible inputs\n// original               // allocated \nld v0, [A]                ld r0, [A]\nld v1, [B]                ld r1, [B]\nld v2, [C]                ld r2, [C]\nadd v3, v0, v1            add r0, r0, r1\nadd v4, v2, v3            add r0, r2, r0\nreturn v4                 return r0\n\nv0 -&gt; vn 1 ld [A]         r0 -&gt; vn 1 ld [A]\nv1 -&gt; vn 2 ld [B]         r1 -&gt; vn 2 ld [B]\nv2 -&gt; vn 3 ld [C]         r2 -&gt; vn 3 ld [C]\nv3 -&gt; vn 4 add 1,2        r0 -&gt; vn 4 add 1,2 \nv4 -&gt; vn 5 add 3,4        r0 -&gt; vn 5 add 3,4 \nreturn vn 5               return vn 5",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#check-more-then-one-program-all-programs-at-once",
    "href": "lectures/ra-checking.html#check-more-then-one-program-all-programs-at-once",
    "title": "Testing Register allocators",
    "section": "check more then one program (all programs at once)",
    "text": "check more then one program (all programs at once)\nThis requires a proof that the two programs get the same result - this is an active research question -\nsome success but not easy\nnot used in production",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "href": "lectures/ra-checking.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "title": "Testing Register allocators",
    "section": "best we can do is generate lots of programs check each one",
    "text": "best we can do is generate lots of programs check each one\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n\nWe could use the fuzzer to generate random programs or we could use a test set",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#algorithm-linear-in-number-of-instructions",
    "href": "lectures/ra-checking.html#algorithm-linear-in-number-of-instructions",
    "title": "Testing Register allocators",
    "section": "algorithm (linear in number of instructions)",
    "text": "algorithm (linear in number of instructions)\nfor each instruction we need to form pairs - virtual and physical register that holds the same value\nfor instruction v and p, check that the arguments are equal, if not fail add the pair dest of v == dest of p\ndoes not matter what the original op code was, just need register names",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#more-general",
    "href": "lectures/ra-checking.html#more-general",
    "title": "Testing Register allocators",
    "section": "more general",
    "text": "more general\nTreat the allocated program as containing:\n\nSpill , : copy data (symbol representing virtual register) from a register to a spill slot.\nReload , : copy data from a spill slot to a register.\ncopy , : move data from one CPU register to another (N.B.: only regalloc-inserted moves are recognized as a Move, not moves in the original input program.)\nOp read:, read_orig: write: write_orig:: some arbitrary operation that reads some registers and writes some other registers.\n\nRun the value number over this:\nstate: for each physical register, and spill slot\nwe need either:\n\nthe virtual register name\nunknown -\n\nconflicted if it has more then one virtual register",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#steps-still-no-control-flow",
    "href": "lectures/ra-checking.html#steps-still-no-control-flow",
    "title": "Testing Register allocators",
    "section": "steps (still no control flow )",
    "text": "steps (still no control flow )\nWhen we see a Spill, Reload, or Move, we copy the symbolic state from the source location (register or spill slot) to the destination location.\nWhen we see an Op, we do some checks then some updates:\nFor each read (input) register, we examine the symbolic value stored in the given register.\nIf that symbol matches the virtual register that the original instruction used, then the allocator has properly conveyed the virtual register’s value to its use here, and thus the allocation is correct\nIf not, we can signal a checker error, and look for the bug in our register allocator. why are there no false positives?\nFor each write (output) register, we set the symbolic value stored in the given CPU register to be the given virtual register.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#control-flow",
    "href": "lectures/ra-checking.html#control-flow",
    "title": "Testing Register allocators",
    "section": "control flow",
    "text": "control flow\nWe can use data flow and a lattice\nhere is the lattice\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#now-for-the-data-flow",
    "href": "lectures/ra-checking.html#now-for-the-data-flow",
    "title": "Testing Register allocators",
    "section": "now for the data flow",
    "text": "now for the data flow\nWe start out with all physical registers and spill slots as ‘unknown’ At each join point move down the lattice\nconflicted is ok, so long as it is not used\nSince the number of physical registers and spill slots is finite we can can merge all of them at the top of each basic block.\nlike usual we might pick a good order to process basic blocks",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#how-about-an-example",
    "href": "lectures/ra-checking.html#how-about-an-example",
    "title": "Testing Register allocators",
    "section": "How about an example:",
    "text": "How about an example:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n\nat the top of C, we see that physical p0 is conflicted -\nbut that is not a error\nafter the reload we find it contains v2",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#tracing-pointers--",
    "href": "lectures/ra-checking.html#tracing-pointers--",
    "title": "Testing Register allocators",
    "section": "tracing pointers -",
    "text": "tracing pointers -\nSince we know what virtual registers are in each spill-slot, and virtual registers have types we can tell which spill slots contain pointers\nsuppose we have a spot where we might call a gc, we could force spilling of all live vrs that contain a pointer and then tell the gc which spill locations to consider",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#this-is-based-on-the-cranelift-compiler-used-for-web-assembly-and-rust",
    "href": "lectures/revealjs_ra-checking.qmd.html#this-is-based-on-the-cranelift-compiler-used-for-web-assembly-and-rust",
    "title": "Testing Register allocators",
    "section": "this is based on the cranelift compiler used for web-assembly and rust",
    "text": "this is based on the cranelift compiler used for web-assembly and rust"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#what-is-register-allocation",
    "href": "lectures/revealjs_ra-checking.qmd.html#what-is-register-allocation",
    "title": "Testing Register allocators",
    "section": "what is register allocation",
    "text": "what is register allocation\nIn Bril and LLVM a program can use an arbitrary number of registers,\nvoid f() {\n    int x0 = compute(0);\n    int x1 = compute(1);\n    // ...\n    int x99 = compute(99);\n    \n    // --- 100 possibly different values were computed \n    // --- where are those values stored?\n    \n    consume(x0);\n    consume(x1);\n    // ...\n    consume(x99);\n}"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#storing-variables",
    "href": "lectures/revealjs_ra-checking.qmd.html#storing-variables",
    "title": "Testing Register allocators",
    "section": "storing variables",
    "text": "storing variables\none option\nAllocate a memory location for each local variable. All of the \\(x_N\\) variables above semantically live in memory. When the function is called, it allocates a nwe area on the stack called the stack frame and uses it to store local variables.\nThis means that adding two variables, takes two loads, one add, and one store so it is very slow\nCompiling code in this way is very fast because we need to make almost no decisions: a variable reference always becomes a memory load,\nOn computers we have a limited set of registers\nRegister allocation: is assigning a value in the program to a register for storage. The register allocator decides how to shuffle values between memory and registers, and between register.\nIn Bril and LLVM we have virtual registers - as many as you want. The register allocator has to rewrite the instructions to use physical registers. Since the number of physical registers is limited, The allocator might insert additional instructions:\n\nstores (called spills) to move a register to memory\nloads (called reloads) to move memory to a register\nmoves to copy from one register to another\n\nThe locations in memory are usually on the stack and are called spill-slots"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "href": "lectures/revealjs_ra-checking.qmd.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "title": "Testing Register allocators",
    "section": "example of register allocation on a machine with two physical registers",
    "text": "example of register allocation on a machine with two physical registers\nvirtual register code          physical register code \n                               {v0 -&gt; r0, v1 -&gt; r1}\n                               store r1, [sp+0]  a spill\nadd v2, v0, v1                 add r1, r0, r1 \n                               {v0 -&gt; r0, v1-&gt; [sp+-0], v2-&gt; r1}\nsub v3, v2, v0                 sub r1, r1, r0\n                               load r0, [sp+0]  a reload \nmul  v4, v3, v1                mul r0, r1, r0\n                               {v4-&gt; r0}\nstore v4, [sp+48]              store r0, [sp+48]"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#complexity",
    "href": "lectures/revealjs_ra-checking.qmd.html#complexity",
    "title": "Testing Register allocators",
    "section": "complexity",
    "text": "complexity\nif you do register allocation for code that is not in SSA, this is NP-complete But if you do it on code that is in SSA, the time complexity is polynomial.\nThere are lots of approximate algorithms- all complicated, lots of machines have extra constraints for instance there is a GPU load instruction that read 128 bits from memory and puts the value into 4 consecutive registers\nI’m not going to talk about these algorithms here"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-to-verify-correctness-of-an-allocator",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-to-verify-correctness-of-an-allocator",
    "title": "Testing Register allocators",
    "section": "How to Verify Correctness of an allocator?",
    "text": "How to Verify Correctness of an allocator?\nBefore and after the allocator, we have the same instructions (except for those added by the allocator)\nassume we have a machine with an infinite register set and a second machine with a finite register set.\nCorrect means both programs executed on these two machines get the same answer for all possible inputs"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-do-we-test-this",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-do-we-test-this",
    "title": "Testing Register allocators",
    "section": "how do we test this?",
    "text": "how do we test this?\nHow do we test this equivalence?\npick a random program and a random input. interpret and see if the result is the same.\ncould try more random inputs, could generate more random programs (fuzzer tools)\nCould reasonably confident but not 100% and very expensive"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "href": "lectures/revealjs_ra-checking.qmd.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "title": "Testing Register allocators",
    "section": "use value numbering check one program, one basic block, all possible inputs",
    "text": "use value numbering check one program, one basic block, all possible inputs\n// original               // allocated \nld v0, [A]                ld r0, [A]\nld v1, [B]                ld r1, [B]\nld v2, [C]                ld r2, [C]\nadd v3, v0, v1            add r0, r0, r1\nadd v4, v2, v3            add r0, r2, r0\nreturn v4                 return r0\n\nv0 -&gt; vn 1 ld [A]         r0 -&gt; vn 1 ld [A]\nv1 -&gt; vn 2 ld [B]         r1 -&gt; vn 2 ld [B]\nv2 -&gt; vn 3 ld [C]         r2 -&gt; vn 3 ld [C]\nv3 -&gt; vn 4 add 1,2        r0 -&gt; vn 4 add 1,2 \nv4 -&gt; vn 5 add 3,4        r0 -&gt; vn 5 add 3,4 \nreturn vn 5               return vn 5"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#check-more-then-one-program-all-programs-at-once",
    "href": "lectures/revealjs_ra-checking.qmd.html#check-more-then-one-program-all-programs-at-once",
    "title": "Testing Register allocators",
    "section": "check more then one program (all programs at once)",
    "text": "check more then one program (all programs at once)\nThis requires a proof that the two programs get the same result - this is an active research question -\nsome success but not easy\nnot used in production"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "href": "lectures/revealjs_ra-checking.qmd.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "title": "Testing Register allocators",
    "section": "best we can do is generate lots of programs check each one",
    "text": "best we can do is generate lots of programs check each one\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n\nWe could use the fuzzer to generate random programs or we could use a test set"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#algorithm-linear-in-number-of-instructions",
    "href": "lectures/revealjs_ra-checking.qmd.html#algorithm-linear-in-number-of-instructions",
    "title": "Testing Register allocators",
    "section": "algorithm (linear in number of instructions)",
    "text": "algorithm (linear in number of instructions)\nfor each instruction we need to form pairs - virtual and physical register that holds the same value\nfor instruction v and p, check that the arguments are equal, if not fail add the pair dest of v == dest of p\ndoes not matter what the original op code was, just need register names"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#more-general",
    "href": "lectures/revealjs_ra-checking.qmd.html#more-general",
    "title": "Testing Register allocators",
    "section": "more general",
    "text": "more general\nTreat the allocated program as containing:\n\nSpill , : copy data (symbol representing virtual register) from a register to a spill slot.\nReload , : copy data from a spill slot to a register.\ncopy , : move data from one CPU register to another (N.B.: only regalloc-inserted moves are recognized as a Move, not moves in the original input program.)\nOp read:, read_orig: write: write_orig:: some arbitrary operation that reads some registers and writes some other registers.\n\nRun the value number over this:\nstate: for each physical register, and spill slot\nwe need either:\n\nthe virtual register name\nunknown -\n\nconflicted if it has more then one virtual register"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#steps-still-no-control-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#steps-still-no-control-flow",
    "title": "Testing Register allocators",
    "section": "steps (still no control flow )",
    "text": "steps (still no control flow )\nWhen we see a Spill, Reload, or Move, we copy the symbolic state from the source location (register or spill slot) to the destination location.\nWhen we see an Op, we do some checks then some updates:\nFor each read (input) register, we examine the symbolic value stored in the given register.\nIf that symbol matches the virtual register that the original instruction used, then the allocator has properly conveyed the virtual register’s value to its use here, and thus the allocation is correct\nIf not, we can signal a checker error, and look for the bug in our register allocator. why are there no false positives?\nFor each write (output) register, we set the symbolic value stored in the given CPU register to be the given virtual register."
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#control-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#control-flow",
    "title": "Testing Register allocators",
    "section": "control flow",
    "text": "control flow\nWe can use data flow and a lattice\nhere is the lattice\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#now-for-the-data-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#now-for-the-data-flow",
    "title": "Testing Register allocators",
    "section": "now for the data flow",
    "text": "now for the data flow\nWe start out with all physical registers and spill slots as ‘unknown’ At each join point move down the lattice\nconflicted is ok, so long as it is not used\nSince the number of physical registers and spill slots is finite we can can merge all of them at the top of each basic block.\nlike usual we might pick a good order to process basic blocks"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-about-an-example",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-about-an-example",
    "title": "Testing Register allocators",
    "section": "How about an example:",
    "text": "How about an example:\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n\nat the top of C, we see that physical p0 is conflicted -\nbut that is not a error\nafter the reload we find it contains v2"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#tracing-pointers--",
    "href": "lectures/revealjs_ra-checking.qmd.html#tracing-pointers--",
    "title": "Testing Register allocators",
    "section": "tracing pointers -",
    "text": "tracing pointers -\nSince we know what virtual registers are in each spill-slot, and virtual registers have types we can tell which spill slots contain pointers\nsuppose we have a spot where we might call a gc, we could force spilling of all live vrs that contain a pointer and then tell the gc which spill locations to consider"
  },
  {
    "objectID": "lectures/02b_bril.html",
    "href": "lectures/02b_bril.html",
    "title": "Overview of Bril",
    "section": "",
    "text": "Bril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#how-to-use-bril-with-real-code",
    "href": "lectures/02b_bril.html#how-to-use-bril-with-real-code",
    "title": "Overview of Bril",
    "section": "",
    "text": "Bril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#lets-look-at-a-bril-program.",
    "href": "lectures/02b_bril.html#lets-look-at-a-bril-program.",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\nimport json\nimport subprocess\nimport os \nimport sys\n\n\n### temp \nout = subprocess.check_output('which python', shell=True)\nprint(out)\nprint('***********************')\n\n# read from a file \nwith open(\"images/add.json\",\"r\") as f:\n    bril_program = json.load(f)\n\n# read from a pipe\n# bril_program = json.load(sys.stdin)\n    \nprint(json.dumps(bril_program, \n    indent=2))\n\nb'/opt/hostedtoolcache/Python/3.10.15/x64/bin/python\\n'\n***********************\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#formatted",
    "href": "lectures/02b_bril.html#formatted",
    "title": "Overview of Bril",
    "section": "Formatted",
    "text": "Formatted\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\"dest\": \"v0\", \"op\": \"const\",\"type\": \"int\",\"value\": 1},\n        {\"dest\": \"v1\", \"op\": \"const\",\"type\": \"int\",\"value\": 2},\n        {\"dest\": \"v2\", \"op\": \"add\",  \"type\": \"int\",\"args\": [\"v0\",\"v1\"],},\n                       \"op\": \"print\",\"args\": [ \"v2\"],}],\n      \"name\": \"main\",\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#getting-started",
    "href": "lectures/02b_bril.html#getting-started",
    "title": "Overview of Bril",
    "section": "getting started",
    "text": "getting started\nlinks:\n\nLanguage specification\ngithub site",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "href": "lectures/02b_bril.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "title": "Overview of Bril",
    "section": "step 1 clone the bril repo on a linux or wsl machine",
    "text": "step 1 clone the bril repo on a linux or wsl machine\ngit clone https://github.com/sampsyo/bril.git",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-2-support-packages",
    "href": "lectures/02b_bril.html#step-2-support-packages",
    "title": "Overview of Bril",
    "section": "step 2 support packages",
    "text": "step 2 support packages\n\ndeno is the runtime for typescript/javascript\n\ncurl -fsSL https://deno.land/install.sh | sh\non my ubuntu machine ‘sudo snap install deno’ also worked\nyou may need to add $HOME/.deno/bin to your $PATH.\n\nflit a python package manager\n\npython3 -m pip install flit",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "href": "lectures/02b_bril.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "title": "Overview of Bril",
    "section": "step 3 install the bril interpreter, and the typescript to bril compiler",
    "text": "step 3 install the bril interpreter, and the typescript to bril compiler\ncd bril\ndeno install brili.ts \ndeno install --allow-env --allow-read ts2bril.ts",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#running-the-interpreter",
    "href": "lectures/02b_bril.html#running-the-interpreter",
    "title": "Overview of Bril",
    "section": "running the interpreter",
    "text": "running the interpreter\nbrili &lt;images/add.json\nbrili -p &lt;images/add.json\nthe -p flag turns on profiling",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#text-to-json-and-back",
    "href": "lectures/02b_bril.html#text-to-json-and-back",
    "title": "Overview of Bril",
    "section": "text to json and back",
    "text": "text to json and back\nThere are programs bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\ninstall text tools\ncd bril-txt\nflit install --symlink --user\nrun json to text\nbril2txt &lt; images/add.json",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#connect-tools-via-pipes",
    "href": "lectures/02b_bril.html#connect-tools-via-pipes",
    "title": "Overview of Bril",
    "section": "connect tools via pipes",
    "text": "connect tools via pipes\ncat images/add.json'\nbril2txt &lt; images/add.json | bril2json",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#other-tools",
    "href": "lectures/02b_bril.html#other-tools",
    "title": "Overview of Bril",
    "section": "Other tools",
    "text": "Other tools\nThere is also a fast interpreter written in Rust see docs for installation",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#turnt-tiny-unified-runner-and-tester",
    "href": "lectures/02b_bril.html#turnt-tiny-unified-runner-and-tester",
    "title": "Overview of Bril",
    "section": "turnt Tiny unified runner and tester",
    "text": "turnt Tiny unified runner and tester\nBril uses turnt as a test tool\nTurnt is a simple snapshot testing tool inspired by LLVM’s lit. It’s good for testing things that translate text files to other text files, like compilers. The idea is that each test is one input file, and you want to run a command and check that it still matches the saved output file.\npip install –user turnt\nAs you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (can be wsl) machine",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#gen-cfg",
    "href": "lectures/02b_bril.html#gen-cfg",
    "title": "Overview of Bril",
    "section": "Gen CFG",
    "text": "Gen CFG\nLets write a sample program - that generates the cfg\nHow would you do that?\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}\n\n. . .\nI’ll do this in two steps\n\nfind all the basic blocks\nadd all the cfg edges\n\nYou can also do this in a single step, adding cfg edges as soon as you reach the successor node.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#basic-blocks-from-a-list-of-instructions-",
    "href": "lectures/02b_bril.html#basic-blocks-from-a-list-of-instructions-",
    "title": "Overview of Bril",
    "section": "basic blocks from a list of instructions-",
    "text": "basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\n. . .\nin: list of instrs \nout: list of lists of instrs \n \nblocks = []\ncurr_block = []\nfor each instr in list \n    if the instruction is not a label put it on curr_block\n    if instr is a label or terminator \n       put curr_block on blocks\n       curr_block = []\n \n if curr_block is not empty add it to blocks\n return blocks \ntwo labels in a row do not need another block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-2-add-edges",
    "href": "lectures/02b_bril.html#step-2-add-edges",
    "title": "Overview of Bril",
    "section": "step 2 add edges",
    "text": "step 2 add edges\nfind cfg: in: is bril program in json \nfor each function find the list of basic blocks\nfor each basic block\n   get last_instr \n   if it is a terminator  br/jmp/ret \n     add edge from current block to successor  \n    --- what do we want to do with call? \n   else it is a fall through\n      add edge to next block\n. . .\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we handle fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case\nwhat happens if try to delete the terminator (because the block never executes)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#code",
    "href": "lectures/02b_bril.html#code",
    "title": "Overview of Bril",
    "section": "code",
    "text": "code\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed.\n\nGitHub Copilot says:\nOrderedDict in Python is a dictionary subclass that maintains the order in which keys are inserted. When iterating over an OrderedDict, the items are returned in the order they were added. This behavior contrasts with a standard dictionary in Python 3.6 and earlier, where the iteration order was not guaranteed. However, starting from Python 3.7, the built-in dict type also maintains insertion order by default, making OrderedDict less necessary for most applications. OrderedDict still provides additional functionality, such as the move_to_end method, which allows moving an existing key to either end of the dictionary.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#ill-use-a-generator",
    "href": "lectures/02b_bril.html#ill-use-a-generator",
    "title": "Overview of Bril",
    "section": "I’ll use a generator",
    "text": "I’ll use a generator\nIn Python, a generator is an iterator that is defined with a function using the yield statement.\n\nProduce items only once\nDo not store all the items in memory\nWhen items from the generator are requested, the function executes until it reaches a yield statement, which produces the next value. Execution then pauses, preserving the function’s state, until the next item is requested.\n\n\nGiven a list of Bril instructions, generate a sequence of instruction lists representing the basic blocks in the program.\nEvery instruction in instr will show up in exactly one block. Jump and branch instructions may only appear at the end of a block, and control can transfer only to the top of a basic block—so labels can only appear at the start of a basic block. Basic blocks may not be empty.\n\n\n    #Instructions that terminate a basic block.\n    TERMINATORS = 'br', 'jmp', 'ret'\n\n    def form_blocks(instrs):\n        # Start with an empty block.\n        cur_block = []\n\n        for instr in instrs:\n            if 'op' in instr:  # It's an instruction.\n                # Add the instruction to the currently-being-formed block.\n                cur_block.append(instr)\n\n                # If this is a terminator (branching instruction), it's the\n                # last instruction in the block. Finish this block and\n                # start a new one.\n                if instr['op'] in TERMINATORS:\n                    yield cur_block\n                    cur_block = []\n            \n            else:  # It's a label.\n                # End the block here (if it contains anything).\n                if cur_block:\n                    yield cur_block\n\n                # Start a new block with the label.\n                cur_block = [instr]\n\n        # Produce the final block, if any.\n        if cur_block:\n            yield cur_block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#as-a-test-lets-print-out-the-blocks",
    "href": "lectures/02b_bril.html#as-a-test-lets-print-out-the-blocks",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\ndef print_blocks(bril):\n    \"\"\"Given a Bril program, print out its basic blocks.\n    \"\"\"\n\n\n    func = bril['functions'][0]  # We only process one function.\n    for block in form_blocks(func['instrs']):\n        # Mark the block.\n        leader = block[0]\n        if 'label' in leader:\n            print( f\"block {leader['label']}\")\n            block = block[1:]  # Hide the label\n        else:\n            print('anonymous block:')\n\n        # Print the instructions.\n        for instr in block:\n            print(instr)\n\nprint_blocks(bril_program)\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}\n\n\nthis test program has one block so pretty easy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#lets-try-a-second-example-with-a-jmp",
    "href": "lectures/02b_bril.html#lets-try-a-second-example-with-a-jmp",
    "title": "Overview of Bril",
    "section": "lets try a second example with a jmp",
    "text": "lets try a second example with a jmp\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#running-commands-inside-python",
    "href": "lectures/02b_bril.html#running-commands-inside-python",
    "title": "Overview of Bril",
    "section": "running commands inside python",
    "text": "running commands inside python\nGitHub Copilot: subprocess.check_output is a function in Python’s subprocess module that runs a command with arguments and returns its output as a byte string. If the command exits with a non-zero exit status, it raises a CalledProcessError, which includes the exit status and output of the command. This function is useful for capturing the output of a command for further processing in Python.\n\n\nimport subprocess\n\n# Run a command and capture its output\noutput = subprocess.check_output(['ls', '-l'])\n\n# Convert the byte string to a regular string (assuming UTF-8 encoding)\noutput_str = output.decode('utf-8')\n\nprint(output_str)\n\ntotal 848\n-rw-r--r-- 1 runner docker 40847 Oct  8 16:18 010_compiler_overview.html\n-rw-r--r-- 1 runner docker 11163 Oct  8 16:18 010_compiler_overview.qmd\n-rw-r--r-- 1 runner docker  3000 Oct  8 16:18 01a1_performance_measurement.qmd\ndrwxr-xr-x 3 runner docker  4096 Oct  8 16:17 01a1_performance_measurement_files\n-rw-r--r-- 1 runner docker  3000 Oct  8 16:18 01a2_performance_measurement.qmd\n-rw-r--r-- 1 runner docker  4134 Oct  8 16:18 01a_performance_measurement.qmd\ndrwxr-xr-x 3 runner docker  4096 Oct  8 16:17 01a_performance_measurement_files\n-rw-r--r-- 1 runner docker  7413 Oct  8 16:18 02a_representation.qmd\n-rw-r--r-- 1 runner docker 13777 Oct  8 16:18 02b_bril.qmd\n-rw-r--r-- 1 runner docker 23797 Oct  8 16:18 02b_bril.quarto_ipynb\n-rw-r--r-- 1 runner docker 12742 Oct  8 16:18 03_local.qmd\n-rw-r--r-- 1 runner docker 13267 Oct  8 16:18 03b_local_value_numbering.qmd\n-rw-r--r-- 1 runner docker  9438 Oct  8 16:18 04_data_flow.qmd\n-rw-r--r-- 1 runner docker  9974 Oct  8 16:18 05_global.qmd\n-rw-r--r-- 1 runner docker  4552 Oct  8 16:18 05b_licm.qmd\n-rw-r--r-- 1 runner docker 33595 Oct  8 16:18 05c_pre.html\n-rw-r--r-- 1 runner docker  3148 Oct  8 16:18 05c_pre.qmd\n-rw-r--r-- 1 runner docker 20184 Oct  8 16:18 06_ssa.qmd\n-rwxr-xr-x 1 runner docker 25506 Oct  8 16:17 07_llvm.ipynb\n-rw-r--r-- 1 runner docker  5691 Oct  8 16:18 08_classic_loop_ops.qmd\n-rwxr-xr-x 1 runner docker 32457 Oct  8 16:18 09_poly.qmd\ndrwxr-xr-x 3 runner docker  4096 Oct  8 16:17 09_poly_files\n-rw-r--r-- 1 runner docker   302 Oct  8 16:18 100_mlir.qmd\n-rw-r--r-- 1 runner docker   320 Oct  8 16:18 110_whole_program.qmd\n-rw-r--r-- 1 runner docker 21228 Oct  8 16:18 12_memory.html\n-rw-r--r-- 1 runner docker   316 Oct  8 16:18 12_memory.qmd\n-rw-r--r-- 1 runner docker 16077 Oct  8 16:18 13_dynamic_compilers.qmd\n-rw-r--r-- 1 runner docker 10116 Oct  8 16:18 14_gpu_compilers.qmd\n-rw-r--r-- 1 runner docker  4682 Oct  8 16:17 a.json\n-rw-r--r-- 1 runner docker   248 Oct  8 16:17 a.ts\ndrwxr-xr-x 2 runner docker  4096 Oct  8 16:17 df\n-rw-r--r-- 1 runner docker  9019 Oct  8 16:18 diverg.qmd\n-rw-r--r-- 1 runner docker  4595 Oct  8 16:17 errors\n-rw-r--r-- 1 runner docker  3623 Oct  8 16:17 foo.ll\n-rw-r--r-- 1 runner docker  2296 Oct  8 16:17 identity.bc\ndrwxr-xr-x 2 runner docker  4096 Oct  8 16:17 images\n-rw-r--r-- 1 runner docker 30795 Oct  8 16:18 junk.html\n-rw-r--r-- 1 runner docker  2134 Oct  8 16:18 junk.qmd\n-rw-r--r-- 1 runner docker   905 Oct  8 16:17 junk.txt\n-rw-r--r-- 1 runner docker 45270 Oct  8 16:18 llvm.html\n-rw-r--r-- 1 runner docker 18081 Oct  8 16:18 llvm.qmd\n-rw-r--r-- 1 runner docker 13221 Oct  8 16:18 mem_consistancy.qmd\n-rw-r--r-- 1 runner docker  2260 Oct  8 16:18 mlir.qmd\ndrwxr-xr-x 2 runner docker  4096 Oct  8 16:17 papers\ndrwxr-xr-x 2 runner docker  4096 Oct  8 16:17 ra\n-rw-r--r-- 1 runner docker  8226 Oct  8 16:18 ra-checking.qmd\n-rw-r--r-- 1 runner docker  8014 Oct  8 16:18 register_allocation.qmd\n-rw-r--r-- 1 runner docker 52254 Oct  8 16:18 revealjs_010_compiler_overview.qmd.html\n-rw-r--r-- 1 runner docker 44624 Oct  8 16:18 revealjs_05c_pre.qmd.html\n-rw-r--r-- 1 runner docker 33176 Oct  8 16:18 revealjs_12_memory.qmd.html\n-rw-r--r-- 1 runner docker 41999 Oct  8 16:18 revealjs_junk.qmd.html\n-rw-r--r-- 1 runner docker 57841 Oct  8 16:18 revealjs_llvm.qmd.html\n-rw-r--r-- 1 runner docker 22316 Oct  8 16:17 xx",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#print-the-blocks",
    "href": "lectures/02b_bril.html#print-the-blocks",
    "title": "Overview of Bril",
    "section": "print the blocks",
    "text": "print the blocks\n\nimport json \nimport os\nimport subprocess\n\nresult =  subprocess.check_output('bril2json &lt; images/jmp.bril', shell=True)\ntest2json = json.loads(result)\nprint_blocks(test2json)\n\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}\n{'labels': ['somewhere'], 'op': 'jmp'}\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}\nblock somewhere\n{'args': ['v'], 'op': 'print'}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#the-map-label-names-to-blocks",
    "href": "lectures/02b_bril.html#the-map-label-names-to-blocks",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\nfrom collections import OrderedDict\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n\n    The name of the block comes from the label it starts with, if any.\n    Anonymous blocks, which don't start with a label, get an\n    automatically generated name. Blocks in the mapping have their\n    labels removed.\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = f'gen_bk_{len(by_name)}'\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\nfor (name, instrs) in od.items():\n    print (name, instrs)\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#the-cfg-given-the-block-map-pseudo-code",
    "href": "lectures/02b_bril.html#the-cfg-given-the-block-map-pseudo-code",
    "title": "Overview of Bril",
    "section": "the cfg given the block map (pseudo code)",
    "text": "the cfg given the block map (pseudo code)\nout cfg = {} \n# map label -&gt; list of labels the successors of the block\n\nfor i,block in enumerate(blocks)  # blocks is a ordereddict \n    last = block[i]  # last instruction\n    if last is jmp:\n        cfg[block_name] = jmp.dest\n    elif last is br:\n        cfg[block.name] = [ last.if_label, last.else_label]\n    else\n        # fall through\n        cfg[block_name] = blocks[i+1].name  ## special case for last block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#cfg",
    "href": "lectures/02b_bril.html#cfg",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\ndef get_cfg(ordered_blocks):\n    cfg = {}\n\n    labels = list(ordered_blocks.keys())\n\n    for i, (block_name, block) in enumerate(ordered_blocks.items()):\n        last = block[-1]\n        op = last['op']\n\n        if op == 'jmp':\n            cfg[block_name] = last['labels']\n        elif op == 'br':\n            cfg[block_name] = last['labels']\n        else:\n            if i+1 &lt; len(labels):  # last block does not fall through\n                cfg[block_name] = [labels[i+1]]\n            else:\n                cfg[block_name] = []\n    return cfg\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\ncfg = get_cfg(od)\n\nprint(cfg)\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere'], 'somewhere': []}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#graph",
    "href": "lectures/02b_bril.html#graph",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#homework",
    "href": "lectures/02b_bril.html#homework",
    "title": "Overview of Bril",
    "section": "homework",
    "text": "homework\nDue in 1 week\nYour goal is to get familiar with Bril.\n\nPart 1\nWrite a new benchmark.\nYou can write it by hand, use the TypeScript compiler, or generate it some other way. Try running it with brili.\nUse turnt –save yours.bril to create the test outputs for your new benchmark. (See the Turnt README for details.)\nStart your blog post, talking about your benchmark.\n\npart 2\nWrite a program to analyze or transform Bril programs in some small way. Pick your favorite programming language—there is no “starter code,” so you can start from scratch.\nLoad up a JSON file. You can start with the tiny ones in lectures/images! Read the docs.\nDo something unambitious with it: count the number of add instructions, or add a print instruction before every jump, or whatever. Pick something small and contrived! Use Turnt to test your new tool.\nAlong the way, you will run into problems! Ask questions on github discussions, use open issues and pull requests to describe or fix problems. For example, even super simple benchmarks you might imagine probably can’t be written easily because Bril is too simple. Mention this in discussions, and consider pitching in to help add features.\nThink about how to write a good test, and add to your post describing your work, submit the post on github, and finally add a link to the post in canvas, homework 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#how-to-use-bril-with-real-code",
    "href": "lectures/revealjs_02b_bril.qmd.html#how-to-use-bril-with-real-code",
    "title": "Overview of Bril",
    "section": "How to use Bril with real code",
    "text": "How to use Bril with real code\n\nBril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\n\nCode\nimport json\nimport subprocess\nimport os \nimport sys\n\n\n### temp \nout = subprocess.check_output('which python', shell=True)\nprint(out)\nprint('***********************')\n\n# read from a file \nwith open(\"images/add.json\",\"r\") as f:\n    bril_program = json.load(f)\n\n# read from a pipe\n# bril_program = json.load(sys.stdin)\n    \nprint(json.dumps(bril_program, \n    indent=2))"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.-output",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\n\nb'/opt/hostedtoolcache/Python/3.10.15/x64/bin/python\\n'\n***********************\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#formatted",
    "href": "lectures/revealjs_02b_bril.qmd.html#formatted",
    "title": "Overview of Bril",
    "section": "Formatted",
    "text": "Formatted\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\"dest\": \"v0\", \"op\": \"const\",\"type\": \"int\",\"value\": 1},\n        {\"dest\": \"v1\", \"op\": \"const\",\"type\": \"int\",\"value\": 2},\n        {\"dest\": \"v2\", \"op\": \"add\",  \"type\": \"int\",\"args\": [\"v0\",\"v1\"],},\n                       \"op\": \"print\",\"args\": [ \"v2\"],}],\n      \"name\": \"main\",\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#getting-started",
    "href": "lectures/revealjs_02b_bril.qmd.html#getting-started",
    "title": "Overview of Bril",
    "section": "getting started",
    "text": "getting started\nlinks:\n\nLanguage specification\ngithub site"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "title": "Overview of Bril",
    "section": "step 1 clone the bril repo on a linux or wsl machine",
    "text": "step 1 clone the bril repo on a linux or wsl machine\ngit clone https://github.com/sampsyo/bril.git"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-2-support-packages",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-2-support-packages",
    "title": "Overview of Bril",
    "section": "step 2 support packages",
    "text": "step 2 support packages\n\ndeno is the runtime for typescript/javascript\n\ncurl -fsSL https://deno.land/install.sh | sh\non my ubuntu machine ‘sudo snap install deno’ also worked\nyou may need to add $HOME/.deno/bin to your $PATH.\n\nflit a python package manager\n\npython3 -m pip install flit"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "title": "Overview of Bril",
    "section": "step 3 install the bril interpreter, and the typescript to bril compiler",
    "text": "step 3 install the bril interpreter, and the typescript to bril compiler\ncd bril\ndeno install brili.ts \ndeno install --allow-env --allow-read ts2bril.ts"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#running-the-interpreter",
    "href": "lectures/revealjs_02b_bril.qmd.html#running-the-interpreter",
    "title": "Overview of Bril",
    "section": "running the interpreter",
    "text": "running the interpreter\nbrili &lt;images/add.json\nbrili -p &lt;images/add.json\nthe -p flag turns on profiling"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#text-to-json-and-back",
    "href": "lectures/revealjs_02b_bril.qmd.html#text-to-json-and-back",
    "title": "Overview of Bril",
    "section": "text to json and back",
    "text": "text to json and back\nThere are programs bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\ninstall text tools\ncd bril-txt\nflit install --symlink --user\nrun json to text\nbril2txt &lt; images/add.json"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#connect-tools-via-pipes",
    "href": "lectures/revealjs_02b_bril.qmd.html#connect-tools-via-pipes",
    "title": "Overview of Bril",
    "section": "connect tools via pipes",
    "text": "connect tools via pipes\ncat images/add.json'\nbril2txt &lt; images/add.json | bril2json"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#other-tools",
    "href": "lectures/revealjs_02b_bril.qmd.html#other-tools",
    "title": "Overview of Bril",
    "section": "Other tools",
    "text": "Other tools\nThere is also a fast interpreter written in Rust see docs for installation"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#turnt-tiny-unified-runner-and-tester",
    "href": "lectures/revealjs_02b_bril.qmd.html#turnt-tiny-unified-runner-and-tester",
    "title": "Overview of Bril",
    "section": "turnt Tiny unified runner and tester",
    "text": "turnt Tiny unified runner and tester\nBril uses turnt as a test tool\nTurnt is a simple snapshot testing tool inspired by LLVM’s lit. It’s good for testing things that translate text files to other text files, like compilers. The idea is that each test is one input file, and you want to run a command and check that it still matches the saved output file.\npip install –user turnt\nAs you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (can be wsl) machine"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#gen-cfg",
    "href": "lectures/revealjs_02b_bril.qmd.html#gen-cfg",
    "title": "Overview of Bril",
    "section": "Gen CFG",
    "text": "Gen CFG\nLets write a sample program - that generates the cfg\nHow would you do that?\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}\n\nI’ll do this in two steps\n\nfind all the basic blocks\nadd all the cfg edges\n\nYou can also do this in a single step, adding cfg edges as soon as you reach the successor node."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#basic-blocks-from-a-list-of-instructions-",
    "href": "lectures/revealjs_02b_bril.qmd.html#basic-blocks-from-a-list-of-instructions-",
    "title": "Overview of Bril",
    "section": "basic blocks from a list of instructions-",
    "text": "basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\n\nin: list of instrs \nout: list of lists of instrs \n \nblocks = []\ncurr_block = []\nfor each instr in list \n    if the instruction is not a label put it on curr_block\n    if instr is a label or terminator \n       put curr_block on blocks\n       curr_block = []\n \n if curr_block is not empty add it to blocks\n return blocks \ntwo labels in a row do not need another block"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-2-add-edges",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-2-add-edges",
    "title": "Overview of Bril",
    "section": "step 2 add edges",
    "text": "step 2 add edges\nfind cfg: in: is bril program in json \nfor each function find the list of basic blocks\nfor each basic block\n   get last_instr \n   if it is a terminator  br/jmp/ret \n     add edge from current block to successor  \n    --- what do we want to do with call? \n   else it is a fall through\n      add edge to next block\n\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we handle fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case\nwhat happens if try to delete the terminator (because the block never executes)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#code",
    "href": "lectures/revealjs_02b_bril.qmd.html#code",
    "title": "Overview of Bril",
    "section": "code",
    "text": "code\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#ill-use-a-generator",
    "href": "lectures/revealjs_02b_bril.qmd.html#ill-use-a-generator",
    "title": "Overview of Bril",
    "section": "I’ll use a generator",
    "text": "I’ll use a generator\nIn Python, a generator is an iterator that is defined with a function using the yield statement.\n\nProduce items only once\nDo not store all the items in memory\nWhen items from the generator are requested, the function executes until it reaches a yield statement, which produces the next value. Execution then pauses, preserving the function’s state, until the next item is requested."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\n\nCode\ndef print_blocks(bril):\n    \"\"\"Given a Bril program, print out its basic blocks.\n    \"\"\"\n\n\n    func = bril['functions'][0]  # We only process one function.\n    for block in form_blocks(func['instrs']):\n        # Mark the block.\n        leader = block[0]\n        if 'label' in leader:\n            print( f\"block {leader['label']}\")\n            block = block[1:]  # Hide the label\n        else:\n            print('anonymous block:')\n\n        # Print the instructions.\n        for instr in block:\n            print(instr)\n\nprint_blocks(bril_program)\n\n\n\nthis test program has one block so pretty easy"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks-output",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-try-a-second-example-with-a-jmp",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-try-a-second-example-with-a-jmp",
    "title": "Overview of Bril",
    "section": "lets try a second example with a jmp",
    "text": "lets try a second example with a jmp\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#running-commands-inside-python",
    "href": "lectures/revealjs_02b_bril.qmd.html#running-commands-inside-python",
    "title": "Overview of Bril",
    "section": "running commands inside python",
    "text": "running commands inside python\nGitHub Copilot: subprocess.check_output is a function in Python’s subprocess module that runs a command with arguments and returns its output as a byte string. If the command exits with a non-zero exit status, it raises a CalledProcessError, which includes the exit status and output of the command. This function is useful for capturing the output of a command for further processing in Python."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#print-the-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#print-the-blocks",
    "title": "Overview of Bril",
    "section": "print the blocks",
    "text": "print the blocks\n\n\nCode\nimport json \nimport os\nimport subprocess\n\nresult =  subprocess.check_output('bril2json &lt; images/jmp.bril', shell=True)\ntest2json = json.loads(result)\nprint_blocks(test2json)\n\n\n\n\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}\n{'labels': ['somewhere'], 'op': 'jmp'}\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}\nblock somewhere\n{'args': ['v'], 'op': 'print'}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\n\nCode\nfrom collections import OrderedDict\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n\n    The name of the block comes from the label it starts with, if any.\n    Anonymous blocks, which don't start with a label, get an\n    automatically generated name. Blocks in the mapping have their\n    labels removed.\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = f'gen_bk_{len(by_name)}'\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\nfor (name, instrs) in od.items():\n    print (name, instrs)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks-output",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-cfg-given-the-block-map-pseudo-code",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-cfg-given-the-block-map-pseudo-code",
    "title": "Overview of Bril",
    "section": "the cfg given the block map (pseudo code)",
    "text": "the cfg given the block map (pseudo code)\nout cfg = {} \n# map label -&gt; list of labels the successors of the block\n\nfor i,block in enumerate(blocks)  # blocks is a ordereddict \n    last = block[i]  # last instruction\n    if last is jmp:\n        cfg[block_name] = jmp.dest\n    elif last is br:\n        cfg[block.name] = [ last.if_label, last.else_label]\n    else\n        # fall through\n        cfg[block_name] = blocks[i+1].name  ## special case for last block"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#cfg",
    "href": "lectures/revealjs_02b_bril.qmd.html#cfg",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\n\nCode\ndef get_cfg(ordered_blocks):\n    cfg = {}\n\n    labels = list(ordered_blocks.keys())\n\n    for i, (block_name, block) in enumerate(ordered_blocks.items()):\n        last = block[-1]\n        op = last['op']\n\n        if op == 'jmp':\n            cfg[block_name] = last['labels']\n        elif op == 'br':\n            cfg[block_name] = last['labels']\n        else:\n            if i+1 &lt; len(labels):  # last block does not fall through\n                cfg[block_name] = [labels[i+1]]\n            else:\n                cfg[block_name] = []\n    return cfg\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\ncfg = get_cfg(od)\n\nprint(cfg)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#cfg-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#cfg-output",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere'], 'somewhere': []}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#graph",
    "href": "lectures/revealjs_02b_bril.qmd.html#graph",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#graph-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#graph-output",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#homework",
    "href": "lectures/revealjs_02b_bril.qmd.html#homework",
    "title": "Overview of Bril",
    "section": "homework",
    "text": "homework\nDue in 1 week\nYour goal is to get familiar with Bril."
  },
  {
    "objectID": "lectures/12_memory.html",
    "href": "lectures/12_memory.html",
    "title": "Dynamic Memory Management",
    "section": "",
    "text": "Warning\n\n\n\nnot done\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Memory Management"
    ]
  },
  {
    "objectID": "lectures/llvm.html",
    "href": "lectures/llvm.html",
    "title": "using llvm",
    "section": "",
    "text": "handy links\nllvm programmers guide\nAdrians tutorial\nskeleton code\nllvm doc\ngoogle, github pilot and chatgpt are very useful.\n\n\nas a first step I’m going to show how to install clang and cmake\nsudo apt install clang cmake",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#install-clang-and-friends",
    "href": "lectures/llvm.html#install-clang-and-friends",
    "title": "using llvm",
    "section": "",
    "text": "as a first step I’m going to show how to install clang and cmake\nsudo apt install clang cmake",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#llvm-ir",
    "href": "lectures/llvm.html#llvm-ir",
    "title": "using llvm",
    "section": "llvm ir",
    "text": "llvm ir\nclang -emit-llvm -S -o - temp.c\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\ncompared to bril\nmore complex types, variables are %n, assumes a stack, must be in ssa",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-copilet",
    "href": "lectures/llvm.html#using-copilet",
    "title": "using llvm",
    "section": "using copilet",
    "text": "using copilet\nwhat does the llvm alloca do\nIn LLVM, the alloca instruction is used to allocate memory on the stack. It stands for “allocate” and is similar to the alloca function in C. The memory allocated by alloca is automatically freed when the function returns, making it suitable for allocating temporary storage within a function.\nExplanation of alloca Instruction\nSyntax: alloca &lt;type&gt;, &lt;num_elements&gt;, &lt;alignment&gt;\n&lt;type&gt;: The type of the elements to be allocated.\n&lt;num_elements&gt;: The number of elements to allocate (optional, defaults to 1).\n&lt;alignment&gt;: The alignment of the allocated memory (optional).\nExample from the Provided Code\nExplanation:\n%3 = alloca i32, align 4:\n\nAllocates memory for a single i32 (32-bit integer) on the stack.\nThe allocated memory is aligned to a 4-byte boundary.\nThe result is a pointer to the allocated memory, stored in the variable %3.\n%4 = alloca i32, align 4:\n\nSimilar to the first instruction, this allocates memory for another i32 on the stack with 4-byte alignment.\nThe result is stored in the variable %4.\n%5 = alloca i8**, align 8:\n\nAllocates memory for a single i8** (pointer to a pointer to an 8-bit integer) on the stack.\nThe allocated memory is aligned to an 8-byte boundary.\nThe result is stored in the variable %5.\nUsage:\nTemporary Storage: alloca is typically used for temporary storage within a function, such as local variables.\nAutomatic Deallocation: The memory allocated by alloca is automatically deallocated when the function returns, so there is no need to manually free it.\nExample in Context:\nIn the provided LLVM IR code, the alloca instructions are used to allocate space for local variables %3, %4, and %5 on the stack. These variables are then used to store values and perform operations within the main function.\n\nIn this function:\n\n%3 is allocated for an i32 and initialized to 0.\n%4 is allocated for an i32 and initialized with the value of the first argument %0.\n%5 is allocated for an i8** and initialized with the value of the second argument %1.\nThe value stored in %4 is loaded into %6 and returned.\nThis demonstrates how alloca is used to manage local variables within an LLVM function.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#llvm-classes",
    "href": "lectures/llvm.html#llvm-classes",
    "title": "using llvm",
    "section": "llvm classes",
    "text": "llvm classes\nwhat is llvm value\nIn LLVM, a Value is a fundamental class that represents a typed constant or variable. It is the base class for all values computed by a program that may be used as operands to other values. This includes constants, instructions, function arguments, and more.\n\nKey Points about llvm::Value:\nBase Class: llvm::Value is the base class for many other classes in LLVM, such as llvm::Instruction, llvm::Constant, llvm::Argument, and llvm::GlobalVariable.\nTyped: Every Value has a type, represented by the llvm::Type class. This type information is crucial for type checking and code generation.\nUse-Def Chain: Value objects maintain a list of uses, which are the places where the value is used. This is part of the use-def (use-definition) chain, which is important for optimizations and transformations.\n\nCommon Subclasses of llvm::Value:\nllvm::Instruction: Represents an individual instruction in the LLVM IR.\nllvm::Constant: Represents a constant value, such as an integer or floating-point constant.\nllvm::Argument: Represents an argument to a function.\nllvm::GlobalVariable: Represents a global variable.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "href": "lectures/llvm.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "title": "using llvm",
    "section": "llvm classes (llvm is c++ but does not use standard library)",
    "text": "llvm classes (llvm is c++ but does not use standard library)\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#plugins",
    "href": "lectures/llvm.html#plugins",
    "title": "using llvm",
    "section": "plugins",
    "text": "plugins\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThe advantage for us is that using a plugin means you do not have to ever build llvm from source.\nThere is a cs6120 package that makes setting up the build process for plugins simpler\npass starter\nThis has branches\nmaster - prints names of functions\ncontainers - prints everything\nmutate - changes the code\nrtlib - easier way to insert code with needing irbuilder",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-llvm-branches",
    "href": "lectures/llvm.html#using-llvm-branches",
    "title": "using llvm",
    "section": "using llvm branches",
    "text": "using llvm branches\nTo clone a specific branch from a GitHub repository, you can use the git clone command with the -b option followed by the branch name and the repository URL. Here is the syntax:\ngit clone -b   \nto switch branches\ngit fetch –all\ngit checkout",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-the-master-branch",
    "href": "lectures/llvm.html#using-the-master-branch",
    "title": "using llvm",
    "section": "using the master branch",
    "text": "using the master branch\ngit clone https://github.com/sampsyo/llvm-pass-skeleton\nls gives\nCMakeLists.txt LICENSE README.md skeleton\nls skeleton CMakeLists.txt Skeleton.cpp",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#skeleton.cpp",
    "href": "lectures/llvm.html#skeleton.cpp",
    "title": "using llvm",
    "section": "Skeleton.cpp",
    "text": "Skeleton.cpp\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M) {\n            errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n        }\n        return PreservedAnalyses::all();\n    };\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#how-to-build-this",
    "href": "lectures/llvm.html#how-to-build-this",
    "title": "using llvm",
    "section": "how to build this",
    "text": "how to build this\n~/llvm/llvm-pass-skeleton$ mkdir build\ncd build \n cmake ..\n\n– Registering SkeletonPass as a pass plugin (static build: OFF) – Configuring done – Generating done – Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n\nThis generates build/skeleton/SkeletonPass.so\n\nto run this \n\nclang -fpass-plugin=llvm-pass-skeleton/build/skeleton/SkeletonPass.so a.cpp\n\ncreates a.out and prints out info from the pass\n\n\nto make this easier to use you might create a bash script or a makefile \n\n## look at the post on containers \n\n## getting more info \n\nSome helpfull llvm operations\n\nerrs() &lt;&lt; “function Body:”; errs() &lt;&lt; F &lt;&lt; ‘“;’\n\noutput\nI saw a function called main! function Body: ; Function Attrs: noinline nounwind optnone uwtable define dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 { %3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 ret i32 %6 }\n\n## entering containers \nPreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) { for (auto &F : M) { errs() &lt;&lt; “I saw a function called” &lt;&lt; F.getName() &lt;&lt; “!”; for (auto &B : F) { errs() &lt;&lt; “starting block”; errs() &lt;&lt; B &lt;&lt; “”; for (auto &I : B) { errs() &lt;&lt; “instr:” &lt;&lt; I &lt;&lt; “”; } }; }; return PreservedAnalyses::all(); };\n\nI saw a function called main! starting block\n%3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 ret i32 %6\ninstr: %3 = alloca i32, align 4 instr: %4 = alloca i32, align 4 instr: %5 = alloca i8, align 8 instr: store i32 0, i32* %3, align 4 instr: store i32 %0, i32* %4, align 4 instr: store i8 %1, i8*** %5, align 8 instr: %6 = load i32, i32* %4, align 4 instr: ret i32 %6\n\n\n## modify the program \n\nfind the first binary operator and change it to a multiply\n\n#// temp.c int main(int argc, char **argv) { return argc + 5; }\n\n``` PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM)\n        {\n            for (auto &F : M)\n            {\n                errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n                for (auto &B : F)\n                {\n                    for (auto &I : B)\n                    {\n                        if (isa&lt;BinaryOperator&gt;(&I))\n                        {\n                            errs() &lt;&lt; \"instr:\" &lt;&lt; I &lt;&lt; \"\\n\";\n                        }\n                        auto *op = dyn_cast&lt;BinaryOperator&gt;(&I);\n                        errs() &lt;&lt; \"from_op:\" &lt;&lt; op &lt;&lt; \"\\n\";\n                    }\n                };\n            };\n            return PreservedAnalyses::all();\n        }\n   \noutput\nI saw a function called main!\nI saw a function called main!\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\ninstr:  %7 = add nsw i32 %6, 5\nfrom_op:0xb58610\nfrom_op:0x0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#getting-analysis-info",
    "href": "lectures/llvm.html#getting-analysis-info",
    "title": "using llvm",
    "section": "getting analysis info",
    "text": "getting analysis info\n   PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Get the DominatorTree for the function.\n            DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Print the dominator tree.\n            errs() &lt;&lt; \"Dominator Tree for function: \" &lt;&lt; F.getName() &lt;&lt; \"\\n\";\n            DT.print(errs());\n        }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#testing",
    "href": "lectures/llvm.html#testing",
    "title": "using llvm",
    "section": "testing",
    "text": "testing\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#irbuilder",
    "href": "lectures/llvm.html#irbuilder",
    "title": "using llvm",
    "section": "irbuilder",
    "text": "irbuilder\n\n errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n                for (auto &B : F)\n                {\n                    errs() &lt;&lt; B &lt;&lt; \"\\n\";\n\n                    for (auto &I : B)\n                    {\n                        if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I))\n                        {\n                            errs() &lt;&lt; \"old inst \" &lt;&lt; *op &lt;&lt; \"\\n\";\n                            IRBuilder&lt;&gt; builder(op);\n                            Value *left = op-&gt;getOperand(0);  // first operand\n                            Value *right = op-&gt;getOperand(1); // second operad\n                            Value *mul = builder.CreateMul(left, right);\n\n                            errs() &lt;&lt; \"new inst:\" &lt;&lt; *mul &lt;&lt; \"\\n\";\n\n                            errs() &lt;&lt; B &lt;&lt; \"\\n\";\n\n                            // replace uses of op with mul\n                            for (auto &U : op-&gt;uses())\n                            {\n                                int num = U.getOperandNo(); // which argument\n                                User *user = U.getUser();   // the instruction with the use\n                                errs() &lt;&lt; \" user:\" &lt;&lt; *user &lt;&lt; \"   \";\n                                user-&gt;setOperand(num, mul);\n                                errs() &lt;&lt; *user &lt;&lt; \"\\n\";\n                            }\n                        }\n                    }\n                }\n            };\n \n             return PreservedAnalyses::none();\noutput\nI saw a function called main!\n%3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 %7 = add nsw i32 %6, 5 ret i32 %7\nold inst %7 = add nsw i32 %6, 5 new inst: %7 = mul i32 %6, 5\n%3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 %7 = mul i32 %6, 5 %8 = add nsw i32 %6, 5 ret i32 %8\nuser: ret i32 %8 ret i32 %7\n\n\n## more complex transforms -  for instrumentation  \n\ninstrumentation code in c not using builder \n\ninsert calls to functions and link them in \n\nusing IRBuilder is a mess, So I'm going to show a trick that makes it much simpler \n\n## chat gpt \n\nhow do i write an instrumentation function in c for llvm, use a plugin pass to insert a call to the instrumentation routine\n\n1. Write the Instrumentation Function in C: Create a C function that you want to call from your LLVM pass.\n1. Create an LLVM Pass: Write an LLVM pass that inserts a call to the instrumentation function.\n1. Build and Load the Pass: Compile the pass and load it using the opt tool or integrate it into your build system.\n\n## instrumentation routine \n\nvoid instrument_function(const char* bb_name) { printf(“Instrumentation function called for basic block: %s”, bb_name); }\n\n\n## pass\n\nPreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) { LLVMContext &Ctx = M.getContext(); IRBuilder&lt;&gt; Builder(Ctx);\n    // Declare the instrumentation function as an external function\n    FunctionType *FuncType = FunctionType::get(Type::getVoidTy(Ctx), Type::getInt8PtrTy(Cctx), false);\n    FunctionCallee InstrumentFunc = M.getOrInsertFunction(\"instrument_function\", FuncType);\n\n    for (Function &F : M) {\n\n        // Insert the call at the beginning of each basic block\n        for (BasicBlock &BB : F) {\n            Builder.SetInsertPoint(&BB, BB.begin());\n\n            // Create a global string for the basic block name\n            Value *BBName = Builder.CreateGlobalStringPtr(BB.getName());\n\n            // Create the call to the instrumentation function\n            Builder.CreateCall(InstrumentFunc, BBName);\n        }\n    }\n\n    return PreservedAnalyses::none();\n\n## starter code \n\nrm -r llvm-pass-skeleton\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n## Adrians skeleton \n\nstruct SkeletonPass : public PassInfoMixin { PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) { for (auto &F : M.functions()) {\n        // Get the function to call from our runtime library.\n        LLVMContext &Ctx = F.getContext();\n        std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n        Type *retType = Type::getVoidTy(Ctx);\n        FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n        FunctionCallee logFunc =\n            F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n        for (auto &B : F) {\n            for (auto &I : B) {\n                if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                    // Insert *after* `op`.\n                    IRBuilder&lt;&gt; builder(op);\n                    builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                    // Insert a call to our function.\n                    Value* args[] = {op};\n                    builder.CreateCall(logFunc, args);\n\n                    return PreservedAnalyses::none();\n                }\n            }\n        }\n\n    }\n    return PreservedAnalyses::all();\n}\n}; ``` #include &lt;stdio.h&gt; void logop(int i) { printf(“computed: %i”, i); }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#link-together",
    "href": "lectures/llvm.html#link-together",
    "title": "using llvm",
    "section": "link together",
    "text": "link together\n`` cd llvm-pass-skeleton cc -c rtlib.c — generates rtlib.o clang -fpass-plugin=build/skeleton/SkeletonPass.so -c test.cpp – generates test.o cc test.o rtlib.o – links it together ./a.out – runs it",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#install-clang-and-friends",
    "href": "lectures/revealjs_llvm.qmd.html#install-clang-and-friends",
    "title": "using llvm",
    "section": "install clang and friends",
    "text": "install clang and friends\nas a first step I’m going to show how to install clang and cmake\nsudo apt install clang cmake"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#llvm-ir",
    "href": "lectures/revealjs_llvm.qmd.html#llvm-ir",
    "title": "using llvm",
    "section": "llvm ir",
    "text": "llvm ir\nclang -emit-llvm -S -o - temp.c\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\ncompared to bril\nmore complex types, variables are %n, assumes a stack, must be in ssa"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-copilet",
    "href": "lectures/revealjs_llvm.qmd.html#using-copilet",
    "title": "using llvm",
    "section": "using copilet",
    "text": "using copilet\nwhat does the llvm alloca do\nIn LLVM, the alloca instruction is used to allocate memory on the stack. It stands for “allocate” and is similar to the alloca function in C. The memory allocated by alloca is automatically freed when the function returns, making it suitable for allocating temporary storage within a function.\nExplanation of alloca Instruction\nSyntax: alloca &lt;type&gt;, &lt;num_elements&gt;, &lt;alignment&gt;\n&lt;type&gt;: The type of the elements to be allocated.\n&lt;num_elements&gt;: The number of elements to allocate (optional, defaults to 1).\n&lt;alignment&gt;: The alignment of the allocated memory (optional).\nExample from the Provided Code\nExplanation:\n%3 = alloca i32, align 4:\n\nAllocates memory for a single i32 (32-bit integer) on the stack.\nThe allocated memory is aligned to a 4-byte boundary.\nThe result is a pointer to the allocated memory, stored in the variable %3.\n%4 = alloca i32, align 4:\n\nSimilar to the first instruction, this allocates memory for another i32 on the stack with 4-byte alignment.\nThe result is stored in the variable %4.\n%5 = alloca i8**, align 8:\n\nAllocates memory for a single i8** (pointer to a pointer to an 8-bit integer) on the stack.\nThe allocated memory is aligned to an 8-byte boundary.\nThe result is stored in the variable %5.\nUsage:\nTemporary Storage: alloca is typically used for temporary storage within a function, such as local variables.\nAutomatic Deallocation: The memory allocated by alloca is automatically deallocated when the function returns, so there is no need to manually free it.\nExample in Context:\nIn the provided LLVM IR code, the alloca instructions are used to allocate space for local variables %3, %4, and %5 on the stack. These variables are then used to store values and perform operations within the main function.\n\nIn this function:\n\n%3 is allocated for an i32 and initialized to 0.\n%4 is allocated for an i32 and initialized with the value of the first argument %0.\n%5 is allocated for an i8** and initialized with the value of the second argument %1.\nThe value stored in %4 is loaded into %6 and returned.\nThis demonstrates how alloca is used to manage local variables within an LLVM function."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#llvm-classes",
    "href": "lectures/revealjs_llvm.qmd.html#llvm-classes",
    "title": "using llvm",
    "section": "llvm classes",
    "text": "llvm classes\nwhat is llvm value\nIn LLVM, a Value is a fundamental class that represents a typed constant or variable. It is the base class for all values computed by a program that may be used as operands to other values. This includes constants, instructions, function arguments, and more.\n\nKey Points about llvm::Value:\nBase Class: llvm::Value is the base class for many other classes in LLVM, such as llvm::Instruction, llvm::Constant, llvm::Argument, and llvm::GlobalVariable.\nTyped: Every Value has a type, represented by the llvm::Type class. This type information is crucial for type checking and code generation.\nUse-Def Chain: Value objects maintain a list of uses, which are the places where the value is used. This is part of the use-def (use-definition) chain, which is important for optimizations and transformations.\n\nCommon Subclasses of llvm::Value:\nllvm::Instruction: Represents an individual instruction in the LLVM IR.\nllvm::Constant: Represents a constant value, such as an integer or floating-point constant.\nllvm::Argument: Represents an argument to a function.\nllvm::GlobalVariable: Represents a global variable."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "href": "lectures/revealjs_llvm.qmd.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "title": "using llvm",
    "section": "llvm classes (llvm is c++ but does not use standard library)",
    "text": "llvm classes (llvm is c++ but does not use standard library)\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#plugins",
    "href": "lectures/revealjs_llvm.qmd.html#plugins",
    "title": "using llvm",
    "section": "plugins",
    "text": "plugins\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThe advantage for us is that using a plugin means you do not have to ever build llvm from source.\nThere is a cs6120 package that makes setting up the build process for plugins simpler\npass starter\nThis has branches\nmaster - prints names of functions\ncontainers - prints everything\nmutate - changes the code\nrtlib - easier way to insert code with needing irbuilder"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-llvm-branches",
    "href": "lectures/revealjs_llvm.qmd.html#using-llvm-branches",
    "title": "using llvm",
    "section": "using llvm branches",
    "text": "using llvm branches\nTo clone a specific branch from a GitHub repository, you can use the git clone command with the -b option followed by the branch name and the repository URL. Here is the syntax:\ngit clone -b   \nto switch branches\ngit fetch –all\ngit checkout"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-the-master-branch",
    "href": "lectures/revealjs_llvm.qmd.html#using-the-master-branch",
    "title": "using llvm",
    "section": "using the master branch",
    "text": "using the master branch\ngit clone https://github.com/sampsyo/llvm-pass-skeleton\nls gives\nCMakeLists.txt LICENSE README.md skeleton\nls skeleton CMakeLists.txt Skeleton.cpp"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#skeleton.cpp",
    "href": "lectures/revealjs_llvm.qmd.html#skeleton.cpp",
    "title": "using llvm",
    "section": "Skeleton.cpp",
    "text": "Skeleton.cpp\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M) {\n            errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n        }\n        return PreservedAnalyses::all();\n    };\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#how-to-build-this",
    "href": "lectures/revealjs_llvm.qmd.html#how-to-build-this",
    "title": "using llvm",
    "section": "how to build this",
    "text": "how to build this\n~/llvm/llvm-pass-skeleton$ mkdir build\ncd build \n cmake ..\n\n– Registering SkeletonPass as a pass plugin (static build: OFF) – Configuring done – Generating done – Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n\nThis generates build/skeleton/SkeletonPass.so\n\nto run this \n\nclang -fpass-plugin=llvm-pass-skeleton/build/skeleton/SkeletonPass.so a.cpp\n\ncreates a.out and prints out info from the pass\n\n\nto make this easier to use you might create a bash script or a makefile \n\n## look at the post on containers \n\n## getting more info \n\nSome helpfull llvm operations\n\nerrs() &lt;&lt; “function Body:”; errs() &lt;&lt; F &lt;&lt; ‘“;’\n\noutput\nI saw a function called main! function Body: ; Function Attrs: noinline nounwind optnone uwtable define dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 { %3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 ret i32 %6 }\n\n## entering containers \nPreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) { for (auto &F : M) { errs() &lt;&lt; “I saw a function called” &lt;&lt; F.getName() &lt;&lt; “!”; for (auto &B : F) { errs() &lt;&lt; “starting block”; errs() &lt;&lt; B &lt;&lt; “”; for (auto &I : B) { errs() &lt;&lt; “instr:” &lt;&lt; I &lt;&lt; “”; } }; }; return PreservedAnalyses::all(); };\n\nI saw a function called main! starting block\n%3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 ret i32 %6\ninstr: %3 = alloca i32, align 4 instr: %4 = alloca i32, align 4 instr: %5 = alloca i8, align 8 instr: store i32 0, i32* %3, align 4 instr: store i32 %0, i32* %4, align 4 instr: store i8 %1, i8*** %5, align 8 instr: %6 = load i32, i32* %4, align 4 instr: ret i32 %6\n\n\n## modify the program \n\nfind the first binary operator and change it to a multiply\n\n#// temp.c int main(int argc, char **argv) { return argc + 5; }\n\n``` PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM)\n        {\n            for (auto &F : M)\n            {\n                errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n                for (auto &B : F)\n                {\n                    for (auto &I : B)\n                    {\n                        if (isa&lt;BinaryOperator&gt;(&I))\n                        {\n                            errs() &lt;&lt; \"instr:\" &lt;&lt; I &lt;&lt; \"\\n\";\n                        }\n                        auto *op = dyn_cast&lt;BinaryOperator&gt;(&I);\n                        errs() &lt;&lt; \"from_op:\" &lt;&lt; op &lt;&lt; \"\\n\";\n                    }\n                };\n            };\n            return PreservedAnalyses::all();\n        }\n   \noutput\nI saw a function called main!\nI saw a function called main!\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\ninstr:  %7 = add nsw i32 %6, 5\nfrom_op:0xb58610\nfrom_op:0x0"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#getting-analysis-info",
    "href": "lectures/revealjs_llvm.qmd.html#getting-analysis-info",
    "title": "using llvm",
    "section": "getting analysis info",
    "text": "getting analysis info\n   PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Get the DominatorTree for the function.\n            DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Print the dominator tree.\n            errs() &lt;&lt; \"Dominator Tree for function: \" &lt;&lt; F.getName() &lt;&lt; \"\\n\";\n            DT.print(errs());\n        }"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#testing",
    "href": "lectures/revealjs_llvm.qmd.html#testing",
    "title": "using llvm",
    "section": "testing",
    "text": "testing\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#irbuilder",
    "href": "lectures/revealjs_llvm.qmd.html#irbuilder",
    "title": "using llvm",
    "section": "irbuilder",
    "text": "irbuilder\n\n errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n                for (auto &B : F)\n                {\n                    errs() &lt;&lt; B &lt;&lt; \"\\n\";\n\n                    for (auto &I : B)\n                    {\n                        if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I))\n                        {\n                            errs() &lt;&lt; \"old inst \" &lt;&lt; *op &lt;&lt; \"\\n\";\n                            IRBuilder&lt;&gt; builder(op);\n                            Value *left = op-&gt;getOperand(0);  // first operand\n                            Value *right = op-&gt;getOperand(1); // second operad\n                            Value *mul = builder.CreateMul(left, right);\n\n                            errs() &lt;&lt; \"new inst:\" &lt;&lt; *mul &lt;&lt; \"\\n\";\n\n                            errs() &lt;&lt; B &lt;&lt; \"\\n\";\n\n                            // replace uses of op with mul\n                            for (auto &U : op-&gt;uses())\n                            {\n                                int num = U.getOperandNo(); // which argument\n                                User *user = U.getUser();   // the instruction with the use\n                                errs() &lt;&lt; \" user:\" &lt;&lt; *user &lt;&lt; \"   \";\n                                user-&gt;setOperand(num, mul);\n                                errs() &lt;&lt; *user &lt;&lt; \"\\n\";\n                            }\n                        }\n                    }\n                }\n            };\n \n             return PreservedAnalyses::none();\noutput\nI saw a function called main!\n%3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 %7 = add nsw i32 %6, 5 ret i32 %7\nold inst %7 = add nsw i32 %6, 5 new inst: %7 = mul i32 %6, 5\n%3 = alloca i32, align 4 %4 = alloca i32, align 4 %5 = alloca i8, align 8 store i32 0, i32* %3, align 4 store i32 %0, i32* %4, align 4 store i8 %1, i8*** %5, align 8 %6 = load i32, i32* %4, align 4 %7 = mul i32 %6, 5 %8 = add nsw i32 %6, 5 ret i32 %8\nuser: ret i32 %8 ret i32 %7\n\n\n## more complex transforms -  for instrumentation  \n\ninstrumentation code in c not using builder \n\ninsert calls to functions and link them in \n\nusing IRBuilder is a mess, So I'm going to show a trick that makes it much simpler \n\n## chat gpt \n\nhow do i write an instrumentation function in c for llvm, use a plugin pass to insert a call to the instrumentation routine\n\n1. Write the Instrumentation Function in C: Create a C function that you want to call from your LLVM pass.\n1. Create an LLVM Pass: Write an LLVM pass that inserts a call to the instrumentation function.\n1. Build and Load the Pass: Compile the pass and load it using the opt tool or integrate it into your build system.\n\n## instrumentation routine \n\nvoid instrument_function(const char* bb_name) { printf(“Instrumentation function called for basic block: %s”, bb_name); }\n\n\n## pass\n\nPreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) { LLVMContext &Ctx = M.getContext(); IRBuilder&lt;&gt; Builder(Ctx);\n    // Declare the instrumentation function as an external function\n    FunctionType *FuncType = FunctionType::get(Type::getVoidTy(Ctx), Type::getInt8PtrTy(Cctx), false);\n    FunctionCallee InstrumentFunc = M.getOrInsertFunction(\"instrument_function\", FuncType);\n\n    for (Function &F : M) {\n\n        // Insert the call at the beginning of each basic block\n        for (BasicBlock &BB : F) {\n            Builder.SetInsertPoint(&BB, BB.begin());\n\n            // Create a global string for the basic block name\n            Value *BBName = Builder.CreateGlobalStringPtr(BB.getName());\n\n            // Create the call to the instrumentation function\n            Builder.CreateCall(InstrumentFunc, BBName);\n        }\n    }\n\n    return PreservedAnalyses::none();\n\n## starter code \n\nrm -r llvm-pass-skeleton\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n## Adrians skeleton \n\nstruct SkeletonPass : public PassInfoMixin { PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) { for (auto &F : M.functions()) {\n        // Get the function to call from our runtime library.\n        LLVMContext &Ctx = F.getContext();\n        std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n        Type *retType = Type::getVoidTy(Ctx);\n        FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n        FunctionCallee logFunc =\n            F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n        for (auto &B : F) {\n            for (auto &I : B) {\n                if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                    // Insert *after* `op`.\n                    IRBuilder&lt;&gt; builder(op);\n                    builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                    // Insert a call to our function.\n                    Value* args[] = {op};\n                    builder.CreateCall(logFunc, args);\n\n                    return PreservedAnalyses::none();\n                }\n            }\n        }\n\n    }\n    return PreservedAnalyses::all();\n}\n}; ``` #include &lt;stdio.h&gt; void logop(int i) { printf(“computed: %i”, i); }"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#link-together",
    "href": "lectures/revealjs_llvm.qmd.html#link-together",
    "title": "using llvm",
    "section": "link together",
    "text": "link together\n`` cd llvm-pass-skeleton cc -c rtlib.c — generates rtlib.o clang -fpass-plugin=build/skeleton/SkeletonPass.so -c test.cpp – generates test.o cc test.o rtlib.o – links it together ./a.out – runs it"
  },
  {
    "objectID": "blogs/aymane/readme2.html",
    "href": "blogs/aymane/readme2.html",
    "title": "Homework 2 – Implementing DCE and LVN",
    "section": "",
    "text": "This assignment assumes that the input program is a single block. Multi block programs might not work as intended. Parsing the program into multiple blocks is handled by the helper functions inside cfg.py.\n\nPart 1: implementing trivial deadcode elimination\nI begin by setting up a class to perform dead code elimination, the class takes as input the program, and parses it before begining to perform the dce optimization. The block_dce() function performs the heavy lifting. Despite the fact that my implementation only works for a single block, I’ve tried to modularize the code such that a multi block implementation is easier.\n# perform deadcode elimination on a single block\ndef block_dce(self, block):\n    for instr in block:\n        if \"args\" not in instr.keys():\n            continue\n        self.used.update(instr[\"args\"])\n    \n    for i in range(len(block)-1, -1, -1):\n        if \"dest\" in block[i].keys() and block[i][\"dest\"] not in self.used:\n            rm_instr = block.pop(i)\n            # print(f\"Instruction removed:\\n {rm_instr}. Destination {rm_instr[\"dest\"]} was not used\")   \n    return block\nThe function loops over all instructions in the block adding only the instructions that have arguments to a set. This is done to keep track of all arguments that are used in the block. The second pass, loops over all instrucitons backwards.\nIf an instruction has a destination variable that doesn’t exists in the set of used variables we know that it is a dead instruction, therefore we can delete it.\nLet’s look at an example typescript program:\nlet x = 5n;  \nlet y = 13n;\n\nlet a = x + y;\nlet b = x + y;\nlet c = a * 2n;     # c is not used\nlet d = b * 2n;     \n\nlet e = a + 15n;    # e is not used\nlet f = d - b;\nlet g = f + 1n;     # g is not used\n\nconsole.log(f);\nWe should be able to eliminate 3 instructions.\nprogram.bril: text representation. program_j.bril: json representation. program.bril_dce: json representation with the dce pass.\nWe want to compare the number of instructions between program_j.bril and program.bril_dce and make sure the outputs are the same.\n$ wc program_j.bril && brili &lt; program_j.bril\n     280     421    4942 program_j.bril\n18\n$ wc program.bril_dce && brili &lt; program.bril_dce\n     249     375    6781 program.bril_dce\n18\nWe notice a reduction in the number of lines from 280, down to 249. Most of this reduction is a direct result of the json format returning to a new line after every entry. So most lines only contain a bracket, or a comma. The output (18) is the same for both programs.\n\n\nPart 2: implementing local value numbering\nMy lvn implementation involves two main functions: vn_gen() to generate the value number, and lvn() which performs the lvn pass.\nThe vn_gen() function returns the value number of a variable. If the variable doesn’t exist, we add it to the table, and increment the value number for the next variable.\n    def vn_gen(self, var):\n        if var not in self.vn2var.keys():\n            self.vn2var[var] = self.vn\n            self.vn += 1\n        return self.vn2var[var] \n    \n    def lvn(self, block):\n        for instr in block:\n            if \"dest\" in instr.keys():\n                if \"args\" in instr.keys():\n                    values = [self.vn_gen(arg) for arg in instr[\"args\"]]\n                    hash_entry = (instr[\"op\"], *values)\n                    canonical_var = instr[\"dest\"]\n                else:   \n                    val = instr[\"value\"]\n                    values = [self.vn_gen(instr[\"dest\"])]\n                    hash_entry = (instr[\"op\"], val)\n                    canonical_var = instr[\"dest\"]\n                \n                if hash_entry in self.hash_table.keys():\n                    vn = self.hash_table[hash_entry][\"vn\"]\n                    canonical_var = self.hash_table[hash_entry][\"canncl_var\"]\n                    self.vn2var[instr[\"dest\"]] = vn\n                    instr[\"dest\"] = canonical_var\n                \n                else:\n                    new_vn = self.vn_gen(instr[\"dest\"])\n                    self.hash_table[hash_entry] = {\"vn\": new_vn, \"canncl_var\": canonical_var}\n            else:\n                continue\n        return block\nThe lvn() function loops over all instructions in a block. If an instruction doesn’t contain a destination, we skip it. Otherwise, we check if the instruction contains arguments, if so, we calculate the value numebers of all arguments, and create the hash entry using those value numbers. If the instruction doesn’t contain arguments, then we only need to compute the value number of the destination variable, and use it to generate a hash entry.\nFinally, we need to check if the hash entry already exists in the table. If so, we update the structs to avoid recomputing the same value.\nIn the program below, the sum2 operation is redundant. Let’s see how the lvn algorithm modifices the code:\n@main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}\nRuning the lvn pass we notice that the sum2 instruction was rewritten in terms of sum1\npython3 lvn.py test.bril && bril2txt &lt; test.bril_lvn\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  sum1: int = add a b;\n  sum2: int = const sum1;\n  prod: int = mul sum1 sum2;\n  print prod;\n}\n\nValue Number Table\n{'a': 1, 'b': 2, 'sum1': 3, 'sum2': 3, 'prod': 4}\nHash Table:\n{('const', 4): {'vn': 1, 'canncl_var': 'a'}, ('const', 2): {'vn': 2, 'canncl_var': 'b'}, ('add', 1, 2): {'vn': 3, 'canncl_var': 'sum1'}, ('mul', 3, 3): {'vn': 4, 'canncl_var': 'prod'}}\n\n\nThings I found challenging\nHandling the formatting of the input and output to each command was a little tricky. It’s sometimes confusing trying to keep track of which format is being used at a specific instance when piping different commands into each other.\nFor example, it seems like the brili interpreter can not read a program from stdin, instead the filename has to be provided as input brili &lt; {filename}. This makes it difficult to pipe programs into brili, which requires running bril2txt and bril2json commands manually to guarantee correct execution.\nTo make things simple for next time, I will make sure that all programs I write accept input from stdin, and output to stdout.\nCode can be found here\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 2 -- Implementing DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/junk_dir/index.html",
    "href": "blogs/junk_dir/index.html",
    "title": "sample blog with an image and a graph",
    "section": "",
    "text": "image of rabbits\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# example data\nx = np.arange(0.1, 4, 0.5)\ny = np.exp(-x)\n\nfig, ax = plt.subplots()\nax.errorbar(x, y, xerr=0.2, yerr=0.4)\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "sample blog with an image and a graph"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html",
    "title": "Homework 1: Exploring Bril",
    "section": "",
    "text": "For this assignment, I explored the Bril intermediate representation and wrote a new benchmark along with a tool to analyze and transform Bril programs.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#introduction",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#introduction",
    "title": "Homework 1: Exploring Bril",
    "section": "",
    "text": "For this assignment, I explored the Bril intermediate representation and wrote a new benchmark along with a tool to analyze and transform Bril programs.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#detail-design",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#detail-design",
    "title": "Homework 1: Exploring Bril",
    "section": "Detail Design",
    "text": "Detail Design\nThe homework was divided into two main parts. I’ll walk through the details of my implementation, challenges faced, and the testing process.\n\nPart 1: Creating and Running a New Benchmark\nPart 2: Implementing a Bril Program Stub-Analyzer",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#conclusion",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#conclusion",
    "title": "Homework 1: Exploring Bril",
    "section": "Conclusion",
    "text": "Conclusion\nThis assignment provided a comprehensive introduction to Bril and its tooling ecosystem. By creating benchmarks and developing a custom analyzer, I gained insights into compiler design and intermediate representations.\nHardest Part: The most challenging aspect was managing dependencies and environment setup for the Bril toolchain. Careful attention to the makefile and troubleshooting through GitHub Discussions helped overcome these issues.\nTesting and Results: I validated my benchmarks and analyzer using various Bril programs. The tools successfully transformed and analyzed the input programs, demonstrating the utility of Bril in simple code analysis and transformation tasks.\nThis experience has equipped me with practical skills in working with compiler tools and representations, paving the way for more complex analyses in future assignments.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html",
    "href": "blogs/oscar/2024-09-20-HW1.html",
    "title": "HW1 - Trying Out Bril",
    "section": "",
    "text": "Bril is a very simple and educational instruction-based intermediate represnetation (IR) that is represented in JSON. It features a simple syntax that can be converted as JSON, and a suite of tools to execute the program.\nIn this assignment, we implement a basic benchmarking program with Bril, then write a simple analysis program that analyzes a Bril (JSON) program, as well as create tests for both of these using Turnt (a snapshot testing tool).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#overview",
    "href": "blogs/oscar/2024-09-20-HW1.html#overview",
    "title": "HW1 - Trying Out Bril",
    "section": "",
    "text": "Bril is a very simple and educational instruction-based intermediate represnetation (IR) that is represented in JSON. It features a simple syntax that can be converted as JSON, and a suite of tools to execute the program.\nIn this assignment, we implement a basic benchmarking program with Bril, then write a simple analysis program that analyzes a Bril (JSON) program, as well as create tests for both of these using Turnt (a snapshot testing tool).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#part-1-bril-benchmark-program",
    "href": "blogs/oscar/2024-09-20-HW1.html#part-1-bril-benchmark-program",
    "title": "HW1 - Trying Out Bril",
    "section": "Part 1: Bril Benchmark Program",
    "text": "Part 1: Bril Benchmark Program\nAfter reviewing the list of existing benchmark programs within the Bril repository (under the benchmarks directory), we notice that most benchmarks tend to consist of basic sample programs that runs a handwritten algorithm that returns some output value.\nIn keeping with this pattern, I had originally wanted to write a program that performs a single forward convolutional pass through a large matrix of data, however after noticing the tedious process of packing individual data values into large arrays, I felt that an implementation of this would be too messy. I had also wanted to test recusion in Bril, so naturally an implementation of Merge Sort would fit this purpose well. I chose an in-place version of the algorithm to reduce the complexity a little.\nAs mentioned earlier, creating arrays appear to require painstakingly pack all the individual values one at a time into memory. I had borrowed the @pack function from the bubblesort.bril benchmark to help create this array from the passed arguments for my program, 8 integer values to be stored into an unsorted array. These arguments are passed in when the program is called, as opposed to many other benchmark programs that hardcode the input values into the program.\nTaking an existing implementation of in-place merge sort written in C and converting it to a functional bril program was a relatively simple task, given the procedural and imperative nature of both languages. The difficulty mostly came down to writing proper control flow (inverting condition statements to support &gt;= and &lt;=), the verbosity of accessing individual elements in an array, and keeping track of what variables to modify. Keeping temporary notes in listing what variables are currently used within a certain scope helps keep track of how state may change in a program if a particular variable is used elsewhere.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#part-2-analysis-tool",
    "href": "blogs/oscar/2024-09-20-HW1.html#part-2-analysis-tool",
    "title": "HW1 - Trying Out Bril",
    "section": "Part 2: Analysis Tool",
    "text": "Part 2: Analysis Tool\nFor the second part of the assignment, we are tasked to write a small program that analyzes or modifies a Bril program in some way. I had originally tried to write my program in Zig for some extra practice, but time constraints locked me back to Python for convenience (JSON handling is a lot easier in Python).\nThe program I had written performs a couple of basic scans through the functions of the specified Bril program, and prints out the following for each function (if applicable):\n\nThe arguments of the function and their types\nThe list of all function calls made and their arguments\nIf recursion is present\nThe number of potential loops found within the function\n\nA potential loop is found by simply scanning for all unique labels that have a jmp or br instruction located somewhere after the label that jumps to said label.\nGathering these statistics for all functions could potentially help internally organize programs into a convenient structure and identify what the most dominating section of code is. I find that it provides a nice synopsis on what a high-level breakdown of a Bril program looks like.\nOriginally, I had also planned to add functionality that will analyze whether variables are unused, but it got needlessly complicated and felt more appropriate for dead code elimination in a later assignment.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#testing",
    "href": "blogs/oscar/2024-09-20-HW1.html#testing",
    "title": "HW1 - Trying Out Bril",
    "section": "Testing",
    "text": "Testing\nAn in-place merge sort implementation in Bril and a simple program to analyze Bril programs were developed. Both of these programs have associated Turnt tests to ensure that the outputs for these programs are matching the expected result when I had written them. For the analysis tool (flow_detect.py), I have included other existing benchmark Bril programs in testing for a variety of outputs.\nHere are some outputs for our Merge Sort program:\n$ bril2json &lt; mergesort-inplace.bril | brili -p 8 1 2 7 3 6 5 4\n1\n2\n3\n4\n5\n6\n7\n8\ntotal_dyn_inst: 677\n$ bril2json &lt; mergesort-inplace.bril | brili -p 8 7 6 5 4 3 2 1\n1\n2\n3\n4\n5\n6\n7\n8\ntotal_dyn_inst: 803\n$ bril2json &lt; mergesort-inplace.bril | brili -p 2 2 2 2 2 2 2 1\n1\n2\n2\n2\n2\n2\n2\n2\ntotal_dyn_inst: 486\nFor our analysis tool, I had selected a handful of benchmarks that have a variety of control flow. Here is the output for eight-queens:\nmain:\n    args:\n        int: input\n    function calls: 1\n        queen(zero, n, icount, site)\n\nqueen:\n    args:\n        int: n, queens, icount\n        int ptr: site\n    num potential loops: 1\n    function calls: 2\n        valid(n, site)\n        queen(n_1, queens, icount, site)\n    recursion present\n\nvalid:\n    args:\n        int: n\n        int ptr: site\n    num potential loops: 1\nAs shown, for each function a list of arguments, function calls, and indication of loops and/or recursion is demonstrated, if applicable. I have tested the program on my own Merge Sort file as well:\nmain:\n    args:\n        int: n1, n2, n3, n4, n5, n6, n7, n8\n    function calls: 3\n        pack(size, n1, n2, n3, n4, n5, n6, n7, n8)\n        merge_sort(array, zero, upper_bound)\n        print_array(array, size)\n\npack:\n    args:\n        int: size, n1, n2, n3, n4, n5, n6, n7, n8\n\nmerge:\n    args:\n        int ptr: arr\n        int: start, mid, end\n    num potential loops: 2\n\nmerge_sort:\n    args:\n        int ptr: arr\n        int: l, r\n    function calls: 3\n        merge_sort(arr, l, m)\n        merge_sort(arr, mp1, r)\n        merge(arr, l, m, r)\n    recursion present\n\nprint_array:\n    args:\n        int ptr: array\n        int: size\n    num potential loops: 1\nHere, the program correctly identifies the use of recursion in our @merge_sort function, as well as finding the two nested loops within @merge as well.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "I created a program that iterates through an array of values both suming and multiplying the values.\n\n\nthe code was written in text forma ns used a pointer to initialize the array. store and load instructions were used to access the array and .loop with a jmp was used for the iterations\n\n\n\nThe code was tested with different size arrays with the answers check using an external calculator.\n\n\n\nThe main challenge for this was finding the best way to populate the array with values. brili is very simple and using just stores and loads to index into the array gave added complexity.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#about-the-code",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "the code was written in text forma ns used a pointer to initialize the array. store and load instructions were used to access the array and .loop with a jmp was used for the iterations",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#testing",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#testing",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "The code was tested with different size arrays with the answers check using an external calculator.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#challenges",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#challenges",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "The main challenge for this was finding the best way to populate the array with values. brili is very simple and using just stores and loads to index into the array gave added complexity.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#python-tool",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#python-tool",
    "title": "Homework1 - Yashaswini",
    "section": "Python Tool",
    "text": "Python Tool\nThe python tool was run on the a new add.json file based off of my benchmark from part 1\nimport json\n\ndef load_bril_program(filename):\n    \"\"\"Load the Bril program from a JSON file.\"\"\"\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef count_add_instructions(program):\n    \"\"\"Count the number of 'add' instructions in the Bril program.\"\"\"\n    add_count = 0\n    for func in program['functions']:\n        for instr in func['instrs']:\n            if instr.get('op') == 'add':\n                add_count += 1\n    return add_count\n\ndef add_print_before_jumps(program):\n    \"\"\"Insert a 'print' instruction before every 'jmp' instruction.\"\"\"\n    for func in program['functions']:\n        new_instrs = []\n        for instr in func['instrs']:\n            if instr.get('op') == 'jmp':\n                # Add a print instruction before the jump\n                new_instr = {\n                    \"op\": \"print\",\n                    \"args\": [\"jmp\"]\n                }\n                new_instrs.append(new_instr)\n            new_instrs.append(instr)\n        func['instrs'] = new_instrs\n    return program\n\ndef save_bril_program(program, filename):\n    \"\"\"Save the transformed Bril program back to a JSON file.\"\"\"\n    with open(filename, 'w') as file:\n        json.dump(program, file, indent=2)\n\n# Main function to load, transform, and save the Bril program\ndef main():\n    # Load the Bril program from a file\n    bril_program = load_bril_program('add.json')\n\n    # Count the number of 'add' instructions\n    add_count = count_add_instructions(bril_program)\n    print(f\"Number of 'add' instructions: {add_count}\")\n\n    # Add 'print' before 'jmp' instructions\n    transformed_program = add_print_before_jumps(bril_program)\n\n    # Save the transformed Bril program to a file\n    save_bril_program(transformed_program, 'output_add.json')\n\n# Run the main function\nif __name__ == \"__main__\":\n    main()",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#output",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#output",
    "title": "Homework1 - Yashaswini",
    "section": "Output",
    "text": "Output\nthe program found 2 add instrucitons and produced and output file shown below\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\n          \"dest\": \"c5\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 5\n        },\n        {\n          \"args\": [\n            \"c5\"\n          ],\n          \"dest\": \"v0\",\n          \"op\": \"alloc\",\n          \"type\": {\n            \"ptr\": \"int\"\n          }\n        },\n        {\n          \"dest\": \"j\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 1\n        },\n        {\n          \"dest\": \"c1\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 1\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c1\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c2\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 2\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c3\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 3\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c4\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 4\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c5\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 5\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"sum\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 0\n        },\n        {\n          \"dest\": \"i\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 0\n        },\n        {\n          \"label\": \"loop\"\n        },\n        {\n          \"args\": [\n            \"i\",\n            \"c5\"\n          ],\n          \"dest\": \"cond\",\n          \"op\": \"lt\",\n          \"type\": \"bool\"\n        },\n        {\n          \"args\": [\n            \"cond\"\n          ],\n          \"labels\": [\n            \"body\",\n            \"end\"\n          ],\n          \"op\": \"br\"\n        },\n        {\n          \"label\": \"body\"\n        },\n        {\n          \"args\": [\n            \"v0\"\n          ],\n          \"dest\": \"current\",\n          \"op\": \"load\",\n          \"type\": \"int\"\n        },\n        {\n          \"args\": [\n            \"sum\",\n            \"current\"\n          ],\n          \"dest\": \"sum\",\n          \"op\": \"add\",\n          \"type\": \"int\"\n        },\n        {\n          \"args\": [\n            \"i\",\n            \"j\"\n          ],\n          \"dest\": \"i\",\n          \"op\": \"add\",\n          \"type\": \"int\"\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"jmp\"\n          ]\n        },\n        {\n          \"labels\": [\n            \"loop\"\n          ],\n          \"op\": \"jmp\"\n        },\n        {\n          \"label\": \"end\"\n        },\n        {\n          \"args\": [\n            \"sum\"\n          ],\n          \"op\": \"print\"\n        },\n        {\n          \"args\": [\n            \"v0\"\n          ],\n          \"op\": \"free\"\n        },\n        {\n          \"op\": \"ret\"\n        }\n      ],\n      \"name\": \"main\"\n    }\n  ]\n}\n##Testing\na good way to otest this is using small scripts where the number of adds is known or can be calculates.\nI could also develop a tool to reverse the addition of prints before jmp and compare the output to the original code using turnt.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-20-HW1.html",
    "href": "blogs/matin/2024-09-20-HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "After looking at the example benchmarks and the BRIL documentation, I noticed that the example benchmarks had a pseudo random number generator, and BRIL had a floating point extension. Inspired by the other scientific-based floating-point benchmarks, I decided on writing a benchmark to calculate PI using Monte Carlo (explained here). What could possibly go wrong?\n\n\nProbably the main issue I encountered was that there was no way to convert floats to ints, meaning no matter how many random integers I was generating, I couldn’t use them to generate numbers inside a unit square (1x1). To get around this issue, I tried sampling integers inside a non-unit square instead (e.g. square is 10x10, and points come from an interval of [-10, 10] on both x and y). All I had to do was make sure the pseudo random number generator outputs had a lower bound that I specified instead of zero. Again, what could possibly go wrong?\n\n\n\nAfter some debugging, I noticed that either the random number generator didn’t work as advertised (I put print statements in other benchmarks, and the values certainly weren’t greater than zero), or I was using it wrong.\nTo get around both of these issues, instead I opted in to discretize the unit square into a set of grid points, and then query whether they are inside the unit circle or not. Increasing the number of points leads to the output of the BRIL program converging to PI, so it seems to work. The benchmark and its test files are added under the benchmarks folder.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-20-HW1.html#problem-1-bril-doesnt-seem-to-convert-float-to-int-or-vice-versa",
    "href": "blogs/matin/2024-09-20-HW1.html#problem-1-bril-doesnt-seem-to-convert-float-to-int-or-vice-versa",
    "title": "Homework 1",
    "section": "",
    "text": "Probably the main issue I encountered was that there was no way to convert floats to ints, meaning no matter how many random integers I was generating, I couldn’t use them to generate numbers inside a unit square (1x1). To get around this issue, I tried sampling integers inside a non-unit square instead (e.g. square is 10x10, and points come from an interval of [-10, 10] on both x and y). All I had to do was make sure the pseudo random number generator outputs had a lower bound that I specified instead of zero. Again, what could possibly go wrong?",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-20-HW1.html#problem-2-the-number-generator-didnt-have-a-lower-bound-or-plain-just-didnt-work-as-advertised.",
    "href": "blogs/matin/2024-09-20-HW1.html#problem-2-the-number-generator-didnt-have-a-lower-bound-or-plain-just-didnt-work-as-advertised.",
    "title": "Homework 1",
    "section": "",
    "text": "After some debugging, I noticed that either the random number generator didn’t work as advertised (I put print statements in other benchmarks, and the values certainly weren’t greater than zero), or I was using it wrong.\nTo get around both of these issues, instead I opted in to discretize the unit square into a set of grid points, and then query whether they are inside the unit circle or not. Increasing the number of points leads to the output of the BRIL program converging to PI, so it seems to work. The benchmark and its test files are added under the benchmarks folder.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-09-20-Sharmila-HW01.html",
    "href": "blogs/sharmila/2024-09-20-Sharmila-HW01.html",
    "title": "Compiler Homework 01 - Trying Out Bril",
    "section": "",
    "text": "About Bril\nBril is a simple educational intermediate representation (IR) language that is used to teach and experiment with compiler and programming language concepts. It provides a set of operations such as arithmetic and logical operations, and basic control flow structures like conditional branches and loops. The idea behind Bril is to keep things minimal and easy to understand, so we can focus on the core concepts of compilers without getting distracted by complicated features found in more advanced languages.\nGoal of this Homework is to get familiar with Bril, so I chose to a write a simple benchmark under core without getting inputs(args).\nIn this blog, I’ll walk you through two parts of my Homework 01 assignment where I first write a benchmark in Bril and then develop a tool to analyze Bril programs.\n\n\nPart 1: Write a New Benchmark\nThe first part of the assignment involved writing a new benchmark in Bril. This helped me get familiar with Bril’s control flow, syntax, and basic operations.\nBenchmark: addsqevenodd.bril\nThe goal of this benchmark is to calculate the sum of squares of even and odd numbers from 1 to 10 separately. Here’s the Bril program I wrote by hand:\n\n@main {\n  sum_even: int = const 0;      \n  sum_odd: int = const 0;       \n  i: int = const 1;             \n  limit: int = const 10;        \n  one: int = const 1;           \n  two: int = const 2;           \n\n.loop:\n  square: int = mul i i;        \n  half: int = div i two;        \n  check: int = mul half two;    \n  is_even: bool = eq check i;   \n  br is_even .even_case .odd_case; \n\n.even_case:\n  sum_even: int = add sum_even square; \n  jmp .increment;\n\n.odd_case:\n  sum_odd: int = add sum_odd square;   \n\n.increment:\n  i: int = add i one;           \n  cond: bool = le i limit;      \n  br cond .loop .exit;          \n\n.exit:\n  print sum_even;               \n  print sum_odd;                \n}\n\nThis program defines a loop that iterates from 1 to 10, calculates the square of each number, and adds the result to two separate sums for even and odd numbers. Finally, it prints the sums of the squares of even and odd numbers\nAfter writing the program, I converted it to a JSON format, which is required for further processing:\nbril2json &lt; addsqevenodd.bril &gt; addsqevenodd.json\nDuring this step, I faced an issue where the Bril interpreter (brili) did not accept direct constant values in core instructions. To resolve this, I explicitly declared constants before using them in operations like add or mul. This was a good learning experience that reinforced the importance of proper initialization in IR.\nTo automate testing, I used turnt to create a test output for this benchmark. I added the following command to a turnt.toml file:\ncommand = “bril2json &lt; {filename} | brili -p {args}”\nThis command runs the benchmark through brili, captures the output, and saves it in an output file. After creating the test, I ran:\nturnt –save addsqevenodd.bril\nThis command saved the output in a file named addsqevenodd.out, which can be used for further validation.\n\n\nPart 2: Write a Bril Analyzer\nIn this part, I developed a small tool to analyze Bril programs using python. I chose to count the number of add and print instructions in the Bril program to better understand the operations performed in the code.\nHere’s the Python code I implemented to count the add and print instructions in a Bril program:\n\nimport json\nimport sys\n\n\ndef count_add_instrs(bril_program):\n\n    count = 0\n    print = 0\n    for func in bril_program['functions']:\n        for instr in func['instrs']:\n            if 'op' in instr:\n                if instr['op'] == 'add':\n                    count += 1\n\n    return count\n\ndef count_print_instrs(bril_program):\n\n    printcount = 0\n    for func in bril_program['functions']:\n        for instr in func['instrs']:\n            if 'op' in instr:\n                if instr['op'] == 'print':\n                    printcount += 1\n                    \n    return printcount\n\nif __name__ == \"__main__\":\n\n    json_file = \"/home/sharmila_ubuntu/Compiler HW 01/addsqevenodd.json\"\n    with open(json_file,'r') as f:\n        bril_program = json.load(f)\n    count = count_add_instrs(bril_program)\n    print(f\"Number of add instructions in addsqevenodd.json file : {count}\")\n    printcount = count_print_instrs(bril_program)\n    print(f\"Number of print instructions in addsqevenodd.json file : {printcount}\")\n\nThis script loads the Bril program in JSON format, iterates over its instructions, and counts how many add and print operations are present.\nI tested my analyzer using turnt by adding the following command to the turnt.toml file:\ncommand = “bril2json &lt; {filename} | python3 analyzebril.py”\nThis command takes the Bril program, converts it to JSON, and runs my Python script (analyzebril.py) to analyze the JSON file. The output file generated by this process contains the number of add and print instructions in the program.\n\n\nConclusion: Summary of this Homework 01\n\nPart 1: I wrote a benchmark (addsqevenodd.bril) that computes the sum of squares of even and odd numbers from 1 to 10 separately. I used bril2json to convert the program into JSON and ran it with brili. I also used turnt to create an automated test for the benchmark.\nPart 2: I created a Python tool to analyze the Bril program. The tool counts add and print instructions in the JSON representation of the Bril program. I tested the tool using turnt, ensuring it ran correctly.\n\n\n\nTest and Results:\nTo verify this analyzer I tested with 3 example: (obtained the later two examples from (https://github.com/sampsyo/bril/tree/main/benchmarks)\n\nInitially, I used my benchmark to test the implementation, that is, using both the addsqevenodd.bril file and its corresponding json file (addsqevenodd.json). The analyzed correctly counted 3 add instructions and 2 print instructions.\nAnd then, I verified using bubblesort.bril, loading it’s json file and analyzed correctly as 8 add instructions and 1 print instruction.\nFinally, I verifies using mat-inv.bril, loading it’s json file and analyzed correctly as 12 add instruction and 2 print instruction.\n\n\n\nChallenges Faced and Solution:\nThe hardest part of this task was dealing with the restriction on directly using constants in core Bril instructions. I initially overlooked this, but after debugging, I realized that every constant had to be initialized in a separate instruction. This helped me better understand Bril’s structure and rules. Moreover, learning to use turnt for automating tests was a valuable lesson, as it streamlines the testing process significantly.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 01 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "",
    "text": "This assignment is designed to allow us to get comfortable with Bril, an intermediate representation designed for learning. In this assignment, we add a benchmark program to the suite, and write a tool for analyzing JSON formatted Bril.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#introduction",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "",
    "text": "This assignment is designed to allow us to get comfortable with Bril, an intermediate representation designed for learning. In this assignment, we add a benchmark program to the suite, and write a tool for analyzing JSON formatted Bril.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-1-bril-benchmark-program",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-1-bril-benchmark-program",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Part 1: Bril Benchmark Program",
    "text": "Part 1: Bril Benchmark Program\nA good benchmark for this assignment is one which is new to the repository, but is fairly simple. As such, a benchmark which fits into the benchmark/core suite is likely a good choice.\nMy first idea was to implement a benchmark which computes the Hamming distance between two integers. In a high level language with a shift operator, this is a fairly easy program to write. However, Bril does not have a built-in shift operator. I spent some time writing a function to compute the Hamming distance without shifting, but it quickly became cumbersome and I searched for other ideas to not overcomplicate this work.\nMy next idea was to write a benchmark which computes the \\(nth\\) value in the Fibonacci sequence recursively. This is a sensible benchmark, as it may test a system’s ability to handle recursive programs, and further tests whether a compiler preserves this relationship.\nTo create this, only about 11 lines of TypeScript were required (when paired with the TypeScript compiler).\nAt the end, I created a program to compute the \\(nth\\) value in the Fibonacci sequence recursively, which can be found at benchmarks/core/fibonacci.bril, and can be tested with turnt.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#problems-faced",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#problems-faced",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Problems Faced",
    "text": "Problems Faced\nOne challenge as I learned was that the TS compiler does not recognize many types, and further regards many types as Any when they cannot be easily predicted. This was not much of a challenge to handle, however I am not much of a TS programmer so learning enough of the language was a step in the process.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Testing",
    "text": "Testing\nTo verify functionality, I first by hand compared the results of execution with different input values of \\(n\\), and additionally developed a turnt test. Results of testing can be observed below:\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 1\n1\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 5\n5\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 10\n55\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 30\n832040\n\n# Including timing results as evidence that recursion is happening \n$ time bril2json &lt; benchmarks/core/fibonacci.bril | brili 30\n832040\n\nreal    0m1.836s\nuser    0m1.817s\nsys 0m0.052s\n[15:02:36] michaelmaurer:~/Documents/NEU/EECE7309-compilers/bril$ time bril2json &lt; benchmarks/core/fibonacci.bril | brili 10\n55\n\nreal    0m0.102s\nuser    0m0.096s\nsys 0m0.031s",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-2-bril-tooling",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-2-bril-tooling",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Part 2: Bril Tooling",
    "text": "Part 2: Bril Tooling\nFor the second part of this assignment, we were asked to design a tool which either analyzed or modified Bril code stored in JSON format. I chose to make a simple program, which for a given file, computes how many of each “type” of instruction the program contains. The three types of instructions are “Constants”, “Value Operations”, and “Effect Operations” as outlined in the docs.\nTo do this, I wrote a Python script which consumed the input JSON, parsed it to get the available instructions, and iterated through the map. Each instruction type has a unique construction, which I used to determine how many of each type of isntruction was contained. This tool only requires one pass through the program JSON to determine the count of each instruction type.\nThis tool could readily be extended to gather information about the types of instructions in a program.\nThe code for this tool is shared below:\n\n#!/usr/bin/env python3\n\nimport json\nimport sys\n\n# Read the input as json\n# Proc Exit: If valid input rec'd\ndef read_json_file(input):\n    try:\n        data = json.load(input)\n        return data\n    except json.JSONDecodeError:\n        print(f\"Error: The input does not contain valid JSON.\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        sys.exit(1)\n\n# Count the instruction types as specified by Bril syntax\ndef count_instr_types(data: dict):\n    db = {'constant': 0, 'value': 0, 'effect': 0}\n    for func in data['functions']:\n        for instr in func['instrs']:\n            # If instr op is const, it must be a constant instruction\n            if 'op' in instr and instr['op'] == 'const':\n                db['constant'] += 1\n            # If instr has a dest and is not a const, it must be a value instruction\n            elif 'dest' in instr:\n                db['value'] += 1\n            # Continue if this is a label\n            elif 'label' in instr:\n                continue\n            # Otherwise this must be an effect instruction\n            else:\n                db['effect'] += 1\n            # Note: this assumes the json is well-formed Bril.\n    return db\n\n# Main\ndef main():\n    data = read_json_file(sys.stdin)\n    print(count_instr_types(data))\n\nif __name__ == \"__main__\":\n    main()",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing-1",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing-1",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Testing",
    "text": "Testing\nI tested this program on a handful of the provided benchmarks, and verified the results by hand. Some results are shared below:\n$ bril2json &lt; ../benchmarks/core/hanoi.bril | python tool.py \n{'constant': 5, 'value': 2, 'effect': 6}\n[15:10:42] michaelmaurer:~/Documents/NEU/EECE7309-compilers/bril/mytools$ bril2json &lt; ../benchmarks/core/birthday.bril | python tool.py \n{'constant': 9, 'value': 26, 'effect': 4}\n[15:11:04] michaelmaurer:~/Documents/NEU/EECE7309-compilers/bril/mytools$ bril2json &lt; ../benchmarks/core/collatz.bril | python tool.py \n{'constant': 3, 'value': 7, 'effect': 7}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Challenges faced",
    "text": "Challenges faced\nOriginally, I had planned to construct a program which identified all control flow instructions, and further identified how many basic blocks the program contained. I moved away from this because I was not sure how exactly to handle call and ret instructions at this time, and it seems likely this work is coming in a future assignment.\nAnother challenge was that I had at first not realized that labels are contained within the instructions in the json files. This was causing my program to crash, and required some (brief) debugging.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#code",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Code",
    "text": "Code\nThe code for this assignment is contained in the latest commit in my fork of Bril.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/junk.html",
    "href": "blogs/junk.html",
    "title": "sample blog",
    "section": "",
    "text": "this is a sample blog!\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "sample blog"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-28-Rohit-HW2.html",
    "href": "blogs/rohit/2024-09-28-Rohit-HW2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\nThe code should remove the instructions that are reassigned without being used.\nIf the value in being used in between the reassigning, then the instruction should be retained.\n\n\n\n\n\n\n\nThis function generates control flow blocks from a list of instructions.\nParameters: instrs - a list of instructions.\nProcess:\n\nIt iterates through each instruction.\nIf the instruction contains an operation (op), it adds it to the current block.\nIf the operation is a terminator (br, jmp, ret), it yields the current block and starts a new one.\nIf the instruction does not contain an operation, it yields the current block and starts a new one.\nAt the end, if there are any remaining instructions in the current block, it yields that block.\n\nReturns: Yields blocks of instructions.\n\n\n\n\n\nThis function removes instructions that are redefined without being used in a function.\nParameters: func - a dictionary representing a function with a list of instructions.\nProcess:\n\nIt repeatedly splits the function’s instructions into blocks using myCFG.\nFor each block, it tracks the last definition of each variable and identifies instructions to drop.\nIt removes instructions that are redefined without being used.\nIt updates the function’s instructions with the optimized blocks.\nThe loop continues until no more changes are made.\n\nReturns: None (modifies the function in place).\n\n\n\n\n\nThis is the main function that orchestrates the optimization process.\nProcess:\n\nIt reads a JSON object from standard input.\nFor each function in the JSON object, it applies remove_reassigned to optimize the instructions.\nIt writes the optimized JSON object to standard output.\n\n\n\n\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 42;\n    b: int = const 42;\n    }\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 42;\n    }",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 2"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-1-trivial-dead-code-elimination-which-you-delete-instructions-that-are-never-used-before-they-are-reassigned.",
    "href": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-1-trivial-dead-code-elimination-which-you-delete-instructions-that-are-never-used-before-they-are-reassigned.",
    "title": "Homework 2",
    "section": "",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\nThe code should remove the instructions that are reassigned without being used.\nIf the value in being used in between the reassigning, then the instruction should be retained.\n\n\n\n\n\n\n\nThis function generates control flow blocks from a list of instructions.\nParameters: instrs - a list of instructions.\nProcess:\n\nIt iterates through each instruction.\nIf the instruction contains an operation (op), it adds it to the current block.\nIf the operation is a terminator (br, jmp, ret), it yields the current block and starts a new one.\nIf the instruction does not contain an operation, it yields the current block and starts a new one.\nAt the end, if there are any remaining instructions in the current block, it yields that block.\n\nReturns: Yields blocks of instructions.\n\n\n\n\n\nThis function removes instructions that are redefined without being used in a function.\nParameters: func - a dictionary representing a function with a list of instructions.\nProcess:\n\nIt repeatedly splits the function’s instructions into blocks using myCFG.\nFor each block, it tracks the last definition of each variable and identifies instructions to drop.\nIt removes instructions that are redefined without being used.\nIt updates the function’s instructions with the optimized blocks.\nThe loop continues until no more changes are made.\n\nReturns: None (modifies the function in place).\n\n\n\n\n\nThis is the main function that orchestrates the optimization process.\nProcess:\n\nIt reads a JSON object from standard input.\nFor each function in the JSON object, it applies remove_reassigned to optimize the instructions.\nIt writes the optimized JSON object to standard output.\n\n\n\n\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 42;\n    b: int = const 42;\n    }\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 42;\n    }",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 2"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-2-implement-local-value-numbering",
    "href": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-2-implement-local-value-numbering",
    "title": "Homework 2",
    "section": "PART 2: Implement local value numbering",
    "text": "PART 2: Implement local value numbering\n\nAbout local value numbering:\nDefinition: Local Value Numbering (LVN) is a compiler optimization technique used to eliminate redundant calculations by assigning unique numbers to equivalent expressions. This helps in identifying and reusing previously computed values, thus improving the efficiency of the code.\n\n\nImplementation:\n\ninit(self)\n\nThis is the constructor for the ImprovedLVN class. It initializes several dictionaries and counters used in the Local Value Numbering (LVN) process.\nself.var2num: Maps variables to their value numbers.\nself.value2num: Maps operations to value numbers.\nself.num2var: Maps value numbers to variable names.\nself.next_vn: Counter for the next value number.\nself.last_computed: Maps operations to their last computed variable.\n\n\n\nfresh_value_number(self)\n\nThis function generates a fresh value number.\nReturns: A new value number and increments the counter.\n\n\n\ncanonicalize(self, value)\n\nThis function canonicalizes commutative operations like addition and multiplication to ensure consistent ordering of arguments.\nParameters: value - a Value namedtuple representing an operation and its arguments.\nReturns: A canonicalized Value namedtuple.\n\n\n\nget_lvn_var(self, vn)\n\nThis function generates a variable name for a given value number.\nParameters: vn - a value number.\nReturns: A string representing the LVN variable name.\n\n\n\nprocess_block(self, block)\n\nThis function performs Local Value Numbering (LVN) on a single block of instructions.\nParameters: block - a list of instructions.\nProcess:\n\nIterates through each instruction in the block.\nIf the instruction has a destination (‘dest’), it processes the instruction:\n\nFetches value numbers for arguments.\nCreates a canonicalized value for the current instruction.\nChecks if the value is already computed:\n\nIf yes, it uses the previous result.\nIf no, it assigns a fresh value number and updates mappings.\n\n\nAdds the processed instruction to the new block.\n\nReturns: A new block of optimized instructions.\n\n\n\nrun_lvn(self, bril_program)\n\nThis function runs LVN on the entire program.\nParameters: bril_program - a dictionary representing the BRIL program.\nProcess:\n\nIterates through each function in the program.\nApplies process_block to the instructions of each function.\n\nReturns: The optimized BRIL program.\n\n\n\n\nExample:\n\nwith a b no permutted\n\nInput bril:\n    @main {\n        a: int = const 4;\n        b: int = const 2;\n        sum1: int = div a b;\n        sum2: int = div a b;\n        prod: int = mul sum1 sum2;\n        sum2: int = div a b;\n        print prod;\n    }\n\n\nOutput bril:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = div a b;\n    sum2 = id sum1;\n    prod: int = mul sum1 sum1;\n    sum2 = id sum1;\n    print prod;\n    }\n\n\n\npairing with dead code analysis:\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  sum1: int = div a b;\n  prod: int = mul sum1 sum1;\n  sum2 = id sum1;\n  print prod;\n}\n\n\n\n\nwith a b with permutted\n\nInput bril:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add b a;\n    prod: int = mul sum1 sum2;\n    sum2: int = add b a;\n    print prod;\n    }\n\n\n\nOutput bril:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2 = id sum1;\n    prod: int = mul sum1 sum1;\n    sum2 = id sum1;\n    print prod;\n    }\n\n\n\npairing with dead code analysis:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = div a b;\n    prod: int = mul sum1 sum1;\n    sum2 = id sum1;\n    print prod;\n    }\n\nfull code: https://github.com/gurusamyanandakuma-r/bril/tree/main/HW/HW2_Rohit",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 2"
    ]
  },
  {
    "objectID": "weekly.html",
    "href": "weekly.html",
    "title": "EECS7398 Weekly Schedule fa 2024",
    "section": "",
    "text": "Since the is the first time this course is offered.\nThis is a tentative schedule.\nThe papers listed here are suggestions, if there is a different paper you would like to present, send me a link so that I can approve it.\nEither 1 or 2 people can sign up for a paper. Once everyone has done so, I’ll schedule which paper gets which date.\n\n\n\n\n\n\n\n\n\n\nsession\nDate\ntopic\ndue\ndiscussions\n\n\n\n\n1\nFriday Sept 6\nCompiler Overview\n\ndiscussion\n\n\n\n\nPerformance Measurement-1\n\n\n\n\n2\nTuesday Sept 10\nPerformance Measurement-2\n\ndiscussion\n\n\n3\nFriday Sept 13\nRepresenting programs\nhw0\ndiscussion\n\n\n\n\nBril\n\ndiscussion\n\n\n4\nTuesday Sept 17\nLocal analysis and optimization\n\ndiscussion\n\n\n5\nFriday Sept 20\nLocal Value Numbering\nhw1\n\n\n\n6\nTuesday Sept 24\nlvn + data flow\n\n\n\n\n7\nFriday Sept 27\nData flow continued\n\n\n\n\n8\nTuesday Oct 1\nData flow + graphs\n\n\n\n\n9\nFriday Oct 4\nStatic single assignment\n\n\n\n\n10\nTuesday Oct 8\nregister allocation\n\n\n\n\n11\nFriday Oct 11\nNorm unavailable - guest lecture over zoom\nhw3\n\n\n\n\nLink in canvas\n\n\n\n\n\n\n\n\n\n\n12\nTuesday Oct 15\nLoop invariant code motion + reading\n\n\n\n\n\nLeader: Aymane Jerari MLIR: A Compiler Infrastructure for the End of Moore’s Law\n\n\n\n\n\n\n\n\n\n\n13\nFriday Oct 18\nGPU Compilers\n\n\n\n\n14\nTuesday Oct 22\nGlobal value number + reading\n\n\n\n\n\nLeader: Oscar Kellner Retargeting and Respecializing GPU Workloads for Performance Portability\nproject proposal due\n\n\n\n\n\n\n\n\n\n\n15\nFriday Oct 25\nLLVM\n\n\n\n\n16\nTuesday Oct 29\ntypic + reading\n\n\n\n\n\nLeader Sana Anvari Large Language Models for Compiler Optimization\n\n\n\n\n\n\n\n\n\n\n17\nFriday Nov 1\nRegister Allocation\n\n\n\n\n18\nTuesday Nov 5\nDynamic compilers 1 + reading\n\n\n\n\n\nLeader: Qucheng Jiang An MLIR-based Compiler Flow for System-Level Design and Hardware Acceleration\n\n\n\n\n\n\n\n\n\n\n19\nFriday Nov 8\nDynamic compilers\n\n\n\n\n20\nTuesday Nov 12\ntypic + reading\n\n\n\n\n\nLeader: Yashaswini Makaram ProGraML: Graph-based Deep Learning for Program Optimization and Analysis\n\n\n\n\n\n\n\n\n\n\n21\nFriday Nov 15\ntypic\n\n\n\n\n22\nTuesday Nov 19\nra checking + reading\n\n\n\n\n\nLeaders: Rohit Anandakumar and Sharmila Sivalingam Generating GPU Compiler Heuristics using Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n23\nFriday Nov 22\npolyhedral part 1\n\n\n\n\n24\nTuesday Nov 26\nPolyhedral part 2 + reading\n\n\n\n\n\nLeader: Michael Maurer Energy-Aware Tile Size Selection for Affine Programs on GPUs\n\n\n\n\n\n\n\n\n\n\nNov 29\nThanksgiving\n\n\n\n\n\n26\nTuesday Dec 3\ntypic + reading\n\n\n\n\n\nLeader: Matin Raayai: Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\n\n\n\n\n\n\n\n\n\n\n27\nFriday Dec 6\nai in compilers\n\n\n\n\n\nPapers\n\nTVM: An Automated End-to-End Optimizing Compiler for Deep Learning](https://www.usenix.org/conference/osdi18/presentation/chen) paper\nleader: SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly\nLeader:ACPO: AI-Enabled Compiler-Driven Program Optimization\nleader: Adaptive Online Context-Sensitive Inlining\nleader: Threaded Code Variations and Optimizations\nleader:Learning Compiler Pass Orders using Coreset and Normalized Value Prediction\nleader: Learning to Optimize Tensor Programs\nleader: End-to-end Deep Learning of Optimization Heuristics\nleader: Compiler Fuzzing through Deep Learning\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Weekly Schedule"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "EECS 7398 Fall 2024\nInstructor: Dr. Norman Rubin\nemail: n.rubin@northeastern.edu\nOffice hours by appointment\nThis course draws heavily from the CS6120 Advanced Compilers course at Cornell University. Special thanks to Adrian Sampson for granting permission to use his course materials.\nYou can find videos of Adrian Sampson’s lectures on the CS6120 self-guided page. These videos provide an in-depth explanation of many topics we’ll cover in this course.\nI want to take a moment to address an important aspect of this course: its evolving nature. Since this is the first time this course is being offered, please be aware that both the schedule and assignments may change as we progress.\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/hw0.html",
    "href": "homework/hw0.html",
    "title": "homework 0",
    "section": "",
    "text": "Write a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "homework 0"
    ]
  },
  {
    "objectID": "homework/1.hw.html",
    "href": "homework/1.hw.html",
    "title": "Homework 1 trying out bril",
    "section": "",
    "text": "you will write a blog post and put in in github using a pull request\nThen will put the name of the blog post into canvas\nYou can ask questions on github discussions\n\nYour goal is to get familiar with Bril.\nPart 1\nWrite a new benchmark.\nYou can write it by hand, use the TypeScript compiler, or generate it some other way. Try running it with brili.\nOpen a pull request to add your new benchmark. ??? Add your code to the the benchmarks directory.\nUse turnt –save yours.bril to create the test outputs for your new benchmark. (See the Turnt README for details.) Mention it in the docs.\npart 2\nWrite a program to analyze or transform Bril programs in some small way. Pick your favorite programming language—there is no “starter code,” so you can start from scratch.\nLoad up a JSON file. You can start with this tiny one! Read the docs.\nDo something unambitious with it: count the number of add instructions, or add a print instruction before every jump, or whatever. Pick something small and contrived! Use Turnt to test your new tool.\nAlong the way, you will run into problems! Ask questions on ???, and open issues and pull requests to describe or fix problems. For example, even super simple benchmarks you might imagine probably can’t be written easily because Bril is too simple. Mention this on ??? discussions, and consider pitching in to help add features.\nThink about how to write a good test, and finally write a post describing your work and submit it to github and submit the name to canvas\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 1 trying out bril"
    ]
  },
  {
    "objectID": "homework/dynamic.html",
    "href": "homework/dynamic.html",
    "title": "homework 7 dynamic compile",
    "section": "",
    "text": "This task is to implement a trace-based speculative optimizer for Bril. You’ll implement the same concept as in a tracing JIT, but in a profile-guided AOT setting: profiling, transformation, and execution will be distinct phases. The idea is to implement the “heavy lifting” for a trace-based JIT without needing all the scaffolding that a complete JIT requires, such as on-stack replacement.\nConcretely, there are three main phases:\n\nModify the reference interpreter to produce traces.\nBuild an optimizer that injects traces back into the original program using the speculation extension to provide a “fast path.”\nCheck that the whole process is correct and had some effect on performance (it needn’t actually be good!).\n\nStart by reading the documentation for the speculation extension (and watch the video!). That should give you an idea of what’s required to augment a program with a speculative execution of an extracted trace. Then make a plan for how you’ll hack the interpreter to produce one of those traces.\nHere’s a recipe:\n\nStart interpreting normally.\nAt some point during execution (at the very beginning of main, for example, or when reaching a backedge), start tracing.\nWhile tracing, record every instruction as it executes. Eliminate jumps; replace branches with guard instructions. Feel free to do the interprocedural version, and to bail out on any other instruction you don’t want to handle.\nStop tracing at some point (after a fixed number of instructions, for example, or at the next backedge) and save the trace to a file.\nFor bonus “points,” statically optimize the trace by eliminating instructions that depend on foregone conclusions enforced by guards.\nTransform the program to stitch the trace back into the program using speculate and commit instructions.\nFor these tasks, unlike some previous lessons, I recommend not attempting to support all the benchmarks. It’s more important that you understand a few programs well than you apply your transformation to a large body of code. (In other words, I recommend that you work depth-first instead of breadth-first.)\n\nIn particular, you do not need to support Bril’s memory extension, which makes things more complicated because it doesn’t get automatically rolled back on speculation aborts. If you are feeling very ambitious, you can try devising a scheme to manually roll back memory modifications on aborts (consider an “undo log” or “redo log,” which are concepts from databases).\nFinally, evaluate your work:\n\nCheck that you didn’t break programs. For at least one benchmark (and ideally a few), create multiple inputs to the program that result in different outputs. Use one input to generate the trace and optimize the program, and use other inputs to check correctness. This approach guards against cases where your tracing optimization “overfits” and you end up with code that only works on one input. Measure performance impact, i.e., the effect of your transformation on the dynamic instruction count.\nfor at least one benchmark, use at least two inputs to evaluate tracing’s impact on executions that are not identical to the traced execution. If you implemented optimizations on the traced code, consider comparing the optimized vs. un-optimized versions. (It’s OK if your tracing apparatus makes programs slower, especially on unseen inputs! We just want to measure the difference.)\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "homework 7 dynamic compile"
    ]
  },
  {
    "objectID": "homework/3_hw.html",
    "href": "homework/3_hw.html",
    "title": "Homework 3 data flow",
    "section": "",
    "text": "Implement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework  3 data flow"
    ]
  },
  {
    "objectID": "homework/project.html",
    "href": "homework/project.html",
    "title": "project",
    "section": "",
    "text": "Half way through the course, you should submit a project proposal, I’ll review it to make sure you are not tackling too big a challenge or going to far afield.\nAt the end of the course, you will complete a compiler research project. This is an open- ended project that can be on any topic in the field of compilers.\nThe final product is an experience report where you rigorously evaluate the success of your implementation. You can work individually or in groups of 2–3 students. When you finish an implementation, write it up. Your writeup should answer these questions in a good degree of detail: ● What was the goal? ● What did you do? (include both the design and the implementation) ● What were the hardest parts to get right? ● Were you successful? (report rigorously on your empirical evaluation)\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "project"
    ]
  },
  {
    "objectID": "homework/5_hw.html",
    "href": "homework/5_hw.html",
    "title": "Homework 5 SSA",
    "section": "",
    "text": "Implement the into SSA and out of SSA transformations on Bril functions. Watch out for variables that are undefined on some paths. The script “is_ssa.py can check if a program is really in SSA and the Bril interpreter bili supports phi functions so you can execute code in the midpoint of your round trip. Measure the overhead (does the final program have more instructions (static or dynamic) the original, be sure to report the overhead in your writeup.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 5 SSA"
    ]
  },
  {
    "objectID": "homework/4_hw.html",
    "href": "homework/4_hw.html",
    "title": "homework dominance",
    "section": "",
    "text": "Implement some of the dominance utilities- 1) Find dominators for a function, 2) construct the dominance tree, 3) compute the dominance frontier. Devise a way to test your implementations. Can you find a way to confirm that block A dominates blockB. When you code this, remember that computing these sets should be cheap while checking their output could use slow naive algorithms.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "homework dominance"
    ]
  },
  {
    "objectID": "homework/6_extra_credit.html",
    "href": "homework/6_extra_credit.html",
    "title": "Homework 6 loop optimization",
    "section": "",
    "text": "Implement and evaluate a loop optimization, either start with Bril or LLVM, you can use the ssa form of Bril if you want. If you use Bril you will have to find the natural loops, if you use LLVM you can call LoopPass but other parts of the implementation will be tricker, Pick an optimization (I’d suggest loop invariant code motion) but any of the others mentioned in class would be fine. Evaluate its performance, in Bril you can use the Bril benchmarks, in LLVM select an existing benchmark such as Embench and feel free to violate the sigplan guidelines SIGPLAN empirical evaluation guidelines by cherry-picking a convenient subset.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 6 loop optimization"
    ]
  },
  {
    "objectID": "homework/2_hw.html",
    "href": "homework/2_hw.html",
    "title": "Homework 2 local optimizations",
    "section": "",
    "text": "part 1: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned.\npart2: Implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 2 local optimizations"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html",
    "href": "Class_Overview/What_to_do.html",
    "title": "How to submit assignments",
    "section": "",
    "text": "Assignments get submitted as blog postings. In setting up the class web site I used quarto which lets you write a blog post in markdown (no messy html required). I recommend you use it as well. quarto converts markdown files to html and revealjs (for slides)",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "href": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "title": "How to submit assignments",
    "section": "",
    "text": "Assignments get submitted as blog postings. In setting up the class web site I used quarto which lets you write a blog post in markdown (no messy html required). I recommend you use it as well. quarto converts markdown files to html and revealjs (for slides)",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "href": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "title": "How to submit assignments",
    "section": "Submitting via pull requests",
    "text": "Submitting via pull requests\nTo add a blog post (which you must do for homework, discussion leading, and project reports), use a pull request.\nYou’ll want to create a text file in the blog directory with your new post. Use a filename like YYYY-MM-DD-title.qmd, where the date is the discussion day or the project deadline and the title is up to you.\nEach quarto file starts with some meta data. For example the sample file has\n---\nformat:\n\n\n\n\n---\nauthor: norm\nformat:\n html: default\ntitle: sample blog\n---\n\n\n\n\n\nThe rest of the text file is the Markdown text of your blog post.\nIf you want to use math in your blog post, you can use latex dollar signs like $\\pi$ for \\(\\pi\\) for inline math and $$ e^{i\\pi} + 1 = 0 $$ for \\[ e^{i\\pi} + 1 = 0 \\].\nTo include images or other resources in your post, make your post into a directory. That is, make a new directory called YYYY-MM-DD-title inside blog. Then, put your text in a file called index.qmd inside that. Put your images in the same directory and refer to them with relative paths. See the QUARTO docs on for more details.\nYou can preview your writing with any Markdown renderer. To see what it will look like when published, install quarto and type quarto render to preview the entire site. Visual code has a really nice quarto extension that can preview pages.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#homework",
    "href": "Class_Overview/What_to_do.html#homework",
    "title": "How to submit assignments",
    "section": "Homework",
    "text": "Homework\nTo reinforce the specific compiler techniques we cover in class, you will implement them on your own. In lessons, we will discuss the high-level ideas and provide pseudo-code; your task is to translate these into working code and collect empirical evidence to demonstrate their effectiveness. Completing these implementations will reveal practical challenges that are not apparent from a high-level overview.\nTesting your implementation is crucial. Your goal is to provide convincing evidence that your implementation performs as intended. For instance, an optimization should generally make programs faster without causing any errors. While formal proofs of these properties are likely out of scope, you will need to find alternative ways to gather evidence. Avoid relying solely on existing test cases in the Bril repository, as they are typically insufficient. instead, consider using all the benchmarks available in the repo.\nYou may work individually or in groups of 2–3 students. Upon completing an implementation, follow these steps:\n\nConsider putting all your code online in an open-source repository, such as GitHub (optional but recommended). Create a fork of the class repository if desired.\nSubmit the assignment on Canvas by providing a text file with a URL to your open-source implementation. If you prefer not to open-source your code, you can upload the code itself.\nWrite a brief post in the lesson’s associated GitHub Discussions thread, covering the following topics (one paragraph each is sufficient):\n\nSummarize what you did.\nExplain how you tested your implementation. What test inputs did you use? Do you have any quantitative results?\nDescribe the hardest part of the task and how you addressed this challenge.\n\n\nEnsure all implementation tasks are your own work or done with your group. Although sample implementations for many tasks are available in the GitHub repository, you are not allowed to use this code. Similarly, you may not use implementations open-sourced by past students. I recommend not looking at these implementations while working on your tasks to ensure you genuinely learn the material. However, if you absolutely need to refer to them, you are responsible for managing your own learning process.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#paper-reading-discussion",
    "href": "Class_Overview/What_to_do.html#paper-reading-discussion",
    "title": "How to submit assignments",
    "section": "Paper Reading & Discussion",
    "text": "Paper Reading & Discussion\nPaper discussions are on GitHub Discussions.\nAnother part of this course involves reading and discussing research papers. For each paper (see the schedule), everyone will participate in the discussion in two ways: asynchronously on GitHub Discussions threads before class, and synchronously in class. For every paper, there will be a Discussions topic; post at least one message with your thoughts on the paper before the class discussion. Your comment doesn’t need to be long—just a couple of sentences is fine. You can also respond to others’ thoughts on the thread.\nFor some papers, you will be the discussion leader. Leaders have three extra responsibilities: monitoring and replying to the asynchronous discussion, moderating and guiding the in-class discussion, and synthesizing ideas into a blog post afterward.\nLeader Responsibilities\nAt least a week before the discussion day:\n1) Create a GitHub Discussions thread in the Reading category for your topic.\nDuring the lead-up to the discussion day:\n1) Monitor the GitHub Discussions thread for your topic. Answer questions and offer additional insights as needed.\n1) Collect a list of questions for the in-class discussion. You can create your own or select the best from the online discussion.\nOn the discussion day:\nModerate the discussion. Provide enough background to get to the discussion questions and facilitate the conversation.\nDue one week after the discussion day:\n\nWrite a post about the paper for our course blog. The post should include:\n\nBackground information necessary to understand the paper.\nA detailed summary of the main contributions.\nCritical analysis of the merits and shortcomings of the work.\nDiscussion of the paper’s role in history and its connections to the current computing landscape.\n\n\nIncorporate the best ideas from the online and in-class discussions. You can present your own opinions, the class consensus, or both.\n\n\nWriting the Blog Post\nWhile summarizing the paper, avoid letting direct summary dominate your post. Keep the technical explanation to about a quarter of the length. Prioritize breadth over depth in your summary, and highlight specific contributions instead of covering the entire paper.\nFocus most of your writing on your own commentary: context, criticism, and discussion. Choose a title for your blog post that reflects the main point you want to make about the paper, rather than just the paper’s title.\nFor inspiration, check out previous cs6120 blog posts. However, avoid reading posts about your paper, if they exist.\nPublishing\nPublish the post to the course GitHub repository by opening a pull request. Once your PR is open, announce it on the appropriate Discussions thread to let others know.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#project-proposal",
    "href": "Class_Overview/What_to_do.html#project-proposal",
    "title": "How to submit assignments",
    "section": "project Proposal",
    "text": "project Proposal\nThe first deadline is the project proposal. Open a GitHub issue answering these three questions:\nWhat will you do? How will you do it? How will you empirically measure success?\nYou should also list the GitHub usernames of everyone in the group. After you send the PR, submit its URL to the “Project Proposal” assignment on canvas.\nThe instructor will have feedback on how to approach your project.\nImplementation\nThe main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nI strongly recommend that you develop your code as an open-source project. Use a publicly-visible version control repository on a host like GitHub, and include an open source license. When you create your repository, comment on your proposal GitHub issue with a link. (If you have a specific objection to open-sourcing your code, that’s OK—include a description of how you’ll share your code privately with me.)\nEvaluation\nA major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\nWhere will you get the input code you’ll use in your evaluation? How will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs. How will you measure the benefit (in performance, energy, complexity, etc.) of your implementation?\nHow will you present the data you collect from your empirical evaluation? Other questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#project-experience-report",
    "href": "Class_Overview/What_to_do.html#project-experience-report",
    "title": "How to submit assignments",
    "section": "project Experience Report",
    "text": "project Experience Report\nFor the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions in excruciating, exhaustive detail:\nWhat was the goal? What did you do? (Include both the design and the implementation.) What were the hardest parts to get right? Were you successful? (Report rigorously on your empirical evaluation.) As with paper discussions, you can optionally include a video to go along with your blog post.\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog. In your PR description, please include “closes #N” where N is the issue number for your proposal",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "check_meta.html",
    "href": "check_meta.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "# gather all the meta info from all  the files -  check for errors \nimport yaml\nfrom pathlib import Path\n\n\ndef extract_meta_from_qmd(file_path):\n    \"\"\"\n    Extracts and returns the YAML front matter (meta information) from a QMD file.\n    \n    Parameters:\n    - file_path: Path to the QMD file.\n    \n    Returns:\n    - A dictionary containing the parsed YAML front matter, or None if not found.\n    \"\"\"\n    # Initialize an empty string to hold the YAML content\n    yaml_content = ''\n    # Flag to indicate if we are within the YAML front matter\n    in_yaml = False\n    \n    with open(file_path, 'r') as f:\n        for line in f:\n            # Check for the start/end of the YAML front matter\n            if line.strip() == '---':\n                if in_yaml:\n                    # We found the second ---, stop reading further\n                    break\n                else:\n                    # We found the first ---, start collecting lines\n                    in_yaml = True\n            elif in_yaml:\n                # Add the current line to the YAML content\n                yaml_content += line\n    \n    # Parse the YAML content if any was found\n    if yaml_content:\n        return yaml.safe_load(yaml_content)\n    else:\n        return None\n\n\n\nimport os\n\ndef list_all_files(root_dir):\n    \"\"\"List all files in a directory and its subdirectories.\"\"\"\n    all_files = []\n    for root, dirs, files in os.walk(root_dir):\n        for file in files:\n            all_files.append(os.path.join(root, file))\n    return all_files\n\n\nbase = Path(\"/home/norm/compiler_course_2024fa/\")\n\n\nfrom numpy import isin\n\n\nmeta_union = {}\nfor file in list_all_files(base):\n    file_path = Path(file)\n    if file_path.suffix in [\".pdf\", \".jpg\", \".png\", \".woff\", \".eot\", \".woff2\", \".ttf\", \".so\", \".pyc\"]:\n        continue\n    if file_path.parent.name == \"bin\":\n        continue \n    if any(parent.name == \".venv\" for parent in file_path.parents):\n        continue\n    if any(parent.name == \".git\" for parent in file_path.parents):\n        continue\n    meta_info = extract_meta_from_qmd(file)\n    if meta_info:\n        for key, value in meta_info.items():\n    \n            if isinstance(value, list):\n                value = ', '.join(map(str, value))\n            elif isinstance(value,dict):\n                for sub_key, sub_value in value.items():\n                    combined_key = f\"{key}.{sub_key}\"  # Combine the parent key and sub-key\n                    sub_value = str(sub_value)  # Convert sub-value to string\n                    if combined_key not in meta_union:\n                        meta_union[combined_key] = {sub_value}\n                    else:\n                        meta_union[combined_key].add(sub_value)\n                continue\n            \n            if key not in meta_union:\n                meta_union[key] = {value}\n            else:\n                meta_union[key].add(value)\n\nfor (k,v) in meta_union.items():\n    print (k, v )\n\n    \n\ntitle {'Representation of programs', 'Performance and Measurement', '14_gpu_compilers', '5_hw', 'project', 'EECE7398 Fall 2024', '10 MLIR', '3_hw ', 'Untitled', '_ loop invariant code motion', '9 polyhedral analysis', '11 Whole program', 'EECS7398 Weekly Schedule', 'How to do assignments', 'homework 0', '8 classic loop optimizations', 'Overview of Bril', '_ partial_redundancy elimination', '4_hw', 'EECS7398 Weekly Schedule fa 2024', '_ local value numbering', '4. Data Flow', 'About', 'Schedule', '3 Local Analysis & Optimization', '2.hw', '12_memory.qmd', 'Testing Register allocators', '6- extra credit hw ', '1 Compiler Overview', '1-Homework', 'Static Single Assignment', '13_dynamic_compielrs', '5 Global Analysis'}\nformat {'html'}\ntbl-colwidths {'10, 20, 20, 20, 15, 15'}\nformat.html {'default'}\nformat.revealjs {\"{'chalkboard': True, 'output-file': 'revealjs-licm', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-rep'}\", \"{'chalkboard': True, 'output-file': 'revealjs-partial-redun', 'scrollable': True}\", \"{'chalkboard': True, 'scrollable': True, 'output-location': 'slide', 'code-line-numbers': True, 'output-file': 'revealjs-bril'}\", \"{'chalkboard': True, 'output-file': 'revealjs-local', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-ssa', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-lvn', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-compiler_overview.html', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-data-flow', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-global-anal', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-performance.html', 'scrollable': True}\"}\nkeep-ipynb {True}\npython {'kaggle_comp'}\nsidebar {False}\nexecute.echo {'True'}\n\n\n\nimport os\nimport yaml\n\nbase = Path(\"/home/norm/compiler_course_2024fa/\")\n\n# Step 1: List all .qmd files\nqmd_files = []\nslide_qmd_files = []\n\nfor root, dirs, files in os.walk(base):  # Adjust '.' to your project directory if necessary\n    revealjs_\n    if \"_site\" in Path(root).parts:\n        continue\n    for file in files:\n        if file.endswith('.qmd'):\n            qmd_files.append(os.path.join(root, file))\n\n# Step 2: Read and parse each .qmd file\nfor qmd_file in qmd_files:\n\n    with open(qmd_file, 'r') as file:\n        content = file.read()\n        # Assuming the YAML metadata is at the top of the file, delimited by ---\n        if content.startswith('---'):\n            end_of_yaml = content.find('---', 3)\n            if end_of_yaml != -1:\n                yaml_content = content[3:end_of_yaml]\n                metadata = yaml.safe_load(yaml_content)  # Parse YAML\n\n                format_data = metadata.get('format')\n                if not format_data:\n                    print(qmd_file, \"no format field\")\n                    continue\n                try:\n                    html_meta_data = format_data.get(\"html\")\n                except Exception as e:\n                    print(qmd_file, e, 'format does not have html')\n                    continue\n\n                if html_meta_data != 'default':\n                    print(qmd_file, \"not html default\")\n                    continue \n                try:\n                    revealjs_meta_data = format_data.get('revealjs')\n                except:\n                    print(\"qmd_file\", \"no revealjs\")\n                    continue\n                if revealjs_meta_data:\n                    chalk = revealjs_meta_data.get(\"chalkboard'\")\n                    if chalk != 'true':\n                        print(qmd_file, \"missing chalkboard\")\n    \n                # get the format\n                # see if it has a subkey, revealjs\n                # if it does check for an deeper subkey of output-file\n\n                # Step 3: Check for format: reveljs\n                if metadata.get('format') == 'revealjs':\n                    # Step 4: Verify the output file name\n                    expected_output = 'reveljs-' + os.path.basename(qmd_file).replace('.qmd', '')\n                    if metadata.get('output-file') == expected_output:\n                        print(f\"{qmd_file}: Success, output file name is correct.\")\n                    else:\n                        print(f\"{qmd_file}: Failure, output file name does not match the expected '{expected_output}'.\")\n\n/home/norm/compiler_course_2024fa/lectures/02a_representation.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/010_compiler_overview.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/02b_bril.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/05_global.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/01a_performance_measurement.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/06_ssa.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/05b_licm.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/04_data_flow.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/03b_local_value_numbering.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/03_local.qmd missing chalkboard\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/rohit/2024-09-20-Rohit-HW1.html",
    "href": "blogs/rohit/2024-09-20-Rohit-HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "A Cyclic Redundancy Check (CRC) is an error-detecting code used in digital networks and storage devices to detect accidental changes to raw data. In embedded systems, CRCs are crucial for ensuring data integrity during communication, verifying data stored in memory, and validating firmware updates. They are popular due to their simplicity, efficiency in binary hardware, and effectiveness in detecting common transmission errors.\n\nIt ensure data integrity in communication protocols like UART, SPI, and I2C by detecting errors caused by noise or interference.\nHow CRC Works:\n\nPolynomial Division: The data block is treated as a large binary number and divided by a fixed polynomial. The remainder of this division is the CRC value.\nAppending CRC: The CRC value is appended to the data before transmission or storage.\nVerification: Upon retrieval, the same polynomial division is performed. If the remainder matches the CRC value, the data is considered intact; otherwise, it indicates corruption\n\nLearn more at: https://en.wikipedia.org/wiki/Cyclic_redundancy_check\n\n\n\n\n\nCRC calculations prominently involve memory allocation, extensively using ptr&lt;int&gt;.\nCRC algorithms typically involve a mix of arithmetic (e.g., addition, subtraction, Multiplication) and bitwise operations (e.g., XOR, shifts).\nThis makes CRC an excellent microbenchmark for evaluating how well your Bril implementation handles these critical operations, which are essential for many real-world applications.\n\n\n\n\n\nBril code for CRC is fully hand typed code of 300+ lines using VS Code, the most useful tool ever was Bril syntax highlighting Extension in VS Code.\nTurnt tool was used to test and save the output file.\nturnt.toml file:\n\n    [envs.test]\n    command = \"bril2json &lt; {filename} | brili -p {args}\"\n    output.out = \"-\"\n    output.prof = \"2\"\n\n\nLearn more at: https://github.com/cucapra/turnt?tab=readme-ov-file\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Initialize Inputs]--&gt; B0[Get CRC Remainder] --&gt; B1[\"Check CRC\"] --&gt; B2[Print Outputs];\n\n\n\n\n\n\n\n\n\nGet Word, Divisor, check_value as an int.\ncheck_value will be 0 if the bits are missing and error.\nAppend Divisor size - 1 zeros to word.\nConvert the int into array, here in bril we can use ptr&lt;int&gt; allocations calling @toPtr function.\nReference to memory allocation in bril: https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/manually-managed-memory/\n\n\n\n\n\nTo divide Word and Divisor we need to do xor in each bit.\nFirst copy first few bits from Word to Word_split having same length as Divisor.\nCall @xorfunction and overwrite the result to first few bits of Word.\nCall @shiftleft function to left shift the Word and decrement word_size.\nRepeat this process until Word_size &lt; Div_size.\nAt the end return Word as a crc_rem to @main.\nConvert crc_rem from ptr&lt;int&gt; to int by calling toNum function.\n\n\n\n\n\nIf: crc_rem == 0 then there is no error in bit and crc_check is true.\nElse: there is a error and crc_check is false.\n\n\n\n\n\nOuputs are bool value crc_check and int value crc_rem.\nWhen check_value is set to 0\n\nThis Indicates that there are error or missing bits.\ncrc_check value will be false\ncheck_rem will give out the correct check_value\nso again replacing 0 from check_rem with check_value and running the code will give us crc_check as true with check_rem = 0 .\n\nFull code: https://github.com/gurusamyanandakuma-r/bril/blob/main/benchmarks/mem/crc_check.bril\n\n\n\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    1011\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 1011;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    100\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 100;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-1-benchmark",
    "href": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-1-benchmark",
    "title": "Homework 1",
    "section": "",
    "text": "A Cyclic Redundancy Check (CRC) is an error-detecting code used in digital networks and storage devices to detect accidental changes to raw data. In embedded systems, CRCs are crucial for ensuring data integrity during communication, verifying data stored in memory, and validating firmware updates. They are popular due to their simplicity, efficiency in binary hardware, and effectiveness in detecting common transmission errors.\n\nIt ensure data integrity in communication protocols like UART, SPI, and I2C by detecting errors caused by noise or interference.\nHow CRC Works:\n\nPolynomial Division: The data block is treated as a large binary number and divided by a fixed polynomial. The remainder of this division is the CRC value.\nAppending CRC: The CRC value is appended to the data before transmission or storage.\nVerification: Upon retrieval, the same polynomial division is performed. If the remainder matches the CRC value, the data is considered intact; otherwise, it indicates corruption\n\nLearn more at: https://en.wikipedia.org/wiki/Cyclic_redundancy_check\n\n\n\n\n\nCRC calculations prominently involve memory allocation, extensively using ptr&lt;int&gt;.\nCRC algorithms typically involve a mix of arithmetic (e.g., addition, subtraction, Multiplication) and bitwise operations (e.g., XOR, shifts).\nThis makes CRC an excellent microbenchmark for evaluating how well your Bril implementation handles these critical operations, which are essential for many real-world applications.\n\n\n\n\n\nBril code for CRC is fully hand typed code of 300+ lines using VS Code, the most useful tool ever was Bril syntax highlighting Extension in VS Code.\nTurnt tool was used to test and save the output file.\nturnt.toml file:\n\n    [envs.test]\n    command = \"bril2json &lt; {filename} | brili -p {args}\"\n    output.out = \"-\"\n    output.prof = \"2\"\n\n\nLearn more at: https://github.com/cucapra/turnt?tab=readme-ov-file\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Initialize Inputs]--&gt; B0[Get CRC Remainder] --&gt; B1[\"Check CRC\"] --&gt; B2[Print Outputs];\n\n\n\n\n\n\n\n\n\nGet Word, Divisor, check_value as an int.\ncheck_value will be 0 if the bits are missing and error.\nAppend Divisor size - 1 zeros to word.\nConvert the int into array, here in bril we can use ptr&lt;int&gt; allocations calling @toPtr function.\nReference to memory allocation in bril: https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/manually-managed-memory/\n\n\n\n\n\nTo divide Word and Divisor we need to do xor in each bit.\nFirst copy first few bits from Word to Word_split having same length as Divisor.\nCall @xorfunction and overwrite the result to first few bits of Word.\nCall @shiftleft function to left shift the Word and decrement word_size.\nRepeat this process until Word_size &lt; Div_size.\nAt the end return Word as a crc_rem to @main.\nConvert crc_rem from ptr&lt;int&gt; to int by calling toNum function.\n\n\n\n\n\nIf: crc_rem == 0 then there is no error in bit and crc_check is true.\nElse: there is a error and crc_check is false.\n\n\n\n\n\nOuputs are bool value crc_check and int value crc_rem.\nWhen check_value is set to 0\n\nThis Indicates that there are error or missing bits.\ncrc_check value will be false\ncheck_rem will give out the correct check_value\nso again replacing 0 from check_rem with check_value and running the code will give us crc_check as true with check_rem = 0 .\n\nFull code: https://github.com/gurusamyanandakuma-r/bril/blob/main/benchmarks/mem/crc_check.bril\n\n\n\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    1011\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 1011;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    100\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 100;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-2-analysis",
    "href": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-2-analysis",
    "title": "Homework 1",
    "section": "PART 2: Analysis:",
    "text": "PART 2: Analysis:\n\nFinding Number of Functions and its Calls\n\nCode: https://github.com/gurusamyanandakuma-r/bril/blob/main/examples/Count_Function.py\n\n\nInitialize\n\nThis analysis is done in python.\nUsing bril2json converting .bril file to JSON.\nLoading into python file using prog = json.load(sys.stdin).\nJSON heap structure will be loaded as dictionary in python.\n\n\n\nProcess\n\nCounting all functions in bril.\nCounting function calls of a function.\n\n\n\nTest\n\nTurnt.toml file:\n\n    [envs.countFunc]\n    default = false\n    command = \"bril2json &lt; {filename} | python3 hw.py &gt; {base}.txt\"\n\nOutput is stored in .txt file.\n\n\nExample 1: CRC\n\nInput:\n\nfile: https://github.com/gurusamyanandakuma-r/bril/blob/main/benchmarks/mem/crc_check.bril\n\n\n\nOutput:\n```\nNumber of Functions:  11\n------------------------\nFunction Call Counts:\nmain     : 0\nrem      : 1\nn_zeros  : 2\ntoPtr    : 2\nwordSplit: 1\nxor      : 1\nshiftLeft: 1\nprint_ptr: 0\ncrc_rem  : 1\ncrc_check: 1\ntoNum    : 1\n\n\n##### Example 2: Fibonacci\n###### Input: \n- file: &lt;https://github.com/normrubin/bril/blob/main/benchmarks/core/fibonacci.bril&gt;\n\n###### Output:\n    ```\n    Number of Functions:  2\n    ------------------------\n    Function Call Counts:\n    main     : 0\n    Fibonacci: 3\n\n\n\nExample 3: Binary Search\n\nInput:\n\nfile: https://github.com/normrubin/bril/blob/main/benchmarks/mem/binary-search.bril\n\n\n\nOutput:\n    Number of Functions:  4\n    ------------------------\n    Function Call Counts:\n    pack         : 1\n    print_array  : 0\n    binary_search: 3\n    main         : 0",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "",
    "text": "This assignment introduces trivial dead code elimination, and local value numbering. Python code which performs these optimizations are available at the link provided in the Code section.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#introduction",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "",
    "text": "This assignment introduces trivial dead code elimination, and local value numbering. Python code which performs these optimizations are available at the link provided in the Code section.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-1-trivial-dead-code-elimination",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-1-trivial-dead-code-elimination",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Part 1: Trivial Dead Code Elimination",
    "text": "Part 1: Trivial Dead Code Elimination\nIn the first part of this assignment, we implemented trivial dead code elimination. By this, we mean removing instructions which are not used before reassignment. Another way to say this, is that an instruction is not dead if it is used, or if it reaches the end of the basic block, before it is reassigned.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nThe primary challenge I faced here was in attempting to implement more sophisticated dead code elimination, such as at the global scope. I thought this would be interesting to explore, but abandoned it as it is out of scope for this assignment. What proved particularly challenging on this front was handling the case where a variable is used across blocks, where the control flow forms cycles. The code I wrote was considering certain instructions to be unused when there were possible paths in which the instructions were used. When only performing local DCE, this task became much more achievable.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Implementation",
    "text": "Implementation\nTo perform local DCE, first I wrote some code which could partition every function into blocks. With these blocks, we have all the code chunks which are candidates for local DCE. Then, determining dead code was simply determining which instructions are not used by any later instructions in the block. This was done repetitively, as some instructions may on first pass not be considered dead, however they are only used by a dead instruction which will be eliminated.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Testing",
    "text": "Testing\nMy initial line of testing was very curated, and used the following source code:\n@main {\n    a: int = const 4;           # Will be eliminated\n    prod: int = id a;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;        # Will be eliminated\n    prod: int = mul sum1 sum2;  # Will be eliminated\n    sum2: int = id a;\n    prod: int = id sum2;\n    print prod;\n}\nHere, we would expect that the first two instructions assigning prod would be eliminated, and then as a follow-on effect, the first assignment of sum2 also becomes dead code. What we observe aligns with these expectations, and is shown below:\n@main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = id a;\n    prod: int = id sum2;\n    print prod;\n}\nTo further test my dead code elimination, I leveraged the brench tool provided by bril. This tool allows for a pipeline to be created, which source code is passed through. Then, using turnt the results of running the optimized code can be compared to what is expected. In the code repository, there is a .csv file containing the results of running brench against all benchmarks in the bril repository. We observe that all tests pass (or timeout in the case of function_call, which times out with or without optimization). Further, and perhaps dissapointingly, we notice that the number of instructions does not change after optimization for these benchmarks. However, this may be unsurprising, as these benchmarks are in a public code-base, and are less likely to have trivial dead code.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-2-local-value-numbering",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-2-local-value-numbering",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Part 2: Local Value Numbering",
    "text": "Part 2: Local Value Numbering\nFor the second part of this assignment, we implemented local value numbering to optimize the number of dynamic instructions executed by a program. The strategy here is to identify where computations have happened before in the code, and where possible do not re-evaluate them, and instead favor a copy.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation-1",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation-1",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Implementation",
    "text": "Implementation\nI used a very straightforward method of implementing LVN, as was discussed in our lectures as well as those from Cornell. The primary difference that one may notice in the code is that there is more significant exception handling which must be done to achieve consistent results.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced-1",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced-1",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nMy initial implementation appeared to work well on some programs, but returned incorrect results on others. This was quite puzzling, but looking at the code which was being produced, it quickly became clear what was going wrong. As a demonstration, consider the following code from dot-product.bril:\nvectorA: ptr&lt;int&gt; = alloc size;\n...\nvectorB: ptr&lt;int&gt; = alloc size;\nThis particular benchmark was failing when testing my initial code, and investigating the results showed the following:\nvectorA: ptr&lt;int&gt; = alloc size;\n...\nvectorB: ptr&lt;int&gt; = id vectorA;\nThis is not good! My hashing / replacement scheme was based entirely off of the instruction operation and the arguments involved, and so in this case, I registered the instruction alloc size as redundant and simply assigned vectorB to vectorA. For simpler instructions this makes sense, however as we are trying to have these vectors point at some dynamically allocated memory, this causes serious issues. So, to handle this, I created a list of special instructions which were not to be optimized in this manner, including functions like alloc.\nAfter this, all but one of the benchmarks was passing, with the lone failure being riemann.bril. Again, this appeared to be a result of the hash function I implemented. Consider the following code:\nleft: float = call @left_riemann a b n;\nprint left;\nmidpoint: float = call @midpoint_riemann a b n;\nprint midpoint;\nright: float = call @right_riemann a b n;\nMy setup was optimizing this code to the following:\nleft: float = call @left_riemann a b n;\nprint left;\nmidpoint: float = id @midpoint_riemann left;\nprint midpoint;\nright: float = id @right_riemann left;\nThis realization came much quicker, as it was clear I omitted certain important values in my hashing function, in this case being the function name which is called. Before this, my algorithm determined that left, midpoint, and right all hashed to callabn, indicating that they are the same value, when of course this is not the case.\nAfter these issues were resolved, everything worked quite well. I spent some time laying the groundwork for constant folding, however I was not able to finish this in reasonable time.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing-1",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing-1",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Testing",
    "text": "Testing\nThe primary line of testing for the LVN code was using brench, and using the code which I have developed for this assignment, in the repository linked below, it can be verified that all bril benchmarks pass through a brench test.\nWhat was interesting was that some benchmarks had a substantial decrease in number of dynamic instructions. One in particular was the quadratic.bril benchmark. What I noticed was that there were calls to @sqrt which took the same inputs, and then these were optimized out using local value numbering. This reduced the number of executed instructions from 785 to 412 (a 47.5% decrease!).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#dce-and-lvn",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#dce-and-lvn",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "DCE and LVN",
    "text": "DCE and LVN\nIn the code submitted with this assignment, the provided brench setup actually tests both optimizations, and passes the input code through dce.py first, followed by lvn.py. The results indicate that all tests still pass, and therefore we can say these optimizations work together!",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#code",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Code",
    "text": "Code\nThe code for this assignment is contained in a public GitHub repository which I set up. Notably, to run brench using the provided brench_config.toml file, bril is expected to be two directories above this one. This can be changed by modifying the benchmarks variable in brench_config.toml.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-09-27-Sharmila-HW02.html",
    "href": "blogs/sharmila/2024-09-27-Sharmila-HW02.html",
    "title": "Compiler Homework 02 - Local Optimization",
    "section": "",
    "text": "Part 1: Dead Code Elimination\nDead Code Elimination (DCE) is an optimization technique in compiler design, aiming to remove instructions that do not affect the program’s final output.\nIn Homework 2, I implemented a “trivial” DCE, where instructions that are never used before being reassigned are deleted.\nThe Basic Idea behind this is to identify and remove the redundant assignment those are never implemented before reassignment.\nIn this blog, I’ll walk throught the implementation process and verify it with an example.\n\n\nImplementation Process:\nI used 3 key step to acheive this task: DCE, Reassignment Handling and Iteration until no changes.\nIn DCE step, identifies the variables that are used by collecting all arguments in the blocks and removes instructions where the destination variable (dest) is not in the used set (indicating it’s redundant). It modifies the blocks and flattens them back into the instruction list. At the next step, Reassignment Handling, removes redundant reassignments. If a variable is defined but then reassigned before its value is used, the earlier definition is deleted. The process is applied block by block.Finally, Iteration until no changes, repeatedly applies DCE and reassignment elimination until no further changes occur.\n\n\nExample:\n\n@main {\n  a: int = const 100;\n  a: int = const 42;\n  b: int = const 5;\n  sum: int = add a b;\n  c: int = id b;\n  sum: int = add c a;\n  print sum;\n}\n\nHere, the variable a is assigned the value 100, but it is immediately overwritten with the value 42, making the first assignment redundant. Similarly, the first computation of sum is also unnecessary as it is overwritten before being used. After running my implementation:\n\n@main {\n  a: int = const 42;\n  b: int = const 5;\n  c: int = id b;\n  sum: int = add c a;\n  print sum;\n}\n\nThe redundant instructions have been successfully removed. The total number of dynamic instructions has been reduced from 7 to 5. Thus it is verified that my implementation acheived the task of the homework.\nAnd another example to verify further, that the code delete instructions that are never used before they are reassigned.\n\n@main {\n a: int = const 100;\n a: int = const 42;\n b: int = const 5;\n sum: int = add a b;\n print sum;\n c: int = id b;\n sum: int = add c a;\n print sum;\n}\n\nAfter running the code:\n@main {\n  a: int = const 42;\n  b: int = const 5;\n  sum: int = add a b;\n  print sum;\n  c: int = id b;\n  sum: int = add c a;\n  print sum;\n}\n\nHere, the variable a is assigned the value 100, but it is immediately overwritten with the value 42, making the first assignment redundant. Since the first sum is used therefore it is not a redundant.\n\n\nPart 2: Local Value Numbering\nLocal Value Numbering (LVN) is an optimization technique used in compilers to eliminate redundant calculations. By assigning a unique number to each distinct computation, LVN helps minimize repeated evaluations of the same expression. In this part, the task is to implement Local value numbering and further to pair with DCE\n\n\nImplementation:\nPseudo Code of the implementation:\nDefine a named tuple ‘Value’ to represent a computation. Create a ‘Numbering’ class to manage unique identifiers for each computation. Implement the ‘last_writes’ function to identify the last write instructions for each variable. Implement the ‘read_first’ function to determine which variables are read before being written to. Define ‘lvn_block’ to process each block of instructions: Initialize mappings for variable-to-number and value-to-number. For each variable read first, assign a unique number. For each instruction, retrieve argument numbers and check for redundancy: If the computation has been seen, replace the instruction with an identity operation. If it’s a new computation, assign a fresh number and record it. Define ‘lvn’ to iterate through functions in the input data and apply ‘lvn_block’. Load JSON data, call ‘lvn’, and output the optimized result.\nThis code implementation is verfied by using an example:\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 5;\n  sum1: int = add a b;\n  sum2: int = add a b;\n  prod1: int = mul sum1 sum2;\n  sum1: int = const 0;\n  sum2: int = const 0;\n  sum3: int = add a b;\n  prod2: int = mul sum3 sum3;\n  print prod2;\n}\nOutput of the implement:\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 5;\n  lvn.3: int = add a b;                \n  sum2: int = id lvn.3;                \n  prod1: int = mul lvn.3 lvn.3;        \n  sum1: int = const 0;\n  sum2: int = const 0;\n  sum3: int = id lvn.3;                \n  prod2: int = id prod1;              \n  print prod1;                         \n}\nIn this output,the operation add a b is computed once and assigned a unique identifier lvn.3, effectively avoiding redundant calculations. Instead of recalculating add a b for sum2 and sum3, the code uses id lvn.3, indicating that these instructions simply take the value of lvn.3. Furthermore, the instruction prod1 utilizes lvn.3 to multiply with itself, showcasing the efficient reuse of computed values and optimizing the overall execution of the code.\n\n\nPairing with DCE:\nI used an example to verify\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 5;\n  sum1: int = add a b;\n  sum2: int = add a b;\n  prod1: int = mul sum1 sum2;\n\n  sum1: int = const 0;\n  sum2: int = const 0;\n  c: int = const 10;\n  sum3: int = add a b;\n  prod2: int = mul sum3 sum3;\n\n  print prod2;\n}\nHere c variable is initiallized twice and not used before reassigned.\nOutput:\n@main { a: int = const 4; b: int = const 2; sum1: int = add a b; sum2: int = add a b; prod1: int = mul sum1 sum2;\nsum1: int = const 0; sum2: int = const 0; c: int = const 10; sum3: int = add a b; prod2: int = mul sum3 sum3;\nprint prod2; }\nThe implementation of Local Value Numbering optimizes computations by eliminating redundancy, thus enhancing performance. This example illustrates how LVN effectively manages computations through unique identifiers.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 02 - Local Optimization"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-28-HW2.html",
    "href": "blogs/matin/2024-09-28-HW2.html",
    "title": "Homework 2: Trivial Dead Code Elimination and Local Value Numbering Passes",
    "section": "",
    "text": "Part 1: Trivial Dead Code Elimination\nThe first part of homework 2 is implemented under the examples/tdce_matin.py file in my BRIL fork. It consists of two function passes that are run in the following order: 1. A pass which iteratively detects unused variables across the entire function and removes them. 2. A local version of the pass, which removes any re-definitions of a variable.\nThe test folder under examples/test/tdce under my BRIL fork contains the turnt script and test cases to test my TDCE implementation.\n\n\nPart 2: Local Value Numbering\nThe second part of homework 2 is implemented under the examples/lvn_matin.py file in my BRIL fork. It implements the vanilla LVN algorithm with support for renaming re-assigned variables.\nSimilar to TDCE, I updated the test folder under examples/test/lvn in my BRIL fork to run my LVN implementation with the existing test cases. As my implementation does not support constant folding and identity propogation, I had to update the expected result of some of the tests.\n\n\nCorrectness Evidence\nBesides the passing tests, I applied both my passes to the fizzbuzz benchmark in BRIL and found a decrease in the number of instructions executed as well as no change in the output of the benchmark, futher demonstrating the correctness of the implementation:\n\nWithout LVN + TDCE:\n\nbril2json &lt; ../benchmarks/core/fizz-buzz.bril | brili 10 -p\n1\n2\n-2\n4\n-3\n-2\n7\n8\n-2\ntotal_dyn_inst: 332\n\nWith LVN + TDCE:\n\nbril2json &lt; ../benchmarks/core/fizz-buzz.bril | python3 lvn_matin.py |\n python3 tdce_matin.py | brili 10 -p\n1\n2\n-2\n4\n-3\n-2\n7\n8\n-2\ntotal_dyn_inst: 278\n\n\nChallenges\nOverall, I found the hard part being working with BRIL.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 2: Trivial Dead Code Elimination and Local Value Numbering Passes"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html",
    "title": "Homework2 - Yashaswini",
    "section": "",
    "text": "starting from the end of the function, the optimzer keeps a record of the variables used.\nif an instruction is assigning value to a variable that is not used later in the function, then it is eliminated\nonce a used variable is defined in the code, it is removed form the list of used varibles. ## Testing:\n\ntest case: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “const”, “type”: “int”, “dest”: “v3”, “value”: 1 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\noutput: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\nAs you can see above, satrting with the last instruction, out is the only variable used. Going backwards the instruction is assigning value to out which is used so this line stays and the inputs, v1 and v2 are added to used variables, and out is removed from used variables. the next instrction up is assigning value to v3, which is not used. there fore this instruction is eliminated and its inputs are not added to used variables.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework2 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code",
    "title": "Homework2 - Yashaswini",
    "section": "",
    "text": "starting from the end of the function, the optimzer keeps a record of the variables used.\nif an instruction is assigning value to a variable that is not used later in the function, then it is eliminated\nonce a used variable is defined in the code, it is removed form the list of used varibles. ## Testing:\n\ntest case: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “const”, “type”: “int”, “dest”: “v3”, “value”: 1 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\noutput: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\nAs you can see above, satrting with the last instruction, out is the only variable used. Going backwards the instruction is assigning value to out which is used so this line stays and the inputs, v1 and v2 are added to used variables, and out is removed from used variables. the next instrction up is assigning value to v3, which is not used. there fore this instruction is eliminated and its inputs are not added to used variables.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework2 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code-1",
    "href": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code-1",
    "title": "Homework2 - Yashaswini",
    "section": "About the Code",
    "text": "About the Code\n\ngiven a block of code the program starts from the top and assigns a vlaue number to each variable and computation.\nif a variable is reasigned it’s value number changes. the value number of a computation is the same only if both the value numbers of the inputs and the operation is the same\nif two instuctions have the same value number, then the instruction is changed by copying the previously computed value.\nall subsiquent instructions that use that variable will check the value table, and choose the earliest variable that has that value\n\n##Testing\ntest case: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 5 }, { “op”: “add”, “type”: “int”, “dest”: “sum1”, “args”: [“v1”, “v2”] }, { “op”: “add”, “type”: “int”, “dest”: “sum2”, “args”: [“v1”, “v2”] }, { “op”: “mul”, “type”: “int”, “dest”: “prod1”, “args”: [“sum1”, “sum2”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum1”, “prod1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum3”, “sum2”] }, { “op”: “print”, “args”: [“sum3”] } ] } ] }\n’’’\noutput:\n’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 5 }, { “op”: “add”, “type”: “int”, “dest”: “sum1”, “args”: [“v1”, “v2”] }, { “op”: “copy”, “type”: “int”, “dest”: “sum2”, “args”: [“sum1”] }, { “op”: “mul”, “type”: “int”, “dest”: “prod1”, “args”: [“sum1”, “sum1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum1”, “prod1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum3”, “sum1”] }, { “op”: “print”, “args”: [“sum3”] } ] } ] }\n’’’ In this case, the local value numbering does not reducte the number of instructions, however it does reduce the number of computations.\nin order to remove the unused instructions, we can now run the dead code elimination.\noutput: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 5 }, { “op”: “add”, “type”: “int”, “dest”: “sum1”, “args”: [“v1”, “v2”] }, { “op”: “mul”, “type”: “int”, “dest”: “prod”, “args”: [“sum1”, “sum1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum1”, “prod”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum3”, “sum1”] }, { “op”: “print”, “args”: [“sum3”] } ] } ] }\n’’’\nnow the duplicated instuction is removed as sum2 is never used.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework2 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html",
    "title": "Homework2 - local optimizations",
    "section": "",
    "text": "All codes are here: lvn_dce_project",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework2 - local optimizations",
    "section": "Explanation of the Code",
    "text": "Explanation of the Code\nThe code I wrote for this question implements a trivial dead code elimination (DCE) optimization for Bril programs. It works by iterating through the instructions in reverse order, maintaining a set of used variables. Instructions that define variables not in this set are eliminated. The algorithm adds variables used as arguments to the set and removes variables when their defining instruction is processed. This approach ensures that instructions defining unused variables are removed while preserving the program’s essential structure and functionality.\nOutput of the code with Example 1 as the input:\n\nimport json\nimport copy\n\n\ndef tdce(func):\n    used_vars = set()\n    instructions = func['instrs']\n    new_instructions = []\n\n    for instr in reversed(instructions):\n        if 'dest' in instr:\n            if instr['dest'] not in used_vars:\n                continue  # skip this instruction as its destination is never used\n            used_vars.remove(instr['dest'])\n        \n        if 'args' in instr:\n            used_vars.update(instr['args'])\n        \n        new_instructions.append(instr)\n    \n    func['instrs'] = list(reversed(new_instructions))\n    return func\n\ndef main(input_str):\n    prog = json.loads(example1)\n    \n    for func in prog['functions']:\n        func = tdce(func)\n    \n    return json.dumps(prog, indent=2)\n\n# Example 1 as a JSON string (after bril2json conversion)\nexample1 = '''\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n'''\n\nprint(\"Original program:\")\nprint(example1)\nprint(\"\\nOptimized program:\")\noptimized_prog = main(example1)\nprint(optimized_prog)\n\nOriginal program:\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n\n\nOptimized program:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 4\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"b\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"d\",\n          \"args\": [\n            \"a\",\n            \"b\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"d\"\n          ]\n        }\n      ]\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code",
    "title": "Homework2 - local optimizations",
    "section": "Testing the Code",
    "text": "Testing the Code\nAs we can see in above output, line 3 ‘c: int = const 1;’ is removed because c is assigned and never used. we can also further test the code with a bigger input:\nexample2:\n@main {\n  # Variables with different usage patterns\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;  # This is dead code\n  d: int = add a b;\n  e: int = add c d;  # 'c' is used here, but 'e' is never used\n  \n  # Reassignment\n  a: int = const 10;\n  a: int = const 200;  # This overwrites the previous 'a'\n  \n  # Prints to mark usage\n  print a;\n  print d;\n}\n\nimport json\nimport copy\n\n\ndef tdce(func):\n    used_vars = set()\n    instructions = func['instrs']\n    new_instructions = []\n\n    for instr in reversed(instructions):\n        if 'dest' in instr:\n            if instr['dest'] not in used_vars:\n                continue  # skip this instruction as its destination is never used\n            used_vars.remove(instr['dest'])\n        \n        if 'args' in instr:\n            used_vars.update(instr['args'])\n        \n        new_instructions.append(instr)\n    \n    func['instrs'] = list(reversed(new_instructions))\n    return func\n\ndef main(input_str):\n    prog = json.loads(example2)\n    \n    for func in prog['functions']:\n        func = tdce(func)\n    \n    return json.dumps(prog, indent=2)\n\n# Example 2 as a JSON string (after bril2json conversion)\nexample2 = '''\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"e\", \"args\": [\"c\", \"d\"] },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 10 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 200 },\n        { \"op\": \"print\", \"args\": [\"a\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n'''\n\nprint(\"Original program:\")\nprint(example2)\nprint(\"\\nOptimized program:\")\noptimized_prog = main(example2)\nprint(optimized_prog)\n\nOriginal program:\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"e\", \"args\": [\"c\", \"d\"] },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 10 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 200 },\n        { \"op\": \"print\", \"args\": [\"a\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n\n\nOptimized program:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 4\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"b\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"d\",\n          \"args\": [\n            \"a\",\n            \"b\"\n          ]\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 200\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"a\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"d\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n\n\nAs we expect, we can see that line 3 ise removed, because c is assigned and used in line 5 for defining e but e is never used so these two lines are both dead code, also a is reassigned in line 6 and thus removed.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges-faced",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges-faced",
    "title": "Homework2 - local optimizations",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nOne of the challenges that I can think of in this question, is that for large and complex programs, the reverse iteration and set operations might become a performance bottleneck. Addressing these challenges would involve extending the algorithm, careful consideration of Bril’s semantics, and developing more sophisticated testing strategies.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#part-2",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#part-2",
    "title": "Homework2 - local optimizations",
    "section": "Part 2",
    "text": "Part 2",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "title": "Homework2 - local optimizations",
    "section": "Explanation of the Code",
    "text": "Explanation of the Code\nThe lvn code implements Local Value Numbering to optimize Bril programs by eliminating redundant computations within basic blocks. It processes each instruction, assigns value numbers to expressions based on their operations and operands, and maintains tables to track these values. When it encounters a redundant computation, it eliminates it by reusing the previously computed result, effectively reducing the number of instructions and optimizing the code.\nExample input:\n@main() {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}\n\nimport json\nimport sys\n\n\ndef lvn(func):\n    new_instrs = []\n    value_table = {}  \n    var_table = {}   \n\n    for instr in func['instrs']:\n        if 'op' in instr:\n            if instr['op'] == 'const':\n                value = instr['value']\n                value_num = get_value_number(value_table, ('const', value))\n                value_table[value_num] = ('const', value, instr['dest'])\n                var_table[instr['dest']] = value_num\n                new_instrs.append(instr)\n            elif instr['op'] == 'print':\n                new_instr = instr.copy()\n                if 'args' in new_instr:\n                    new_instr['args'] = [value_table[var_table[arg]][2] for arg in new_instr['args']]\n                new_instrs.append(new_instr)\n            else:\n                args = [var_table.get(arg, arg) for arg in instr.get('args', [])]\n                value_num = get_value_number(value_table, (instr['op'], tuple(args)))\n\n                if value_num in value_table:\n                    # Redundant computation found here!\n                    canonical_op, canonical_args, canonical_var = value_table[value_num]\n                    var_table[instr['dest']] = value_num\n                else:\n                    new_instr = instr.copy()\n                    new_instr['args'] = [value_table[arg][2] if arg in value_table else arg for arg in args]\n                    value_table[value_num] = (instr['op'], tuple(args), instr['dest'])\n                    var_table[instr['dest']] = value_num\n                    new_instrs.append(new_instr)\n        else:\n            new_instrs.append(instr)\n\n    func['instrs'] = new_instrs\n    return func\n\n       \ndef get_value_number(value_table, key):\n    for num, (op, args, var) in value_table.items():\n        if op == key[0] and args == key[1]:\n            return num\n    return len(value_table)\n\ndef main():\n    try:\n        bril_input = json.loads(example1)\n        for func in bril_input['functions']:\n            lvn(func)\n        json.dump(bril_input, sys.stdout, indent=2)\n        sys.stdout.flush()\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n\n\n# Example 1 as a JSON string (after bril2json conversion)\nexample1 = '''\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"sum1\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"sum2\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"mul\", \"type\": \"int\", \"dest\": \"prod\", \"args\": [\"sum1\", \"sum2\"] },\n        { \"op\": \"print\", \"args\": [\"prod\"] }\n      ]\n    }\n  ]\n}\n\n'''\n\nif __name__ == '__main__':\n    main()\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 4\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"b\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"sum1\",\n          \"args\": [\n            \"a\",\n            \"b\"\n          ]\n        },\n        {\n          \"op\": \"mul\",\n          \"type\": \"int\",\n          \"dest\": \"prod\",\n          \"args\": [\n            \"sum1\",\n            \"sum1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"prod\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n\n\nAs we can see in the output above, line 5 has been changed to prod: int = mul sum1 sum1;",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code-1",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code-1",
    "title": "Homework2 - local optimizations",
    "section": "Testing the Code",
    "text": "Testing the Code\nFor testing the correctness of the code, I used brench.py code in bril, and for that we need to have a brench.toml file (or a configuration file for brench.py) configures the Brench tool to run a Bril benchmark through four different pipelines: baseline (no optimization), DCE only, LVN only, and LVN followed by DCE. It then extracts the total number of dynamic instructions executed for each run, allowing us to compare the effectiveness of these optimizations. We use brench.toml with python3 ../brench/brench.py brench.toml &gt; results.csv\nexample test:\n@main {\n    a: int = const 1;\n    b: int = const 2;\n\n    c: int = add a b;\n    d: int = add a b;    # Redundant computation\n    e: int = add b a;    # Redundant due to commutativity\n    f: int = mul c d;\n    g: int = mul c e;    # Redundant computation\n\n    sum1: int = add a b; # Same as c, d, and e\n    sum2: int = add a b; # Same as c, d, e, and sum1\n    prod: int = mul sum1 sum2; # Uses two identical values\n\n    h: int = sub f g;    # Dead code: computed but never used\n    i: int = add a a;    # Dead code: computed but never used\n\n    print f;\n    print g;\n    print prod;\n}\nresults.csv:\nbenchmark,run,result\ntest_lvn,baseline,15\ntest_lvn,dce,13\ntest_lvn,lvn,11\ntest_lvn,lvn_dce,9\nBased on this analysis, let’s count the instructions that should remain after each optimization:\nBaseline: 15 instructions (all original instructions)\nDCE: 13 instructions (removes h and i)\nLVN: 11 instructions (keeps a, b, c, f, prod, and the three print statements)\nLVN + DCE: 9 instructions (same as LVN, but also removes h and i)\nTherefore, We can confirm the correctness of the implementations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges",
    "title": "Homework2 - local optimizations",
    "section": "Challenges",
    "text": "Challenges\nThe main challenges in lvn.py include handling commutative operations (like recognizing that add a b and add b a are equivalent) and ensuring that value numbering accurately tracks and replaces redundant computations without altering the program’s correct behavior.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "I created a Brill benchmark that calculates and prints the sum of prime numbers and composite numbers up to a given input (in this case, 100). The algorithm used here is very similar to the algorithm used in sieve.bril code in the Brill benchmark folder which is designed to find and print all prime numbers up to a specified limit. It emphasizes the identification of primes through boolean flags and modular functions. Our implementation extends the algorithm to calculate the sum of primes and the sum of composites up to a specified limit. It uses an integer array to flag primes and composites and focuses on aggregating values rather than listing them.\n\n\n\nTo give a little explanation about what each part of the code does:\n\n\n@sumOfPrimes: This function calculates the sum of all prime numbers up to n. First, an array nums of size n is allocated, where each index represents whether a number is prime or composite (1 for prime, 0 for composite). Initially, all numbers are marked as prime. Starting from current = 2, the function marks the multiples of each number as composite (0), skipping prime numbers. The outer loop increments current, and the inner loop marks all multiples of current as composite. After marking non-primes, the function iterates over the array from 2 to n and sums the numbers where the value is 1 (they are prime).\n@sumOfComposites: This function calculates the sum of all composite numbers up to n. It works similarly to the sumOfPrimes function but focuses on composite numbers. The main difference is in the summing step: instead of summing primes, the function starts summing from 4 (since 1 is neither prime nor composite, and 2 and 3 are primes) and adds all numbers marked as 0 (composite).\n\n\n\n\nTo test the implementation, I used the following approach:\n\na) I ran the benchmark with different input values, starting with small numbers like 10, 20, and then larger numbers like 100.\nb) I verified the results manually for smaller inputs by calculating the expected sums of primes and composites.\nc) I used the Brill interpreter (brili) to run the benchmark and checked both the output and the number of dynamic instructions executed.\n\nQuantitative results for input 100:\n1060\n3889\n\n\n\nThe most challenging part was handling the inner and outer loops in the Bril format, especially managing control flow with branches (br) and jumps (jmp). In Bril, control flow is more explicit than in higher-level languages, and ensuring proper transitions between loop bodies and loop conditions while avoiding infinite loops or incorrect logic was complex.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "To give a little explanation about what each part of the code does:\n\n\n@sumOfPrimes: This function calculates the sum of all prime numbers up to n. First, an array nums of size n is allocated, where each index represents whether a number is prime or composite (1 for prime, 0 for composite). Initially, all numbers are marked as prime. Starting from current = 2, the function marks the multiples of each number as composite (0), skipping prime numbers. The outer loop increments current, and the inner loop marks all multiples of current as composite. After marking non-primes, the function iterates over the array from 2 to n and sums the numbers where the value is 1 (they are prime).\n@sumOfComposites: This function calculates the sum of all composite numbers up to n. It works similarly to the sumOfPrimes function but focuses on composite numbers. The main difference is in the summing step: instead of summing primes, the function starts summing from 4 (since 1 is neither prime nor composite, and 2 and 3 are primes) and adds all numbers marked as 0 (composite).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "To test the implementation, I used the following approach:\n\na) I ran the benchmark with different input values, starting with small numbers like 10, 20, and then larger numbers like 100.\nb) I verified the results manually for smaller inputs by calculating the expected sums of primes and composites.\nc) I used the Brill interpreter (brili) to run the benchmark and checked both the output and the number of dynamic instructions executed.\n\nQuantitative results for input 100:\n1060\n3889",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "The most challenging part was handling the inner and outer loops in the Bril format, especially managing control flow with branches (br) and jumps (jmp). In Bril, control flow is more explicit than in higher-level languages, and ensuring proper transitions between loop bodies and loop conditions while avoiding infinite loops or incorrect logic was complex.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "title": "Homework1 - Sana",
    "section": "Explanation of the Code",
    "text": "Explanation of the Code\nThe code first iterates through each function in the program using the outer loop. Inside the function, the inner loop goes through each instruction. For each instruction, it increments the instruction count and checks if the instruction is a jump (br or jmp). If it is, a print instruction is added before the jump.\n\nimport json\nimport copy\n\nbril_json = \"\"\"\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\", \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"br\", \"args\": [\"v2\"], \"labels\": [\"then\", \"else\"] },\n        { \"label\": \"then\" },\n        { \"op\": \"print\", \"args\": [\"v2\"] },\n        { \"op\": \"jmp\", \"labels\": [\"end\"] },\n        { \"label\": \"else\" },\n        { \"op\": \"print\", \"args\": [\"v1\"] },\n        { \"label\": \"end\" },\n        { \"op\": \"ret\" }\n      ]\n    }\n  ]\n}\n\"\"\"\n\nbril_program = json.loads(bril_json)\n\ndef process_bril_program(bril_program):\n    total_instructions = 0\n    for function in bril_program['functions']:\n        new_instrs = []\n        for instruction in function['instrs']:\n            total_instructions += 1\n            \n            # add a print instruction before a jump!\n            if instruction.get('op') in ['br', 'jmp']:\n                print_instr = {\n                    \"op\": \"print\",\n                    \"args\": [\"Jumping\"]\n                }\n                new_instrs.append(print_instr)\n            \n            new_instrs.append(instruction)\n        \n        function['instrs'] = new_instrs\n\n    return bril_program, total_instructions\n\nmodified_program, instruction_count = process_bril_program(bril_program)\n\nprint(\"Total number of instructions:\", instruction_count)\nprint(\"Modified Bril program:\")\nprint(json.dumps(modified_program, indent=2))\n\nTotal number of instructions: 11\nModified Bril program:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"Jumping\"\n          ]\n        },\n        {\n          \"op\": \"br\",\n          \"args\": [\n            \"v2\"\n          ],\n          \"labels\": [\n            \"then\",\n            \"else\"\n          ]\n        },\n        {\n          \"label\": \"then\"\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"Jumping\"\n          ]\n        },\n        {\n          \"op\": \"jmp\",\n          \"labels\": [\n            \"end\"\n          ]\n        },\n        {\n          \"label\": \"else\"\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v1\"\n          ]\n        },\n        {\n          \"label\": \"end\"\n        },\n        {\n          \"op\": \"ret\"\n        }\n      ]\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested-1",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested-1",
    "title": "Homework1 - Sana",
    "section": "How the Implementation is Tested",
    "text": "How the Implementation is Tested\nTo test the implementation, I created a small Bril program called test.json that contains various types of instructions, including constants, an add operation, a branch instruction (br), a jump instruction (jmp), and print statements. I used this file to verify that the transformation was applied correctly and that the total number of instructions was counted.\nTest Input (test.json):\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\", \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"br\", \"args\": [\"v2\"], \"labels\": [\"then\", \"else\"] },\n        { \"label\": \"then\" },\n        { \"op\": \"print\", \"args\": [\"v2\"] },\n        { \"op\": \"jmp\", \"labels\": [\"end\"] },\n        { \"label\": \"else\" },\n        { \"op\": \"print\", \"args\": [\"v1\"] },\n        { \"label\": \"end\" },\n        { \"op\": \"ret\" }\n      ]\n    }\n  ]\n}\n\nOutput of The program is shown in previous section.\nQuantitative Results: The total number of instructions before the transformation was 11. After transformation, 2 print instructions were added (one before the br and another before the jmp), making the total number of instructions 13. (We can conclude this by counting the instructions in the modified Bril program)",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced-1",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced-1",
    "title": "Homework1 - Sana",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nThe most challenging part of the task was ensuring that the additional instructions were inserted in the correct place without modifying the logic of the Bril program. The Bril program must still execute in the intended order, and placing the print instructions incorrectly could have changed the control flow. To address this challenge, I carefully looped through the instruction list, checked for br and jmp operations, and inserted the print instructions before each of these jump-related instructions by also maintaining the program’s original flow and semantics.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "",
    "text": "This assignment aims to implement two key local optimizations for the Bril intermediate language: Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN). These optimizations enhance the efficiency of Bril programs by removing unnecessary instructions and consolidating equivalent expressions. This report outlines the development process, testing methodology, and analysis of the implemented optimizations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#introduction",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#introduction",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "",
    "text": "This assignment aims to implement two key local optimizations for the Bril intermediate language: Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN). These optimizations enhance the efficiency of Bril programs by removing unnecessary instructions and consolidating equivalent expressions. This report outlines the development process, testing methodology, and analysis of the implemented optimizations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#detail-design",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#detail-design",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Detail Design",
    "text": "Detail Design\nCode: For details, check the code repository.\n\nAbstraction Classes\nThe core of the Bril language representation in this project is implemented in the bril_model/_bril_struct.py file. This module provides a structured and object-oriented way to represent Bril programs (BrilScript), functions (BrilFunction), and instructions (BrilInstruction). Each Bril instruction is modeled as a Python object, enabling intuitive manipulation and transformation of the program during optimization.\nThe primary classes include:\nBril Program: Represents the entire Bril program, containing multiple functions.\nBril Function: Encapsulates a sequence of instructions and metadata for a function within the program.\nBril Instruction: Models individual instructions, differentiating between operations (e.g., addition, multiplication) and effectful statements (e.g., print).\nFirst, the BrilInstruction class is the base class for all instructions. Its constructor accepts a dictionary raw and deeply copies its contents into the instance variable _raw. It also initializes a mark dictionary _marks to track whether the instruction has been deleted, modified, or replaced. The constructor also checks whether the key in the raw dictionary is in the allowed key set AVAILABLE_KEYS, and throws NotImplementedError if there is an unrecognized key. The class also defines a series of properties and methods for accessing and modifying various parts of the instruction, such as dest, type, op, args, etc.\nNext are several subclasses inherited from BrilInstruction, which handle different types of instructions. The BrilInstruction_Const class is used to handle constant instructions. It checks whether the opcode is const in the constructor and verifies whether the key in the dictionary is in the allowed set. The BrilInstruction_Label class is used to handle label instructions. It checks whether the label exists in the constructor and verifies the key in the dictionary. The BrilInstruction_ValOp class is used to handle operation instructions with a return value. It checks whether the opcode is in the allowed set and verifies the key in the dictionary in the constructor. The BrilInstruction_EffOp class is used to handle operation instructions without a return value. It performs similar checks and verifications in the constructor.\nThe BrilFunction class is used to represent a Bril function. Its constructor accepts a dictionary raw and extracts the instruction list instrs from it, converting each instruction into a corresponding BrilInstruction subclass instance. It also checks whether the key in the dictionary is in the allowed set. The class also defines some properties and methods for accessing and modifying various parts of the function, such as name, type, args, etc.\nFinally, the BrilScript class is used to represent a Bril script. Its constructor accepts a dictionary raw and extracts the function list functions from it, converting each function into a BrilFunction instance. It also checks whether the key in the dictionary is in the allowed set. The class also defines some properties and methods for accessing and modifying various parts of the script, such as functions, etc.\nTogether, these classes form a framework for processing Bril language instructions and scripts, providing a wealth of properties and methods to access and modify various parts of instructions and scripts.\n\n\nTrivial Dead Code Elimination (DCE)\nThe Trivial-DCE implementation is encapsulated in tdce.py. This script scans through the instructions of a Bril function and removes any instructions whose results are not used before being overwritten. The optimization process involves:\nThe trivial_dce_once function performs a dead code elimination operation. It traverses all instructions in the function, collects all used variables, and marks unused instructions for deletion. Then, it updates the function’s instruction list, deletes the instructions marked for deletion, and returns a Boolean value indicating whether the instruction is deleted.\nThe trivial_dce function is a loop that repeatedly calls the trivial_dce_once function until no more instructions are deleted.\nThe _block_mark_reassign_before_use function deletes instructions that are reassigned before use within a single basic block. It maintains a dictionary to track the most recent unused assignment instructions and deletes old assignment instructions before reassignment is found.\nThe rm_reassign_before_use function traverses all basic blocks of the function, calls the _block_mark_reassign_before_use function to delete instructions that are reassigned before use, and updates the function’s instruction list.\nThe trivial_dce_plus function combines function-level dead code elimination with instruction removal before reassignment until there are no more instructions to remove.\nThis straightforward approach efficiently eliminates redundant calculations, contributing to a cleaner and faster program.\n\n\nLocal Value Numbering (LVN)\nLocal Value Numbering optimization is implemented in lvn.py, LVN assigns unique numbers to distinct computations to detect and eliminate redundant expressions within a single block. Key steps include:\nNumbering Expressions: LVN assigns a unique identifier to each distinct computation. This identifier, or value number, is used to track expressions within a block. If an identical computation is encountered later, the existing value number is reused, eliminating the need to recompute the expression. For example, if the expression a + b is already computed and assigned a value number, any subsequent occurrence of a + b will directly use the same value number instead of recalculating the result.\nSimplification and Substitution: The script replaces redundant operations with precomputed values or previously assigned variables, reducing the number of cpu-intense operations in the block. This is done by looking up the value number table for existing computations and substituting them wherever possible. By minimizing redundant calculations, LVN not only optimizes runtime performance but also simplifies the code.\nConstant Folding: Constant folding is a compile-time optimization technique that evaluates expressions with known constant values. For instance, an expression like const 2 + const 3 is directly replaced with const 5. In the script, a dictionary named FOLDABLE_OPS maps operation names (e.g., add, mul, sub) to their respective lambda functions that perform the computation. When the LVN process encounters an expression with constant arguments, it applies the corresponding function to compute the result immediately. Credit: Bril Official Example\nExpression Tracking and Reuse: An Expr class is defined to uniquely represent computations in terms of operations and their arguments. This allows the LVN process to easily check if a computation has been previously performed and reuse the result if possible. The implementation also handles commutative operations (e.g., add, mul, and, or, eq) by normalizing the order of arguments, ensuring that expressions like a + b and b + a are recognized as identical.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#integration-and-testing",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#integration-and-testing",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Integration and Testing",
    "text": "Integration and Testing\nThe brench tool is used for batch testing both optimizations across a variety of Bril programs. The brench_test_lvn.toml and brench_test_tdce.toml configuration files specify the programs and expected results for LVN and DCE tests, respectively. This ensures that both optimizations work correctly and consistently.\nAs defined in brench_test_lvn.toml, we specifies the path to the Bril benchmark programs to be tested, which are all the *.bril located in the ../bril/benchmarks/core/.\nThe configuration file defines multiple test run pipelines, each of which is defined in the [runs.&lt;name&gt;] section. Each pipeline contains a pipeline field that lists the sequence of commands to be executed.\nThe baseline pipeline is a baseline test without any optimization. It first converts the Bril program to JSON format and then runs the program using the brili interpreter.\nThe hw2p1_s0 pipeline is used to test whether the input and output structures are correct, but it does not perform any optimization. The purpose of this pipeline is to test if the Bril Construction work has no bug in it.\nThe hw2p1_s1 pipeline tests simple dead code elimination optimization. It calls the tdce.py script and passes the tdce parameter to enable function-level dead code elimination.\nThe hw2p1_s2 pipeline tests the instruction removal optimization used before revalue. It calls the tdce.py script and passes the raby argument to enable the rm_reassign_before_use pass optimization.\nThe hw2p1_s3 pipeline combines function-level dead code elimination and instruction removal optimization used before revalue. It calls the tdce.py script and passes the tdce+ argument to enable both optimizations.\nEach pipeline ultimately runs the optimized Bril program using the brili interpreter, passing arguments via the -p {args} option.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#results-and-analysis",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#results-and-analysis",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Results and Analysis",
    "text": "Results and Analysis\nThe optimizations were tested using brench tool, which verifies the correctness and performance of the implemented passes. The tool checks the brili Standard Output (STDOUT) for each test specification to ensure that the optimized programs produce the same results as their unoptimized counterparts. This rigorous testing confirms that the optimization passes do not alter the semantics of the Bril programs.\nThe testing demonstrated significant improvements in reducing the number of executed instructions for each Bril program. Programs with redundant calculations and unused instructions were simplified, leading to a reduced instruction count and faster execution times (based on Instructions Executed reported by brili -p).\nFor example, in the original benchmark check-primes, the program required 8,468 instructions to complete its execution. After applying the hw2p1_s3 optimization pipeline (DCE-only), the number of instructions executed was reduced to 8,419. Furthermore, using the hw2p2_s2 optimization pipeline (LVN+DCE), the total instructions executed dropped significantly to 4,238, representing a reduction to 50.05% of the original execution time. This demonstrates the substantial impact of combining LVN and DCE optimizations on program efficiency.\n\nRaw test log\n❯ brench brench_test_tdce.toml\nbenchmark,run,result\nfact,baseline,229\nfact,hw2p1_s0,229\nfact,hw2p1_s1,228\nfact,hw2p1_s2,229\nfact,hw2p1_s3,228\nquadratic,baseline,785\nquadratic,hw2p1_s0,785\nquadratic,hw2p1_s1,783\nquadratic,hw2p1_s2,785\nquadratic,hw2p1_s3,783\nrecfact,baseline,104\nrecfact,hw2p1_s0,104\nrecfact,hw2p1_s1,103\nrecfact,hw2p1_s2,104\nrecfact,hw2p1_s3,103\npascals-row,baseline,146\npascals-row,hw2p1_s0,146\npascals-row,hw2p1_s1,139\npascals-row,hw2p1_s2,146\npascals-row,hw2p1_s3,139\nloopfact,baseline,116\nloopfact,hw2p1_s0,116\nloopfact,hw2p1_s1,115\nloopfact,hw2p1_s2,116\nloopfact,hw2p1_s3,115\nsum-sq-diff,baseline,3038\nsum-sq-diff,hw2p1_s0,3038\nsum-sq-diff,hw2p1_s1,3036\nsum-sq-diff,hw2p1_s2,3038\nsum-sq-diff,hw2p1_s3,3036\nbirthday,baseline,484\nbirthday,hw2p1_s0,484\nbirthday,hw2p1_s1,483\nbirthday,hw2p1_s2,484\nbirthday,hw2p1_s3,483\nmod_inv,baseline,558\nmod_inv,hw2p1_s0,558\nmod_inv,hw2p1_s1,555\nmod_inv,hw2p1_s2,558\nmod_inv,hw2p1_s3,555\ncheck-primes,baseline,8468\ncheck-primes,hw2p1_s0,8468\ncheck-primes,hw2p1_s1,8419\ncheck-primes,hw2p1_s2,8468\ncheck-primes,hw2p1_s3,8419\nbitwise-ops,baseline,1690\nbitwise-ops,hw2p1_s0,1690\nbitwise-ops,hw2p1_s1,1689\nbitwise-ops,hw2p1_s2,1690\nbitwise-ops,hw2p1_s3,1689\nrelative-primes,baseline,1923\nrelative-primes,hw2p1_s0,1923\nrelative-primes,hw2p1_s1,1914\nrelative-primes,hw2p1_s2,1923\nrelative-primes,hw2p1_s3,1914\neuclid,baseline,563\neuclid,hw2p1_s0,563\neuclid,hw2p1_s1,562\neuclid,hw2p1_s2,563\neuclid,hw2p1_s3,562\nprimes-between,baseline,574100\nprimes-between,hw2p1_s0,574100\nprimes-between,hw2p1_s1,574100\nprimes-between,hw2p1_s2,574100\nprimes-between,hw2p1_s3,574100\nsum-check,baseline,5018\nsum-check,hw2p1_s0,5018\nsum-check,hw2p1_s1,5018\nsum-check,hw2p1_s2,5018\nsum-check,hw2p1_s3,5018\narmstrong,baseline,133\narmstrong,hw2p1_s0,133\narmstrong,hw2p1_s1,130\narmstrong,hw2p1_s2,133\narmstrong,hw2p1_s3,130\n\n❯ brench brench_test_lvn.toml\nbenchmark,run,result\nfact,baseline,229\nfact,hw2p2_s1,229\nfact,hw2p2_s2,167\nis-decreasing,baseline,127\nis-decreasing,hw2p2_s1,127\nis-decreasing,hw2p2_s2,123\nquadratic,baseline,785\nquadratic,hw2p2_s1,785\nquadratic,hw2p2_s2,500\nrecfact,baseline,104\nrecfact,hw2p2_s1,104\nrecfact,hw2p2_s2,64\nfizz-buzz,baseline,3652\nfizz-buzz,hw2p2_s1,3652\nfizz-buzz,hw2p2_s2,2103\npascals-row,baseline,146\npascals-row,hw2p2_s1,146\npascals-row,hw2p2_s2,68\nloopfact,baseline,116\nloopfact,hw2p2_s1,116\nloopfact,hw2p2_s2,78\nreverse,baseline,46\nreverse,hw2p2_s1,46\nreverse,hw2p2_s2,38\nsum-sq-diff,baseline,3038\nsum-sq-diff,hw2p2_s1,3038\nsum-sq-diff,hw2p2_s2,1717\nbirthday,baseline,484\nbirthday,hw2p2_s1,484\nbirthday,hw2p2_s2,278\nmod_inv,baseline,558\nmod_inv,hw2p2_s1,558\nmod_inv,hw2p2_s2,304\ncheck-primes,baseline,8468\ncheck-primes,hw2p2_s1,8468\ncheck-primes,hw2p2_s2,4238\nbitwise-ops,baseline,1690\nbitwise-ops,hw2p2_s1,1690\nbitwise-ops,hw2p2_s2,1689\nrelative-primes,baseline,1923\nrelative-primes,hw2p2_s1,1923\nrelative-primes,hw2p2_s2,1207\neuclid,baseline,563\neuclid,hw2p2_s1,563\neuclid,hw2p2_s2,272\nprimes-between,baseline,574100\nprimes-between,hw2p2_s1,574100\nprimes-between,hw2p2_s2,571439\nperfect,baseline,232\nperfect,hw2p2_s1,232\nperfect,hw2p2_s2,231\nbitshift,baseline,167\nbitshift,hw2p2_s1,167\nbitshift,hw2p2_s2,104\nsum-check,baseline,5018\nsum-check,hw2p2_s1,5018\nsum-check,hw2p2_s2,5018\narmstrong,baseline,133\narmstrong,hw2p2_s1,133\narmstrong,hw2p2_s2,130",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#conclusion",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#conclusion",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation successfully optimizes Bril programs through Trivial Dead Code Elimination and Local Value Numbering. Both techniques were integrated and tested using brench, confirming their effectiveness. Future work could focus on extending these optimizations to handle more complex cases, such as multi-block programs and interprocedural optimizations.\nThis project demonstrates the power of local optimizations in streamlining intermediate representations and serves as a solid foundation for further exploration of compiler optimization techniques.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/aymane/readme.html",
    "href": "blogs/aymane/readme.html",
    "title": "Homework 1 – Trying Out Bril",
    "section": "",
    "text": "To compile from typescript to bril and execute the program run the following:\n$ ts2bril bench.ts &gt; bench.bril && brili &lt; bench.bril\n727\nThe typescript benchmark I wrote performs a series of simple arithmetic, logical and alu operations. The function outputs 727 with the default input value 10.\n\n\nWhen writing the typescript benchmark, the input function argument was hardcoded to have value 10. So I couldn’t parametrized the turnt tests. I wanted to figure out a way to pass the input as a command line argument from stdin in order to generate different tests. Now I could do this by importing a typescript package to handle user input. But I’ve decided to manually modify my benchmark at the bril level.\nInitially, the typescript benchmark I wrote resulted in the following bril ir:\nbench.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"value\": 10,\n          \"dest\": \"v31\",\n          \"type\": \"int\"\n        },\n        ...\n      ]\n      \"args\": []\n    },\n    ...\n  ]\n}\nThe value 10 is passed in as a constant to main. In order to parametrize it, a few things need to be modified. First, we need to change the op field from const to id. As explained in the bril documentation, the id opcode is a type-insensitive identity we can use to pass variables around. Additonally, we also need specify the arguments passed to main. To do so, we pass a argument to the function. So the new bril representation becomes:\nbench-param.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"args\": [\n        {\n          \"name\": \"val\",\n          \"type\": \"int\"\n        }\n      ],\n      \"instrs\": [\n        {\n          \"args\": [\n            \"val\"\n          ],\n          \"dest\": \"v31\",\n          \"op\": \"id\",\n          \"type\": \"int\"\n        }, \n      ],\n    },\n    ...\n  ]\n}\n\nNow we can pass any value to the function:\n$ brili &lt; bench-param.bril 12\n2796\nTo more easily view these changes, let’s look at the text formatting of bril by running these commands to convert from json to text.\n$ bril2txt &lt; bench.bril &gt; bench.txt && bril2txt &lt; bench-param.bril &gt; bench-param.txt\nbench.txt\n@main {\n  v31: int = const 10;\n  ...\n}\nbench-param.txt\n@main(val: int) {\n  v31: int = id val;\n  ...\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/aymane/readme.html#passing-command-line-arugments",
    "href": "blogs/aymane/readme.html#passing-command-line-arugments",
    "title": "Homework 1 – Trying Out Bril",
    "section": "",
    "text": "When writing the typescript benchmark, the input function argument was hardcoded to have value 10. So I couldn’t parametrized the turnt tests. I wanted to figure out a way to pass the input as a command line argument from stdin in order to generate different tests. Now I could do this by importing a typescript package to handle user input. But I’ve decided to manually modify my benchmark at the bril level.\nInitially, the typescript benchmark I wrote resulted in the following bril ir:\nbench.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"value\": 10,\n          \"dest\": \"v31\",\n          \"type\": \"int\"\n        },\n        ...\n      ]\n      \"args\": []\n    },\n    ...\n  ]\n}\nThe value 10 is passed in as a constant to main. In order to parametrize it, a few things need to be modified. First, we need to change the op field from const to id. As explained in the bril documentation, the id opcode is a type-insensitive identity we can use to pass variables around. Additonally, we also need specify the arguments passed to main. To do so, we pass a argument to the function. So the new bril representation becomes:\nbench-param.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"args\": [\n        {\n          \"name\": \"val\",\n          \"type\": \"int\"\n        }\n      ],\n      \"instrs\": [\n        {\n          \"args\": [\n            \"val\"\n          ],\n          \"dest\": \"v31\",\n          \"op\": \"id\",\n          \"type\": \"int\"\n        }, \n      ],\n    },\n    ...\n  ]\n}\n\nNow we can pass any value to the function:\n$ brili &lt; bench-param.bril 12\n2796\nTo more easily view these changes, let’s look at the text formatting of bril by running these commands to convert from json to text.\n$ bril2txt &lt; bench.bril &gt; bench.txt && bril2txt &lt; bench-param.bril &gt; bench-param.txt\nbench.txt\n@main {\n  v31: int = const 10;\n  ...\n}\nbench-param.txt\n@main(val: int) {\n  v31: int = id val;\n  ...\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#partial-redundancy-elimination",
    "href": "lectures/revealjs_05c_pre.qmd.html#partial-redundancy-elimination",
    "title": "_ partial_redundancy elimination",
    "section": "partial redundancy elimination",
    "text": "partial redundancy elimination\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#simplifications",
    "href": "lectures/revealjs_05c_pre.qmd.html#simplifications",
    "title": "_ partial_redundancy elimination",
    "section": "simplifications",
    "text": "simplifications\n\nonly going to look at one expression \\(b + c\\)\ninitially all nodes in the cfg contain at most one assignment statement\nif there is a node that has multiple successors (a branch node) and one of the successors has multiple predecessors (a join) node we have added a extra node between them"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#down-safe",
    "href": "lectures/revealjs_05c_pre.qmd.html#down-safe",
    "title": "_ partial_redundancy elimination",
    "section": "down safe",
    "text": "down safe\nwe are moving computations earlier in the cfg\ndon’t move so far that it might not be used, or that an argument gets changed\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n\n\n\ncannot move b +c to top, because b changes"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#up-safe",
    "href": "lectures/revealjs_05c_pre.qmd.html#up-safe",
    "title": "_ partial_redundancy elimination",
    "section": "up-safe",
    "text": "up-safe\nWe can add a computation of \\(b+c\\) in any down-safe node. We want to pick a good one.\ndefine up-safe(block) (also called available) if \\(b+c\\) will be definitely used without being killed, computed on every path from entry to the block and not killed\nDo not add \\(b+c\\) to a block if the expression is available at that block\nup-safe is a second data flow problem\n\\[\nU_{\\text{safe}}(\\text{entry}) = \\text{false}\n\\]\n\\[\nU_{\\text{safe}}(n)=  \\text{trans}(n) \\cap_{p \\in \\text{preds}(n)} \\text{used}(p) \\cup \\text{U}_{\\text{safwe}}(p)\n\\]"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#placement",
    "href": "lectures/revealjs_05c_pre.qmd.html#placement",
    "title": "_ partial_redundancy elimination",
    "section": "placement",
    "text": "placement\nwant a down-safe node, that is not up-safe\n\npick the closest to the entry (min number of computations)\npick a later node to lower register pressure\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\nWe could move b+c in nodes a,c or e, but e does not help"
  },
  {
    "objectID": "lectures/05c_pre.html",
    "href": "lectures/05c_pre.html",
    "title": "_ partial_redundancy elimination",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#partial-redundancy-elimination",
    "href": "lectures/05c_pre.html#partial-redundancy-elimination",
    "title": "_ partial_redundancy elimination",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#simplifications",
    "href": "lectures/05c_pre.html#simplifications",
    "title": "_ partial_redundancy elimination",
    "section": "simplifications",
    "text": "simplifications\n\nonly going to look at one expression \\(b + c\\)\ninitially all nodes in the cfg contain at most one assignment statement\nif there is a node that has multiple successors (a branch node) and one of the successors has multiple predecessors (a join) node we have added a extra node between them",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#down-safe",
    "href": "lectures/05c_pre.html#down-safe",
    "title": "_ partial_redundancy elimination",
    "section": "down safe",
    "text": "down safe\nwe are moving computations earlier in the cfg\ndon’t move so far that it might not be used, or that an argument gets changed\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n\n\n\ncannot move b +c to top, because b changes",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#up-safe",
    "href": "lectures/05c_pre.html#up-safe",
    "title": "_ partial_redundancy elimination",
    "section": "up-safe",
    "text": "up-safe\nWe can add a computation of \\(b+c\\) in any down-safe node. We want to pick a good one.\ndefine up-safe(block) (also called available) if \\(b+c\\) will be definitely used without being killed, computed on every path from entry to the block and not killed\nDo not add \\(b+c\\) to a block if the expression is available at that block\nup-safe is a second data flow problem\n\\[\nU_{\\text{safe}}(\\text{entry}) = \\text{false}\n\\]\n\\[\nU_{\\text{safe}}(n)=  \\text{trans}(n) \\cap_{p \\in \\text{preds}(n)} \\text{used}(p) \\cup \\text{U}_{\\text{safwe}}(p)\n\\]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#placement",
    "href": "lectures/05c_pre.html#placement",
    "title": "_ partial_redundancy elimination",
    "section": "placement",
    "text": "placement\nwant a down-safe node, that is not up-safe\n\npick the closest to the entry (min number of computations)\npick a later node to lower register pressure\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\nWe could move b+c in nodes a,c or e, but e does not help",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/revealjs_junk.qmd.html#other",
    "href": "lectures/revealjs_junk.qmd.html#other",
    "title": "test",
    "section": "other",
    "text": "other\nentry – a b –&gt; b1 b1 –v1_0 v0_0 v0_1 + c m–&gt; comp_val comp_val – v1_1 v0_1 + c m –&gt; if_1\ncomp_val – v0_1 v1_1 c m –&gt; else_1 if_1 – v3_2 v1_1 c m –&gt; loop_bound else_1 – v3_1 v1_1 c m –&gt; loop_bound loop_bound – m –&gt; pend loop_bound –c –&gt; update_val update_val – v3_3 v0_2 c v0_1 g –&gt; if_2 update_val – v3_3 v0_2 c v0_1 g –&gt; else_2 if_2 – v4_1 v3_3 c v1_3 v0_1–&gt; back else_2 – v3_3 v9_2 c v1_1 v0_3–&gt; back back– v3_3 v1_2 c p1 –&gt; comp_val\n```"
  },
  {
    "objectID": "lectures/junk.html",
    "href": "lectures/junk.html",
    "title": "test",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry[\"op1=\n       op2=\"]\nb1[\"  vc0.0: int = const 0;\n  v0.0: int = id op1;\n  v1.0: int = id op2;\n  v1.1 = v1.0 \nv0.1 = v0.0 \n  jmp .cmp.val;\"]\n\ncomp_val[\"comp_val:\n  v1.1 = v1.1\n  v0.1: = v0.1\n  v2.1: bool = lt v0.1 v1.1;\n  br v2.1 .if.1 .else.1;\"]\nif_1[\"if1:  v3.2: int = sub v1.1 v0.1;\n v3.3: = v3.2 \n  jmp .loop.bound;\"]\nelse_1[\" v3.1: int = sub v0.1 v1.1;\n v3.3 = v3.1 \n  jmp .loop.bound;\"]\nloop_bound[\"loop_bound   v3.3 = v3.3\n  v4.1: bool = eq v3.3 vc0.0;\n  br v4.1 .program.end .update.val;\"]\nupdate_val[\"br v2.1 .if.2 .else.2;\"]\nif_2[\"  v1.3: int = id v3.3;\nv1.2 = v1.3\n  v0.2 = v0.1\n  jmp .back;\"]\nelse_2[\"  v0.3: int = id v3.3;\nv1.2 = v1.1 v1.3 \n  v0.2 = v0.3 v0.1\n  jmp .back;\"]\nback[\"  v1.2= v1.2\n  v0.2: = v0.2\n   v3.0 =  v3.3 \n    v2.0 = v2.1\n    v1.1 = v1.2\n    v0.1 = v0.2\n  jmp .cmp.val;\"]\npend[\"= v1.1\"]\n\nentry -- op1 op2 --&gt; b1\nb1 -- Xv1.1 Xv0.1 --&gt; comp_val\ncomp_val -- v1_1 xv0_1 --&gt; if_1\ncomp_val -- Xv_1 Xv0_1  --&gt; else_1\nif_1 --   Xv1_1 Xv3_3 --&gt; loop_bound\nelse_1 -- Xv1_1 Xv3_3--&gt; loop_bound\nloop_bound -- Xv1_1 --&gt; pend\nloop_bound --&gt; update_val\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1--&gt; if_2\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1 --&gt; else_2\nif_2 -- v4_1 v3_3  vc0_0 v1_3 v0_1--&gt; back\nelse_2  -- v4_1 v3_3  v9_2 vc0_0 v1_1 v0_3--&gt; back\nback-- xv1.1 Xv0.0--&gt; comp_val\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry[\"op1=\n       op2=\"]\nb1[\"  vc0.0: int = const 0;\n  v0.0: int = id op1;\n  v1.0: int = id op2;\n  v1.1 = v1.0 \nv0.1 = v0.0 \n  jmp .cmp.val;\"]\n\ncomp_val[\"comp_val:\n  v1.1 = v1.1\n  v0.1: = v0.1\n  v2.1: bool = lt v0.1 v1.1;\n  br v2.1 .if.1 .else.1;\"]\nif_1[\"if1:  v3.2: int = sub v1.1 v0.1;\n v3.3: = v3.2 \n  jmp .loop.bound;\"]\nelse_1[\" v3.1: int = sub v0.1 v1.1;\n v3.3 = v3.1 \n  jmp .loop.bound;\"]\nloop_bound[\"loop_bound   v3.3 = v3.3\n  v4.1: bool = eq v3.3 vc0.0;\n  br v4.1 .program.end .update.val;\"]\nupdate_val[\"br v2.1 .if.2 .else.2;\"]\nif_2[\"  v1.3: int = id v3.3;\nv1.2 = v1.3\n  v0.2 = v0.1\n  jmp .back;\"]\nelse_2[\"  v0.3: int = id v3.3;\nv1.2 = v1.1 v1.3 \n  v0.2 = v0.3 v0.1\n  jmp .back;\"]\nback[\"  v1.2= v1.2\n  v0.2: = v0.2\n   v3.0 =  v3.3 \n    v2.0 = v2.1\n    v1.1 = v1.2\n    v0.1 = v0.2\n  jmp .cmp.val;\"]\npend[\"= v1.1\"]\n\nentry -- op1 op2 --&gt; b1\nb1 -- Xv1.1 Xv0.1 --&gt; comp_val\ncomp_val -- v1_1 xv0_1 --&gt; if_1\ncomp_val -- Xv_1 Xv0_1  --&gt; else_1\nif_1 --   Xv1_1 Xv3_3 --&gt; loop_bound\nelse_1 -- Xv1_1 Xv3_3--&gt; loop_bound\nloop_bound -- Xv1_1 --&gt; pend\nloop_bound --&gt; update_val\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1--&gt; if_2\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1 --&gt; else_2\nif_2 -- v4_1 v3_3  vc0_0 v1_3 v0_1--&gt; back\nelse_2  -- v4_1 v3_3  v9_2 vc0_0 v1_1 v0_3--&gt; back\nback-- xv1.1 Xv0.0--&gt; comp_val",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "test"
    ]
  },
  {
    "objectID": "lectures/junk.html#other",
    "href": "lectures/junk.html#other",
    "title": "test",
    "section": "other",
    "text": "other\nentry – a b –&gt; b1 b1 –v1_0 v0_0 v0_1 + c m–&gt; comp_val comp_val – v1_1 v0_1 + c m –&gt; if_1\ncomp_val – v0_1 v1_1 c m –&gt; else_1 if_1 – v3_2 v1_1 c m –&gt; loop_bound else_1 – v3_1 v1_1 c m –&gt; loop_bound loop_bound – m –&gt; pend loop_bound –c –&gt; update_val update_val – v3_3 v0_2 c v0_1 g –&gt; if_2 update_val – v3_3 v0_2 c v0_1 g –&gt; else_2 if_2 – v4_1 v3_3 c v1_3 v0_1–&gt; back else_2 – v3_3 v9_2 c v1_1 v0_3–&gt; back back– v3_3 v1_2 c p1 –&gt; comp_val\n```",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "test"
    ]
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#homework",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#homework",
    "title": "Compiler Overview",
    "section": "Homework",
    "text": "Homework\nMost homework\n\nwe talk about some algorithm using pseudo\nYou implement that algorithm\nYou write up a blog post explaining what happened\nIf you like up to 3 people can submit a homework\n\nSince most programming languages have a json library, you can do homework in any language you like."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#readings",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#readings",
    "title": "Compiler Overview",
    "section": "Readings",
    "text": "Readings\nwe are going to critically read current research papers\n\nEach person leads a paper discussion (up to two people can sign up as a team to present the same paper)\nEveryone reads the paper; the leader goes over the contents pros and cons\nThe leader writes a blog post, (possibly including discussion insights )\nblog is due one week after the presentation.\nI recommend that people pair up (two people going over a paper before hand is a lot easier)\nI listed a lot of papers, but if there is a different paper you want to present let me know"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#project",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#project",
    "title": "Compiler Overview",
    "section": "Project",
    "text": "Project\nEverybody gets to do a project, which is compiler related\n\nyou will need to get a proposal approved half way through the term\nyou submit a blog reporting on what happened\nIf you like up to 3 people can submit a project"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#homework-0",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#homework-0",
    "title": "Compiler Overview",
    "section": "homework 0",
    "text": "homework 0\nWrite a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#early-compilers",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#early-compilers",
    "title": "Compiler Overview",
    "section": "Early Compilers",
    "text": "Early Compilers\nOriginally, a compiler was a person doing calculations.\nhidden figures"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#fortran",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#fortran",
    "title": "Compiler Overview",
    "section": "FORTRAN",
    "text": "FORTRAN\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\n2/3 of the cost and 90% of the time for solving a problem was coding.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-development-model",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-development-model",
    "title": "Compiler Overview",
    "section": "Compiler Development Model",
    "text": "Compiler Development Model\nIn these early years, the vendor development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#gcc",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#gcc",
    "title": "Compiler Overview",
    "section": "gcc",
    "text": "gcc\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#llvm",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#llvm",
    "title": "Compiler Overview",
    "section": "LLVM",
    "text": "LLVM\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#bril",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#bril",
    "title": "Compiler Overview",
    "section": "bril",
    "text": "bril\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#cost-of-a-compiler.",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#cost-of-a-compiler.",
    "title": "Compiler Overview",
    "section": "Cost of a compiler.",
    "text": "Cost of a compiler.\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nsource"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-assumptions-how-many-are-still-true",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-assumptions-how-many-are-still-true",
    "title": "Compiler Overview",
    "section": "Compiler Assumptions (How many are still true?)",
    "text": "Compiler Assumptions (How many are still true?)\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#how-well-do-compilers-do",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#how-well-do-compilers-do",
    "title": "Compiler Overview",
    "section": "How well do compilers do",
    "text": "How well do compilers do\nAt the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#proebstings-law",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#proebstings-law",
    "title": "Compiler Overview",
    "section": "proebsting’s law",
    "text": "proebsting’s law\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#why-compilers-are-not-better",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#why-compilers-are-not-better",
    "title": "Compiler Overview",
    "section": "why compilers are not better",
    "text": "why compilers are not better\nTalk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#effects-of-optimization",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#effects-of-optimization",
    "title": "Compiler Overview",
    "section": "effects of optimization",
    "text": "effects of optimization\nRemove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types"
  },
  {
    "objectID": "lectures/010_compiler_overview.html",
    "href": "lectures/010_compiler_overview.html",
    "title": "Compiler Overview",
    "section": "",
    "text": "A compiler writer builds bridges between people and machines, and every day this task becomes more challenging.\n\nSoftware engineers want abstractions\n\nHardware engineers want efficiency\n\n\n\n\nA compiler\n\n\n\n\nMost homework\n\nwe talk about some algorithm using pseudo\nYou implement that algorithm\nYou write up a blog post explaining what happened\nIf you like up to 3 people can submit a homework\n\nSince most programming languages have a json library, you can do homework in any language you like.\n\n\n\nwe are going to critically read current research papers\n\nEach person leads a paper discussion (up to two people can sign up as a team to present the same paper)\nEveryone reads the paper; the leader goes over the contents pros and cons\nThe leader writes a blog post, (possibly including discussion insights )\nblog is due one week after the presentation.\nI recommend that people pair up (two people going over a paper before hand is a lot easier)\nI listed a lot of papers, but if there is a different paper you want to present let me know\n\n\n\n\nEverybody gets to do a project, which is compiler related\n\nyou will need to get a proposal approved half way through the term\nyou submit a blog reporting on what happened\nIf you like up to 3 people can submit a project\n\n\n\n\nWrite a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website.\n\n\n\nOriginally, a compiler was a person doing calculations.\nhidden figures\n\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n\n\n\nGrace Hopper\n\n\n\n\n\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.\n\n\n\nIn these early years, the vendor development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on stage 2 (The middle end)\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy\n\n\n\n\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.\n\n\n\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.\n\n\n\n\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n\n\n\n\n\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nsource\n\nSome observations:\n\nProduction compilers are expensive.\nIR does not change easily.\nMuch of compiler technology is old.\nThere is a vast difference between production and student projects.\n\n\n\n\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Domain specific languages for AI)\nMore kinds of hardware\n\n\n\n\nAt the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\n\n\n\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt\n\n\n\nTalk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write.\n\n\n\nRemove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types\n\n\nOver time hardware has become more of a challenge for compilers, for example caches are not predictable at compile time. So compilers have to guess\nAnd hardware can ignore features of the compiler can deal with them - for example interlock",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#homework",
    "href": "lectures/010_compiler_overview.html#homework",
    "title": "Compiler Overview",
    "section": "",
    "text": "Most homework\n\nwe talk about some algorithm using pseudo\nYou implement that algorithm\nYou write up a blog post explaining what happened\nIf you like up to 3 people can submit a homework\n\nSince most programming languages have a json library, you can do homework in any language you like.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#readings",
    "href": "lectures/010_compiler_overview.html#readings",
    "title": "Compiler Overview",
    "section": "",
    "text": "we are going to critically read current research papers\n\nEach person leads a paper discussion (up to two people can sign up as a team to present the same paper)\nEveryone reads the paper; the leader goes over the contents pros and cons\nThe leader writes a blog post, (possibly including discussion insights )\nblog is due one week after the presentation.\nI recommend that people pair up (two people going over a paper before hand is a lot easier)\nI listed a lot of papers, but if there is a different paper you want to present let me know",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#project",
    "href": "lectures/010_compiler_overview.html#project",
    "title": "Compiler Overview",
    "section": "",
    "text": "Everybody gets to do a project, which is compiler related\n\nyou will need to get a proposal approved half way through the term\nyou submit a blog reporting on what happened\nIf you like up to 3 people can submit a project",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#homework-0",
    "href": "lectures/010_compiler_overview.html#homework-0",
    "title": "Compiler Overview",
    "section": "",
    "text": "Write a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#early-compilers",
    "href": "lectures/010_compiler_overview.html#early-compilers",
    "title": "Compiler Overview",
    "section": "",
    "text": "Originally, a compiler was a person doing calculations.\nhidden figures\n\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n\n\n\nGrace Hopper",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#fortran",
    "href": "lectures/010_compiler_overview.html#fortran",
    "title": "Compiler Overview",
    "section": "",
    "text": "In 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-development-model",
    "href": "lectures/010_compiler_overview.html#compiler-development-model",
    "title": "Compiler Overview",
    "section": "",
    "text": "In these early years, the vendor development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on stage 2 (The middle end)\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#gcc",
    "href": "lectures/010_compiler_overview.html#gcc",
    "title": "Compiler Overview",
    "section": "",
    "text": "In 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#llvm",
    "href": "lectures/010_compiler_overview.html#llvm",
    "title": "Compiler Overview",
    "section": "",
    "text": "in about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#bril",
    "href": "lectures/010_compiler_overview.html#bril",
    "title": "Compiler Overview",
    "section": "",
    "text": "In this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "href": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "title": "Compiler Overview",
    "section": "",
    "text": "Compilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nsource\n\nSome observations:\n\nProduction compilers are expensive.\nIR does not change easily.\nMuch of compiler technology is old.\nThere is a vast difference between production and student projects.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-assumptions-how-many-are-still-true",
    "href": "lectures/010_compiler_overview.html#compiler-assumptions-how-many-are-still-true",
    "title": "Compiler Overview",
    "section": "",
    "text": "The time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Domain specific languages for AI)\nMore kinds of hardware",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "href": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "title": "Compiler Overview",
    "section": "",
    "text": "At the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#proebstings-law",
    "href": "lectures/010_compiler_overview.html#proebstings-law",
    "title": "Compiler Overview",
    "section": "",
    "text": "proebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#why-compilers-are-not-better",
    "href": "lectures/010_compiler_overview.html#why-compilers-are-not-better",
    "title": "Compiler Overview",
    "section": "",
    "text": "Talk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#effects-of-optimization",
    "href": "lectures/010_compiler_overview.html#effects-of-optimization",
    "title": "Compiler Overview",
    "section": "",
    "text": "Remove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types\n\n\nOver time hardware has become more of a challenge for compilers, for example caches are not predictable at compile time. So compilers have to guess\nAnd hardware can ignore features of the compiler can deal with them - for example interlock",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/revealjs_01a1_performance_measurement.qmd.html#example-1",
    "href": "lectures/revealjs_01a1_performance_measurement.qmd.html#example-1",
    "title": "Performance and Measurement part 1",
    "section": "example 1",
    "text": "example 1\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references"
  },
  {
    "objectID": "lectures/revealjs_01a1_performance_measurement.qmd.html#violin-plots",
    "href": "lectures/revealjs_01a1_performance_measurement.qmd.html#violin-plots",
    "title": "Performance and Measurement part 1",
    "section": "violin plots",
    "text": "violin plots\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n\nCode\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots"
  },
  {
    "objectID": "lectures/revealjs_01a1_performance_measurement.qmd.html#error-bars",
    "href": "lectures/revealjs_01a1_performance_measurement.qmd.html#error-bars",
    "title": "Performance and Measurement part 1",
    "section": "error bars",
    "text": "error bars\n\n\nCode\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000"
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html",
    "href": "lectures/01a1_performance_measurement.html",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\nA sample blog post about this paper blog\n\n\n\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.\n\n\n\n\n\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html#example-1",
    "href": "lectures/01a1_performance_measurement.html#example-1",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\nA sample blog post about this paper blog",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html#violin-plots",
    "href": "lectures/01a1_performance_measurement.html#violin-plots",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "data\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html#error-bars",
    "href": "lectures/01a1_performance_measurement.html#error-bars",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "print(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#terms",
    "href": "lectures/revealjs_register_allocation.qmd.html#terms",
    "title": "Register Allocation",
    "section": "terms",
    "text": "terms\n\nThe task of determining the register in which each variable will be stored is known as register assignment.\nIf a variable must be stored in memory, it is referred to as a spill. Spilling involves identifying which variables need to be mapped to memory.\nIf the same register can be assigned to two variables related by a move instruction, the move can be eliminated. This optimization is called coalescing."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#more-terms",
    "href": "lectures/revealjs_register_allocation.qmd.html#more-terms",
    "title": "Register Allocation",
    "section": "more terms",
    "text": "more terms\n\nGPU performance often improves when fewer registers are used.\nVariables in Bril are virtual registers. After assignment, they become physical registers.\n\nRegister allocators often have to manage constraints. For example, a function argument may need to be placed in a specific physical register."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#formal-limits",
    "href": "lectures/revealjs_register_allocation.qmd.html#formal-limits",
    "title": "Register Allocation",
    "section": "Formal Limits",
    "text": "Formal Limits\nRegister allocation is NP complete. Given a program P and K registers, is there an assignment where each variable gets a register and all simultaneously live variables get different registers\nGregory Chaitin showed that if we have a graph that we want to paint with K colors, such that adjacent vertices get different colors we can construct a program where the program can be allocated with K registers iff the graph can be colored with K colors"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#interference-graph",
    "href": "lectures/revealjs_register_allocation.qmd.html#interference-graph",
    "title": "Register Allocation",
    "section": "Interference Graph",
    "text": "Interference Graph\nChaitin used the interference graph. One vertex for each variable, and edge between variables that are simultaneously live.\nTwo variables that interfere cannot be in the same register"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#allocation-and-liveness",
    "href": "lectures/revealjs_register_allocation.qmd.html#allocation-and-liveness",
    "title": "Register Allocation",
    "section": "Allocation and Liveness",
    "text": "Allocation and Liveness\nIf two variables are alive at the same point, and they have different values, they have to be assigned different registers\nApproximate this by ignoring “have different values” - Different registers if alive at the same point. (id is special)\nMaxLive is the max number of values live at the same point\nMinReg is the min number of registers we need\nminReg &gt;= MaxLive"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#an-example",
    "href": "lectures/revealjs_register_allocation.qmd.html#an-example",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\nWhat is the maximum number of variables alive at any program point?\nWhat is the interference graph of this program?\n\ndraw it?"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#interference-graph-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#interference-graph-1",
    "title": "Register Allocation",
    "section": "interference graph",
    "text": "interference graph\n\nMaxLive = 2 Can we compile this with 2 registers? - Need 3\ndraw it?\nThe interference graph is a pentagon, needed 3 registers.\nA pentagon is the smallest graph whose chromatic number (number of colors needed 3 ) is less the maximum clique (2)"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#ssa-form",
    "href": "lectures/revealjs_register_allocation.qmd.html#ssa-form",
    "title": "Register Allocation",
    "section": "SSA Form",
    "text": "SSA Form"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#with-liveness",
    "href": "lectures/revealjs_register_allocation.qmd.html#with-liveness",
    "title": "Register Allocation",
    "section": "with liveness",
    "text": "with liveness"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#ssa-with-interference-graph",
    "href": "lectures/revealjs_register_allocation.qmd.html#ssa-with-interference-graph",
    "title": "Register Allocation",
    "section": "ssa with interference graph",
    "text": "ssa with interference graph"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#register-allocation",
    "href": "lectures/revealjs_register_allocation.qmd.html#register-allocation",
    "title": "Register Allocation",
    "section": "register allocation",
    "text": "register allocation"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#swaps-via-xor",
    "href": "lectures/revealjs_register_allocation.qmd.html#swaps-via-xor",
    "title": "Register Allocation",
    "section": "swaps via xor",
    "text": "swaps via xor"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#final-code",
    "href": "lectures/revealjs_register_allocation.qmd.html#final-code",
    "title": "Register Allocation",
    "section": "final code",
    "text": "final code"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#ssa-based-register-allocation",
    "href": "lectures/revealjs_register_allocation.qmd.html#ssa-based-register-allocation",
    "title": "Register Allocation",
    "section": "ssa based register allocation",
    "text": "ssa based register allocation\nWe have been able to compile the SSA-form program with less registers than the minimum that the original program requires.\nTwo claims\n\nThe SSA-form program will never require more registers than the original program.\nAnd we can find the minimum number of registers that the SSA-form program needs in polynomial time."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#setting-up-the-colors",
    "href": "lectures/revealjs_register_allocation.qmd.html#setting-up-the-colors",
    "title": "Register Allocation",
    "section": "setting up the colors",
    "text": "setting up the colors\nsuppose we have an ordering of the vertices, where the neighbors of a node to the left of the node in the ordering from a clique. If there are K such neighbors we need K+1 colors"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#an-example-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#an-example-1",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n\n\ndraw it\ngiven this order - it is simple to pick the colors\nonce we have an order , we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored, so just pick one\nmaybe try not to clobber a copy\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#how-do-we-get-the-order",
    "href": "lectures/revealjs_register_allocation.qmd.html#how-do-we-get-the-order",
    "title": "Register Allocation",
    "section": "how do we get the order",
    "text": "how do we get the order\n\ngive each node number\ninitially each node gets count of zero 1 pick an unordered node with max count\nput that node in the front of the list, mark that node ordered\nincrement each neighbor by 1"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dominance-trees",
    "href": "lectures/revealjs_register_allocation.qmd.html#dominance-trees",
    "title": "Register Allocation",
    "section": "dominance trees",
    "text": "dominance trees\nWhat is the dominance tree of this program?"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dominance-tree",
    "href": "lectures/revealjs_register_allocation.qmd.html#dominance-tree",
    "title": "Register Allocation",
    "section": "dominance tree",
    "text": "dominance tree"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dom-sub-trees",
    "href": "lectures/revealjs_register_allocation.qmd.html#dom-sub-trees",
    "title": "Register Allocation",
    "section": "dom sub trees",
    "text": "dom sub trees"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#chordal-graphs-triangular-graphs",
    "href": "lectures/revealjs_register_allocation.qmd.html#chordal-graphs-triangular-graphs",
    "title": "Register Allocation",
    "section": "Chordal Graphs (triangular graphs)",
    "text": "Chordal Graphs (triangular graphs)\n\nintersection graph of subtrees\nA graph is chordal if each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle.\nif each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle. An equivalent definition is that any chord free cycles have at most three nodes."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#examples-of-chordal-graphs",
    "href": "lectures/revealjs_register_allocation.qmd.html#examples-of-chordal-graphs",
    "title": "Register Allocation",
    "section": "examples of chordal graphs",
    "text": "examples of chordal graphs\ndraw am example of a cord graph"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#orderings",
    "href": "lectures/revealjs_register_allocation.qmd.html#orderings",
    "title": "Register Allocation",
    "section": "orderings",
    "text": "orderings\nwe number the vertices of G\nv0,v1,v2,…., vi, …\nconsider vi all the neighbors to the left are a clique (all connected )"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-1",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-2",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-2",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-3",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-3",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-4",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-4",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-5",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-5",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-6",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-6",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-7",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-7",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#coloring",
    "href": "lectures/revealjs_register_allocation.qmd.html#coloring",
    "title": "Register Allocation",
    "section": "coloring",
    "text": "coloring\nonce we have an order (the reverse order above), we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#spilling",
    "href": "lectures/revealjs_register_allocation.qmd.html#spilling",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling\nif we ever have a program point where the number of live variables is &gt; MaxRegs we will have to spill - so do it here"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#spilling-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#spilling-1",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#coalescing",
    "href": "lectures/revealjs_register_allocation.qmd.html#coalescing",
    "title": "Register Allocation",
    "section": "coalescing",
    "text": "coalescing\nif we assign both sides of a copy to the same register, we can eliminate the copy.\ninput: L list of copy instructions, G=(V,E), K\noutput: updated graph G'\n\nG' = G\nfor all x=y in L\n   sx is the set of colors in the neighborhood of x\n   sy is the set of colors in the neighborood of y\n   let c be a color &lt; K that not in either set \n   add xy a new node xy is ajacent to all node in the union of neighborhoods \n   remove x and y from G'\nxy is a merge of x and y"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "href": "lectures/revealjs_register_allocation.qmd.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "title": "Register Allocation",
    "section": "how do we know that ssa graphs are chordal",
    "text": "how do we know that ssa graphs are chordal"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dominance-and-interference-thm-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#dominance-and-interference-thm-1",
    "title": "Register Allocation",
    "section": "dominance and interference Thm 1",
    "text": "dominance and interference Thm 1\nIn a strict ssa form the definition of a variable dominates all the uses\nlemma1 : if two variables interfere then the def of one dominates the def of the other\nlemma2 if two variables a and b interfere and Da &lt; Db, then a is live at Db\nlemma3 if u,v,w are variables u-v interfere and v-w interfere and u-w do not if Du &lt; Dv then Dv &lt; Dw\nthm: the interference graph of an ssa form program is chordal"
  },
  {
    "objectID": "lectures/register_allocation.html",
    "href": "lectures/register_allocation.html",
    "title": "Register Allocation",
    "section": "",
    "text": "Register allocation is the process of determining storage locations to the values used in a program.\nThese values can either be stored in registers or in memory.\nRegisters provide fast access but are limited in number.\nMemory has much higher latency and slower access speeds.\nA good register allocation strategy keeps frequently accessed variables in registers to maximize performance.\nmuch of the material for these slides comes from fernando",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#terms",
    "href": "lectures/register_allocation.html#terms",
    "title": "Register Allocation",
    "section": "terms",
    "text": "terms\n\nThe task of determining the register in which each variable will be stored is known as register assignment.\nIf a variable must be stored in memory, it is referred to as a spill. Spilling involves identifying which variables need to be mapped to memory.\nIf the same register can be assigned to two variables related by a move instruction, the move can be eliminated. This optimization is called coalescing.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#more-terms",
    "href": "lectures/register_allocation.html#more-terms",
    "title": "Register Allocation",
    "section": "more terms",
    "text": "more terms\n\nGPU performance often improves when fewer registers are used.\nVariables in Bril are virtual registers. After assignment, they become physical registers.\n\nRegister allocators often have to manage constraints. For example, a function argument may need to be placed in a specific physical register.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#formal-limits",
    "href": "lectures/register_allocation.html#formal-limits",
    "title": "Register Allocation",
    "section": "Formal Limits",
    "text": "Formal Limits\nRegister allocation is NP complete. Given a program P and K registers, is there an assignment where each variable gets a register and all simultaneously live variables get different registers\nGregory Chaitin showed that if we have a graph that we want to paint with K colors, such that adjacent vertices get different colors we can construct a program where the program can be allocated with K registers iff the graph can be colored with K colors",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#interference-graph",
    "href": "lectures/register_allocation.html#interference-graph",
    "title": "Register Allocation",
    "section": "Interference Graph",
    "text": "Interference Graph\nChaitin used the interference graph. One vertex for each variable, and edge between variables that are simultaneously live.\nTwo variables that interfere cannot be in the same register",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#allocation-and-liveness",
    "href": "lectures/register_allocation.html#allocation-and-liveness",
    "title": "Register Allocation",
    "section": "Allocation and Liveness",
    "text": "Allocation and Liveness\nIf two variables are alive at the same point, and they have different values, they have to be assigned different registers\nApproximate this by ignoring “have different values” - Different registers if alive at the same point. (id is special)\nMaxLive is the max number of values live at the same point\nMinReg is the min number of registers we need\nminReg &gt;= MaxLive",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#an-example",
    "href": "lectures/register_allocation.html#an-example",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\nWhat is the maximum number of variables alive at any program point?\nWhat is the interference graph of this program?\n\ndraw it?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#interference-graph-1",
    "href": "lectures/register_allocation.html#interference-graph-1",
    "title": "Register Allocation",
    "section": "interference graph",
    "text": "interference graph\n\nMaxLive = 2 Can we compile this with 2 registers? - Need 3\ndraw it?\nThe interference graph is a pentagon, needed 3 registers.\nA pentagon is the smallest graph whose chromatic number (number of colors needed 3 ) is less the maximum clique (2)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#ssa-form",
    "href": "lectures/register_allocation.html#ssa-form",
    "title": "Register Allocation",
    "section": "SSA Form",
    "text": "SSA Form",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#with-liveness",
    "href": "lectures/register_allocation.html#with-liveness",
    "title": "Register Allocation",
    "section": "with liveness",
    "text": "with liveness",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#ssa-with-interference-graph",
    "href": "lectures/register_allocation.html#ssa-with-interference-graph",
    "title": "Register Allocation",
    "section": "ssa with interference graph",
    "text": "ssa with interference graph",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#register-allocation",
    "href": "lectures/register_allocation.html#register-allocation",
    "title": "Register Allocation",
    "section": "register allocation",
    "text": "register allocation",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#swaps-via-xor",
    "href": "lectures/register_allocation.html#swaps-via-xor",
    "title": "Register Allocation",
    "section": "swaps via xor",
    "text": "swaps via xor",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#final-code",
    "href": "lectures/register_allocation.html#final-code",
    "title": "Register Allocation",
    "section": "final code",
    "text": "final code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#ssa-based-register-allocation",
    "href": "lectures/register_allocation.html#ssa-based-register-allocation",
    "title": "Register Allocation",
    "section": "ssa based register allocation",
    "text": "ssa based register allocation\nWe have been able to compile the SSA-form program with less registers than the minimum that the original program requires.\nTwo claims\n\nThe SSA-form program will never require more registers than the original program.\nAnd we can find the minimum number of registers that the SSA-form program needs in polynomial time.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#setting-up-the-colors",
    "href": "lectures/register_allocation.html#setting-up-the-colors",
    "title": "Register Allocation",
    "section": "setting up the colors",
    "text": "setting up the colors\nsuppose we have an ordering of the vertices, where the neighbors of a node to the left of the node in the ordering from a clique. If there are K such neighbors we need K+1 colors",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#an-example-1",
    "href": "lectures/register_allocation.html#an-example-1",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n\n\ndraw it\ngiven this order - it is simple to pick the colors\nonce we have an order , we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored, so just pick one\nmaybe try not to clobber a copy\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#how-do-we-get-the-order",
    "href": "lectures/register_allocation.html#how-do-we-get-the-order",
    "title": "Register Allocation",
    "section": "how do we get the order",
    "text": "how do we get the order\n\ngive each node number\ninitially each node gets count of zero 1 pick an unordered node with max count\nput that node in the front of the list, mark that node ordered\nincrement each neighbor by 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dominance-trees",
    "href": "lectures/register_allocation.html#dominance-trees",
    "title": "Register Allocation",
    "section": "dominance trees",
    "text": "dominance trees\nWhat is the dominance tree of this program?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dominance-tree",
    "href": "lectures/register_allocation.html#dominance-tree",
    "title": "Register Allocation",
    "section": "dominance tree",
    "text": "dominance tree",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dom-sub-trees",
    "href": "lectures/register_allocation.html#dom-sub-trees",
    "title": "Register Allocation",
    "section": "dom sub trees",
    "text": "dom sub trees",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#chordal-graphs-triangular-graphs",
    "href": "lectures/register_allocation.html#chordal-graphs-triangular-graphs",
    "title": "Register Allocation",
    "section": "Chordal Graphs (triangular graphs)",
    "text": "Chordal Graphs (triangular graphs)\n\nintersection graph of subtrees\nA graph is chordal if each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle.\nif each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle. An equivalent definition is that any chord free cycles have at most three nodes.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#examples-of-chordal-graphs",
    "href": "lectures/register_allocation.html#examples-of-chordal-graphs",
    "title": "Register Allocation",
    "section": "examples of chordal graphs",
    "text": "examples of chordal graphs\ndraw am example of a cord graph",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#orderings",
    "href": "lectures/register_allocation.html#orderings",
    "title": "Register Allocation",
    "section": "orderings",
    "text": "orderings\nwe number the vertices of G\nv0,v1,v2,…., vi, …\nconsider vi all the neighbors to the left are a clique (all connected )",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example",
    "href": "lectures/register_allocation.html#running-example",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-1",
    "href": "lectures/register_allocation.html#running-example-1",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-2",
    "href": "lectures/register_allocation.html#running-example-2",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-3",
    "href": "lectures/register_allocation.html#running-example-3",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-4",
    "href": "lectures/register_allocation.html#running-example-4",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-5",
    "href": "lectures/register_allocation.html#running-example-5",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-6",
    "href": "lectures/register_allocation.html#running-example-6",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-7",
    "href": "lectures/register_allocation.html#running-example-7",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#coloring",
    "href": "lectures/register_allocation.html#coloring",
    "title": "Register Allocation",
    "section": "coloring",
    "text": "coloring\nonce we have an order (the reverse order above), we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#spilling",
    "href": "lectures/register_allocation.html#spilling",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling\nif we ever have a program point where the number of live variables is &gt; MaxRegs we will have to spill - so do it here",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#spilling-1",
    "href": "lectures/register_allocation.html#spilling-1",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#coalescing",
    "href": "lectures/register_allocation.html#coalescing",
    "title": "Register Allocation",
    "section": "coalescing",
    "text": "coalescing\nif we assign both sides of a copy to the same register, we can eliminate the copy.\ninput: L list of copy instructions, G=(V,E), K\noutput: updated graph G'\n\nG' = G\nfor all x=y in L\n   sx is the set of colors in the neighborhood of x\n   sy is the set of colors in the neighborood of y\n   let c be a color &lt; K that not in either set \n   add xy a new node xy is ajacent to all node in the union of neighborhoods \n   remove x and y from G'\nxy is a merge of x and y",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "href": "lectures/register_allocation.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "title": "Register Allocation",
    "section": "how do we know that ssa graphs are chordal",
    "text": "how do we know that ssa graphs are chordal",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dominance-and-interference-thm-1",
    "href": "lectures/register_allocation.html#dominance-and-interference-thm-1",
    "title": "Register Allocation",
    "section": "dominance and interference Thm 1",
    "text": "dominance and interference Thm 1\nIn a strict ssa form the definition of a variable dominates all the uses\nlemma1 : if two variables interfere then the def of one dominates the def of the other\nlemma2 if two variables a and b interfere and Da &lt; Db, then a is live at Db\nlemma3 if u,v,w are variables u-v interfere and v-w interfere and u-w do not if Du &lt; Dv then Dv &lt; Dw\nthm: the interference graph of an ssa form program is chordal",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/revealjs_08_classic_loop_ops.qmd.html#induction-variable-elimination",
    "href": "lectures/revealjs_08_classic_loop_ops.qmd.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l"
  },
  {
    "objectID": "lectures/revealjs_08_classic_loop_ops.qmd.html#loop-un-switching",
    "href": "lectures/revealjs_08_classic_loop_ops.qmd.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects"
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html",
    "href": "lectures/08_classic_loop_ops.html",
    "title": "8 classic loop optimizations",
    "section": "",
    "text": "Loops optimizations are important because\nWhat are classic loop optimizations?\nLess classic loop optimizations\nFirst recall natural loops\ndef of loop invariant for an instruction d = op a,b\nin SSA form if we find a loop invariant instruction we can always move it into the pre-header, because the value it writes is never rewritten, and the values that it depends on come from outside the loop\nconditions when moving an instruction d = a op b is ok\ncan move d\nL0: d = 0 preheader L1: if (i&gt;=N) goto L2 i = i + 1 d = a ⊕ b = d goto L1 L2: x = d ```\nno good d used after the loop, would not be changed if the loop executes zero times\nno good d reassigned in the loop, do invar would be changed\nwhile (e) { j = loopinv // may never execute S }\nj = loopinv // always executes while (e) { S }\nif (e) { j = loopinv // may never execute while (e) { S }\n} ````",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "href": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "href": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#challenges-in-learning-about-gpus",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#challenges-in-learning-about-gpus",
    "title": "GPU Compilers",
    "section": "Challenges in Learning About GPUs",
    "text": "Challenges in Learning About GPUs\n\nArchitectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc."
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-nvidia-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-nvidia-model",
    "title": "GPU Compilers",
    "section": "hardware styles NVIDIA model",
    "text": "hardware styles NVIDIA model\n\ncompute and graphics parts have same programmable parts, compute leaves out non-programmable features\ngraphics customers pay a tax for the compute instructions\nmore transistors for compute instructions\none big die"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-amd-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-amd-model",
    "title": "GPU Compilers",
    "section": "hardware styles AMD model",
    "text": "hardware styles AMD model\n\ncompute has extra instructions (no tax on graphics customers to support compute)\nchiplet model (great engineering!)\nR series is graphics, C series is compute"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#programming-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#programming-model",
    "title": "GPU Compilers",
    "section": "programming model",
    "text": "programming model\nboth vendors use the CUDA programming model. AMD supports a variation of the CUDA language\nmachines have multiple SIMD processors, each SIMD can be running a different instruction but each lane of a SIMD runs the same instruction\na lane of a SIMD is called a thread"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#threading-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#threading-model",
    "title": "GPU Compilers",
    "section": "threading model",
    "text": "threading model"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#warps-waveswavefronts",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#warps-waveswavefronts",
    "title": "GPU Compilers",
    "section": "warps/ waves/wavefronts",
    "text": "warps/ waves/wavefronts\n\nthreads are grouped together into warps.\nSize is fixed by hardware (usually 32), programmers know this and often make data set sizes a multiple of 32.\nsince all threads in a warp are running the same instruction, there is no need for explicit synchronization\nthere are a few instructions that work across a warp, - which break the model and give the compiler problems"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-blocks-groups-of-warps",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-blocks-groups-of-warps",
    "title": "GPU Compilers",
    "section": "thread blocks groups of warps,",
    "text": "thread blocks groups of warps,\n\nthreads within a block can access a fast scratchpad memory (called shared or LDS) - Violates the C memory model.\n\nthreads are identified by a 3d index inside a block\nthread blocks need synchronization operations.\n\nhardware schedules each block into execution units. Max block size is limited by the size of a execution unit."
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#grid-groups-of-blocks",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#grid-groups-of-blocks",
    "title": "GPU Compilers",
    "section": "grid groups of blocks,",
    "text": "grid groups of blocks,\n\n3d collection of blocks,\nusually hardware limits mean that all the threads in a grid do not run at the same time\nprogrammers need to make grids big enough to fill the hardware\nsoftware launches a grid and a program\nthreads within a grid but in different blocks do not have sync operations"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#heterogeneous-programming",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#heterogeneous-programming",
    "title": "GPU Compilers",
    "section": "Heterogeneous programming",
    "text": "Heterogeneous programming\nthe cpu is called the host\nthe gpu is called the device\ncpu launches grids and kernels to gpu\nComputations launched on the device execute asynchronously with respect to the host, and it is the user’s responsibility to synchronize"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#memory-spaces",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#memory-spaces",
    "title": "GPU Compilers",
    "section": "memory spaces",
    "text": "memory spaces\n\ncpu and gpu have different memory spaces (cpu can copy from one to the other). Some amount of combined memory (slower the not combined)\ngpu has shared/lds memory which can be accessed by threads within a block, passing an address to a different block does not work\nmain gpu memory is called global accessible by all threads\ngpu has per thread memory called local or scratch ot private memory - unlike C, passing an address in local memory to another thread does not work. (under some restrictions AMD implements part of the C memory model)\na few special gpu memory types: constant, texture, surface (left over from graphics)\ngpu can treat registers as fast memory"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware",
    "title": "GPU Compilers",
    "section": "Hardware",
    "text": "Hardware\nNVIDIA\n\nnv image level 0Each box here is hardware, an int32/fp32/fp64 can perform one operation, so here we have 32 fp32 units which can do 32 float operations in parallel as well as 16 int32 and 16 fp64 units , there are also 8 units can do loads or stores and a final special function unit that can do transcendental operations like sin/cos\nunder some conditions two instructions (a float and an int) from the same warp can execute at the same time\nI’m not going to talk much about the tensor cores\nall these units execute the same instruction (SIMT) Simple instruction multiple thread (not the same as SIMD but related )"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#one-instruction-does-vector-work",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#one-instruction-does-vector-work",
    "title": "GPU Compilers",
    "section": "one instruction does vector work",
    "text": "one instruction does vector work\nadd 32 float32 values (all coming from registers) and store the result in 32 other registers\nNotice no branch prediction, no out of order execution\ngreat at switching a warp holds the instruction, it knows which registers it owns (continuous set, so it just needs a start and length) switching to a different warp, means changing these two numbers and the pc (this is done by the dispatch unt )\nWhen we do a load, we need to wait for the result. CPU might do some kind of out of order execution, a gpu switches to another warp\nfinally we need to pick the warp to switch to, this is done by the warp scheduler (half of the hardware scheduler)"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#streaming-multiprocessors-sm",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#streaming-multiprocessors-sm",
    "title": "GPU Compilers",
    "section": "streaming multiprocessors (SM)",
    "text": "streaming multiprocessors (SM)\nnvidia packs 4 execution engines into a SM (streaming multi-processor) ands an L1 instruction cache, a special memory accelerator for tensors and 256kb l1 data cache/ shared memory block"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#pack-sms-together",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#pack-sms-together",
    "title": "GPU Compilers",
    "section": "pack sm’s together",
    "text": "pack sm’s together"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#amd",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#amd",
    "title": "GPU Compilers",
    "section": "AMD",
    "text": "AMD"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#and",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#and",
    "title": "GPU Compilers",
    "section": "and",
    "text": "and\n\nAMD has a similar block with some important differences\n\nAt the bottom of a compute core there are 4 general purpose simd engines each of length 16 and one scalar engine\n\nGiven 5 waves, this compute core can execute 4 vector instructions and one scalar instruction per clock Two instructions from the same wave never execute at the same time\nThe SIMD engines can execute different instructions\nThe simd sizes vary over different chips"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#amd-cdna",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#amd-cdna",
    "title": "GPU Compilers",
    "section": "amd CDNA",
    "text": "amd CDNA"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#packing-sms",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#packing-sms",
    "title": "GPU Compilers",
    "section": "packing sms",
    "text": "packing sms"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#simd-and-control-flow",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#simd-and-control-flow",
    "title": "GPU Compilers",
    "section": "simd and control flow",
    "text": "simd and control flow\nto execute an if then else\n\ncompute the if condition\nturn off the lanes where the condition is false\nexecute the if side\nflip the lanes\nexecute the else side\n\ntime is the sum of the times for then and the else"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#number-of-warps-in-flight",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#number-of-warps-in-flight",
    "title": "GPU Compilers",
    "section": "number of warps in flight",
    "text": "number of warps in flight\nsince an entire block has to fit on one compute unit/sm, the resources used in the block limit the number of warps on a sm,\nif a warp needs 100 registers and there are 256 vector registers on the compute unit, then two warps can run at once, compiler controls number of registers"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#latency",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#latency",
    "title": "GPU Compilers",
    "section": "latency",
    "text": "latency\ngpu is a throughput machine- how many threads finish in a unit of time not how long a single thread takes to finish\nunlike the cpu, gpu can have lots of loads in flight, time for these loads overlap so compiler tries to group loads together, but this needs extra registers\n\na warp issues a group of loads\nwarp issues a wait for loads to finish (hardware in cpu, software in gpu)\nhardware switches to another warp (if there is on), good to have a lot of warps 1, if all warps waiting for memory, alu units are idle"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#compiler-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#compiler-model",
    "title": "GPU Compilers",
    "section": "compiler model",
    "text": "compiler model\n\nlike a regular compiler for a scalar machine\nnew problem: registers used in warp limits number of warps in flight, so ra is different\nnew problem: control flow is more critical\nnew problem: latency means grouping loads but not to much\nnew problem: arch keeps changing"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-coarsening",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-coarsening",
    "title": "GPU Compilers",
    "section": "thread coarsening",
    "text": "thread coarsening\nSuppose we are computing a matrix multiply\nwe could say each thread writes one result so a 32 x 32 matrix would need 32 * 32 threads each thread reads one column and one row of the input,\nwe have a lot of reuse (redundant loads of data )\nwe could say each thread writes 4 results, so we need 1/4 of the threads each thread reads a raw and 4 columns"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#technique",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#technique",
    "title": "GPU Compilers",
    "section": "technique",
    "text": "technique\n\nmerge multiple threads so each resulting thread writes multiple outputs\ndo the redundant work once and save in registers\nuse the registers for computing all the outputs\n\nBut\n\nneeds extra registers\nincreased efficiency but reduced parallelism\n\nAfter thread coarsening, computation from merged threads can see each others results"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#doing-this-by-hand",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#doing-this-by-hand",
    "title": "GPU Compilers",
    "section": "doing this by hand",
    "text": "doing this by hand\nfor (atomid=0; atomid&lt;numatoms; atomid++) { \n  float dy = coory - atominfo[atomid].y; \n  float dysqpdzsq = (dy * dy) + atominfo[atomid].z; \n  float dx1 = coorx1 - atominfo[atomid].x; \n  float dx2 = coorx2 - atominfo[atomid].x; \n  float dx3 = coorx3 - atominfo[atomid].x; \n  float dx4 = coorx4 - atominfo[atomid].x; \n  energyvalx1 += atominfo[atomid].w * (1.0f / sqrtf(dx1*dx1 + dysqpdzsq));\n  energyvalx2 += atominfo[atomid].w * (1.0f / sqrtf(dx2*dx2 + dysqpdzsq)); \n  energyvalx3 += atominfo[atomid].w * (1.0f / sqrtf(dx3*dx3 + dysqpdzsq)); \n  energyvalx4 += atominfo[atomid].w * (1.0f / sqrtf(dx4*dx4 + dysqpdzsq)); } …"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html",
    "href": "lectures/14_gpu_compilers.html",
    "title": "GPU Compilers",
    "section": "",
    "text": "Architectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#challenges-in-learning-about-gpus",
    "href": "lectures/14_gpu_compilers.html#challenges-in-learning-about-gpus",
    "title": "GPU Compilers",
    "section": "",
    "text": "Architectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware-styles-nvidia-model",
    "href": "lectures/14_gpu_compilers.html#hardware-styles-nvidia-model",
    "title": "GPU Compilers",
    "section": "hardware styles NVIDIA model",
    "text": "hardware styles NVIDIA model\n\ncompute and graphics parts have same programmable parts, compute leaves out non-programmable features\ngraphics customers pay a tax for the compute instructions\nmore transistors for compute instructions\none big die",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware-styles-amd-model",
    "href": "lectures/14_gpu_compilers.html#hardware-styles-amd-model",
    "title": "GPU Compilers",
    "section": "hardware styles AMD model",
    "text": "hardware styles AMD model\n\ncompute has extra instructions (no tax on graphics customers to support compute)\nchiplet model (great engineering!)\nR series is graphics, C series is compute",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#programming-model",
    "href": "lectures/14_gpu_compilers.html#programming-model",
    "title": "GPU Compilers",
    "section": "programming model",
    "text": "programming model\nboth vendors use the CUDA programming model. AMD supports a variation of the CUDA language\nmachines have multiple SIMD processors, each SIMD can be running a different instruction but each lane of a SIMD runs the same instruction\na lane of a SIMD is called a thread\n\nthe programming model is SIMT (single instruction multiple threads)\nUser writes a scalar program, compiler maps that program to a lane of a SIMD, many instances of the program run at once, hardware combines copies of the scalar program into warps, hardware schedules warps into the SIMD engines\nprograms are called kernels",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#threading-model",
    "href": "lectures/14_gpu_compilers.html#threading-model",
    "title": "GPU Compilers",
    "section": "threading model",
    "text": "threading model",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#warps-waveswavefronts",
    "href": "lectures/14_gpu_compilers.html#warps-waveswavefronts",
    "title": "GPU Compilers",
    "section": "warps/ waves/wavefronts",
    "text": "warps/ waves/wavefronts\n\nthreads are grouped together into warps.\nSize is fixed by hardware (usually 32), programmers know this and often make data set sizes a multiple of 32.\nsince all threads in a warp are running the same instruction, there is no need for explicit synchronization\nthere are a few instructions that work across a warp, - which break the model and give the compiler problems",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#thread-blocks-groups-of-warps",
    "href": "lectures/14_gpu_compilers.html#thread-blocks-groups-of-warps",
    "title": "GPU Compilers",
    "section": "thread blocks groups of warps,",
    "text": "thread blocks groups of warps,\n\nthreads within a block can access a fast scratchpad memory (called shared or LDS) - Violates the C memory model.\n\nthreads are identified by a 3d index inside a block\nthread blocks need synchronization operations.\n\nhardware schedules each block into execution units. Max block size is limited by the size of a execution unit.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#grid-groups-of-blocks",
    "href": "lectures/14_gpu_compilers.html#grid-groups-of-blocks",
    "title": "GPU Compilers",
    "section": "grid groups of blocks,",
    "text": "grid groups of blocks,\n\n3d collection of blocks,\nusually hardware limits mean that all the threads in a grid do not run at the same time\nprogrammers need to make grids big enough to fill the hardware\nsoftware launches a grid and a program\nthreads within a grid but in different blocks do not have sync operations",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#heterogeneous-programming",
    "href": "lectures/14_gpu_compilers.html#heterogeneous-programming",
    "title": "GPU Compilers",
    "section": "Heterogeneous programming",
    "text": "Heterogeneous programming\nthe cpu is called the host\nthe gpu is called the device\ncpu launches grids and kernels to gpu\nComputations launched on the device execute asynchronously with respect to the host, and it is the user’s responsibility to synchronize",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#memory-spaces",
    "href": "lectures/14_gpu_compilers.html#memory-spaces",
    "title": "GPU Compilers",
    "section": "memory spaces",
    "text": "memory spaces\n\ncpu and gpu have different memory spaces (cpu can copy from one to the other). Some amount of combined memory (slower the not combined)\ngpu has shared/lds memory which can be accessed by threads within a block, passing an address to a different block does not work\nmain gpu memory is called global accessible by all threads\ngpu has per thread memory called local or scratch ot private memory - unlike C, passing an address in local memory to another thread does not work. (under some restrictions AMD implements part of the C memory model)\na few special gpu memory types: constant, texture, surface (left over from graphics)\ngpu can treat registers as fast memory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware",
    "href": "lectures/14_gpu_compilers.html#hardware",
    "title": "GPU Compilers",
    "section": "Hardware",
    "text": "Hardware\nNVIDIA\n\n\n\nnv image level 0\n\n\nEach box here is hardware, an int32/fp32/fp64 can perform one operation, so here we have 32 fp32 units which can do 32 float operations in parallel as well as 16 int32 and 16 fp64 units , there are also 8 units can do loads or stores and a final special function unit that can do transcendental operations like sin/cos\nunder some conditions two instructions (a float and an int) from the same warp can execute at the same time\nI’m not going to talk much about the tensor cores\nall these units execute the same instruction (SIMT) Simple instruction multiple thread (not the same as SIMD but related )",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#one-instruction-does-vector-work",
    "href": "lectures/14_gpu_compilers.html#one-instruction-does-vector-work",
    "title": "GPU Compilers",
    "section": "one instruction does vector work",
    "text": "one instruction does vector work\nadd 32 float32 values (all coming from registers) and store the result in 32 other registers\nNotice no branch prediction, no out of order execution\ngreat at switching a warp holds the instruction, it knows which registers it owns (continuous set, so it just needs a start and length) switching to a different warp, means changing these two numbers and the pc (this is done by the dispatch unt )\nWhen we do a load, we need to wait for the result. CPU might do some kind of out of order execution, a gpu switches to another warp\nfinally we need to pick the warp to switch to, this is done by the warp scheduler (half of the hardware scheduler)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#streaming-multiprocessors-sm",
    "href": "lectures/14_gpu_compilers.html#streaming-multiprocessors-sm",
    "title": "GPU Compilers",
    "section": "streaming multiprocessors (SM)",
    "text": "streaming multiprocessors (SM)\nnvidia packs 4 execution engines into a SM (streaming multi-processor) ands an L1 instruction cache, a special memory accelerator for tensors and 256kb l1 data cache/ shared memory block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#pack-sms-together",
    "href": "lectures/14_gpu_compilers.html#pack-sms-together",
    "title": "GPU Compilers",
    "section": "pack sm’s together",
    "text": "pack sm’s together",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#amd",
    "href": "lectures/14_gpu_compilers.html#amd",
    "title": "GPU Compilers",
    "section": "AMD",
    "text": "AMD",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#and",
    "href": "lectures/14_gpu_compilers.html#and",
    "title": "GPU Compilers",
    "section": "and",
    "text": "and\n\nAMD has a similar block with some important differences\n\nAt the bottom of a compute core there are 4 general purpose simd engines each of length 16 and one scalar engine\n\nGiven 5 waves, this compute core can execute 4 vector instructions and one scalar instruction per clock Two instructions from the same wave never execute at the same time\nThe SIMD engines can execute different instructions\nThe simd sizes vary over different chips",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#amd-cdna",
    "href": "lectures/14_gpu_compilers.html#amd-cdna",
    "title": "GPU Compilers",
    "section": "amd CDNA",
    "text": "amd CDNA",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#packing-sms",
    "href": "lectures/14_gpu_compilers.html#packing-sms",
    "title": "GPU Compilers",
    "section": "packing sms",
    "text": "packing sms",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#simd-and-control-flow",
    "href": "lectures/14_gpu_compilers.html#simd-and-control-flow",
    "title": "GPU Compilers",
    "section": "simd and control flow",
    "text": "simd and control flow\nto execute an if then else\n\ncompute the if condition\nturn off the lanes where the condition is false\nexecute the if side\nflip the lanes\nexecute the else side\n\ntime is the sum of the times for then and the else",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#number-of-warps-in-flight",
    "href": "lectures/14_gpu_compilers.html#number-of-warps-in-flight",
    "title": "GPU Compilers",
    "section": "number of warps in flight",
    "text": "number of warps in flight\nsince an entire block has to fit on one compute unit/sm, the resources used in the block limit the number of warps on a sm,\nif a warp needs 100 registers and there are 256 vector registers on the compute unit, then two warps can run at once, compiler controls number of registers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#latency",
    "href": "lectures/14_gpu_compilers.html#latency",
    "title": "GPU Compilers",
    "section": "latency",
    "text": "latency\ngpu is a throughput machine- how many threads finish in a unit of time not how long a single thread takes to finish\nunlike the cpu, gpu can have lots of loads in flight, time for these loads overlap so compiler tries to group loads together, but this needs extra registers\n\na warp issues a group of loads\nwarp issues a wait for loads to finish (hardware in cpu, software in gpu)\nhardware switches to another warp (if there is on), good to have a lot of warps 1, if all warps waiting for memory, alu units are idle",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#compiler-model",
    "href": "lectures/14_gpu_compilers.html#compiler-model",
    "title": "GPU Compilers",
    "section": "compiler model",
    "text": "compiler model\n\nlike a regular compiler for a scalar machine\nnew problem: registers used in warp limits number of warps in flight, so ra is different\nnew problem: control flow is more critical\nnew problem: latency means grouping loads but not to much\nnew problem: arch keeps changing",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#thread-coarsening",
    "href": "lectures/14_gpu_compilers.html#thread-coarsening",
    "title": "GPU Compilers",
    "section": "thread coarsening",
    "text": "thread coarsening\nSuppose we are computing a matrix multiply\nwe could say each thread writes one result so a 32 x 32 matrix would need 32 * 32 threads each thread reads one column and one row of the input,\nwe have a lot of reuse (redundant loads of data )\nwe could say each thread writes 4 results, so we need 1/4 of the threads each thread reads a raw and 4 columns",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#technique",
    "href": "lectures/14_gpu_compilers.html#technique",
    "title": "GPU Compilers",
    "section": "technique",
    "text": "technique\n\nmerge multiple threads so each resulting thread writes multiple outputs\ndo the redundant work once and save in registers\nuse the registers for computing all the outputs\n\nBut\n\nneeds extra registers\nincreased efficiency but reduced parallelism\n\nAfter thread coarsening, computation from merged threads can see each others results",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#doing-this-by-hand",
    "href": "lectures/14_gpu_compilers.html#doing-this-by-hand",
    "title": "GPU Compilers",
    "section": "doing this by hand",
    "text": "doing this by hand\nfor (atomid=0; atomid&lt;numatoms; atomid++) { \n  float dy = coory - atominfo[atomid].y; \n  float dysqpdzsq = (dy * dy) + atominfo[atomid].z; \n  float dx1 = coorx1 - atominfo[atomid].x; \n  float dx2 = coorx2 - atominfo[atomid].x; \n  float dx3 = coorx3 - atominfo[atomid].x; \n  float dx4 = coorx4 - atominfo[atomid].x; \n  energyvalx1 += atominfo[atomid].w * (1.0f / sqrtf(dx1*dx1 + dysqpdzsq));\n  energyvalx2 += atominfo[atomid].w * (1.0f / sqrtf(dx2*dx2 + dysqpdzsq)); \n  energyvalx3 += atominfo[atomid].w * (1.0f / sqrtf(dx3*dx3 + dysqpdzsq)); \n  energyvalx4 += atominfo[atomid].w * (1.0f / sqrtf(dx4*dx4 + dysqpdzsq)); } …",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/110_whole_program.html",
    "href": "lectures/110_whole_program.html",
    "title": "11 Whole program",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "11 Whole program"
    ]
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#mlir-multi-level-intermediate-representation",
    "href": "lectures/revealjs_mlir.qmd.html#mlir-multi-level-intermediate-representation",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "MLIR: Multi-Level Intermediate Representation",
    "text": "MLIR: Multi-Level Intermediate Representation\nMLIR (Multi-Level Intermediate Representation) was introduced by Google in April 2019 and is designed to serve as an IR from the outset. It provides various forms:"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#high-level-form",
    "href": "lectures/revealjs_mlir.qmd.html#high-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "High-level form",
    "text": "High-level form\nOps (general purpose to domain speciﬁc) on tensor types / memref types\n%patches = \"tf.reshape\"(%patches, %minus_one, %minor_dim_size)\n: (tensor&lt;? x ? x ? x ? x f32&gt;, index, index) −&gt; tensor&lt;? x ? x f32&gt;\n%mat_out = \"tf.matmul\"(%patches_ﬂat, %patches_ﬂat){transpose_a : true}\n: (tensor&lt;? x ? x f32&gt;, tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x ?\nx f32&gt;\n%vec_out = \"tf.reduce_sum\"(%patches_ﬂat) {axis: 0}\n: (tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x f32&gt;"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#loop-level-mid-level-form",
    "href": "lectures/revealjs_mlir.qmd.html#loop-level-mid-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Loop-level / mid-level form",
    "text": "Loop-level / mid-level form\naffine.for %i = 0 to 8 step 4 {\n  affine.for %j = 0 to 8 step 4 {\n    %5 = affine.load %arg0[%ii, %kk] : memref&lt;8x8xvector&lt;64xf32&gt;&gt;\n  }\n}"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#low-level-form-closer-to-hardware",
    "href": "lectures/revealjs_mlir.qmd.html#low-level-form-closer-to-hardware",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Low-level form: closer to hardware",
    "text": "Low-level form: closer to hardware\n%v1 = load %a[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;\n%v3 = addf %v1, %v2 : vector&lt;16xf32&gt;\nstore %v3, %d[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#design-principles",
    "href": "lectures/revealjs_mlir.qmd.html#design-principles",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Design principles",
    "text": "Design principles\n\nTextual format\nAbility to represent code at multiple levels\nUniﬁed representation for all the levels\nFirst class abstractions for multi-dimensional arrays (tensors), loop nests, and more\nVery ﬂexible, extensible"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#concepts",
    "href": "lectures/revealjs_mlir.qmd.html#concepts",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "concepts",
    "text": "concepts\n\nSSA, typed\nModule/Function/Block/Operation structure\nOperations can hold a “region” (a list of blocks)\n\nno phi nodes, basic blocks take arguments\n~~~{plaintext} func @condbr_simple() -&gt; (i32) { %cond = “foo”() : () -&gt; i1 %a = “bar”() : () -&gt; i32 %b = “bar”() : () -&gt; i64\n^bb1(%x : i32): %w = “foo_bar”(%x) : (i32) -&gt; i64 br ^bb2(%w: i64)\n^bb2(%y : i64): %z = “abc”(%y) : (i64) -&gt; i32 return %z : i32\n} ~~~"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#operations",
    "href": "lectures/revealjs_mlir.qmd.html#operations",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "operations",
    "text": "operations\n\nalways have a name and source location\narbitrary number of ssa operands and results\nattributes - constant values\nregions"
  },
  {
    "objectID": "lectures/mlir.html",
    "href": "lectures/mlir.html",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "",
    "text": "#html: default",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#mlir-multi-level-intermediate-representation",
    "href": "lectures/mlir.html#mlir-multi-level-intermediate-representation",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "MLIR: Multi-Level Intermediate Representation",
    "text": "MLIR: Multi-Level Intermediate Representation\nMLIR (Multi-Level Intermediate Representation) was introduced by Google in April 2019 and is designed to serve as an IR from the outset. It provides various forms:",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#high-level-form",
    "href": "lectures/mlir.html#high-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "High-level form",
    "text": "High-level form\nOps (general purpose to domain speciﬁc) on tensor types / memref types\n%patches = \"tf.reshape\"(%patches, %minus_one, %minor_dim_size)\n: (tensor&lt;? x ? x ? x ? x f32&gt;, index, index) −&gt; tensor&lt;? x ? x f32&gt;\n%mat_out = \"tf.matmul\"(%patches_ﬂat, %patches_ﬂat){transpose_a : true}\n: (tensor&lt;? x ? x f32&gt;, tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x ?\nx f32&gt;\n%vec_out = \"tf.reduce_sum\"(%patches_ﬂat) {axis: 0}\n: (tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x f32&gt;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#loop-level-mid-level-form",
    "href": "lectures/mlir.html#loop-level-mid-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Loop-level / mid-level form",
    "text": "Loop-level / mid-level form\naffine.for %i = 0 to 8 step 4 {\n  affine.for %j = 0 to 8 step 4 {\n    %5 = affine.load %arg0[%ii, %kk] : memref&lt;8x8xvector&lt;64xf32&gt;&gt;\n  }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#low-level-form-closer-to-hardware",
    "href": "lectures/mlir.html#low-level-form-closer-to-hardware",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Low-level form: closer to hardware",
    "text": "Low-level form: closer to hardware\n%v1 = load %a[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;\n%v3 = addf %v1, %v2 : vector&lt;16xf32&gt;\nstore %v3, %d[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#design-principles",
    "href": "lectures/mlir.html#design-principles",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Design principles",
    "text": "Design principles\n\nTextual format\nAbility to represent code at multiple levels\nUniﬁed representation for all the levels\nFirst class abstractions for multi-dimensional arrays (tensors), loop nests, and more\nVery ﬂexible, extensible",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#concepts",
    "href": "lectures/mlir.html#concepts",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "concepts",
    "text": "concepts\n\nSSA, typed\nModule/Function/Block/Operation structure\nOperations can hold a “region” (a list of blocks)\n\nno phi nodes, basic blocks take arguments\n~~~{plaintext} func @condbr_simple() -&gt; (i32) { %cond = “foo”() : () -&gt; i1 %a = “bar”() : () -&gt; i32 %b = “bar”() : () -&gt; i64\n^bb1(%x : i32): %w = “foo_bar”(%x) : (i32) -&gt; i64 br ^bb2(%w: i64)\n^bb2(%y : i64): %z = “abc”(%y) : (i64) -&gt; i32 return %z : i32\n} ~~~",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#operations",
    "href": "lectures/mlir.html#operations",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "operations",
    "text": "operations\n\nalways have a name and source location\narbitrary number of ssa operands and results\nattributes - constant values\nregions",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#example-1",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#example-1",
    "title": "Performance and Measurement",
    "section": "example 1",
    "text": "example 1\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#another-example",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#another-example",
    "title": "Performance and Measurement",
    "section": "another example",
    "text": "another example\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#violin-plots",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#violin-plots",
    "title": "Performance and Measurement",
    "section": "violin plots",
    "text": "violin plots\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n\nCode\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#error-bars",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#error-bars",
    "title": "Performance and Measurement",
    "section": "error bars",
    "text": "error bars\n\n\nCode\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000"
  },
  {
    "objectID": "lectures/01a_performance_measurement.html",
    "href": "lectures/01a_performance_measurement.html",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog\n\n\n\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\n\n\n\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.\n\n\n\n\n\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#example-1",
    "href": "lectures/01a_performance_measurement.html#example-1",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#another-example",
    "href": "lectures/01a_performance_measurement.html#another-example",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Strangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#violin-plots",
    "href": "lectures/01a_performance_measurement.html#violin-plots",
    "title": "Performance and Measurement",
    "section": "",
    "text": "data\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#error-bars",
    "href": "lectures/01a_performance_measurement.html#error-bars",
    "title": "Performance and Measurement",
    "section": "",
    "text": "print(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#licm",
    "href": "lectures/revealjs_05b_licm.qmd.html#licm",
    "title": "loop invariant code motion",
    "section": "licm",
    "text": "licm\nLoop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop."
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#a-very-common-case-for-this-is-matrix-addressing",
    "href": "lectures/revealjs_05b_licm.qmd.html#a-very-common-case-for-this-is-matrix-addressing",
    "title": "loop invariant code motion",
    "section": "A very common case for this is matrix addressing",
    "text": "A very common case for this is matrix addressing\na[i,j] might expand to to \\(i*4*\\operatorname{stride_{a}} + j *4\\)\nfor j \n  a[i,j] = f(a[i,j+1])\nturns into\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant",
    "href": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\nf(a,b)\n\na,b are constants\na,b are defined outside the loop,\na,b are loop invariant\n\nif in ssa there is only one reaching def\nfor non ssa, we need\n\nall reaching defs of a,b defined outside of the loop\nonly one def of a,b reaches the computation and that def is loop invariant"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant-1",
    "href": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant-1",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\na defined outside of the loop (need one definition or ssa )\n\nb = a*2 \n\nd = 5 + b is loop invariant if b\nIn ssa a variable is loop invariant if it does not have a phi function at the loop of the loop, or it is defined by a phi function and all the inputs come from outside of the loop\nSSA If we find a loop-invariant computation in SSA form, then we just move it out of the loop to a block before the loop. When moving a (side effect-free) SSA loop-invariant computation to a previous position, nothing can go wrong, because the value it computes cannot be overwritten later and the values it depends on cannot have been changed"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#pre-steps---reshape-the-cfg",
    "href": "lectures/revealjs_05b_licm.qmd.html#pre-steps---reshape-the-cfg",
    "title": "loop invariant code motion",
    "section": "pre steps - reshape the cfg",
    "text": "pre steps - reshape the cfg\n\nfind the natural loops\nadd pre-header\n\nif we are going to move code we often need to add a special basic block which is called a landing pad or a a pre-header create a new block b. change all the preds of the loop header to point to the pre-header, add an edge from b to the loop header"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#pre-header-can-change-phi-nodes",
    "href": "lectures/revealjs_05b_licm.qmd.html#pre-header-can-change-phi-nodes",
    "title": "loop invariant code motion",
    "section": "pre-header can change phi nodes",
    "text": "pre-header can change phi nodes\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "href": "lectures/revealjs_05b_licm.qmd.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "title": "loop invariant code motion",
    "section": "while loop may not execute, we can restructure into a do-while",
    "text": "while loop may not execute, we can restructure into a do-while\n\n\nwhile(e) {\n  s(j) \n}\n\nif (e) {\n  t  = j loopinv \n  do {\n    s\n  } while(e)\n}"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#check-for-zero-trip-count",
    "href": "lectures/revealjs_05b_licm.qmd.html#check-for-zero-trip-count",
    "title": "loop invariant code motion",
    "section": "check for zero trip count",
    "text": "check for zero trip count\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#when-is-ok-to-move-a-computation",
    "href": "lectures/revealjs_05b_licm.qmd.html#when-is-ok-to-move-a-computation",
    "title": "loop invariant code motion",
    "section": "when is ok to move a computation",
    "text": "when is ok to move a computation\n\nno side effects - cannot move alloc 10 outside of loop;\nin non ssa, computation d dominates all loop exits where d is live\nin non ssa only one def of d in the loop\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#find-loop-invariant-instructions",
    "href": "lectures/revealjs_05b_licm.qmd.html#find-loop-invariant-instructions",
    "title": "loop invariant code motion",
    "section": "find loop invariant instructions,",
    "text": "find loop invariant instructions,"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#naturally-iterative",
    "href": "lectures/revealjs_05b_licm.qmd.html#naturally-iterative",
    "title": "loop invariant code motion",
    "section": "naturally iterative",
    "text": "naturally iterative\niterate to convergence\n for each instr in  the loop\n   see if it is loop invar \n   if it is - move it"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#nested-loops",
    "href": "lectures/revealjs_05b_licm.qmd.html#nested-loops",
    "title": "loop invariant code motion",
    "section": "nested loops",
    "text": "nested loops\nwe want to process inner loops first\n\nadd all the pre-headers\nwalk the dominator tree in reverse post order - saving all the loop headers"
  },
  {
    "objectID": "lectures/05b_licm.html",
    "href": "lectures/05b_licm.html",
    "title": "loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#licm",
    "href": "lectures/05b_licm.html#licm",
    "title": "loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#a-very-common-case-for-this-is-matrix-addressing",
    "href": "lectures/05b_licm.html#a-very-common-case-for-this-is-matrix-addressing",
    "title": "loop invariant code motion",
    "section": "A very common case for this is matrix addressing",
    "text": "A very common case for this is matrix addressing\na[i,j] might expand to to \\(i*4*\\operatorname{stride_{a}} + j *4\\)\nfor j \n  a[i,j] = f(a[i,j+1])\nturns into\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#when-is-a-computation-loop-invariant",
    "href": "lectures/05b_licm.html#when-is-a-computation-loop-invariant",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\nf(a,b)\n\na,b are constants\na,b are defined outside the loop,\na,b are loop invariant\n\nif in ssa there is only one reaching def\nfor non ssa, we need\n\nall reaching defs of a,b defined outside of the loop\nonly one def of a,b reaches the computation and that def is loop invariant",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#when-is-a-computation-loop-invariant-1",
    "href": "lectures/05b_licm.html#when-is-a-computation-loop-invariant-1",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\na defined outside of the loop (need one definition or ssa )\n\nb = a*2 \n\nd = 5 + b is loop invariant if b\nIn ssa a variable is loop invariant if it does not have a phi function at the loop of the loop, or it is defined by a phi function and all the inputs come from outside of the loop\nSSA If we find a loop-invariant computation in SSA form, then we just move it out of the loop to a block before the loop. When moving a (side effect-free) SSA loop-invariant computation to a previous position, nothing can go wrong, because the value it computes cannot be overwritten later and the values it depends on cannot have been changed",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#pre-steps---reshape-the-cfg",
    "href": "lectures/05b_licm.html#pre-steps---reshape-the-cfg",
    "title": "loop invariant code motion",
    "section": "pre steps - reshape the cfg",
    "text": "pre steps - reshape the cfg\n\nfind the natural loops\nadd pre-header\n\nif we are going to move code we often need to add a special basic block which is called a landing pad or a a pre-header create a new block b. change all the preds of the loop header to point to the pre-header, add an edge from b to the loop header",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#pre-header-can-change-phi-nodes",
    "href": "lectures/05b_licm.html#pre-header-can-change-phi-nodes",
    "title": "loop invariant code motion",
    "section": "pre-header can change phi nodes",
    "text": "pre-header can change phi nodes\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "href": "lectures/05b_licm.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "title": "loop invariant code motion",
    "section": "while loop may not execute, we can restructure into a do-while",
    "text": "while loop may not execute, we can restructure into a do-while\n\n\nwhile(e) {\n  s(j) \n}\n\nif (e) {\n  t  = j loopinv \n  do {\n    s\n  } while(e)\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#check-for-zero-trip-count",
    "href": "lectures/05b_licm.html#check-for-zero-trip-count",
    "title": "loop invariant code motion",
    "section": "check for zero trip count",
    "text": "check for zero trip count\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#when-is-ok-to-move-a-computation",
    "href": "lectures/05b_licm.html#when-is-ok-to-move-a-computation",
    "title": "loop invariant code motion",
    "section": "when is ok to move a computation",
    "text": "when is ok to move a computation\n\nno side effects - cannot move alloc 10 outside of loop;\nin non ssa, computation d dominates all loop exits where d is live\nin non ssa only one def of d in the loop\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#find-loop-invariant-instructions",
    "href": "lectures/05b_licm.html#find-loop-invariant-instructions",
    "title": "loop invariant code motion",
    "section": "find loop invariant instructions,",
    "text": "find loop invariant instructions,",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#naturally-iterative",
    "href": "lectures/05b_licm.html#naturally-iterative",
    "title": "loop invariant code motion",
    "section": "naturally iterative",
    "text": "naturally iterative\niterate to convergence\n for each instr in  the loop\n   see if it is loop invar \n   if it is - move it",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#nested-loops",
    "href": "lectures/05b_licm.html#nested-loops",
    "title": "loop invariant code motion",
    "section": "nested loops",
    "text": "nested loops\nwe want to process inner loops first\n\nadd all the pre-headers\nwalk the dominator tree in reverse post order - saving all the loop headers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/revealjs_01a2_performance_measurement.qmd.html#another-example",
    "href": "lectures/revealjs_01a2_performance_measurement.qmd.html#another-example",
    "title": "Performance and Measurement part 2",
    "section": "another example",
    "text": "another example\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\nchecklist\nHere are the criteria by Berger, Blackburn, Hauswirth, and Hicks (2018):\n\nClearly stated claims\n\nExplicit Claims\nAppropriately-Scoped Claims\nAcknowledges Limitations\n\nSuitable Comparison\n\nAppropriate Baseline for Comparison\nFair Comparison\n\nPrincipled Benchmark Choice\n\nAppropriate Suite\nNon-Standard Suite(s) Justified\nApplications, Not (Just) Kernels\n\nAdequate Data Analysis\n\nSufficient Number of Trials\nAppropriate Summary Statistics\nReport Data Distribution\n\nRelevant Metrics\n\nDirect or Appropriate Proxy Metric\nMeasures All Important Effects\n\nAppropriate and Clear Experimental Design\n\nSufficient Information to Repeat\nReasonable Platform\nExplores Key Design Parameters\nOpen Loop in Workload Generator\nCross-Validation Where Needed\n\nPresentation of Results\n\nComprehensive Summary Results\nAxes Include Zero\nRatios Plotted Correctly\nAppropriate Level of Precision"
  },
  {
    "objectID": "lectures/01a2_performance_measurement.html",
    "href": "lectures/01a2_performance_measurement.html",
    "title": "Performance and Measurement part 2",
    "section": "",
    "text": "last time we looked at\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog\n\n\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\nchecklist\nHere are the criteria by Berger, Blackburn, Hauswirth, and Hicks (2018):\n\nClearly stated claims\n\nExplicit Claims\nAppropriately-Scoped Claims\nAcknowledges Limitations\n\nSuitable Comparison\n\nAppropriate Baseline for Comparison\nFair Comparison\n\nPrincipled Benchmark Choice\n\nAppropriate Suite\nNon-Standard Suite(s) Justified\nApplications, Not (Just) Kernels\n\nAdequate Data Analysis\n\nSufficient Number of Trials\nAppropriate Summary Statistics\nReport Data Distribution\n\nRelevant Metrics\n\nDirect or Appropriate Proxy Metric\nMeasures All Important Effects\n\nAppropriate and Clear Experimental Design\n\nSufficient Information to Repeat\nReasonable Platform\nExplores Key Design Parameters\nOpen Loop in Workload Generator\nCross-Validation Where Needed\n\nPresentation of Results\n\nComprehensive Summary Results\nAxes Include Zero\nRatios Plotted Correctly\nAppropriate Level of Precision",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 2"
    ]
  },
  {
    "objectID": "lectures/01a2_performance_measurement.html#another-example",
    "href": "lectures/01a2_performance_measurement.html#another-example",
    "title": "Performance and Measurement part 2",
    "section": "",
    "text": "Strangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\nchecklist\nHere are the criteria by Berger, Blackburn, Hauswirth, and Hicks (2018):\n\nClearly stated claims\n\nExplicit Claims\nAppropriately-Scoped Claims\nAcknowledges Limitations\n\nSuitable Comparison\n\nAppropriate Baseline for Comparison\nFair Comparison\n\nPrincipled Benchmark Choice\n\nAppropriate Suite\nNon-Standard Suite(s) Justified\nApplications, Not (Just) Kernels\n\nAdequate Data Analysis\n\nSufficient Number of Trials\nAppropriate Summary Statistics\nReport Data Distribution\n\nRelevant Metrics\n\nDirect or Appropriate Proxy Metric\nMeasures All Important Effects\n\nAppropriate and Clear Experimental Design\n\nSufficient Information to Repeat\nReasonable Platform\nExplores Key Design Parameters\nOpen Loop in Workload Generator\nCross-Validation Where Needed\n\nPresentation of Results\n\nComprehensive Summary Results\nAxes Include Zero\nRatios Plotted Correctly\nAppropriate Level of Precision",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 2"
    ]
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#graph-properties",
    "href": "lectures/revealjs_05_global.qmd.html#graph-properties",
    "title": "5 Global Analysis",
    "section": "Graph Properties",
    "text": "Graph Properties\nWe are going to define assorted graph properties, that can be calculated on cfgs."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominators",
    "href": "lectures/revealjs_05_global.qmd.html#dominators",
    "title": "5 Global Analysis",
    "section": "dominators",
    "text": "dominators\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominator-trees",
    "href": "lectures/revealjs_05_global.qmd.html#dominator-trees",
    "title": "5 Global Analysis",
    "section": "dominator trees",
    "text": "dominator trees\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#an-example",
    "href": "lectures/revealjs_05_global.qmd.html#an-example",
    "title": "5 Global Analysis",
    "section": "an example",
    "text": "an example\n\n\nA control flow graph\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\n\nThe dominator tree\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#simple-implementation-dominators",
    "href": "lectures/revealjs_05_global.qmd.html#simple-implementation-dominators",
    "title": "5 Global Analysis",
    "section": "simple implementation dominators",
    "text": "simple implementation dominators\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#pseudo-code",
    "href": "lectures/revealjs_05_global.qmd.html#pseudo-code",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nassume nodes start at 0,\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#how-do-we-implement-this",
    "href": "lectures/revealjs_05_global.qmd.html#how-do-we-implement-this",
    "title": "5 Global Analysis",
    "section": "How do we implement this",
    "text": "How do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#a-faster-way",
    "href": "lectures/revealjs_05_global.qmd.html#a-faster-way",
    "title": "5 Global Analysis",
    "section": "a faster way",
    "text": "a faster way\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, (the dominator)"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#a-more-complex-example",
    "href": "lectures/revealjs_05_global.qmd.html#a-more-complex-example",
    "title": "5 Global Analysis",
    "section": "a more complex example",
    "text": "a more complex example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n\nneed n4 and n8\n\nboth are dominated by n0"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "href": "lectures/revealjs_05_global.qmd.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "title": "5 Global Analysis",
    "section": "subproblem: find lowest common ancestor in dt of two nodes a and b",
    "text": "subproblem: find lowest common ancestor in dt of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower keep the nodes in post order, nodes at the top of the cfg have higher numbers"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#part1",
    "href": "lectures/revealjs_05_global.qmd.html#part1",
    "title": "5 Global Analysis",
    "section": "part1",
    "text": "part1\nintersect(b1, b2, idoms,postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#pseudo-code-1",
    "href": "lectures/revealjs_05_global.qmd.html#pseudo-code-1",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse i in postorder) {\n      bb = cffg block i \n      new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n\n      for pred in preds (bb)) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominator-frontiers",
    "href": "lectures/revealjs_05_global.qmd.html#dominator-frontiers",
    "title": "5 Global Analysis",
    "section": "dominator frontiers",
    "text": "dominator frontiers\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5 dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#natural-loops",
    "href": "lectures/revealjs_05_global.qmd.html#natural-loops",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\n\n\nCode\ngraph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#cycle-but-not-header",
    "href": "lectures/revealjs_05_global.qmd.html#cycle-but-not-header",
    "title": "5 Global Analysis",
    "section": "cycle but not header",
    "text": "cycle but not header\nHow about an example that has a cycle and no header\n\n\nCode\ngraph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#natural-loops-1",
    "href": "lectures/revealjs_05_global.qmd.html#natural-loops-1",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\nA back-edge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a back-edge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#example",
    "href": "lectures/revealjs_05_global.qmd.html#example",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\n\n\nBackedges B -&gt; H2,\nB-&gt; H1\n\nfor B-&gt; H2, loop is H2,\nfor B-&gt; H1, loop is H1, A, H2, B"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#reducible-control-flow",
    "href": "lectures/revealjs_05_global.qmd.html#reducible-control-flow",
    "title": "5 Global Analysis",
    "section": "reducible control flow",
    "text": "reducible control flow\nin a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#what-is-the-surface-version",
    "href": "lectures/revealjs_05_global.qmd.html#what-is-the-surface-version",
    "title": "5 Global Analysis",
    "section": "what is the surface version",
    "text": "what is the surface version\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#t1-and-t2-transforms",
    "href": "lectures/revealjs_05_global.qmd.html#t1-and-t2-transforms",
    "title": "5 Global Analysis",
    "section": "t1 and t2 transforms",
    "text": "t1 and t2 transforms\nLet G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1: on node n is removal of this self-loop.\nLet n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node.\ntransformation T2: on node pair (n1,n2) is merging nodes n1 and n2 into one node,"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#t1-t2",
    "href": "lectures/revealjs_05_global.qmd.html#t1-t2",
    "title": "5 Global Analysis",
    "section": "t1 / t2",
    "text": "t1 / t2\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#example-1",
    "href": "lectures/revealjs_05_global.qmd.html#example-1",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#simplified-control-flow",
    "href": "lectures/revealjs_05_global.qmd.html#simplified-control-flow",
    "title": "5 Global Analysis",
    "section": "simplified control flow",
    "text": "simplified control flow\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\nnot reducible"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#other-optimizations-interactions",
    "href": "lectures/revealjs_05_global.qmd.html#other-optimizations-interactions",
    "title": "5 Global Analysis",
    "section": "other optimizations interactions",
    "text": "other optimizations interactions\nloop: if (cond) goto past_loop\n    s1\n    call bar()\n    goto loop\npastloop:\n\nfunction bar()\n    b1 \n    if () return\n    b2"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#inline-the-function-combine-jmps-to-jmps",
    "href": "lectures/revealjs_05_global.qmd.html#inline-the-function-combine-jmps-to-jmps",
    "title": "5 Global Analysis",
    "section": "inline the function, combine jmps to jmps",
    "text": "inline the function, combine jmps to jmps\n\n\nloop: if (cond) goto past_loop\n    s1\n    b1\n    if () go to next\n    b2\n    next:\ngoto loop\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n\n\nNow we have two back edges so two loops"
  },
  {
    "objectID": "lectures/05_global.html",
    "href": "lectures/05_global.html",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#graph-properties",
    "href": "lectures/05_global.html#graph-properties",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#dominators",
    "href": "lectures/05_global.html#dominators",
    "title": "5 Global Analysis",
    "section": "dominators",
    "text": "dominators\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#dominator-trees",
    "href": "lectures/05_global.html#dominator-trees",
    "title": "5 Global Analysis",
    "section": "dominator trees",
    "text": "dominator trees\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#an-example",
    "href": "lectures/05_global.html#an-example",
    "title": "5 Global Analysis",
    "section": "an example",
    "text": "an example\n\n\nA control flow graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\n\nThe dominator tree\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#simple-implementation-dominators",
    "href": "lectures/05_global.html#simple-implementation-dominators",
    "title": "5 Global Analysis",
    "section": "simple implementation dominators",
    "text": "simple implementation dominators\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]\n\nTo find the dominators of a node, first put the node itself in the dominators set. Then, take all the common (i.e. intersection) dominators of its predecessors and put them in the set.\nWhat order do we want to process the nodes?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#pseudo-code",
    "href": "lectures/05_global.html#pseudo-code",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nassume nodes start at 0,\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#how-do-we-implement-this",
    "href": "lectures/05_global.html#how-do-we-implement-this",
    "title": "5 Global Analysis",
    "section": "How do we implement this",
    "text": "How do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#a-faster-way",
    "href": "lectures/05_global.html#a-faster-way",
    "title": "5 Global Analysis",
    "section": "a faster way",
    "text": "a faster way\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, (the dominator)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#a-more-complex-example",
    "href": "lectures/05_global.html#a-more-complex-example",
    "title": "5 Global Analysis",
    "section": "a more complex example",
    "text": "a more complex example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n\nneed n4 and n8\n\nboth are dominated by n0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "href": "lectures/05_global.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "title": "5 Global Analysis",
    "section": "subproblem: find lowest common ancestor in dt of two nodes a and b",
    "text": "subproblem: find lowest common ancestor in dt of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower keep the nodes in post order, nodes at the top of the cfg have higher numbers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#part1",
    "href": "lectures/05_global.html#part1",
    "title": "5 Global Analysis",
    "section": "part1",
    "text": "part1\nintersect(b1, b2, idoms,postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#pseudo-code-1",
    "href": "lectures/05_global.html#pseudo-code-1",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse i in postorder) {\n      bb = cffg block i \n      new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n\n      for pred in preds (bb)) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#dominator-frontiers",
    "href": "lectures/05_global.html#dominator-frontiers",
    "title": "5 Global Analysis",
    "section": "dominator frontiers",
    "text": "dominator frontiers\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5 dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#natural-loops",
    "href": "lectures/05_global.html#natural-loops",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\n\ngraph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#cycle-but-not-header",
    "href": "lectures/05_global.html#cycle-but-not-header",
    "title": "5 Global Analysis",
    "section": "cycle but not header",
    "text": "cycle but not header\nHow about an example that has a cycle and no header\n\ngraph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#natural-loops-1",
    "href": "lectures/05_global.html#natural-loops-1",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\nA back-edge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a back-edge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#example",
    "href": "lectures/05_global.html#example",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\n\n\nBackedges B -&gt; H2,\nB-&gt; H1\n\nfor B-&gt; H2, loop is H2,\nfor B-&gt; H1, loop is H1, A, H2, B",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#reducible-control-flow",
    "href": "lectures/05_global.html#reducible-control-flow",
    "title": "5 Global Analysis",
    "section": "reducible control flow",
    "text": "reducible control flow\nin a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#what-is-the-surface-version",
    "href": "lectures/05_global.html#what-is-the-surface-version",
    "title": "5 Global Analysis",
    "section": "what is the surface version",
    "text": "what is the surface version\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#t1-and-t2-transforms",
    "href": "lectures/05_global.html#t1-and-t2-transforms",
    "title": "5 Global Analysis",
    "section": "t1 and t2 transforms",
    "text": "t1 and t2 transforms\nLet G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1: on node n is removal of this self-loop.\nLet n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node.\ntransformation T2: on node pair (n1,n2) is merging nodes n1 and n2 into one node,",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#t1-t2",
    "href": "lectures/05_global.html#t1-t2",
    "title": "5 Global Analysis",
    "section": "t1 / t2",
    "text": "t1 / t2\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#example-1",
    "href": "lectures/05_global.html#example-1",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#simplified-control-flow",
    "href": "lectures/05_global.html#simplified-control-flow",
    "title": "5 Global Analysis",
    "section": "simplified control flow",
    "text": "simplified control flow\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\nnot reducible",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#other-optimizations-interactions",
    "href": "lectures/05_global.html#other-optimizations-interactions",
    "title": "5 Global Analysis",
    "section": "other optimizations interactions",
    "text": "other optimizations interactions\nloop: if (cond) goto past_loop\n    s1\n    call bar()\n    goto loop\npastloop:\n\nfunction bar()\n    b1 \n    if () return\n    b2",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#inline-the-function-combine-jmps-to-jmps",
    "href": "lectures/05_global.html#inline-the-function-combine-jmps-to-jmps",
    "title": "5 Global Analysis",
    "section": "inline the function, combine jmps to jmps",
    "text": "inline the function, combine jmps to jmps\n\n\nloop: if (cond) goto past_loop\n    s1\n    b1\n    if () go to next\n    b2\n    next:\ngoto loop\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n\n\n\nNow we have two back edges so two loops",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "href": "lectures/revealjs_03_local.qmd.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "title": "Local Analysis & Optimization",
    "section": "reminder hw1 due on Friday- I expected some questions?",
    "text": "reminder hw1 due on Friday- I expected some questions?\nand anyone who forgot hw0, still needed!"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#llvm-control-flow-graph",
    "href": "lectures/revealjs_03_local.qmd.html#llvm-control-flow-graph",
    "title": "Local Analysis & Optimization",
    "section": "llvm control flow graph",
    "text": "llvm control flow graph\ncommands to draw a dot list of a c file from llvm\n clang -S -emit-llvm images/identity.c -o foo.ll \n opt -dot-cfg foo.ll -disable-output -enable-new-pm=0\nvoid identity(int **a, int N)\n{\n    int i, j;\n    for (i = 0; i &lt; N; i++)\n    {\n        for (j = 0; j &lt; N; j++)\n        {\n            a[i][j] = 0;\n        }\n    }\n    for (i = 0; i &lt; N; i++)\n    {\n        a[i][i] = 1;\n    }\n}\n\n\nCode\ndigraph \"CFG for 'identity' function\" {\n    label=\"CFG for 'identity' function\";\n\n    Node0x12c5490 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%2:\\l  %3 = alloca i32**, align 8\\l  %4 = alloca i32, align 4\\l  %5 = alloca i32, align 4\\l  %6 = alloca i32, align 4\\l  store i32** %0, i32*** %3, align 8\\l  store i32 %1, i32* %4, align 4\\l  store i32 0, i32* %5, align 4\\l  br label %7\\l}\"];\n    Node0x12c5490 -&gt; Node0x12c5da0;\n    Node0x12c5da0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%7:\\l7:                                                \\l  %8 = load i32, i32* %5, align 4\\l  %9 = load i32, i32* %4, align 4\\l  %10 = icmp slt i32 %8, %9\\l  br i1 %10, label %11, label %32\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c5da0:s0 -&gt; Node0x12c5c70;\n    Node0x12c5da0:s1 -&gt; Node0x12c5f40;\n    Node0x12c5c70 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%11:\\l11:                                               \\l  store i32 0, i32* %6, align 4\\l  br label %12\\l}\"];\n    Node0x12c5c70 -&gt; Node0x12c6080;\n    Node0x12c6080 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%12:\\l12:                                               \\l  %13 = load i32, i32* %6, align 4\\l  %14 = load i32, i32* %4, align 4\\l  %15 = icmp slt i32 %13, %14\\l  br i1 %15, label %16, label %28\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c6080:s0 -&gt; Node0x12c62b0;\n    Node0x12c6080:s1 -&gt; Node0x12c6300;\n    Node0x12c62b0 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%16:\\l16:                                               \\l  %17 = load i32**, i32*** %3, align 8\\l  %18 = load i32, i32* %5, align 4\\l  %19 = sext i32 %18 to i64\\l  %20 = getelementptr inbounds i32*, i32** %17, i64 %19\\l  %21 = load i32*, i32** %20, align 8\\l  %22 = load i32, i32* %6, align 4\\l  %23 = sext i32 %22 to i64\\l  %24 = getelementptr inbounds i32, i32* %21, i64 %23\\l  store i32 0, i32* %24, align 4\\l  br label %25\\l}\"];\n    Node0x12c62b0 -&gt; Node0x12c6820;\n    Node0x12c6820 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%25:\\l25:                                               \\l  %26 = load i32, i32* %6, align 4\\l  %27 = add nsw i32 %26, 1\\l  store i32 %27, i32* %6, align 4\\l  br label %12, !llvm.loop !6\\l}\"];\n    Node0x12c6820 -&gt; Node0x12c6080;\n    Node0x12c6300 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%28:\\l28:                                               \\l  br label %29\\l}\"];\n    Node0x12c6300 -&gt; Node0x12c75b0;\n    Node0x12c75b0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%29:\\l29:                                               \\l  %30 = load i32, i32* %5, align 4\\l  %31 = add nsw i32 %30, 1\\l  store i32 %31, i32* %5, align 4\\l  br label %7, !llvm.loop !8\\l}\"];\n    Node0x12c75b0 -&gt; Node0x12c5da0;\n    Node0x12c5f40 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%32:\\l32:                                               \\l  store i32 0, i32* %5, align 4\\l  br label %33\\l}\"];\n    Node0x12c5f40 -&gt; Node0x12c7bd0;\n    Node0x12c7bd0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%33:\\l33:                                               \\l  %34 = load i32, i32* %5, align 4\\l  %35 = load i32, i32* %4, align 4\\l  %36 = icmp slt i32 %34, %35\\l  br i1 %36, label %37, label %49\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c7bd0:s0 -&gt; Node0x12c7e00;\n    Node0x12c7bd0:s1 -&gt; Node0x12c7e50;\n    Node0x12c7e00 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%37:\\l37:                                               \\l  %38 = load i32**, i32*** %3, align 8\\l  %39 = load i32, i32* %5, align 4\\l  %40 = sext i32 %39 to i64\\l  %41 = getelementptr inbounds i32*, i32** %38, i64 %40\\l  %42 = load i32*, i32** %41, align 8\\l  %43 = load i32, i32* %5, align 4\\l  %44 = sext i32 %43 to i64\\l  %45 = getelementptr inbounds i32, i32* %42, i64 %44\\l  store i32 1, i32* %45, align 4\\l  br label %46\\l}\"];\n    Node0x12c7e00 -&gt; Node0x12c8400;\n    Node0x12c8400 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%46:\\l46:                                               \\l  %47 = load i32, i32* %5, align 4\\l  %48 = add nsw i32 %47, 1\\l  store i32 %48, i32* %5, align 4\\l  br label %33, !llvm.loop !9\\l}\"];\n    Node0x12c8400 -&gt; Node0x12c7bd0;\n    Node0x12c7e50 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%49:\\l49:                                               \\l  ret void\\l}\"];\n}\n\n\n\n\n\n\n\nCFG for 'identity' function\n\nCFG for 'identity' function\n\n\nNode0x12c5490\n\n%2:\n %3 = alloca i32**, align 8\n %4 = alloca i32, align 4\n %5 = alloca i32, align 4\n %6 = alloca i32, align 4\n store i32** %0, i32*** %3, align 8\n store i32 %1, i32* %4, align 4\n store i32 0, i32* %5, align 4\n br label %7\n\n\n\nNode0x12c5da0\n\n%7:\n7: \n %8 = load i32, i32* %5, align 4\n %9 = load i32, i32* %4, align 4\n %10 = icmp slt i32 %8, %9\n br i1 %10, label %11, label %32\n\nT\n\nF\n\n\n\nNode0x12c5490-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c5c70\n\n%11:\n11: \n store i32 0, i32* %6, align 4\n br label %12\n\n\n\nNode0x12c5da0:s0-&gt;Node0x12c5c70\n\n\n\n\n\nNode0x12c5f40\n\n%32:\n32: \n store i32 0, i32* %5, align 4\n br label %33\n\n\n\nNode0x12c5da0:s1-&gt;Node0x12c5f40\n\n\n\n\n\nNode0x12c6080\n\n%12:\n12: \n %13 = load i32, i32* %6, align 4\n %14 = load i32, i32* %4, align 4\n %15 = icmp slt i32 %13, %14\n br i1 %15, label %16, label %28\n\nT\n\nF\n\n\n\nNode0x12c5c70-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c7bd0\n\n%33:\n33: \n %34 = load i32, i32* %5, align 4\n %35 = load i32, i32* %4, align 4\n %36 = icmp slt i32 %34, %35\n br i1 %36, label %37, label %49\n\nT\n\nF\n\n\n\nNode0x12c5f40-&gt;Node0x12c7bd0\n\n\n\n\n\nNode0x12c62b0\n\n%16:\n16: \n %17 = load i32**, i32*** %3, align 8\n %18 = load i32, i32* %5, align 4\n %19 = sext i32 %18 to i64\n %20 = getelementptr inbounds i32*, i32** %17, i64 %19\n %21 = load i32*, i32** %20, align 8\n %22 = load i32, i32* %6, align 4\n %23 = sext i32 %22 to i64\n %24 = getelementptr inbounds i32, i32* %21, i64 %23\n store i32 0, i32* %24, align 4\n br label %25\n\n\n\nNode0x12c6080:s0-&gt;Node0x12c62b0\n\n\n\n\n\nNode0x12c6300\n\n%28:\n28: \n br label %29\n\n\n\nNode0x12c6080:s1-&gt;Node0x12c6300\n\n\n\n\n\nNode0x12c6820\n\n%25:\n25: \n %26 = load i32, i32* %6, align 4\n %27 = add nsw i32 %26, 1\n store i32 %27, i32* %6, align 4\n br label %12, !llvm.loop !6\n\n\n\nNode0x12c62b0-&gt;Node0x12c6820\n\n\n\n\n\nNode0x12c75b0\n\n%29:\n29: \n %30 = load i32, i32* %5, align 4\n %31 = add nsw i32 %30, 1\n store i32 %31, i32* %5, align 4\n br label %7, !llvm.loop !8\n\n\n\nNode0x12c6300-&gt;Node0x12c75b0\n\n\n\n\n\nNode0x12c6820-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c75b0-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c7e00\n\n%37:\n37: \n %38 = load i32**, i32*** %3, align 8\n %39 = load i32, i32* %5, align 4\n %40 = sext i32 %39 to i64\n %41 = getelementptr inbounds i32*, i32** %38, i64 %40\n %42 = load i32*, i32** %41, align 8\n %43 = load i32, i32* %5, align 4\n %44 = sext i32 %43 to i64\n %45 = getelementptr inbounds i32, i32* %42, i64 %44\n store i32 1, i32* %45, align 4\n br label %46\n\n\n\nNode0x12c7bd0:s0-&gt;Node0x12c7e00\n\n\n\n\n\nNode0x12c7e50\n\n%49:\n49: \n ret void\n\n\n\nNode0x12c7bd0:s1-&gt;Node0x12c7e50\n\n\n\n\n\nNode0x12c8400\n\n%46:\n46: \n %47 = load i32, i32* %5, align 4\n %48 = add nsw i32 %47, 1\n store i32 %48, i32* %5, align 4\n br label %33, !llvm.loop !9\n\n\n\nNode0x12c7e00-&gt;Node0x12c8400\n\n\n\n\n\nNode0x12c8400-&gt;Node0x12c7bd0"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#flavors-of-optimization",
    "href": "lectures/revealjs_03_local.qmd.html#flavors-of-optimization",
    "title": "Local Analysis & Optimization",
    "section": "flavors of optimization",
    "text": "flavors of optimization\nI want to separate 3 flavors of optimization.\n\nlocal meaning within one basic block\nglobal meaning within one function (not really global)\ninter-procedural over the entire program"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/revealjs_03_local.qmd.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels do not write a variable so they do not get deleted as well."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/revealjs_03_local.qmd.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#iterating-till-convergence",
    "href": "lectures/revealjs_03_local.qmd.html#iterating-till-convergence",
    "title": "Local Analysis & Optimization",
    "section": "iterating till convergence",
    "text": "iterating till convergence\nwhile changes:\n       run one pass of tdce above"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "href": "lectures/revealjs_03_local.qmd.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "title": "Local Analysis & Optimization",
    "section": "what would be faster? What is some pseudo code for the change",
    "text": "what would be faster? What is some pseudo code for the change\n\n  find all the variables that are used in more then one block\n  for each block b \n     used = all variables used in more then one block\n     walk backwards over the instruction in the block\n     for each instruction is dest in used?\n        yes - remove dest from used, add arguments to used \n        no  - instruction is dead \n\nfinding all the variables used in more then one block might be expensive"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#for-now-we-want-to-skip-control-flow",
    "href": "lectures/revealjs_03_local.qmd.html#for-now-we-want-to-skip-control-flow",
    "title": "Local Analysis & Optimization",
    "section": "for now we want to skip control flow",
    "text": "for now we want to skip control flow"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#testing",
    "href": "lectures/revealjs_03_local.qmd.html#testing",
    "title": "Local Analysis & Optimization",
    "section": "testing",
    "text": "testing\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamically executed instructions.\nHow good a measure is this for real programs?"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#using-trunt-golden-images",
    "href": "lectures/revealjs_03_local.qmd.html#using-trunt-golden-images",
    "title": "Local Analysis & Optimization",
    "section": "using trunt (golden images)",
    "text": "using trunt (golden images)\n\nConfigure. Decide what command you want to test. Make a turnt.toml config file and put command = “mycmd {filename}” in it to pass each test file as an argument to mycmd.\nTake a snapshot. Run turnt –save foo.bril. Execute mycmd foo.bril and save the standard output into foo.out.\n\nYou might want to take a look at this output to make sure it’s what you expect\n\nTest your work. Now that you have a test in place, keep working. Use turnt *.bril to run all your tests and confirm that the output still matches.\n\nIf there’s a mismatch, you can do turnt –diff to see the changes."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#peephole-optimizations",
    "href": "lectures/revealjs_03_local.qmd.html#peephole-optimizations",
    "title": "Local Analysis & Optimization",
    "section": "peephole optimizations",
    "text": "peephole optimizations\n1.Peephole optimizations are a category of local code optimizations.\n1. The principle is very simple: a. the optimizer analyzes sequences of instructions. –  a. only code that is within a small window of instructions is analyzed each time.\na. this window slides over the code. a. once patterns are discovered inside this window, optimizations are applied."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#some-examples",
    "href": "lectures/revealjs_03_local.qmd.html#some-examples",
    "title": "Local Analysis & Optimization",
    "section": "some examples",
    "text": "some examples\nredundant loads and stores\nm = load r0 store m in r0\nbranch transformations\n’’’ if debug ==1 go to l1 go to l2 l1: l2:\ntransforms to \nif debug !=1 goto l2 l1: l2: ```\nreduction in strength\n4*x =&gt; x &lt;&lt; 2\nspecial machine idioms"
  },
  {
    "objectID": "lectures/03_local.html",
    "href": "lectures/03_local.html",
    "title": "Local Analysis & Optimization",
    "section": "",
    "text": "and anyone who forgot hw0, still needed!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "href": "lectures/03_local.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "title": "Local Analysis & Optimization",
    "section": "",
    "text": "and anyone who forgot hw0, still needed!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#llvm-control-flow-graph",
    "href": "lectures/03_local.html#llvm-control-flow-graph",
    "title": "Local Analysis & Optimization",
    "section": "llvm control flow graph",
    "text": "llvm control flow graph\ncommands to draw a dot list of a c file from llvm\n clang -S -emit-llvm images/identity.c -o foo.ll \n opt -dot-cfg foo.ll -disable-output -enable-new-pm=0\nvoid identity(int **a, int N)\n{\n    int i, j;\n    for (i = 0; i &lt; N; i++)\n    {\n        for (j = 0; j &lt; N; j++)\n        {\n            a[i][j] = 0;\n        }\n    }\n    for (i = 0; i &lt; N; i++)\n    {\n        a[i][i] = 1;\n    }\n}\n\ndigraph \"CFG for 'identity' function\" {\n    label=\"CFG for 'identity' function\";\n\n    Node0x12c5490 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%2:\\l  %3 = alloca i32**, align 8\\l  %4 = alloca i32, align 4\\l  %5 = alloca i32, align 4\\l  %6 = alloca i32, align 4\\l  store i32** %0, i32*** %3, align 8\\l  store i32 %1, i32* %4, align 4\\l  store i32 0, i32* %5, align 4\\l  br label %7\\l}\"];\n    Node0x12c5490 -&gt; Node0x12c5da0;\n    Node0x12c5da0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%7:\\l7:                                                \\l  %8 = load i32, i32* %5, align 4\\l  %9 = load i32, i32* %4, align 4\\l  %10 = icmp slt i32 %8, %9\\l  br i1 %10, label %11, label %32\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c5da0:s0 -&gt; Node0x12c5c70;\n    Node0x12c5da0:s1 -&gt; Node0x12c5f40;\n    Node0x12c5c70 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%11:\\l11:                                               \\l  store i32 0, i32* %6, align 4\\l  br label %12\\l}\"];\n    Node0x12c5c70 -&gt; Node0x12c6080;\n    Node0x12c6080 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%12:\\l12:                                               \\l  %13 = load i32, i32* %6, align 4\\l  %14 = load i32, i32* %4, align 4\\l  %15 = icmp slt i32 %13, %14\\l  br i1 %15, label %16, label %28\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c6080:s0 -&gt; Node0x12c62b0;\n    Node0x12c6080:s1 -&gt; Node0x12c6300;\n    Node0x12c62b0 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%16:\\l16:                                               \\l  %17 = load i32**, i32*** %3, align 8\\l  %18 = load i32, i32* %5, align 4\\l  %19 = sext i32 %18 to i64\\l  %20 = getelementptr inbounds i32*, i32** %17, i64 %19\\l  %21 = load i32*, i32** %20, align 8\\l  %22 = load i32, i32* %6, align 4\\l  %23 = sext i32 %22 to i64\\l  %24 = getelementptr inbounds i32, i32* %21, i64 %23\\l  store i32 0, i32* %24, align 4\\l  br label %25\\l}\"];\n    Node0x12c62b0 -&gt; Node0x12c6820;\n    Node0x12c6820 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%25:\\l25:                                               \\l  %26 = load i32, i32* %6, align 4\\l  %27 = add nsw i32 %26, 1\\l  store i32 %27, i32* %6, align 4\\l  br label %12, !llvm.loop !6\\l}\"];\n    Node0x12c6820 -&gt; Node0x12c6080;\n    Node0x12c6300 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%28:\\l28:                                               \\l  br label %29\\l}\"];\n    Node0x12c6300 -&gt; Node0x12c75b0;\n    Node0x12c75b0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%29:\\l29:                                               \\l  %30 = load i32, i32* %5, align 4\\l  %31 = add nsw i32 %30, 1\\l  store i32 %31, i32* %5, align 4\\l  br label %7, !llvm.loop !8\\l}\"];\n    Node0x12c75b0 -&gt; Node0x12c5da0;\n    Node0x12c5f40 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%32:\\l32:                                               \\l  store i32 0, i32* %5, align 4\\l  br label %33\\l}\"];\n    Node0x12c5f40 -&gt; Node0x12c7bd0;\n    Node0x12c7bd0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%33:\\l33:                                               \\l  %34 = load i32, i32* %5, align 4\\l  %35 = load i32, i32* %4, align 4\\l  %36 = icmp slt i32 %34, %35\\l  br i1 %36, label %37, label %49\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c7bd0:s0 -&gt; Node0x12c7e00;\n    Node0x12c7bd0:s1 -&gt; Node0x12c7e50;\n    Node0x12c7e00 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%37:\\l37:                                               \\l  %38 = load i32**, i32*** %3, align 8\\l  %39 = load i32, i32* %5, align 4\\l  %40 = sext i32 %39 to i64\\l  %41 = getelementptr inbounds i32*, i32** %38, i64 %40\\l  %42 = load i32*, i32** %41, align 8\\l  %43 = load i32, i32* %5, align 4\\l  %44 = sext i32 %43 to i64\\l  %45 = getelementptr inbounds i32, i32* %42, i64 %44\\l  store i32 1, i32* %45, align 4\\l  br label %46\\l}\"];\n    Node0x12c7e00 -&gt; Node0x12c8400;\n    Node0x12c8400 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%46:\\l46:                                               \\l  %47 = load i32, i32* %5, align 4\\l  %48 = add nsw i32 %47, 1\\l  store i32 %48, i32* %5, align 4\\l  br label %33, !llvm.loop !9\\l}\"];\n    Node0x12c8400 -&gt; Node0x12c7bd0;\n    Node0x12c7e50 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%49:\\l49:                                               \\l  ret void\\l}\"];\n}\n\n\n\n\n\n\nCFG for 'identity' function\n\nCFG for 'identity' function\n\n\nNode0x12c5490\n\n%2:\n %3 = alloca i32**, align 8\n %4 = alloca i32, align 4\n %5 = alloca i32, align 4\n %6 = alloca i32, align 4\n store i32** %0, i32*** %3, align 8\n store i32 %1, i32* %4, align 4\n store i32 0, i32* %5, align 4\n br label %7\n\n\n\nNode0x12c5da0\n\n%7:\n7: \n %8 = load i32, i32* %5, align 4\n %9 = load i32, i32* %4, align 4\n %10 = icmp slt i32 %8, %9\n br i1 %10, label %11, label %32\n\nT\n\nF\n\n\n\nNode0x12c5490-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c5c70\n\n%11:\n11: \n store i32 0, i32* %6, align 4\n br label %12\n\n\n\nNode0x12c5da0:s0-&gt;Node0x12c5c70\n\n\n\n\n\nNode0x12c5f40\n\n%32:\n32: \n store i32 0, i32* %5, align 4\n br label %33\n\n\n\nNode0x12c5da0:s1-&gt;Node0x12c5f40\n\n\n\n\n\nNode0x12c6080\n\n%12:\n12: \n %13 = load i32, i32* %6, align 4\n %14 = load i32, i32* %4, align 4\n %15 = icmp slt i32 %13, %14\n br i1 %15, label %16, label %28\n\nT\n\nF\n\n\n\nNode0x12c5c70-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c7bd0\n\n%33:\n33: \n %34 = load i32, i32* %5, align 4\n %35 = load i32, i32* %4, align 4\n %36 = icmp slt i32 %34, %35\n br i1 %36, label %37, label %49\n\nT\n\nF\n\n\n\nNode0x12c5f40-&gt;Node0x12c7bd0\n\n\n\n\n\nNode0x12c62b0\n\n%16:\n16: \n %17 = load i32**, i32*** %3, align 8\n %18 = load i32, i32* %5, align 4\n %19 = sext i32 %18 to i64\n %20 = getelementptr inbounds i32*, i32** %17, i64 %19\n %21 = load i32*, i32** %20, align 8\n %22 = load i32, i32* %6, align 4\n %23 = sext i32 %22 to i64\n %24 = getelementptr inbounds i32, i32* %21, i64 %23\n store i32 0, i32* %24, align 4\n br label %25\n\n\n\nNode0x12c6080:s0-&gt;Node0x12c62b0\n\n\n\n\n\nNode0x12c6300\n\n%28:\n28: \n br label %29\n\n\n\nNode0x12c6080:s1-&gt;Node0x12c6300\n\n\n\n\n\nNode0x12c6820\n\n%25:\n25: \n %26 = load i32, i32* %6, align 4\n %27 = add nsw i32 %26, 1\n store i32 %27, i32* %6, align 4\n br label %12, !llvm.loop !6\n\n\n\nNode0x12c62b0-&gt;Node0x12c6820\n\n\n\n\n\nNode0x12c75b0\n\n%29:\n29: \n %30 = load i32, i32* %5, align 4\n %31 = add nsw i32 %30, 1\n store i32 %31, i32* %5, align 4\n br label %7, !llvm.loop !8\n\n\n\nNode0x12c6300-&gt;Node0x12c75b0\n\n\n\n\n\nNode0x12c6820-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c75b0-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c7e00\n\n%37:\n37: \n %38 = load i32**, i32*** %3, align 8\n %39 = load i32, i32* %5, align 4\n %40 = sext i32 %39 to i64\n %41 = getelementptr inbounds i32*, i32** %38, i64 %40\n %42 = load i32*, i32** %41, align 8\n %43 = load i32, i32* %5, align 4\n %44 = sext i32 %43 to i64\n %45 = getelementptr inbounds i32, i32* %42, i64 %44\n store i32 1, i32* %45, align 4\n br label %46\n\n\n\nNode0x12c7bd0:s0-&gt;Node0x12c7e00\n\n\n\n\n\nNode0x12c7e50\n\n%49:\n49: \n ret void\n\n\n\nNode0x12c7bd0:s1-&gt;Node0x12c7e50\n\n\n\n\n\nNode0x12c8400\n\n%46:\n46: \n %47 = load i32, i32* %5, align 4\n %48 = add nsw i32 %47, 1\n store i32 %48, i32* %5, align 4\n br label %33, !llvm.loop !9\n\n\n\nNode0x12c7e00-&gt;Node0x12c8400\n\n\n\n\n\nNode0x12c8400-&gt;Node0x12c7bd0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#flavors-of-optimization",
    "href": "lectures/03_local.html#flavors-of-optimization",
    "title": "Local Analysis & Optimization",
    "section": "flavors of optimization",
    "text": "flavors of optimization\nI want to separate 3 flavors of optimization.\n\nlocal meaning within one basic block\nglobal meaning within one function (not really global)\ninter-procedural over the entire program\n\n\nUsually an optimization takes time that is more then linear in some property, For example a local optimization might take time \\(n^2\\) in the number of instructions in the block. a global optimization might take much longer, and an inter-procedural longer still. To keep compile time reasonable many compilers limit the number of global optimizations and skip inter-procedural optimizations. As a consequence many more optimizations get published but not used in production.\n\nWhen would running an optimization speedup compilation?\nFor a local optimization, instructions within a block are ordered, so it makes sense to talk about instructions coming before or after others.\nFor a global optimization, two instructions are ordered by a path from one block to another and different paths through the program give different orders.\n\nOne special case is JIT (just in time) compilers, where programs get compiled at the start of execution. GPU compilers (and java compilers) look like this. They may use run-time information to decide of recompiling a function is a good idea. This is called Hotspot compiling. Some JIT compilers use hot/cold compiling, where they only run the fancy compiler on basic blocks that are hot , i.e., execute a lot.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\n\n\n\n\n\n\n\n\nWe are going to consider several versions of trivial dead code elimination. Trivial because we are going to hold off on control flow related optimizations till later. Sometimes people call this DCE or trivial DCE.\n\nFor each case, we start by defining what we mean by dead code.\nexample 1\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;\n  d: int = add a b;\n  print d;\n}\nWhat instruction is dead? (meaning get the same answer if we delete the instruction) What is your definition? Is this meaning of dead code local or global?\n\nWhy would you ever have dead code in a program? One reason is that have DCE as a separate pass means other optimizations do not have to clean up.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels do not write a variable so they do not get deleted as well.\n\nWhat is the pseudo code to find dead instructions using this definition?\n. . .\nused = empty set \nfor instr in func \n   used += instr.args \nfor instd in func\n    if instr has a dest and dest in not in used \n       delete instr\n\nexample 2\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;  \n  d: int = add a b;\n  e: int = add c d; \n  print d;\n}\n. . .\nThe code so far only deletes one instruction, but we would like to get rid of two. Instruction c should also be dead. How do we change the definition",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#iterating-till-convergence",
    "href": "lectures/03_local.html#iterating-till-convergence",
    "title": "Local Analysis & Optimization",
    "section": "iterating till convergence",
    "text": "iterating till convergence\nwhile changes:\n       run one pass of tdce above",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "href": "lectures/03_local.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "title": "Local Analysis & Optimization",
    "section": "what would be faster? What is some pseudo code for the change",
    "text": "what would be faster? What is some pseudo code for the change\n. . .\n  find all the variables that are used in more then one block\n  for each block b \n     used = all variables used in more then one block\n     walk backwards over the instruction in the block\n     for each instruction is dest in used?\n        yes - remove dest from used, add arguments to used \n        no  - instruction is dead \n\nfinding all the variables used in more then one block might be expensive\n\nexample 3\n@main {\n  a: int = const 4;\n  a: int = const 200;\n  print a;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#for-now-we-want-to-skip-control-flow",
    "href": "lectures/03_local.html#for-now-we-want-to-skip-control-flow",
    "title": "Local Analysis & Optimization",
    "section": "for now we want to skip control flow",
    "text": "for now we want to skip control flow",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\ncands are the variables that are defined but not used \nlast_def = {}  variables -&gt; instructions \nthis is a mapping variables that have been defined but not used\n\n   for instr in block:\n      each arg (use) removes arg from last def \n      if the instr has a dest \n          if the dest is in last_def, \n      add dest-&gt;instr to last def\n  \nand as you might expect, we need to iterate this till convergence\n\nCompilers often run dce more then once- why?\n\ntesting out dce\n\nprogram should get the same answer\nprogram should run less instructions\n\n\nSome test cases:\n\nsimple.bril,\nreassign.bril,\nother examples in the DCE test directory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#testing",
    "href": "lectures/03_local.html#testing",
    "title": "Local Analysis & Optimization",
    "section": "testing",
    "text": "testing\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamically executed instructions.\nHow good a measure is this for real programs?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#using-trunt-golden-images",
    "href": "lectures/03_local.html#using-trunt-golden-images",
    "title": "Local Analysis & Optimization",
    "section": "using trunt (golden images)",
    "text": "using trunt (golden images)\n\nConfigure. Decide what command you want to test. Make a turnt.toml config file and put command = “mycmd {filename}” in it to pass each test file as an argument to mycmd.\nTake a snapshot. Run turnt –save foo.bril. Execute mycmd foo.bril and save the standard output into foo.out.\n\nYou might want to take a look at this output to make sure it’s what you expect\n\nTest your work. Now that you have a test in place, keep working. Use turnt *.bril to run all your tests and confirm that the output still matches.\n\nIf there’s a mismatch, you can do turnt –diff to see the changes.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#peephole-optimizations",
    "href": "lectures/03_local.html#peephole-optimizations",
    "title": "Local Analysis & Optimization",
    "section": "peephole optimizations",
    "text": "peephole optimizations\n1.Peephole optimizations are a category of local code optimizations.\n1. The principle is very simple: a. the optimizer analyzes sequences of instructions. –  a. only code that is within a small window of instructions is analyzed each time.\na. this window slides over the code. a. once patterns are discovered inside this window, optimizations are applied.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#some-examples",
    "href": "lectures/03_local.html#some-examples",
    "title": "Local Analysis & Optimization",
    "section": "some examples",
    "text": "some examples\n\nredundant loads and stores\nm = load r0 store m in r0\n\n\nbranch transformations\n’’’ if debug ==1 go to l1 go to l2 l1: l2:\ntransforms to \nif debug !=1 goto l2 l1: l2: ```\n\n\nreduction in strength\n4*x =&gt; x &lt;&lt; 2\n\n\nspecial machine idioms",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "notebooks/02aa_reps.html",
    "href": "notebooks/02aa_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02aa_reps.html#a-more-regular-representation",
    "href": "notebooks/02aa_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/llvm.html",
    "href": "notebooks/llvm.html",
    "title": "intro to llvm",
    "section": "",
    "text": "difference between bril and llvm\nlinks\nllvm page\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n[sudo] password for norm: The following packages were automatically installed and are no longer required:\n  cmake-data dh-elpa-helper emacsen-common libarchive13 libjsoncpp25 librhash0\nUse 'sudo apt autoremove' to remove them.\nThe following packages will be REMOVED:\n  clang* cmake*\n0 upgraded, 0 newly installed, 2 to remove and 48 not upgraded.\nAfter this operation, 21.3 MB disk space will be freed.\n\n(Reading database ... 40226 files and directories currently installed.)\nRemoving clang (1:14.0-55~exp2) ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Progress: [ 22%] [############..............................................] Progress: [ 33%] [###################.......................................] Progress: [ 44%] [#########################.................................] emoving cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] Progress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n[sudo] password for norm: Suggested packages:\n  cmake-doc ninja-build cmake-format\nThe following NEW packages will be installed:\n  clang cmake\n0 upgraded, 2 newly installed, 0 to remove and 48 not upgraded.\nNeed to get 0 B/5014 kB of archives.\nAfter this operation, 21.3 MB of additional disk space will be used.\n\nSelecting previously unselected package clang.\n(Reading database ... 40203 files and directories currently installed.)\nPreparing to unpack .../clang_1%3a14.0-55~exp2_amd64.deb ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Unpacking clang (1:14.0-55~exp2) ...\nProgress: [ 22%] [############..............................................] electing previously unselected package cmake.\nPreparing to unpack .../cmake_3.22.1-1ubuntu1.22.04.2_amd64.deb ...\nProgress: [ 33%] [###################.......................................] Unpacking cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 44%] [#########################.................................] etting up clang (1:14.0-55~exp2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] etting up cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/possible_papers.html",
    "href": "notebooks/possible_papers.html",
    "title": "possible papers",
    "section": "",
    "text": "Glow: Graph Lowering Compiler Techniques for Neural Networks Nadav Rotem, Jordan Fix, Saleem Abdulrasool, Garret Catron, Summer Deng, Roman Dzhabarov, Nick Gibson, James Hegeman, Meghan Lele, Roman Levenstein, Jack Montgomery, Bert Maher, Satish Nadathur, Jakob Olesen, Jongsoo Park, Artem Rakhov, Misha Smelyanski chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/1805.00907\nA Deep Learning Based Cost Model for Automatic Code Optimization. Riyadh Baghdadi, Massinissa Merouani, Mohamed-Hicham Leghettas, Kamel Abdous, Taha Arbaoui, Karima Benatchba, Saman Amarasinghe. Proceedings of the Fourth Conference on Machine Learning and Systems (MLSys).\nhttps://dl.acm.org/doi/abs/10.1145/3213846.3213848?casa_token=cbgdY_Wgz9kAAAAA:IMKfnKAYKl3t9wXFen_yauFHY__vyUHcqSgjENz7RB2QEGeTC1L70FEC5vM9FnKBWdAiL6tw1uC4 Compiler fuzzing through deep learning\n“Effective Superword Level Parallelism for Multimedia Extension Architectures” by Samuel Larsen and Saman Amarasinghe (2000)\nEnergy-Aware Tile Size Selection for Affine Programs on GPUs, M. Jayaweera, M. Kong, Y. Wang, D. Kaeli, Pre-print, Artifact\n\n\n\n Back to top"
  }
]