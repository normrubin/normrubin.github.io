[
  {
    "objectID": "blogs/junk_dir/index.html",
    "href": "blogs/junk_dir/index.html",
    "title": "sample blog with an image and a graph",
    "section": "",
    "text": "image of rabbits\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# example data\nx = np.arange(0.1, 4, 0.5)\ny = np.exp(-x)\n\nfig, ax = plt.subplots()\nax.errorbar(x, y, xerr=0.2, yerr=0.4)\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "sample blog with an image and a graph"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-20-HW1.html",
    "href": "blogs/matin/2024-09-20-HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "After looking at the example benchmarks and the BRIL documentation, I noticed that the example benchmarks had a pseudo random number generator, and BRIL had a floating point extension. Inspired by the other scientific-based floating-point benchmarks, I decided on writing a benchmark to calculate PI using Monte Carlo (explained here). What could possibly go wrong?\n\n\nProbably the main issue I encountered was that there was no way to convert floats to ints, meaning no matter how many random integers I was generating, I couldn’t use them to generate numbers inside a unit square (1x1). To get around this issue, I tried sampling integers inside a non-unit square instead (e.g. square is 10x10, and points come from an interval of [-10, 10] on both x and y). All I had to do was make sure the pseudo random number generator outputs had a lower bound that I specified instead of zero. Again, what could possibly go wrong?\n\n\n\nAfter some debugging, I noticed that either the random number generator didn’t work as advertised (I put print statements in other benchmarks, and the values certainly weren’t greater than zero), or I was using it wrong.\nTo get around both of these issues, instead I opted in to discretize the unit square into a set of grid points, and then query whether they are inside the unit circle or not. Increasing the number of points leads to the output of the BRIL program converging to PI, so it seems to work. The benchmark and its test files are added under the benchmarks folder.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-20-HW1.html#problem-1-bril-doesnt-seem-to-convert-float-to-int-or-vice-versa",
    "href": "blogs/matin/2024-09-20-HW1.html#problem-1-bril-doesnt-seem-to-convert-float-to-int-or-vice-versa",
    "title": "Homework 1",
    "section": "",
    "text": "Probably the main issue I encountered was that there was no way to convert floats to ints, meaning no matter how many random integers I was generating, I couldn’t use them to generate numbers inside a unit square (1x1). To get around this issue, I tried sampling integers inside a non-unit square instead (e.g. square is 10x10, and points come from an interval of [-10, 10] on both x and y). All I had to do was make sure the pseudo random number generator outputs had a lower bound that I specified instead of zero. Again, what could possibly go wrong?",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-20-HW1.html#problem-2-the-number-generator-didnt-have-a-lower-bound-or-plain-just-didnt-work-as-advertised.",
    "href": "blogs/matin/2024-09-20-HW1.html#problem-2-the-number-generator-didnt-have-a-lower-bound-or-plain-just-didnt-work-as-advertised.",
    "title": "Homework 1",
    "section": "",
    "text": "After some debugging, I noticed that either the random number generator didn’t work as advertised (I put print statements in other benchmarks, and the values certainly weren’t greater than zero), or I was using it wrong.\nTo get around both of these issues, instead I opted in to discretize the unit square into a set of grid points, and then query whether they are inside the unit circle or not. Increasing the number of points leads to the output of the BRIL program converging to PI, so it seems to work. The benchmark and its test files are added under the benchmarks folder.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html",
    "title": "Homework5 - Yashaswini",
    "section": "",
    "text": "This pass looks for floating-point division operations (FDivOperator) and injects a call to a function named log_float_division whenever such an instruction is found.\nThe log_float_division function needs to be defined separately (e.g., in a C file) to print a message or log data.\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\nusing namespace llvm;\n\nnamespace {\nclass FloatDivLogger : public PassInfoMixin&lt;FloatDivLogger&gt; {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM) {\n    bool modified = false;\n\n    for (auto &BB : F) {\n      for (auto &I : BB) {\n        // Check if the instruction is a floating-point division\n        if (auto *op = dyn_cast&lt;FDivOperator&gt;(&I)) {\n          IRBuilder&lt;&gt; builder(&I);\n          FunctionCallee logFunc = F.getParent()-&gt;getOrInsertFunction(\n              \"log_float_division\", builder.getVoidTy());\n          builder.CreateCall(logFunc);\n\n          modified = true;\n        }\n      }\n    }\n\n    return (modified ? PreservedAnalyses::none() : PreservedAnalyses::all());\n  }\n};\n} // namespace\n\n// Register the pass with the LLVM Pass Manager\nllvm::PassPluginLibraryInfo getFloatDivLoggerPluginInfo() {\n  return {LLVM_PLUGIN_API_VERSION, \"FloatDivLogger\", LLVM_VERSION_STRING,\n          [](PassBuilder &PB) {\n            PB.registerPipelineParsingCallback(\n                [](StringRef Name, FunctionPassManager &FPM,\n                   ArrayRef&lt;PassBuilder::PipelineElement&gt;) {\n                  if (Name == \"float-div-logger\") {\n                    FPM.addPass(FloatDivLogger());\n                    return true;\n                  }\n                  return false;\n                });\n          }};\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n  return getFloatDivLoggerPluginInfo();\n}\n#include &lt;stdio.h&gt;\n\nvoid log_float_division() {\n    printf(\"Floating-point division detected!\\n\");\n}\n\n\n\n\nA simple program that uses floating point division:\n#include &lt;stdio.h&gt;\n\nint main() {\n    float a = 10.0;\n    float b = 2.0;\n    float c = a / b;\n    printf(\"Result: %f\\n\", c);\n    return 0;\n}\n##Output\nThe message: “Floating-point division detected!” is printed after every floating point division.\n\n\n\nThe most difficult part of this Homework was getting LLVM properly installed along with cmake and clang.\nAs I am using WSL, the cmake function does not update properly and was outof date for the llvm installation.\nensuring all installations worked and were properly linked together took some time.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework5 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html#about-the-code",
    "title": "Homework5 - Yashaswini",
    "section": "",
    "text": "This pass looks for floating-point division operations (FDivOperator) and injects a call to a function named log_float_division whenever such an instruction is found.\nThe log_float_division function needs to be defined separately (e.g., in a C file) to print a message or log data.\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\nusing namespace llvm;\n\nnamespace {\nclass FloatDivLogger : public PassInfoMixin&lt;FloatDivLogger&gt; {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM) {\n    bool modified = false;\n\n    for (auto &BB : F) {\n      for (auto &I : BB) {\n        // Check if the instruction is a floating-point division\n        if (auto *op = dyn_cast&lt;FDivOperator&gt;(&I)) {\n          IRBuilder&lt;&gt; builder(&I);\n          FunctionCallee logFunc = F.getParent()-&gt;getOrInsertFunction(\n              \"log_float_division\", builder.getVoidTy());\n          builder.CreateCall(logFunc);\n\n          modified = true;\n        }\n      }\n    }\n\n    return (modified ? PreservedAnalyses::none() : PreservedAnalyses::all());\n  }\n};\n} // namespace\n\n// Register the pass with the LLVM Pass Manager\nllvm::PassPluginLibraryInfo getFloatDivLoggerPluginInfo() {\n  return {LLVM_PLUGIN_API_VERSION, \"FloatDivLogger\", LLVM_VERSION_STRING,\n          [](PassBuilder &PB) {\n            PB.registerPipelineParsingCallback(\n                [](StringRef Name, FunctionPassManager &FPM,\n                   ArrayRef&lt;PassBuilder::PipelineElement&gt;) {\n                  if (Name == \"float-div-logger\") {\n                    FPM.addPass(FloatDivLogger());\n                    return true;\n                  }\n                  return false;\n                });\n          }};\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n  return getFloatDivLoggerPluginInfo();\n}\n#include &lt;stdio.h&gt;\n\nvoid log_float_division() {\n    printf(\"Floating-point division detected!\\n\");\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework5 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html#testing",
    "href": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html#testing",
    "title": "Homework5 - Yashaswini",
    "section": "",
    "text": "A simple program that uses floating point division:\n#include &lt;stdio.h&gt;\n\nint main() {\n    float a = 10.0;\n    float b = 2.0;\n    float c = a / b;\n    printf(\"Result: %f\\n\", c);\n    return 0;\n}\n##Output\nThe message: “Floating-point division detected!” is printed after every floating point division.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework5 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html#challanges",
    "href": "blogs/yashaswini/11-1-2024-HW5-YashaswiniMakaram.html#challanges",
    "title": "Homework5 - Yashaswini",
    "section": "",
    "text": "The most difficult part of this Homework was getting LLVM properly installed along with cmake and clang.\nAs I am using WSL, the cmake function does not update properly and was outof date for the llvm installation.\nensuring all installations worked and were properly linked together took some time.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework5 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-11-2024-HW3-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/10-11-2024-HW3-YashaswiniMakaram.html",
    "title": "Homework3 - Yashaswini",
    "section": "",
    "text": "creates a flow diagram for a given bril code. can choose whether to ggo forwards,ay must, ect.\n\n’’’ import json from collections import defaultdict import graphviz\ndef load_bril_program(filename): “““Load the Bril program from a JSON file.”“” with open(filename, ‘r’) as file: return json.load(file)\ndef build_cfg(function): “““Build the Control Flow Graph (CFG) for a given function.”“” instrs = function[‘instrs’] cfg = defaultdict(list) label_map = {}\n# Map labels to instruction indices\nfor i, instr in enumerate(instrs):\n    if 'label' in instr:\n        label_map[instr['label']] = i\n\nfor i, instr in enumerate(instrs):\n    if 'op' in instr and instr['op'] == 'jmp':\n        target = label_map[instr['labels'][0]]\n        cfg[i].append(target)\n    elif 'op' in instr and instr['op'] == 'br':\n        target1 = label_map[instr['labels'][0]]\n        target2 = label_map[instr['labels'][1]]\n        cfg[i].extend([target1, target2])\n    else:\n        # Fall-through case: connect to the next instruction\n        if i + 1 &lt; len(instrs):\n            cfg[i].append(i + 1)\n\nreturn cfg\ndef predecessors(cfg): “““Find predecessors for each node in the CFG.”“” pred = defaultdict(list) for node, successors in cfg.items(): for succ in successors: pred[succ].append(node) return pred\ndef generic_data_flow_analysis(function, transfer_fn, gen_fn, kill_fn, direction=“forward”, merge=“union”): “““Perform a generic data flow analysis on the given function.”“” cfg = build_cfg(function) preds = predecessors(cfg)\n# Initialize IN and OUT sets for all nodes\nin_sets = defaultdict(set)\nout_sets = defaultdict(set)  # Initialize with defaultdict to avoid KeyError\n\n# Ensure every node in the function has an entry in out_sets\nfor node in range(len(function['instrs'])):\n    out_sets[node] = gen_fn(node)  # Start with GEN[n] if desired, or an empty set\n\nchanged = set(cfg.keys())\n\nwhile changed:\n    n = changed.pop()\n\n    # Calculate IN[n] or OUT[n] based on direction\n    if direction == \"forward\":\n        in_sets[n] = set()\n        for p in preds[n]:\n            if merge == \"union\":\n                in_sets[n] |= out_sets[p]\n            elif merge == \"intersection\" and out_sets[p]:\n                in_sets[n] &= out_sets[p]\n    else:  # Backward analysis\n        out_sets[n] = set()\n        for s in cfg[n]:\n            if merge == \"union\":\n                out_sets[n] |= in_sets[s]\n            elif merge == \"intersection\" and in_sets[s]:\n                out_sets[n] &= in_sets[s]\n\n    old_out = out_sets[n].copy() if direction == \"forward\" else in_sets[n].copy()\n    \n    # Update OUT[n] or IN[n] using the transfer function\n    if direction == \"forward\":\n        out_sets[n] = transfer_fn(in_sets[n], gen_fn(n), kill_fn(n))\n    else:\n        in_sets[n] = transfer_fn(out_sets[n], gen_fn(n), kill_fn(n))\n\n    # If there's a change, update the changed set\n    if direction == \"forward\" and old_out != out_sets[n]:\n        for s in cfg[n]:\n            changed.add(s)\n    elif direction == \"backward\" and old_out != in_sets[n]:\n        for p in preds[n]:\n            changed.add(p)\n\nreturn in_sets, out_sets\ndef reaching_definitions_transfer(in_set, gen_set, kill_set): “““Transfer function for Reaching Definitions: OUT[n] = GEN[n] U (IN[n] - KILL[n]).”“” return gen_set | (in_set - kill_set)\ndef reaching_definitions_gen_kill(instr, idx): “““GEN and KILL sets for Reaching Definitions.”“” if ‘dest’ in instr: gen_set = {(instr[‘dest’], idx)} kill_set = {var for var, _ in gen_set} return gen_set, kill_set return set(), set()\ndef create_cfg_visualization(function, in_sets, out_sets): “““Create a graphical view of the CFG with IN and OUT sets.”“” cfg = build_cfg(function) dot = graphviz.Digraph(comment=function[‘name’])\nfor node, instr in enumerate(function['instrs']):\n    label = f\"Instr {node}: {instr}\\nIN: {in_sets[node]}\\nOUT: {out_sets[node]}\"\n    dot.node(str(node), label)\n\nfor node, successors in cfg.items():\n    for succ in successors:\n        dot.edge(str(node), str(succ))\n\n# Save the CFG visualization as a PDF\ndot.render(f\"cfg_{function['name']}\", format=\"pdf\", cleanup=True)\ndef run_analysis(program): “““Run the generic data flow analysis on each function in the Bril program.”“” for function in program[‘functions’]: print(f”Analyzing function: {function[‘name’]}“)\n    def gen_fn(n):\n        instr = function['instrs'][n]\n        return reaching_definitions_gen_kill(instr, n)[0]\n\n    def kill_fn(n):\n        instr = function['instrs'][n]\n        return reaching_definitions_gen_kill(instr, n)[1]\n\n    in_sets, out_sets = generic_data_flow_analysis(\n        function, reaching_definitions_transfer, gen_fn, kill_fn, direction=\"forward\", merge=\"union\"\n    )\n\n    print(f\"IN sets: {in_sets}\")\n    print(f\"OUT sets: {out_sets}\")\n\n    # Create a graphical view of the CFG\n    create_cfg_visualization(function, in_sets, out_sets)\ndef main(): # Load the Bril program from a file bril_program = load_bril_program(‘add.bril’)\n# Run the analysis\nrun_analysis(bril_program)",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework3 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-11-2024-HW3-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/10-11-2024-HW3-YashaswiniMakaram.html#about-the-code",
    "title": "Homework3 - Yashaswini",
    "section": "",
    "text": "creates a flow diagram for a given bril code. can choose whether to ggo forwards,ay must, ect.\n\n’’’ import json from collections import defaultdict import graphviz\ndef load_bril_program(filename): “““Load the Bril program from a JSON file.”“” with open(filename, ‘r’) as file: return json.load(file)\ndef build_cfg(function): “““Build the Control Flow Graph (CFG) for a given function.”“” instrs = function[‘instrs’] cfg = defaultdict(list) label_map = {}\n# Map labels to instruction indices\nfor i, instr in enumerate(instrs):\n    if 'label' in instr:\n        label_map[instr['label']] = i\n\nfor i, instr in enumerate(instrs):\n    if 'op' in instr and instr['op'] == 'jmp':\n        target = label_map[instr['labels'][0]]\n        cfg[i].append(target)\n    elif 'op' in instr and instr['op'] == 'br':\n        target1 = label_map[instr['labels'][0]]\n        target2 = label_map[instr['labels'][1]]\n        cfg[i].extend([target1, target2])\n    else:\n        # Fall-through case: connect to the next instruction\n        if i + 1 &lt; len(instrs):\n            cfg[i].append(i + 1)\n\nreturn cfg\ndef predecessors(cfg): “““Find predecessors for each node in the CFG.”“” pred = defaultdict(list) for node, successors in cfg.items(): for succ in successors: pred[succ].append(node) return pred\ndef generic_data_flow_analysis(function, transfer_fn, gen_fn, kill_fn, direction=“forward”, merge=“union”): “““Perform a generic data flow analysis on the given function.”“” cfg = build_cfg(function) preds = predecessors(cfg)\n# Initialize IN and OUT sets for all nodes\nin_sets = defaultdict(set)\nout_sets = defaultdict(set)  # Initialize with defaultdict to avoid KeyError\n\n# Ensure every node in the function has an entry in out_sets\nfor node in range(len(function['instrs'])):\n    out_sets[node] = gen_fn(node)  # Start with GEN[n] if desired, or an empty set\n\nchanged = set(cfg.keys())\n\nwhile changed:\n    n = changed.pop()\n\n    # Calculate IN[n] or OUT[n] based on direction\n    if direction == \"forward\":\n        in_sets[n] = set()\n        for p in preds[n]:\n            if merge == \"union\":\n                in_sets[n] |= out_sets[p]\n            elif merge == \"intersection\" and out_sets[p]:\n                in_sets[n] &= out_sets[p]\n    else:  # Backward analysis\n        out_sets[n] = set()\n        for s in cfg[n]:\n            if merge == \"union\":\n                out_sets[n] |= in_sets[s]\n            elif merge == \"intersection\" and in_sets[s]:\n                out_sets[n] &= in_sets[s]\n\n    old_out = out_sets[n].copy() if direction == \"forward\" else in_sets[n].copy()\n    \n    # Update OUT[n] or IN[n] using the transfer function\n    if direction == \"forward\":\n        out_sets[n] = transfer_fn(in_sets[n], gen_fn(n), kill_fn(n))\n    else:\n        in_sets[n] = transfer_fn(out_sets[n], gen_fn(n), kill_fn(n))\n\n    # If there's a change, update the changed set\n    if direction == \"forward\" and old_out != out_sets[n]:\n        for s in cfg[n]:\n            changed.add(s)\n    elif direction == \"backward\" and old_out != in_sets[n]:\n        for p in preds[n]:\n            changed.add(p)\n\nreturn in_sets, out_sets\ndef reaching_definitions_transfer(in_set, gen_set, kill_set): “““Transfer function for Reaching Definitions: OUT[n] = GEN[n] U (IN[n] - KILL[n]).”“” return gen_set | (in_set - kill_set)\ndef reaching_definitions_gen_kill(instr, idx): “““GEN and KILL sets for Reaching Definitions.”“” if ‘dest’ in instr: gen_set = {(instr[‘dest’], idx)} kill_set = {var for var, _ in gen_set} return gen_set, kill_set return set(), set()\ndef create_cfg_visualization(function, in_sets, out_sets): “““Create a graphical view of the CFG with IN and OUT sets.”“” cfg = build_cfg(function) dot = graphviz.Digraph(comment=function[‘name’])\nfor node, instr in enumerate(function['instrs']):\n    label = f\"Instr {node}: {instr}\\nIN: {in_sets[node]}\\nOUT: {out_sets[node]}\"\n    dot.node(str(node), label)\n\nfor node, successors in cfg.items():\n    for succ in successors:\n        dot.edge(str(node), str(succ))\n\n# Save the CFG visualization as a PDF\ndot.render(f\"cfg_{function['name']}\", format=\"pdf\", cleanup=True)\ndef run_analysis(program): “““Run the generic data flow analysis on each function in the Bril program.”“” for function in program[‘functions’]: print(f”Analyzing function: {function[‘name’]}“)\n    def gen_fn(n):\n        instr = function['instrs'][n]\n        return reaching_definitions_gen_kill(instr, n)[0]\n\n    def kill_fn(n):\n        instr = function['instrs'][n]\n        return reaching_definitions_gen_kill(instr, n)[1]\n\n    in_sets, out_sets = generic_data_flow_analysis(\n        function, reaching_definitions_transfer, gen_fn, kill_fn, direction=\"forward\", merge=\"union\"\n    )\n\n    print(f\"IN sets: {in_sets}\")\n    print(f\"OUT sets: {out_sets}\")\n\n    # Create a graphical view of the CFG\n    create_cfg_visualization(function, in_sets, out_sets)\ndef main(): # Load the Bril program from a file bril_program = load_bril_program(‘add.bril’)\n# Run the analysis\nrun_analysis(bril_program)",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework3 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html",
    "title": "Homework 5: LLVM - Spinning Up",
    "section": "",
    "text": "New dependency packages are required to build targets in this Homework. I choose using conda for clear isolation with the system build toolchain. However, things were much more difficult than ever if the idiot VSCode (and unreliable official plugins) came to the context: VSCode IntelliSense could not easily recognize the header file, although LSP had already found out where to go; copilot continued to ask me to fix the include path to clear these import error; and the corresponding items in setting panel I have specified and pointed to the correct direction is always ignored or overwritten by their default location, which is point to the system default path. After trying a bunch of suggestions posted in the VSCode community forum, I finally gave up on making the autocomplete and type-checking stuff work.\nconda install conda-forge::clang\nconda install conda-forge::cmake\nconda install -c conda-forge llvmdev;  # header file, cmake recipe\nAfter experiencing these kinds of frustrating config stuff, I strongly recommend installing/updating the system’s default LLVM toolchain to make VSCode find the definition of the functions and variables, and not draw red underlines to interrupt your mind.\n\n\n\nIf the LLVM toolchain is installed in the system-level default location, there’s no need to do this extra step.\nexport LLVM_DIR=$CONDA_PREFIX/lib/cmake/llvm\nexport LD_LIBRARY_PATH=&lt;PRJ_DIR&gt;/HW5/llvm-passes/show-float-div/build:$LD_LIBRARY_PATH;",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 5: LLVM - Spinning Up"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#env",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#env",
    "title": "Homework 5: LLVM - Spinning Up",
    "section": "",
    "text": "New dependency packages are required to build targets in this Homework. I choose using conda for clear isolation with the system build toolchain. However, things were much more difficult than ever if the idiot VSCode (and unreliable official plugins) came to the context: VSCode IntelliSense could not easily recognize the header file, although LSP had already found out where to go; copilot continued to ask me to fix the include path to clear these import error; and the corresponding items in setting panel I have specified and pointed to the correct direction is always ignored or overwritten by their default location, which is point to the system default path. After trying a bunch of suggestions posted in the VSCode community forum, I finally gave up on making the autocomplete and type-checking stuff work.\nconda install conda-forge::clang\nconda install conda-forge::cmake\nconda install -c conda-forge llvmdev;  # header file, cmake recipe\nAfter experiencing these kinds of frustrating config stuff, I strongly recommend installing/updating the system’s default LLVM toolchain to make VSCode find the definition of the functions and variables, and not draw red underlines to interrupt your mind.\n\n\n\nIf the LLVM toolchain is installed in the system-level default location, there’s no need to do this extra step.\nexport LLVM_DIR=$CONDA_PREFIX/lib/cmake/llvm\nexport LD_LIBRARY_PATH=&lt;PRJ_DIR&gt;/HW5/llvm-passes/show-float-div/build:$LD_LIBRARY_PATH;",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 5: LLVM - Spinning Up"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#detail-design",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#detail-design",
    "title": "Homework 5: LLVM - Spinning Up",
    "section": "Detail Design",
    "text": "Detail Design\nThere’re 3 passes implemented in this Homework: - loop-unroll: Implemented a straightforward loop unrolling pass, only unrolling once if it finds a valid loop. (An ambitious task as the instruction of this homework suggested.) - show-bin-op: Display when there is a binary operation, log it out when doing compile, and call a stab function in rtlib during runtime to print the value stored in the destination. - show-float-div: As the instruction of this homework suggested, this pass is an example of an unambitious task, which displays only the fdiv operation, and acts the very same as the show-bin-op pass does when encountering fdiv operation.\n* Check Passes Source Code for details.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 5: LLVM - Spinning Up"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#integration-testing",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#integration-testing",
    "title": "Homework 5: LLVM - Spinning Up",
    "section": "Integration, Testing",
    "text": "Integration, Testing\nSome examples of the real-ish C/C++ program are provided in this homework. - example.c in each pass: Unit Tests to make sure passes are performing the correct results as wished. - matmul.cpp: A square matrix multiply testbench, which would be a great scenario to test the loop unrolling pass, but also can test the other two display passes. - projectile_motion.cpp: Simulates the motion of a projectile launched at a given angle and initial velocity within finite N steps.\nTo build the tests:\nFor examples.c and the pass library, go to each pass folder, and run make. All the results will be generated, including: - $(BUILD_DIR)/$(PASS_NAME)/$(PASS_NAME)Pass.so: Pass plugin as a dynamic lib. - $(BUILD_DIR)/lib$(RTLIB_LIB_NAME).so: Additional Runtime functions (i.e. Stab call funcs). - example: Executable of examples.c. To run the example, use make run instead of make.\nFor matmul.cpp and projectile_motion.cpp, go to the app folder, and run make. Executable will be generated in the same folder. Use make run to test the execution.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 5: LLVM - Spinning Up"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#results-and-analysis",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW5.html#results-and-analysis",
    "title": "Homework 5: LLVM - Spinning Up",
    "section": "Results and Analysis",
    "text": "Results and Analysis\n\nMatrix Multiply - Loop Unroll\nSlightly different in wall clock speed.\n❯ make run\nRunning target with custom LLVM pass...\ntime ./matmul_with_pass\nC[0][0] = 200\n0.02user 0.00system 0:00.02elapsed 96%CPU (0avgtext+0avgdata 2772maxresident)k\n0inputs+0outputs (0major+149minor)pagefaults 0swaps\nRunning target without custom LLVM pass...\ntime ./matmul_without_pass\nC[0][0] = 200\n0.01user 0.00system 0:00.02elapsed 95%CPU (0avgtext+0avgdata 2896maxresident)k\n0inputs+0outputs (0major+153minor)pagefaults 0swaps\n\n\nExample - Show FDiv\n# ~/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div    main !8 ?7      ✔  15s   course-eece7398-st-compiler   jiang@builder  04:29:01  \n\n❯ make clean\n❯ make run\nmkdir -p build\nBuilding RTLib...\nmake[1]: Entering directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div'\nmake[1]: 'build' is up to date.\nmake[1]: Leaving directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div'\nclang -fPIC -shared rtlib.c -o build/librtlib.so\nBuilding LLVM Pass...\nmake[1]: Entering directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div'\nmake[1]: 'build' is up to date.\nmake[1]: Leaving directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div'\ncd build && cmake .. && make\n-- The C compiler identification is GNU 14.2.0\n-- The CXX compiler identification is GNU 9.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /home/jiang/miniconda3/envs/course-eece7398-st-compiler/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")\n-- Found zstd: /home/jiang/miniconda3/envs/course-eece7398-st-compiler/lib/libzstd.so\n-- Found LibXml2: /home/jiang/miniconda3/envs/course-eece7398-st-compiler/lib/libxml2.so (found version \"2.13.1\")\n-- Linker detection: GNU ld\n-- Registering ShowFDivPass as a pass plugin (static build: OFF)\n-- Configuring done (0.7s)\n-- Generating done (0.0s)\n-- Build files have been written to: /home/jiang/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build\nmake[1]: Entering directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\nmake[2]: Entering directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\nmake[3]: Entering directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\nmake[3]: Leaving directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\nmake[3]: Entering directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\n[ 50%] Building CXX object ShowFDiv/CMakeFiles/ShowFDivPass.dir/ShowFDiv.cpp.o\n[100%] Linking CXX shared module ShowFDivPass.so\nmake[3]: Leaving directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\n[100%] Built target ShowFDivPass\nmake[2]: Leaving directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\nmake[1]: Leaving directory '/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build'\nCompiling target...\nclang -fpass-plugin=build/ShowFDiv/ShowFDivPass.so -c example.c\n\nShowFDiv.cpp:34: Found FDiv operator:   %38 = fdiv double %37, 2.000000e+00\n  %38 = fdiv double %37, 2.000000e+00\nOpcodeName: fdiv\n\nclang example.o -Lbuild -lrtlib -o example\nrm -f example.o\nRunning target...\nexport LD_LIBRARY_PATH=/home/jiang/scratch/work/course/EECE7398_ST_Compiler/HW5/llvm-passes/show-float-div/build:$LD_LIBRARY_PATH && \\\n./example\nEnter a number: 123\n125\n121\n246\n61\nEnter a float number: 123.456\n125.456001\n121.456001\n246.912003\n[logfdiv: 61.728001 = 123.456001 / 2.000000]\n61.728001",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 5: LLVM - Spinning Up"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html",
    "title": "Homework 4: Dominance",
    "section": "",
    "text": "Dominance analysis is a fundamental concept in compiler optimization, crucial for understanding the structure of control flow within programs. It involves identifying dominance relationships among blocks in a Control Flow Graph (CFG), where a program is broken down into basic blocks connected by directed edges representing the possible flow of execution. This analysis is often used for advanced compiler optimizations like code motion, dead code elimination, and Static Single Assignment (SSA) form conversion.\nThis blog post delves into the key concepts of dominance analysis, including dominators, immediate dominators, and dominance frontiers. These concepts form the basis of various control flow optimizations and transformations.\n\n\n\n\n\nIn a CFG, a block BB1 is said to dominate another block BB2 if every path from the entry block to BB2 must pass through BB1 . The entry block itself trivially dominates all other blocks in the graph because all execution paths must originate from it.\nThe concept of dominators can be useful to identify regions in the program where specific code fragments will always execute before others. This information is essential for optimizations such as moving invariant computations out of loops and removing unreachable code.\n\n\n\nAmong the set of blocks that dominate a particular block, the one closest to in terms of control flow is known as its immediate dominator. The immediate dominator is unique for each block (except the entry block) and forms the basis of the dominator tree, a hierarchical structure that reveals the dominance relationships within the CFG.\nIn the dominator tree, each node represents a basic block, and an edge from BB1 to BB2 indicates that BB1 is the immediate dominator of BB2 . This tree structure helps in visualizing the control dependencies in a program.\n\n\n\nThe dominance frontier of a block BB1 is the set of all blocks where the dominance relationship breaks. More formally, a block BBX is in the dominance frontier of BB1 if BB1 dominates a predecessor of BBX , but BB1 does not strictly dominate BBX itself.\nDominance frontiers are used to identify the points in the CFG where variables need to be merged or “phi-inserted” during SSA form conversion. This is important because it ensures that all possible values of a variable reaching a certain block are correctly accounted for.\n\n\n\n\nIn the context of compiler design, the CFG represents the program’s execution paths, with nodes corresponding to basic blocks and edges denoting control flow between them. Dominance analysis provides a way to understand the flow of control within a program by identifying how execution paths interact and where they converge or diverge.\n\n\nDominators can be seen as checkpoints that ensure certain computations always happen before others. For example, if a block BB1 dominates BB2 , we can be certain that the execution of BB2 implies the execution of BB1 at some point. This property allows for optimizations such as moving loop-invariant computations out of loops, as the computations are guaranteed to occur before each iteration of the loop.\n\n\n\nThe dominator tree provides a structured way to represent the dominance relationships within the CFG. By identifying the immediate dominator for each block, we can construct a tree where each block is a child of its immediate dominator. This structure is useful for identifying regions of code that are tightly coupled in terms of control flow, aiding in optimizations such as code motion and dead code elimination.\n\n\n\nThe dominance frontier is particularly useful in scenarios where multiple control paths converge. It helps identify the blocks where different execution paths must be reconciled, especially in the context of SSA form, where variables may have different values depending on the path taken to reach a block. By inserting “phi functions” at the dominance frontier, the compiler can correctly handle the merging of variable values from different paths.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 4: Dominance"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html#introduction",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html#introduction",
    "title": "Homework 4: Dominance",
    "section": "",
    "text": "Dominance analysis is a fundamental concept in compiler optimization, crucial for understanding the structure of control flow within programs. It involves identifying dominance relationships among blocks in a Control Flow Graph (CFG), where a program is broken down into basic blocks connected by directed edges representing the possible flow of execution. This analysis is often used for advanced compiler optimizations like code motion, dead code elimination, and Static Single Assignment (SSA) form conversion.\nThis blog post delves into the key concepts of dominance analysis, including dominators, immediate dominators, and dominance frontiers. These concepts form the basis of various control flow optimizations and transformations.\n\n\n\n\n\nIn a CFG, a block BB1 is said to dominate another block BB2 if every path from the entry block to BB2 must pass through BB1 . The entry block itself trivially dominates all other blocks in the graph because all execution paths must originate from it.\nThe concept of dominators can be useful to identify regions in the program where specific code fragments will always execute before others. This information is essential for optimizations such as moving invariant computations out of loops and removing unreachable code.\n\n\n\nAmong the set of blocks that dominate a particular block, the one closest to in terms of control flow is known as its immediate dominator. The immediate dominator is unique for each block (except the entry block) and forms the basis of the dominator tree, a hierarchical structure that reveals the dominance relationships within the CFG.\nIn the dominator tree, each node represents a basic block, and an edge from BB1 to BB2 indicates that BB1 is the immediate dominator of BB2 . This tree structure helps in visualizing the control dependencies in a program.\n\n\n\nThe dominance frontier of a block BB1 is the set of all blocks where the dominance relationship breaks. More formally, a block BBX is in the dominance frontier of BB1 if BB1 dominates a predecessor of BBX , but BB1 does not strictly dominate BBX itself.\nDominance frontiers are used to identify the points in the CFG where variables need to be merged or “phi-inserted” during SSA form conversion. This is important because it ensures that all possible values of a variable reaching a certain block are correctly accounted for.\n\n\n\n\nIn the context of compiler design, the CFG represents the program’s execution paths, with nodes corresponding to basic blocks and edges denoting control flow between them. Dominance analysis provides a way to understand the flow of control within a program by identifying how execution paths interact and where they converge or diverge.\n\n\nDominators can be seen as checkpoints that ensure certain computations always happen before others. For example, if a block BB1 dominates BB2 , we can be certain that the execution of BB2 implies the execution of BB1 at some point. This property allows for optimizations such as moving loop-invariant computations out of loops, as the computations are guaranteed to occur before each iteration of the loop.\n\n\n\nThe dominator tree provides a structured way to represent the dominance relationships within the CFG. By identifying the immediate dominator for each block, we can construct a tree where each block is a child of its immediate dominator. This structure is useful for identifying regions of code that are tightly coupled in terms of control flow, aiding in optimizations such as code motion and dead code elimination.\n\n\n\nThe dominance frontier is particularly useful in scenarios where multiple control paths converge. It helps identify the blocks where different execution paths must be reconciled, especially in the context of SSA form, where variables may have different values depending on the path taken to reach a block. By inserting “phi functions” at the dominance frontier, the compiler can correctly handle the merging of variable values from different paths.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 4: Dominance"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html#detail-design",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html#detail-design",
    "title": "Homework 4: Dominance",
    "section": "Detail Design",
    "text": "Detail Design\n\nAbstraction Classes\nThe abstraction class remain the same structure as last homework submittion, see detail in HW3 - Abstraction Classes.\nI add one additional feature: __lt__() for class BrilInstruction_Label, therefore use current ./bril_model for further development.\n\n\nDominance Analysis Implementation\nThe script dom_analysis.py is designed to perform dominance analysis on Bril program. It includes functionalities for generating a Control Flow Graph (CFG), computing dominators for each block, constructing the dominator tree, and identifying the dominance frontier. Below is a breakdown of the key parts of the code with brief notes on their functions and corresponding source code line indxx.\n\n1. Imports and Argument Parsing\n\nThe code imports necessary libraries like os, networkx, pyvis, and matplotlib for graph visualization, as well as custom modules from bril_model.\nIt also sets up argument parsing to allow the user to specify the Bril file to analyze and an optional save directory for generated outputs.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n # %% [markdown] \n # # Playground - data flow graph  \n  \n # %% \n import os \n import networkx as nx \n import pyvis as pv \n import matplotlib.pyplot as plt \n import graphviz as gv \n from typing import Iterable, Tuple, Set, List, Dict, OrderedDict, Optional \n import bril_model as bm \n from bril_model.form_blocks import form_blocks \n from hashlib import sha256 \n fast_hash = lambda str: sha256(str).hexdigest()[:3] \n  \n  \n # usage: &lt;this_script&gt; DEMO_BRIL_FILE [--save-dir=./save | --mute-output]  \n  \n import argparse \n parser = argparse.ArgumentParser(description='Generate CFG with dominance frontier and Dominator-Tree for a bril script') \n parser.add_argument('DEMO_BRIL_FILE', type=str, help='Path to the bril file') \n parser.add_argument('--save-dir', type=str, default='./save', help='Path to save the generated html files') \n parser.add_argument('--mute-output', action='store_true', help='Mute the output of the graphviz render', default=False) \n args = parser.parse_args() \n  \n DEMO_BRIL_FILE = args.DEMO_BRIL_FILE \n SAVE_DIR = args.save_dir \n MUTE_OUTPUT = args.mute_output \n  \n # DEMO_BRIL_FILE = \"../bril/examples/test/dom/loopcond.bril\" \n # DEMO_BRIL_FILE = \"../bril/examples/test/dom/while.bril\" \n  \n # %% \n # make sure args are allowed \n args_correct = True \n if not os.path.exists(DEMO_BRIL_FILE): \n     print(f\"File &lt;{DEMO_BRIL_FILE}&gt; not found\") \n     args_correct = False \n if not args_correct: \n     # print help and exit \n     parser.print_help() \n     exit(1) \n  \n # %% \n ENTRY_POINT_NAME = 'ENTRY' \n RETURN_POINT_NAME = 'RETURN' \n\n\n\n2. Basic Block Definition\n\nThis section defines the BasicBlock class, representing a basic block in the CFG. Each basic block consists of a label and a list of instructions.\nIt also includes properties for successors (succ) and predecessors (pred), which form the edges in the CFG.\nThe class implements various methods for equality checks, hashing, and string representation.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n class BasicBlock(): \n     def __init__(self, label: bm.BrilInstruction_Label, instrs: List[bm.BrilInstruction]): \n         if not isinstance(label, bm.BrilInstruction_Label): \n             raise TypeError(f\"Expected label, got {type(label)}\") \n         if label not in instrs: \n             instrs.insert(0, label) \n         self.instrs = instrs \n         self.succ: Set[BasicBlock] = set() \n         self.pred: Set[BasicBlock] = set() \n      \n     @property \n     def label(self): \n         return self.instrs[0] \n      \n     def __hash__(self) -&gt; int: \n         return hash(self.label) \n     def __eq__(self, o: object) -&gt; bool: \n         if not isinstance(o, BasicBlock): \n             return False \n         return self.label == o.label \n     def __lt__(self, o: object) -&gt; bool: \n         if not isinstance(o, BasicBlock): \n             return False \n         # return block is always the last one \n         if self.label.label == RETURN_POINT_NAME: return False \n         if o.label.label == RETURN_POINT_NAME: return True \n         # entry block is always the first one \n         if self.label.label == ENTRY_POINT_NAME: return True \n         if o.label.label == ENTRY_POINT_NAME: return False \n         return self.label &lt; o.label \n  \n     def __str__(self): \n         if self.label.label in {ENTRY_POINT_NAME, RETURN_POINT_NAME}: return self.label.label \n         _instrs = '\\n  '.join([x.to_briltxt() for x in self.instrs[1:]]) \n         if _instrs: \n             _instrs = f\"\\n  {_instrs}\" \n         return f\"{self.label.to_briltxt()}{_instrs}\" \n     def __repr__(self): \n         return f\"{self.__class__.__name__} :: {self.label.to_briltxt()}..[{len(self.instrs) - 1}]\" \n\n\n\n3. Forming Basic Blocks from Bril Functions\n\nThe function iter_func_blocks generates basic blocks from the provided Bril script by iterating over each function in the script and forming blocks based on instruction labels.\nFor functions without explicit labels, it creates anonymous basic blocks.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n def iter_func_blocks(bs: bm.BrilScript) -&gt; Iterable[Tuple[bm.BrilFunction, List[BasicBlock]]]: \n     for each_func in bs.functions: \n         bbs: List[BasicBlock] = list() \n         anonymous_id = 0 \n         for each_block in form_blocks(each_func.instrs): \n             this_block_label: bm.BrilInstruction_Label = None \n             if isinstance(each_block[0], bm.BrilInstruction_Label): \n                 this_block_label = each_block[0] \n             else: \n                 this_block_label = bm.BrilInstruction_Label(dict(label='_f{}._anon{}'.format(fast_hash(each_func.name.encode()), anonymous_id))) \n                 anonymous_id += 1 \n             bbs.append(BasicBlock(this_block_label, each_block)) \n         yield (each_func, bbs) \n\n\n\n4. Generating the CFG\n\nThe generate_func_cfg_dict function builds the CFG by establishing the control flow between basic blocks. It adds entry and return blocks to represent the start and end points of a function.\nIt iterates over the blocks and updates the predecessors and successors based on control flow instructions (jmp, br, ret).\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n def generate_func_cfg_dict(bscript: bm.BrilScript) -&gt; Dict[bm.BrilFunction, List[BasicBlock]]: \n     app_bbs_dict: OrderedDict[bm.BrilFunction, List[BasicBlock]] = {} \n     for each_func, basic_blocks in iter_func_blocks(bscript): \n         # print(\"Function: {}\".format(each_func.name)) \n         entry_bb = BasicBlock(bm.BrilInstruction_Label(dict(label=ENTRY_POINT_NAME)), []) \n         return_bb = BasicBlock(bm.BrilInstruction_Label(dict(label=RETURN_POINT_NAME)), []) \n         prev_bb: Optional[BasicBlock] = None \n         is_first: bool = True \n         for each_bb in basic_blocks: \n             if prev_bb: \n                 # reason: fallthrough edge \n                 prev_bb.succ.add(each_bb) \n                 each_bb.pred.add(prev_bb) \n             elif is_first: \n                 # reason: entry edge \n                 entry_bb.succ.add(each_bb) \n                 each_bb.pred.add(entry_bb) \n                 is_first = False \n              \n             # get last instruction if exists \n             final_instr = each_bb.instrs[-1] if each_bb.instrs else None \n             if final_instr is None: \n                 # empty block, skip \n                 prev_bb = each_bb \n             elif final_instr.op in ['jmp', 'br']: \n                 # reaching control flow instruction \n                 for redirect_instr_to_bb_label in final_instr.labels: \n                     next_bb = next((bb for bb in basic_blocks if bb.label.label == redirect_instr_to_bb_label), None) \n                     if next_bb is None: \n                         raise ValueError(f\"Cannot find block with label {redirect_instr_to_bb_label}\") \n                     # reason: control flow edge \n                     each_bb.succ.add(next_bb) \n                     next_bb.pred.add(each_bb) \n                 prev_bb = None \n             elif final_instr.op in ['ret']: \n                 # reaching return instruction \n                 # reason: return edge \n                 each_bb.succ.add(return_bb) \n                 return_bb.pred.add(each_bb) \n                 prev_bb = None \n                 # explicit return block, no fallthrough \n             else: \n                 # normal instruction, prepare for fallthrough \n                 prev_bb = each_bb \n         # check if last block has no fallthrough \n         if prev_bb: \n             # reason: return edge \n             prev_bb.succ.add(return_bb) \n             return_bb.pred.add(prev_bb) \n         # add entry/return block \n         basic_blocks.insert(0, entry_bb) \n         basic_blocks.append(return_bb) \n         app_bbs_dict[each_func] = basic_blocks \n     return app_bbs_dict \n\n\n\n5. Computing Dominators\n\nThe generate_dom_dict function calculates the dominators for each block using an iterative fixed-point algorithm.\nInitially, every block is assumed to dominate itself and all others. The algorithm repeatedly refines the dominator sets by intersecting the dominator sets of each block’s predecessors.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n def generate_dom_dict(bbs: List[BasicBlock]) -&gt; dict[BasicBlock, set[BasicBlock]]: \n     # Initialize dominator sets for each block \n     # Initially, every block dominates every other block \n     dom: Dict[BasicBlock, Set[BasicBlock]] = {bb: set(bbs) for bb in bbs} \n     # The entry block only dominates itself \n     bb_entry = getBasicBlockByLabel(bbs, ENTRY_POINT_NAME) \n     dom[bb_entry] = set([bb_entry]) \n  \n     changed: bool = True \n     while changed: \n         changed = False \n         for each_bb in bbs: \n             if each_bb == bb_entry: continue \n             # The dominator set of a bb is the intersection of the dominator sets of its predecessors \n             this_bb_dom = set.intersection(*[dom[each_pred] for each_pred in each_bb.pred] or [set()]) \n             # The dominator set of a bb should includes itself \n             this_bb_dom.add(each_bb) \n             # Update if changed \n             if dom[each_bb] != this_bb_dom: \n                 dom[each_bb] = this_bb_dom \n                 changed = True \n     return dom \n\n\n\n6. Immediate Dominator Calculation\n\nThe get_lease_superset_dom function identifies the immediate dominator for a given block by finding the closest dominator in the dominator set.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n # get the last dom of a given block \n def get_lease_superset_dom(dom_dict: dict[BasicBlock, set[BasicBlock]], bb: BasicBlock) -&gt; Optional[BasicBlock]: \n     return next((test_dom for test_dom in dom_dict[bb] if ((dom_dict[bb] - dom_dict[test_dom]) == set([bb]))), None) \n\n\n\n7. Dominance Frontier Computation\n\nThe get_dom_frontier function determines the dominance frontier for a given block. It checks blocks where the dominance relationship changes based on control flow.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n # get the dom frontiers of a given block. (One-liner version, the well-commented version is hidden in previous commits) \n def get_dom_frontier(dom: Dict[BasicBlock, Set[BasicBlock]], bb: BasicBlock) -&gt; Set[BasicBlock]: \n     return set([test_with_bb for test_with_bb in dom.keys() if (bb not in dom[test_with_bb] or bb == test_with_bb) and (bb in set.union(*[dom[each_tbp] for each_tbp in test_with_bb.pred] or [set()]))]) \n\n\n\n8. Graph Visualization\n\nThe code includes helper functions for generating graph visualizations using Graphviz. The functions create_graphviz_dot_node and create_graphviz_dot_edge create nodes and edges for the CFG and dominator tree graphs.\nThe create_graphviz_dot function produces separate visualizations for the CFG and dominator tree.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n def create_graphviz_dot(app_graph: Dict[bm.BrilFunction, List[BasicBlock]]) -&gt; Tuple[gv.Digraph, gv.Digraph]: \n     dot_cfg = gv.Digraph('CFG', comment='Control Flow Graph') \n     dot_domt = gv.Digraph('DOMTREE', comment='Dominator Tree') \n     for each_func, bbs in app_graph.items(): \n         _func_show_str = str(each_func).replace('\\t', '  ') \n         print(f\" {_func_show_str} \".center(80, '=')) \n         dom = generate_dom_dict(bbs) \n         _max_bb_label_len = max([len(bb.label.label) for bb in bbs]) \n  \n         # each func is a subgraph \n         with dot_cfg.subgraph(name=f\"cluster_{each_func.name}\") as dot_cfg_func, dot_domt.subgraph(name=f\"cluster_{each_func.name}\") as dot_domt_func: \n             dot_cfg_func.attr(label=each_func.name) \n             dot_cfg_func.attr(color='#f7f7f7') \n             dot_cfg_func.attr(style='filled') \n             dot_cfg_func.attr(rankdir='TB') \n             dot_domt_func.attr(label=each_func.name) \n             dot_domt_func.attr(color='#f7f7f7') \n             dot_domt_func.attr(style='filled') \n             dot_domt_func.attr(rankdir='TB') \n  \n             print(\" Dom-Front \".center(80, '-')) \n             # generate cfg dot graph \n             for each_bb in bbs: \n                 dom_frontiers = get_dom_frontier(dom, each_bb) \n                 print(f\"{each_bb.label.label.ljust(_max_bb_label_len)} : {', '.join([x.label.label for x in sorted(dom_frontiers)])}\") \n                 create_graphviz_dot_node(dot_cfg_func, each_func, each_bb) \n                 for each_df in dom_frontiers: \n                     create_graphviz_dot_edge(dot_cfg_func, each_func, each_bb, each_df, style='dashed', color='#66ccff', label='DF', fontsize='10', fontcolor='#66ccff', constraint='false') \n                 for each_succ in each_bb.succ: \n                     create_graphviz_dot_edge(dot_cfg_func, each_func, each_bb, each_succ) \n  \n             # generate domt dot graph \n             print(\" Dom & Dom-Tree \".center(80, '-')) \n             for each_bb in dom.keys(): \n                 least_superset_dom = get_lease_superset_dom(dom, each_bb) \n                 print(f\"{each_bb.label.label.ljust(_max_bb_label_len)} &lt;- {(least_superset_dom.label.label if least_superset_dom else '[ROOT]').ljust(_max_bb_label_len)} : {', '.join([x.label.label for x in sorted(dom[each_bb])])}\") \n                 create_graphviz_dot_node(dot_domt_func, each_func, each_bb) \n                 if least_superset_dom: \n                     create_graphviz_dot_edge(dot_domt_func, each_func, least_superset_dom, each_bb) \n              \n             # print the script in briltxt format for reference \n             print(\" Script \".center(80, '-')) \n             for each_bb in bbs: \n                 for each_instr in each_bb.instrs: \n                     print( (\"\" if isinstance(each_instr, bm.BrilInstruction_Label) else \"  \") + each_instr.to_briltxt()) \n              \n             print() \n     return dot_cfg, dot_domt \n\n\n\n9. Main Execution\n\nThe script loads the specified Bril file and constructs the CFG for the functions in the script.\nIt then generates the dot files for the CFG and dominator tree, saving them in the specified directory.\n\n\n\nℹ️ View source code : EECE7398_ST_Compiler/HW4/dom_analysis.py @ 582ec4a.\n\n # %% \n # load the bril script \n bscript = bm.BrilScript(script_name=os.path.basename(DEMO_BRIL_FILE), file_dir=os.path.dirname(DEMO_BRIL_FILE)) \n print(bscript) \n app_graph: Dict[bm.BrilFunction, List[BasicBlock]] = generate_func_cfg_dict(bscript) \n # print(\"Functions: {}\".format(', '.join([f\"[{idx}]={x.name}\" for idx, x in enumerate(app_graph.keys())]))) \n  \n print() \n dot_cfg, dot_domt = create_graphviz_dot(app_graph) \n  \n if MUTE_OUTPUT: \n     exit(0) \n  \n # Finally, create the save directory if not exists, and save the generated dot files \n if not os.path.exists(SAVE_DIR): \n     os.makedirs(SAVE_DIR) \n  \n _gv_ret = dot_cfg.render(os.path.join(SAVE_DIR, bscript.script_name+\".cfg.gv\"), view=False) \n print(_gv_ret) \n _gv_ret = dot_domt.render(os.path.join(SAVE_DIR, bscript.script_name+\".domt.gv\"), view=False) \n print(_gv_ret) \n\n\n\n\nIntegration and Testing\nThe integration and testing phase focuses on verifying the correctness of the dominance analysis by evaluating its results against various test cases. The goal is to ensure that the dominance rules defined in the dominator tree are upheld for different basic block execution paths. This involves checking if any execution sequence violates the dominance relationships established by the analysis. To achieve this, the following steps are used:\n\nGeneral Testing Approach:\n\nThe basic and general idea of verification is to iterate over all possible paths of execution in the Control Flow Graph (CFG) and validate the dominance properties. Specifically, we ensure that if block BB1 dominates block BB2, then any execution path reaching BB2 must pass through BB1.\nFor each basic block, we confirm that its set of dominators conforms to the expectations as derived from the dominator tree.\nThe results are compared against reference outputs from well-understood examples discussed in class, as well as other edge cases designed to stress test the analysis.\nAll analysis output are checked manually, and stored as the golden snapshot using turnt toolchain. To test any modification, use command make turnt to submit a fast check if anything have changed.\n\nTest Cases:\n\nTo thoroughly validate the implementation, several test cases in .bril format are used, which cover a variety of CFG structures. These include:\n\nBranching and Merging: Simple branches where different paths converge into a single block. This tests if the dominance frontier is correctly identified.\nLoop Structures:\n\nNatural Loops: A basic loop where the execution repeatedly returns to the entry point. This checks if the analysis can handle back edges correctly.\nCross Loops: Where multiple loops share a common point, testing the algorithm’s handling of intertwined control flows.\nSelf-Loops: Where a block jumps to itself, testing the edge case of dominance with cyclic behavior.\n\nComplex Branches: Multi-level branching scenarios that test cascading decision-making processes.\nSelect Cases with Fallthrough: A switch-like structure where control can fall through to subsequent cases, testing non-trivial flow paths.\nCycle with/without Header: Examining cases where cycles may or may not have a designated entry block, testing the analysis of entry points and loop headers.\nMultiple Entry Points: CFGs with more than one entry point, challenging the assumptions about where execution begins.\n\n\nTesting Execution:\n\nEach test case is analyzed using the implemented dominance utilities, and the results are compared against expected outputs derived manually or from reference solutions provided in class.\nThe verification process involves:\n\nDominators Check: Ensuring that for each block BB1, its dominator set only contains blocks that dominate BB1 as per the expected results.\nImmediate Dominators Check: Validating the immediate dominator for each block against the reference dominator tree structure.\nDominance Frontier Check: Confirming that the dominance frontier of each block matches the expected set of blocks where the dominance relationship changes.\n\n\n\n\n\nResults and Analysis\n👉 Check HERE to see all graphical testcase results.\nThe analysis results demonstrate the correctness and robustness of the dominance utilities. The generated dominance information (dominator sets, dominator tree, and dominance frontier) matches the expected results for all test cases. Below is a summary of the findings:\n\nBranching and Merging:\n\nThe dominance analysis correctly identifies the blocks that dominate each branch and accurately determines the dominance frontiers where paths converge. \n\n\n\n\nℹ️ View log : Natural-Loops.golden-log @ 16fcb67.\n\n BrilScript ::  Natural-Loops.bril &lt;1 func&gt; @ example/in_class_example_dom \n  \n ================ BrilFunction ::  main (  ) -&gt; None: &lt;14 instr&gt; ================ \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY  :  \n entry  :  \n loop   : loop \n if     : loop \n then   : endif \n else   : endif \n endif  : loop \n exit   :  \n RETURN :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY  &lt;- [ROOT] : ENTRY \n entry  &lt;- ENTRY  : ENTRY, entry \n loop   &lt;- entry  : ENTRY, entry, loop \n if     &lt;- loop   : ENTRY, entry, if, loop \n then   &lt;- if     : ENTRY, entry, if, loop, then \n else   &lt;- if     : ENTRY, else, entry, if, loop \n endif  &lt;- if     : ENTRY, endif, entry, if, loop \n exit   &lt;- loop   : ENTRY, entry, exit, loop \n RETURN &lt;- exit   : ENTRY, entry, exit, loop, RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n .entry: \n   jmp  .loop; \n .loop: \n   br cond .if .exit; \n .if: \n   br cond .then .else; \n .then: \n   jmp  .endif; \n .else: \n   jmp  .endif; \n .endif: \n   jmp  .loop; \n .exit: \n   ret ; \n .RETURN: \n\n\nLoop Structures:\n\nNatural Loops: The algorithm successfully handles back edges and identifies the loop entry points as dominators for the loop body.\nCross Loops and Multiple Entry Points: The implementation accurately distinguishes between blocks that dominate each shared section, even when the control flow is complex.\nSelf-Loops: Dominance analysis treats the block as dominating itself, which is correctly identified in the results. \n\n\n\n\nℹ️ View log : Cycle-with-Header-One-Entry-Point.golden-log @ 16fcb67.\n\n BrilScript ::  Cycle-with-Header-One-Entry-Point.bril &lt;1 func&gt; @ example/in_class_example_dom \n  \n ================ BrilFunction ::  main (  ) -&gt; None: &lt;12 instr&gt; ================ \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY  :  \n entry  :  \n H1     : H1 \n A      : H1 \n H2     : H1, H2 \n B      : H1, H2 \n exit   :  \n RETURN :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY  &lt;- [ROOT] : ENTRY \n entry  &lt;- ENTRY  : ENTRY, entry \n H1     &lt;- entry  : ENTRY, H1, entry \n A      &lt;- H1     : ENTRY, A, H1, entry \n H2     &lt;- A      : ENTRY, A, H1, H2, entry \n B      &lt;- H2     : ENTRY, A, B, H1, H2, entry \n exit   &lt;- H1     : ENTRY, H1, entry, exit \n RETURN &lt;- exit   : ENTRY, H1, entry, exit, RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n .entry: \n   jmp  .H1; \n .H1: \n   br if_cond .A .exit; \n .A: \n   jmp  .H2; \n .H2: \n   br cond .B .H1; \n .B: \n   br cond .H2 .H1; \n .exit: \n   ret ; \n .RETURN: \n\n\n\nℹ️ View log : Cycle-without-Header-Two-Entry-Points.golden-log @ 16fcb67.\n\n BrilScript ::  Cycle-without-Header-Two-Entry-Points.bril &lt;1 func&gt; @ example/in_class_example_dom \n  \n ================ BrilFunction ::  main (  ) -&gt; None: &lt;8 instr&gt; ================= \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY  :  \n entry  :  \n if     :  \n loop2  : loop1 \n loop1  : loop2 \n RETURN :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY  &lt;- [ROOT] : ENTRY \n entry  &lt;- ENTRY  : ENTRY, entry \n if     &lt;- entry  : ENTRY, entry, if \n loop2  &lt;- if     : ENTRY, entry, if, loop2 \n loop1  &lt;- if     : ENTRY, entry, if, loop1 \n RETURN &lt;- [ROOT] : RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n .entry: \n   jmp  .if; \n .if: \n   br cond .loop1 .loop2; \n .loop2: \n   jmp  .loop1; \n .loop1: \n   jmp  .loop2; \n .RETURN: \n\n\nComplex Branches and Fallthrough Cases:\n\nFor cases with multiple branches and fallthrough behavior, the dominance frontier calculation correctly identifies the regions where the execution paths merge.\nThis indicates that the implementation can handle cases where control flow does not follow a simple pattern, such as switch statements with fallthrough. \n\n\n\n\nℹ️ View log : Branch-Another-Example.golden-log @ 16fcb67.\n\n BrilScript ::  Branch-Another-Example.bril &lt;1 func&gt; @ example/in_class_example_dom \n  \n ================ BrilFunction ::  main (  ) -&gt; None: &lt;10 instr&gt; ================ \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY  :  \n n1     :  \n n2     : n2 \n n3     : n5 \n n4     : n5 \n n5     : n2 \n RETURN :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY  &lt;- [ROOT] : ENTRY \n n1     &lt;- ENTRY  : ENTRY, n1 \n n2     &lt;- n1     : ENTRY, n1, n2 \n n3     &lt;- n2     : ENTRY, n1, n2, n3 \n n4     &lt;- n2     : ENTRY, n1, n2, n4 \n n5     &lt;- n2     : ENTRY, n1, n2, n5 \n RETURN &lt;- [ROOT] : RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n .n1: \n   jmp  .n2; \n .n2: \n   br cond1 .n3 .n4; \n .n3: \n   jmp  .n5; \n .n4: \n   jmp  .n5; \n .n5: \n   jmp  .n2; \n .RETURN: \n\n\n\nℹ️ View log : Branch-Complex-Example.golden-log @ 16fcb67.\n\n BrilScript ::  Branch-Complex-Example.bril &lt;1 func&gt; @ example/in_class_example_dom \n  \n ================ BrilFunction ::  main (  ) -&gt; None: &lt;18 instr&gt; ================ \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY  :  \n n0     :  \n n5     : n4, n8 \n n1     : n4, n8 \n n7     : n8 \n n6     : n4 \n n2     : n4 \n n4     : n8 \n n3     : n8 \n n8     :  \n RETURN :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY  &lt;- [ROOT] : ENTRY \n n0     &lt;- ENTRY  : ENTRY, n0 \n n5     &lt;- n0     : ENTRY, n0, n5 \n n1     &lt;- n0     : ENTRY, n0, n1 \n n7     &lt;- n5     : ENTRY, n0, n5, n7 \n n6     &lt;- n5     : ENTRY, n0, n5, n6 \n n2     &lt;- n1     : ENTRY, n0, n1, n2 \n n4     &lt;- n0     : ENTRY, n0, n4 \n n3     &lt;- n1     : ENTRY, n0, n1, n3 \n n8     &lt;- n0     : ENTRY, n0, n8 \n RETURN &lt;- n8     : ENTRY, n0, n8, RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n .n0: \n   br cond1 .n5 .n1; \n .n5: \n   br cond2 .n7 .n6; \n .n1: \n   br cond3 .n2 .n3; \n .n7: \n   jmp  .n8; \n .n6: \n   jmp  .n4; \n .n2: \n   jmp  .n4; \n .n4: \n   jmp  .n8; \n .n3: \n   jmp  .n8; \n .n8: \n   ret ; \n .RETURN: \n\n\nOther Edge Cases:\n\nTests involving cycles without a clear header, and cases with two or more entry points, show that the analysis correctly computes dominators based on the actual paths from any entry to each block.\nThe results reveal that the dominance utilities can generalize beyond typical loop constructs, making them suitable for analyzing diverse control flow patterns.\n\nOther Real Benchmarks: \n\n\n\nℹ️ View log : in_class_example_1.golden-log @ 16fcb67.\n\n BrilScript ::  in_class_example_1.bril &lt;2 func&gt; @ example/in_class_example_df \n  \n ==== BrilFunction ::  in_class_example_1 ( input&lt;int&gt; ) -&gt; None: &lt;33 instr&gt; ==== \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY             :  \n _ffb1._anon0      :  \n assign_input_to_x :  \n is_x_gt_1         : is_x_gt_1 \n loop_start        : is_x_gt_1 \n is_y_gt_3         : is_x_gt_1 \n y_gt_3            : loop_cont1 \n loop_cont1        : is_x_gt_1 \n is_z_gt_0         : is_x_gt_1 \n z_gt_0            : loop_cont2 \n loop_cont2        : is_x_gt_1 \n print_output      :  \n RETURN            :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY             &lt;- [ROOT]            : ENTRY \n _ffb1._anon0      &lt;- ENTRY             : ENTRY, _ffb1._anon0 \n assign_input_to_x &lt;- _ffb1._anon0      : ENTRY, _ffb1._anon0, assign_input_to_x \n is_x_gt_1         &lt;- assign_input_to_x : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1 \n loop_start        &lt;- is_x_gt_1         : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, loop_start \n is_y_gt_3         &lt;- loop_start        : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, is_y_gt_3, loop_start \n y_gt_3            &lt;- is_y_gt_3         : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, is_y_gt_3, loop_start, y_gt_3 \n loop_cont1        &lt;- is_y_gt_3         : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, is_y_gt_3, loop_cont1, loop_start \n is_z_gt_0         &lt;- loop_cont1        : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, is_y_gt_3, is_z_gt_0, loop_cont1, loop_start \n z_gt_0            &lt;- is_z_gt_0         : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, is_y_gt_3, is_z_gt_0, loop_cont1, loop_start, z_gt_0 \n loop_cont2        &lt;- is_z_gt_0         : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, is_y_gt_3, is_z_gt_0, loop_cont1, loop_cont2, loop_start \n print_output      &lt;- is_x_gt_1         : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, print_output \n RETURN            &lt;- print_output      : ENTRY, _ffb1._anon0, assign_input_to_x, is_x_gt_1, print_output, RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n ._ffb1._anon0: \n   zero: int = const 0; \n   one: int = const 1; \n   two: int = const 2; \n   three: int = const 3; \n   four: int = const 4; \n   x: int = const 0; \n   y: int = const 0; \n   z: int = const 0; \n .assign_input_to_x: \n   x: int = id input; \n .is_x_gt_1: \n   cond1: bool = gt x one; \n   br cond1 .loop_start .print_output; \n .loop_start: \n   y: int = div x two; \n .is_y_gt_3: \n   cond2: bool = gt y three; \n   br cond2 .y_gt_3 .loop_cont1; \n .y_gt_3: \n   x: int = sub x y; \n .loop_cont1: \n   z: int = sub x four; \n .is_z_gt_0: \n   cond3: bool = gt z zero; \n   br cond3 .z_gt_0 .loop_cont2; \n .z_gt_0: \n   x: int = div x two; \n .loop_cont2: \n   z: int = sub z one; \n   jmp  .is_x_gt_1; \n .print_output: \n   print x; \n   ret ; \n .RETURN: \n  \n ================ BrilFunction ::  main (  ) -&gt; None: &lt;2 instr&gt; ================= \n ---------------------------------- Dom-Front ----------------------------------- \n ENTRY        :  \n _f0d6._anon0 :  \n RETURN       :  \n -------------------------------- Dom & Dom-Tree -------------------------------- \n ENTRY        &lt;- [ROOT]       : ENTRY \n _f0d6._anon0 &lt;- ENTRY        : ENTRY, _f0d6._anon0 \n RETURN       &lt;- _f0d6._anon0 : ENTRY, _f0d6._anon0, RETURN \n ------------------------------------ Script ------------------------------------ \n .ENTRY: \n ._f0d6._anon0: \n   input: int = const 10; \n   call in_class_example_1; \n .RETURN: \n\n* Check HERE to see all graphical test case results. ** Check HERE to see all golden snapshots.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 4: Dominance"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html#conclusion",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW4.html#conclusion",
    "title": "Homework 4: Dominance",
    "section": "Conclusion",
    "text": "Conclusion\nDominance analysis is a key part of CFG-based optimizations in compilers. It involves: - Identifying dominators to understand the flow of control. - Using the immediate dominator to build the dominator tree. - Computing the dominance frontier to manage variable merging.\nThese concepts enable powerful optimizations and transformations that improve program efficiency and correctness. In the following sections, we will explore how to implement dominance analysis in a compiler framework, test the correctness of the results, and apply these concepts to optimize real programs.\nThe integration and testing of the dominance analysis show that the implementation is reliable and performs well across a range of control flow scenarios. By comparing the analysis results with known references and carefully designed test cases, we ensure the correctness of the dominator tree construction and dominance frontier calculations.\nThe next steps involve using this verified dominance analysis for further compiler optimizations, such as SSA form conversion, dead code elimination, and loop-invariant code motion, leveraging the dominance relationships identified in this phase.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 4: Dominance"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html",
    "title": "Homework 3: Data Flow",
    "section": "",
    "text": "This assignment focuses on implementing dataflow analysis for the Bril intermediate language to support three major analyses: liveness, availability, and busy expressions. These analyses play a crucial role in various compiler optimizations, including Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN) that we discussed and implemented in previous homework, HW2. The goal is to analyze the flow of data within a program, identify redundant or unnecessary computations, and determine which values are still “live” or “in use” at various points in a program.\nThe report details the design of a flexible framework for these analyses, the implementation strategy for each type of dataflow analysis, and the use of visualization to display the results. The integration and testing process ensures the framework’s correctness through various benchmark tests, and the results are analyzed to demonstrate its effectiveness.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#introduction",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#introduction",
    "title": "Homework 3: Data Flow",
    "section": "",
    "text": "This assignment focuses on implementing dataflow analysis for the Bril intermediate language to support three major analyses: liveness, availability, and busy expressions. These analyses play a crucial role in various compiler optimizations, including Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN) that we discussed and implemented in previous homework, HW2. The goal is to analyze the flow of data within a program, identify redundant or unnecessary computations, and determine which values are still “live” or “in use” at various points in a program.\nThe report details the design of a flexible framework for these analyses, the implementation strategy for each type of dataflow analysis, and the use of visualization to display the results. The integration and testing process ensures the framework’s correctness through various benchmark tests, and the results are analyzed to demonstrate its effectiveness.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#interactive-demo",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#interactive-demo",
    "title": "Homework 3: Data Flow",
    "section": "Interactive Demo",
    "text": "Interactive Demo\n\n\n\n 🚧 Use the link HERE if not showing",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#detail-design",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#detail-design",
    "title": "Homework 3: Data Flow",
    "section": "Detail Design",
    "text": "Detail Design\nCheck EECE7398_ST_Compiler/HW3 for source code.\n\nAbstraction Classes\nThe abstraction class remain the same structure as last homework submittion, see detail in HW2 - Abstraction Classes.\nI add some additional features and fix something like __repr__ for some of the classes, therefore use current ./bril_model for further development.\n\n\nGraph Result Demonstration\nSince this task is about analizing some properties of the data-flow graph, a better way to demonstrate it clear and straight forward is to show the computated result in visual format. I developed the framework to view analyze results using vis.js and networkx.\n\n\n🚧 Expand HERE for HD Video\n\n\n\n\n\n\n\n\n\n\nDataflow Analysis Implementation\nThe script df_analysis.py performs dataflow analysis on Bril programs, supporting three types of analysis: liveness, availability, and busy expressions. The implementation is designed to be generic, allowing for easy extension to other types of dataflow analysis with minimal code changes.\n\n\n1. Argument Parsing and Setup\nThe script begins by utilizing the argparse module to handle command-line argument parsing. This allows the user to specify three key arguments when running the script:\n\nANALYSIS: Specifies the type of dataflow analysis to perform. The valid options are 'liveness', 'availability', or 'busy'. This argument is required and ensures the script knows what kind of analysis to perform on the Bril program.\nDEMO_BRIL_FILE: This is the path to the Bril program that will be analyzed. The file contains the intermediate representation (IR) of the program.\n--save-dir: An optional argument that specifies where to save the generated output HTML files (visualizations). If not provided, the default directory ./save is used.\n\nBy parsing these arguments, the script can dynamically handle different types of analysis and ensure the correct files are processed and results saved to the right locations.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 20 to 25\n import argparse \n parser = argparse.ArgumentParser(description='Generate data flow graph for a bril script') \n parser.add_argument('ANALYSIS', type=str, help='Analysis: [liveness, availability, busy]') \n parser.add_argument('DEMO_BRIL_FILE', type=str, help='Path to the bril file') \n parser.add_argument('--save-dir', type=str, default='./save', help='Path to save the generated html files') \n args = parser.parse_args() \n\n\n\n2. Validation of Arguments\nOnce the arguments are parsed, the script proceeds to validate them:\n\nANALYSIS: The provided value is converted to lowercase for consistency. The script checks whether the specified analysis type is one of the allowed options: 'liveness', 'availability', or 'busy'. If the user specifies an unsupported analysis, the script prints an error message and exits.\nDEMO_BRIL_FILE: The script checks if the provided file path exists on the system. If not, an error message is displayed, and the script terminates.\nIf all validations pass, the script proceeds with the execution; otherwise, it prints the usage information (parser.print_help()) to guide the user on how to run the script correctly.\n\nThis ensures that only valid input and analysis types are processed.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 27 to 43\n ANALYSIS = args.ANALYSIS.lower() \n DEMO_BRIL_FILE = args.DEMO_BRIL_FILE \n # how to get the save-dir value \n SAVE_DIR = args.save_dir \n  \n # make sure args are allowed \n correct = True \n if ANALYSIS not in ['liveness', 'availability', 'busy']: \n     print(f\"Analysis &lt;{ANALYSIS}&gt; not supported\") \n     correct = False \n if not os.path.exists(DEMO_BRIL_FILE): \n     print(f\"File &lt;{DEMO_BRIL_FILE}&gt; not found\") \n     correct = False \n if not correct: \n     # print help and exit \n     parser.print_help() \n     exit(1) \n\n\n\n3. Loading the Bril Script\nThe script loads the Bril program into a BrilScript object, which represents the structure of the input program. This object provides an abstraction over the Bril instructions and functions, making it easier to manipulate and analyze.\n\nThe BrilScript object is initialized with the name of the file, and the control flow graph (CFG) for each function in the Bril script is constructed. The CFG represents how control flows between basic blocks (sequences of instructions without branches) in each function, which is crucial for performing dataflow analysis.\napp_graph is a dictionary that maps each BrilFunction to a tuple consisting of a networkx directed graph (the CFG) and a mapping of labels to their corresponding instructions.\n\nThe CFG provides the foundation for performing various types of dataflow analysis, as it organizes the program’s structure into a form that can be traversed and analyzed.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 135 to 137\n bbs = bm.BrilScript(script_name=os.path.basename(DEMO_BRIL_FILE), file_dir=os.path.dirname(DEMO_BRIL_FILE)) \n app_graph: Dict[bm.BrilFunction, Tuple[nx.DiGraph, Dict[bm.BrilInstruction_Label, List[bm.BrilInstruction]]]] = {} \n update_to_graph(bbs, app_graph) \n\n\n\n4. Generating GEN, KILL, and EXPR Sets\nFor each basic block, the script calculates three sets:\n\nGEN: The set of variables used before being assigned a new value in the block. These are the variables that “generate” dependencies in the block.\nKILL: The set of variables that are redefined or “killed” within the block.\nEXPR: The set of expressions that are still available at the end of the block.\n\nThe function get__args_used_before_assign__assigned__calc_expr_available_at_bb_end iterates over the instructions in a basic block. It collects the following information: - used_first: Variables that are used before any assignment in the block. - written: Variables that are assigned new values within the block. - avail_exprs: Expressions that remain available for future use at the end of the block, ensuring that they haven’t been invalidated by any assignments.\nThe GEN, KILL, and EXPR sets are essential for performing dataflow analysis like liveness and availability, which rely on tracking how variables and expressions evolve over the program.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 150 to 168\n def get__args_used_before_assign__assigned__calc_expr_available_at_bb_end(instrs: List[bm.BrilInstruction]) -&gt; Tuple[Set[str],Set[str],Set[Expr]]: \n     \"\"\" \n     Given a list of instructions, return the set of variables that are used before defined and the set of variables that are modified. \n     This is from HW2, but modified to return the sets instead of printing them. \n     \"\"\" \n     used_first: Set[str] = set() \n     written: Set[str] = set() \n     avail_exprs: Set[Expr] = set() \n     for instr in instrs: \n         used_first.update(set(instr.args if instr.args else []) - written) \n         if instr.dest: \n             # check if the dest was used in generating any of the expressions, if so, remove it from exprs \n             for expr in list(avail_exprs): \n                 if instr.dest in expr.args: \n                     avail_exprs.remove(expr) \n             written.add(instr.dest) \n             if instr.args and instr.op not in ['id', 'const', 'call']: \n                 avail_exprs.add(Expr(instr.op, instr.args)) \n     return used_first, written, avail_exprs \n\n\n\n5. Updating GEN, KILL, and EXPR Sets\nAfter calculating the GEN, KILL, and EXPR sets for each basic block, the script updates the CFG with this information. The update_gen_kill_sets function iterates over each node (basic block) in the CFG and stores the calculated GEN, KILL, and EXPR sets in the node’s attributes.\nThis step enriches the CFG with the necessary dataflow information, setting up the foundation for more complex analyses like determining which variables are live or which expressions are available.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 173 to 180\n def update_gen_kill_sets(app_graph: Dict[bm.BrilFunction, Tuple[nx.DiGraph, Dict[bm.BrilInstruction_Label, List[bm.BrilInstruction]]]]): \n     for _, (fdg, _) in app_graph.items(): \n         for each_node, each_node_data in fdg.nodes(data=True): \n             each_block: List[bm.BrilInstruction] = each_node_data.get('instructions', None) \n             _gen, _kill, _expr = gen_kill_expr_sets(each_block) if each_block else (set(), set(), set()) \n             fdg.nodes[each_node]['GEN'] = _gen \n             fdg.nodes[each_node]['KILL'] = _kill \n             fdg.nodes[each_node]['EXPR'] = _expr \n\n\n\n6. Generic Dataflow Analysis\nThe script defines a generic dataflow analysis function _fdg_update_bare_bone, which can be adapted for different types of analyses (liveness, availability, busy expressions). This function operates by traversing the CFG and updating the IN and OUT sets of each node (basic block):\n\nIN: The set of variables or expressions that are live or available at the entry to a basic block.\nOUT: The set of variables or expressions that are live or available at the exit of a basic block.\n\nThe function takes as input a specific analysis function (e.g., for liveness or availability) and applies it to update the IN and OUT sets for each node. The function also checks whether the IN and OUT sets change during the analysis—if they do, it indicates that the dataflow information has propagated, and further iterations are required.\nThe generic nature of this function minimizes code duplication and allows the script to easily switch between different types of analyses.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 202 to 213\n def _fdg_update_bare_bone(specific_analysis_func: Callable[[nx.DiGraph, str], Tuple[Set[str], Set[str]]], fdg: nx.DiGraph) -&gt; bool: \n     # here we extract the common part of the analysis \n     has_changed = False \n     for this_node, _ in fdg.nodes(data=True): \n         _print_this_node_name = this_node.replace('\\n', '\\\\n') \n         _in, _out = specific_analysis_func(fdg, this_node) \n         print(f\"Node: {_print_this_node_name}, IN: {_in}, OUT: {_out}\") \n         if _in != _get_node_in_set(fdg, this_node) or _out != _get_node_out_set(fdg, this_node): \n             fdg.nodes[this_node]['IN'] = _in \n             fdg.nodes[this_node]['OUT'] = _out \n             has_changed = True \n     return has_changed \n\n\n\n7. Specific Analysis Functions\nThe script defines specific analysis functions for each type of dataflow analysis:\n\nLiveness Analysis: Computes the IN and OUT sets based on the liveness of variables. It updates the sets by looking at the successors of each node and determining which variables are still live at the entry of a basic block.\nAvailability Analysis: Determines which expressions are available at the entry and exit of a block. It considers the predecessor nodes and checks whether the expressions remain valid by avoiding any variables that were killed in the block.\nBusy Expressions Analysis: Identifies which expressions must be computed before reaching the next use of a variable. This analysis is useful for identifying common subexpressions that can be optimized.\n\nEach function is passed to the generic _fdg_update_bare_bone function to perform the corresponding analysis.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 215 to 258\n def _fdg_update_internal_liveness_sets(fdg: nx.DiGraph, this_node: str) -&gt; Tuple[Set[str], Set[str]]: \n     \"\"\" \n         this.gen = {v | v is used before defined here} \n         this.kill = {v | v is assigned here} \n         IN = this.gen + (OUT - this.kill) \n         OUT = union(successors' IN) \n     \"\"\" \n     _print_this_node_name = this_node.replace('\\n', '\\\\n') \n     _temp_succ_req = [_get_node_in_set(fdg, each_succ_node) for each_succ_node in _get_node_succ_set(fdg, this_node)] \n     _out: Set[str] = set.union(*_temp_succ_req) if _temp_succ_req else set() \n     print(f\"Node: {_print_this_node_name}, Succ: {_get_node_succ_set(fdg, this_node)}=&gt;{_temp_succ_req}, OUT: {_out}\") \n     _in: Set[str] = set.union(_get_node_gen_set(fdg, this_node), set.difference(_out, _get_node_kill_set(fdg, this_node))) \n     return _in, _out \n  \n def _fdg_update_internal_availability_sets(fdg: nx.DiGraph, this_node: str) -&gt; Tuple[Set[Expr], Set[Expr]]: \n     \"\"\" \n         this.exprs = {e | e is available at the end of the block} \n         IN = intersection(predeccessors' OUT) \n         OUT = (IN + this.exprs) - OUT(expr: any(var modified here exist in expr)) \n     \"\"\" \n     _print_this_node_name = this_node.replace('\\n', '\\\\n') \n     _temp_pred_give = [_get_node_out_set(fdg, each_pred_node) for each_pred_node in _get_node_pred_set(fdg, this_node)] \n     _in: Set[Expr] = set.intersection(*_temp_pred_give) if _temp_pred_give else set() \n     print(f\"Node: {_print_this_node_name}, Pred: {_get_node_pred_set(fdg, this_node)}=&gt;{_temp_pred_give}, IN: {_in}\") \n     # gatter all exprs that were computed before the end of this block  \n     _out: Set[Expr] = set.union(_get_node_in_set(fdg, this_node), _get_node_expr_set(fdg, this_node)) \n     # remove such expr that include variables that were modified in this block \n     _out = set([each_expr for each_expr in _out if not set.intersection(set(each_expr.args), _get_node_kill_set(fdg, this_node))]) \n     return _in, _out \n  \n def _fdg_update_internal_busy_sets(fdg: nx.DiGraph, this_node: str) -&gt; Tuple[Set[Expr], Set[Expr]]: \n     \"\"\" \n         IN = (OUT - OUT(expr: any(var modified here exist in expr)) + this.exprs \n         OUT = intersection(successors' IN) \n     \"\"\" \n     _print_this_node_name = this_node.replace('\\n', '\\\\n') \n     _temp_succ_req = [_get_node_in_set(fdg, each_succ_node) for each_succ_node in _get_node_succ_set(fdg, this_node)] \n     _out: Set[Expr] = set.intersection(*_temp_succ_req) if _temp_succ_req else set() \n     print(f\"Node: {_print_this_node_name}, Succ: {_get_node_succ_set(fdg, this_node)}=&gt;{_temp_succ_req}, OUT: {_out}\") \n     # remove such expr that include variables that were modified in this block \n     _in: Set[Expr] = set([each_expr for each_expr in _out if not set.intersection(set(each_expr.args), _get_node_kill_set(fdg, this_node))]) \n     # add all exprs that are computed in this block \n     _in = set.union(_in, _get_node_expr_set(fdg, this_node)) \n     return _in, _out \n\n\n\n8. Running the Analysis\nThe update_analysis_sets function orchestrates the execution of the selected analysis. Based on the user’s input (liveness, availability, or busy), the corresponding analysis function is retrieved from a mapping (ANALYSIS_FUNC).\nThe analysis is executed iteratively, updating the CFG with the calculated IN and OUT sets until no further changes occur. This iterative approach is necessary because dataflow analysis typically involves propagating information through the CFG until a fixed point is reached (i.e., the point where further iterations don’t change the dataflow sets).\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 266 to 277\n def update_analysis_sets(analysis_type_str: str , app_graph: Dict[bm.BrilFunction, Tuple[nx.DiGraph, Dict[bm.BrilInstruction_Label, List[bm.BrilInstruction]]]]): \n     analysis_func = ANALYSIS_FUNC.get(analysis_type_str, None) \n     if not analysis_func: \n         print(f\"Analysis &lt;{analysis_type_str}&gt; not supported\") \n         return \n     has_changed = True \n     while has_changed: \n         has_changed = False \n         print(f\"Updating {analysis_type_str} sets\") \n         for _, (fdg, _) in app_graph.items(): \n             has_changed |= _fdg_update_bare_bone(analysis_func, fdg) \n         print() \n\n\n\n9. Visualization\nThe script concludes by generating a visual representation of the CFG using the pyvis library. It creates an interactive HTML file that displays the CFG along with the computed IN, OUT, GEN, KILL, and EXPR sets for each basic block.\n\nThe dump_into_pv_graph function takes the CFG as input and converts it into a visual format. For each node (basic block) in the CFG, the IN, OUT, GEN, KILL, and EXPR sets are formatted as strings and added as attributes to the node in the visualization.\nThe visualization allows users to interact with the CFG, inspect the dataflow information for each node, and understand the results of the analysis in a more intuitive manner.\n\nThis final step provides a clear and accessible way to verify the results of the analysis.\nEECE7398_ST_Compiler(601e0e9) :: HW3/df_analysis.py :: Lines 318 to 376\n     for node in net.nodes: \n         node['IN'] = _in = generate_set_str(node.pop('IN', set())) \n         node['OUT'] = _out = generate_set_str(node.pop('OUT', set())) \n         node['GEN'] = _gen = generate_set_str(node.pop('GEN', set())) \n         node['KILL'] = _kill = generate_set_str(node.pop('KILL', set())) \n         node['EXPR'] = _expr = generate_set_str([str(x) for x in node.pop('EXPR', set())]) \n  \n         node['title'] = '' \n         if 'instructions' in node: \n             # remove 'data' key from node, and set 'title' key to the string representation of the data \n             node['title'] = \"\\n  \".join([obj.to_briltxt() if hasattr(obj, 'to_briltxt') else str(obj) for obj in node.pop('instructions', [])]) \n             node['shape'] = 'box' \n         node['title'] += \"\\n\" \n         node['title'] += f\"\\nGEN: { _gen }\" \n         node['title'] += f\"\\nKILL: { _kill }\" \n         node['title'] += f\"\\nEXPR: { _expr }\" \n         node['title'] += f\"\\nIN: { _in }\" \n         node['title'] += f\"\\nOUT: { _out }\" \n  \n         # title layout change (word replace): \n         #  strip: remove leading/trailing spaces, tabs, newlines, and carriage returns \n         #  double return -&gt; dash line \n         #  double space -&gt; full corner single space \n         node['title'] = node['title'].strip(' \\t\\n\\r').replace('\\n\\n', '\\n--------\\n').replace('  ', '\\u3000') \n  \n         # node['label'] = f\"IN: {_in}\" + '\\n' + node['label'] + '\\n' + f\"OUT: {_out}\" \n  \n         if node['id'] in (ENTRY_POINT_NAME, RETURN_POINT_NAME): \n             node['color'] = 'grey' \n             node['shape'] = 'circle' \n  \n     for edge in net.edges: \n         _reason = edge.pop('reason', None) \n         if _reason: \n             edge['label'] = _reason \n         _src_node, _dst_node = _get_node_by_name(edge['from']), _get_node_by_name(edge['to']) \n         if _src_node and _dst_node and 'OUT' in _src_node and 'IN' in _dst_node: \n             src_id, src_out, dst_id, dst_in = _src_node['id'], _src_node['OUT'], _dst_node['id'], _dst_node['IN'] \n             if src_out == CONST_EMPTY_STR: src_out = dst_in \n             if dst_in == CONST_EMPTY_STR: dst_in = src_out \n             new_label = f\"{src_id}.OUT:{src_out}\\n{dst_id}.IN:{dst_in}\" if src_out != dst_in else src_out \n             edge['title'] = edge.get('title', \"\") + edge.get('label', \"\")  # move label to popup title \n             edge['label'] = new_label  # set new label \n      \n     return net \n  \n # Safe linux fs name \n safe_fs_name = lambda raw_string: \"\".join(c if c.isalnum() or c in (' ', '.', '_') else '_' for c in raw_string) \n  \n for each_func in bbs.functions: \n     # Remove illegal characters for Linux filesystem \n     save_dir = os.path.join(SAVE_DIR, safe_fs_name(bbs.script_name), ANALYSIS) \n     save_file = f\"{safe_fs_name(each_func.name)}.html\" \n     # get the function directed graph \n     fdg, _ = app_graph.get(each_func) \n     # mkdir -p ./save_dir \n     os.makedirs(f\"./{save_dir}\", exist_ok=True) \n     # save to html \n     dump_into_pv_graph(fdg).save_graph(os.path.join(save_dir, save_file)) \n\n\n\n\nConclusion\nThe script of df_analysis.py provides a flexible and extensible framework for performing dataflow analysis on Bril programs. By defining generic functions and specific analysis functions, it minimizes code duplication and allows for easy addition of new analysis types. The visualization step helps in understanding the results of the analysis by generating an interactive HTML representation of the CFG.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#integration-and-testing",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#integration-and-testing",
    "title": "Homework 3: Data Flow",
    "section": "Integration and Testing",
    "text": "Integration and Testing\nThe integration of the optimizations was done manually and thoroughly tested to ensure correctness. Testing was carried out using both class examples and official test cases from the Bril repository.\nManual Testing: To validate the correctness of the dataflow analysis, I manually executed the script on several examples provided during class lectures. This helped confirm that the basic dataflow functionality (liveness, availability, and busy expression analysis) was functioning as expected. To test each step of the workflow, use the playground.ipynb to break between steps and check output of each cell.\nClass Examples: I tested the implementation with in-class examples, which serve as benchmarks for the expected output of liveness and availability analysis. Each example was carefully compared with the correct CFG and dataflow analysis results.\nBril Benchmark Tests: Additionally, I tested the system on Bril’s official dataflow test cases found in bril/examples/test/df/*.bril. These benchmark examples cover edge cases and typical control flow scenarios, further ensuring the robustness of the implementation.\nOther Benchmarks: Beyond the standard tests, I applied the analysis to select benchmarks from bril/benchmarks/core. These more complex scenarios helped confirm that the system could scale effectively while maintaining correct results.\nAcross all test cases, the output CFGs and the results of liveness, availability, and busy expressions analysis were consistent with the expected behavior. No discrepancies were found during manual inspection or benchmark comparisons.\nBTW, to rerun all results that I submitted to this repo, just simply use make.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#results-and-analysis",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#results-and-analysis",
    "title": "Homework 3: Data Flow",
    "section": "Results and Analysis",
    "text": "Results and Analysis\nTo make life easier, the Bril scripts that are tested in this HW are copied/created in the ./example folder. The three types of dataflow analyses (liveness, availability, busy) were tested on the following :\n\nbirthday.bril\ncheck-primes.bril\ncond-args.bril\ncond.bril\nfact.bril\nin_class_example_1.bril\nin_class_example_2.bril\nin_class_example_3.bril\nis-decreasing.bril\n\nTo view the graph, set up a http server and use any of your favourite modern web browsers to open the .html file that just generated.\nExample:\n❯ cd HW3\n❯ python -m http.server\nServing HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...\n# Goto http://&lt;server-ip&gt;:8000/output/in_class_example_1.bril/liveness/in_class_example_1.html\n\nLiveness Analysis\nLiveness analysis was correctly computed in all test cases. The variables that were “live” at each point in the program were accurately tracked. The results were particularly effective in identifying opportunities for Trivial DCE. For instance, variables that were defined but never live in subsequent instructions were correctly flagged, highlighting code that could be safely eliminated.\n\n\nAvailability Analysis\nAvailability analysis was applied successfully, and all expressions available at the entry and exit of each basic block were correctly computed. This analysis is critical for Local Value Numbering (LVN), where equivalent expressions are consolidated. In benchmarks such as in_class_example_3.bril, the implementation showed how redundant computations could be eliminated by detecting available expressions early.\n\n\nBusy Expressions Analysis\nBusy expressions analysis worked as expected, identifying expressions that were critical to compute before the next use. This was particularly useful in loops, where understanding which expressions are “busy” helps optimize the repeated evaluation of the same values.\n\n\nComparison and Insights\nFor all test cases, I carefully compared the output CFG and dataflow graph to the expected results. No differences were found in any of the test cases, confirming that the implementation is consistent with the theoretical expectations for dataflow analysis.\nThe visual representation of the analysis results (generated using vis.js and networkx) provided an intuitive way to verify the correctness of the IN, OUT, GEN, KILL, and EXPR sets for each basic block. This helped to easily identify points of optimization and confirmed that the framework was operating as intended.\n\n\nRaw test log\nCheck the following pages: \n\nTypical Examples:\nin_class_example_1.bril/liveness\n\n\n\nimage\n\n\nin_class_example_3.bril/busy\n\n\n\nimage",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#conclusion-1",
    "href": "blogs/Qucheng/2024-10-11-Qucheng-HW3.html#conclusion-1",
    "title": "Homework 3: Data Flow",
    "section": "Conclusion",
    "text": "Conclusion\nThe dataflow analysis framework for Bril successfully implements liveness, availability, and busy expressions analyses, all of which are foundational for key compiler optimizations. Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN) will extremely benefit from these analyses by eliminating redundant computations and identifying unused variables.\nThe testing of the framework on various Bril programs—ranging from simple in-class examples to more complex benchmark scripts—demonstrates that the analyses work correctly and efficiently. The interactive visualizations of the control flow graph (CFG) and associated dataflow sets provide valuable insights, making it easier to verify correctness and identify optimization opportunities.\nThis project establishes a strong foundation for performing local optimizations on intermediate representations like Bril. Future work could extend the framework to handle interprocedural analyses, multi-block optimizations, or more advanced global dataflow analyses. By further refining these optimizations, we can significantly enhance the efficiency of compiled programs.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 3: Data Flow"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-09-27-Sharmila-HW02.html",
    "href": "blogs/sharmila/2024-09-27-Sharmila-HW02.html",
    "title": "Compiler Homework 02 - Local Optimization",
    "section": "",
    "text": "Part 1: Dead Code Elimination\nDead Code Elimination (DCE) is an optimization technique in compiler design, aiming to remove instructions that do not affect the program’s final output.\nIn Homework 2, I implemented a “trivial” DCE, where instructions that are never used before being reassigned are deleted.\nThe Basic Idea behind this is to identify and remove the redundant assignment those are never implemented before reassignment.\nIn this blog, I’ll walk throught the implementation process and verify it with an example.\n\n\nImplementation Process:\nI used 3 key step to acheive this task: DCE, Reassignment Handling and Iteration until no changes.\nIn DCE step, identifies the variables that are used by collecting all arguments in the blocks and removes instructions where the destination variable (dest) is not in the used set (indicating it’s redundant). It modifies the blocks and flattens them back into the instruction list. At the next step, Reassignment Handling, removes redundant reassignments. If a variable is defined but then reassigned before its value is used, the earlier definition is deleted. The process is applied block by block.Finally, Iteration until no changes, repeatedly applies DCE and reassignment elimination until no further changes occur.\n\n\nExample:\n\n@main {\n  a: int = const 100;\n  a: int = const 42;\n  b: int = const 5;\n  sum: int = add a b;\n  c: int = id b;\n  sum: int = add c a;\n  print sum;\n}\n\nHere, the variable a is assigned the value 100, but it is immediately overwritten with the value 42, making the first assignment redundant. Similarly, the first computation of sum is also unnecessary as it is overwritten before being used. After running my implementation:\n\n@main {\n  a: int = const 42;\n  b: int = const 5;\n  c: int = id b;\n  sum: int = add c a;\n  print sum;\n}\n\nThe redundant instructions have been successfully removed. The total number of dynamic instructions has been reduced from 7 to 5. Thus it is verified that my implementation acheived the task of the homework.\nAnd another example to verify further, that the code delete instructions that are never used before they are reassigned.\n\n@main {\n a: int = const 100;\n a: int = const 42;\n b: int = const 5;\n sum: int = add a b;\n print sum;\n c: int = id b;\n sum: int = add c a;\n print sum;\n}\n\nAfter running the code:\n@main {\n  a: int = const 42;\n  b: int = const 5;\n  sum: int = add a b;\n  print sum;\n  c: int = id b;\n  sum: int = add c a;\n  print sum;\n}\n\nHere, the variable a is assigned the value 100, but it is immediately overwritten with the value 42, making the first assignment redundant. Since the first sum is used therefore it is not a redundant.\n\n\nPart 2: Local Value Numbering\nLocal Value Numbering (LVN) is an optimization technique used in compilers to eliminate redundant calculations. By assigning a unique number to each distinct computation, LVN helps minimize repeated evaluations of the same expression. In this part, the task is to implement Local value numbering and further to pair with DCE\n\n\nImplementation:\nPseudo Code of the implementation:\nDefine a named tuple ‘Value’ to represent a computation. Create a ‘Numbering’ class to manage unique identifiers for each computation. Implement the ‘last_writes’ function to identify the last write instructions for each variable. Implement the ‘read_first’ function to determine which variables are read before being written to. Define ‘lvn_block’ to process each block of instructions: Initialize mappings for variable-to-number and value-to-number. For each variable read first, assign a unique number. For each instruction, retrieve argument numbers and check for redundancy: If the computation has been seen, replace the instruction with an identity operation. If it’s a new computation, assign a fresh number and record it. Define ‘lvn’ to iterate through functions in the input data and apply ‘lvn_block’. Load JSON data, call ‘lvn’, and output the optimized result.\nThis code implementation is verfied by using an example:\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 5;\n  sum1: int = add a b;\n  sum2: int = add a b;\n  prod1: int = mul sum1 sum2;\n  sum1: int = const 0;\n  sum2: int = const 0;\n  sum3: int = add a b;\n  prod2: int = mul sum3 sum3;\n  print prod2;\n}\nOutput of the implement:\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 5;\n  lvn.3: int = add a b;                \n  sum2: int = id lvn.3;                \n  prod1: int = mul lvn.3 lvn.3;        \n  sum1: int = const 0;\n  sum2: int = const 0;\n  sum3: int = id lvn.3;                \n  prod2: int = id prod1;              \n  print prod1;                         \n}\nIn this output,the operation add a b is computed once and assigned a unique identifier lvn.3, effectively avoiding redundant calculations. Instead of recalculating add a b for sum2 and sum3, the code uses id lvn.3, indicating that these instructions simply take the value of lvn.3. Furthermore, the instruction prod1 utilizes lvn.3 to multiply with itself, showcasing the efficient reuse of computed values and optimizing the overall execution of the code.\n\n\nPairing with DCE:\nI used an example to verify\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 5;\n  sum1: int = add a b;\n  sum2: int = add a b;\n  prod1: int = mul sum1 sum2;\n\n  sum1: int = const 0;\n  sum2: int = const 0;\n  c: int = const 10;\n  sum3: int = add a b;\n  prod2: int = mul sum3 sum3;\n\n  print prod2;\n}\nHere c variable is initiallized twice and not used before reassigned.\nOutput:\n@main { a: int = const 4; b: int = const 2; sum1: int = add a b; sum2: int = add a b; prod1: int = mul sum1 sum2;\nsum1: int = const 0; sum2: int = const 0; c: int = const 10; sum3: int = add a b; prod2: int = mul sum3 sum3;\nprint prod2; }\nThe implementation of Local Value Numbering optimizes computations by eliminating redundancy, thus enhancing performance. This example illustrates how LVN effectively manages computations through unique identifiers.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 02 - Local Optimization"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-09-20-Sharmila-HW01.html",
    "href": "blogs/sharmila/2024-09-20-Sharmila-HW01.html",
    "title": "Compiler Homework 01 - Trying Out Bril",
    "section": "",
    "text": "About Bril\nBril is a simple educational intermediate representation (IR) language that is used to teach and experiment with compiler and programming language concepts. It provides a set of operations such as arithmetic and logical operations, and basic control flow structures like conditional branches and loops. The idea behind Bril is to keep things minimal and easy to understand, so we can focus on the core concepts of compilers without getting distracted by complicated features found in more advanced languages.\nGoal of this Homework is to get familiar with Bril, so I chose to a write a simple benchmark under core without getting inputs(args).\nIn this blog, I’ll walk you through two parts of my Homework 01 assignment where I first write a benchmark in Bril and then develop a tool to analyze Bril programs.\n\n\nPart 1: Write a New Benchmark\nThe first part of the assignment involved writing a new benchmark in Bril. This helped me get familiar with Bril’s control flow, syntax, and basic operations.\nBenchmark: addsqevenodd.bril\nThe goal of this benchmark is to calculate the sum of squares of even and odd numbers from 1 to 10 separately. Here’s the Bril program I wrote by hand:\n\n@main {\n  sum_even: int = const 0;      \n  sum_odd: int = const 0;       \n  i: int = const 1;             \n  limit: int = const 10;        \n  one: int = const 1;           \n  two: int = const 2;           \n\n.loop:\n  square: int = mul i i;        \n  half: int = div i two;        \n  check: int = mul half two;    \n  is_even: bool = eq check i;   \n  br is_even .even_case .odd_case; \n\n.even_case:\n  sum_even: int = add sum_even square; \n  jmp .increment;\n\n.odd_case:\n  sum_odd: int = add sum_odd square;   \n\n.increment:\n  i: int = add i one;           \n  cond: bool = le i limit;      \n  br cond .loop .exit;          \n\n.exit:\n  print sum_even;               \n  print sum_odd;                \n}\n\nThis program defines a loop that iterates from 1 to 10, calculates the square of each number, and adds the result to two separate sums for even and odd numbers. Finally, it prints the sums of the squares of even and odd numbers\nAfter writing the program, I converted it to a JSON format, which is required for further processing:\nbril2json &lt; addsqevenodd.bril &gt; addsqevenodd.json\nDuring this step, I faced an issue where the Bril interpreter (brili) did not accept direct constant values in core instructions. To resolve this, I explicitly declared constants before using them in operations like add or mul. This was a good learning experience that reinforced the importance of proper initialization in IR.\nTo automate testing, I used turnt to create a test output for this benchmark. I added the following command to a turnt.toml file:\ncommand = “bril2json &lt; {filename} | brili -p {args}”\nThis command runs the benchmark through brili, captures the output, and saves it in an output file. After creating the test, I ran:\nturnt –save addsqevenodd.bril\nThis command saved the output in a file named addsqevenodd.out, which can be used for further validation.\n\n\nPart 2: Write a Bril Analyzer\nIn this part, I developed a small tool to analyze Bril programs using python. I chose to count the number of add and print instructions in the Bril program to better understand the operations performed in the code.\nHere’s the Python code I implemented to count the add and print instructions in a Bril program:\n\nimport json\nimport sys\n\n\ndef count_add_instrs(bril_program):\n\n    count = 0\n    print = 0\n    for func in bril_program['functions']:\n        for instr in func['instrs']:\n            if 'op' in instr:\n                if instr['op'] == 'add':\n                    count += 1\n\n    return count\n\ndef count_print_instrs(bril_program):\n\n    printcount = 0\n    for func in bril_program['functions']:\n        for instr in func['instrs']:\n            if 'op' in instr:\n                if instr['op'] == 'print':\n                    printcount += 1\n                    \n    return printcount\n\nif __name__ == \"__main__\":\n\n    json_file = \"/home/sharmila_ubuntu/Compiler HW 01/addsqevenodd.json\"\n    with open(json_file,'r') as f:\n        bril_program = json.load(f)\n    count = count_add_instrs(bril_program)\n    print(f\"Number of add instructions in addsqevenodd.json file : {count}\")\n    printcount = count_print_instrs(bril_program)\n    print(f\"Number of print instructions in addsqevenodd.json file : {printcount}\")\n\nThis script loads the Bril program in JSON format, iterates over its instructions, and counts how many add and print operations are present.\nI tested my analyzer using turnt by adding the following command to the turnt.toml file:\ncommand = “bril2json &lt; {filename} | python3 analyzebril.py”\nThis command takes the Bril program, converts it to JSON, and runs my Python script (analyzebril.py) to analyze the JSON file. The output file generated by this process contains the number of add and print instructions in the program.\n\n\nConclusion: Summary of this Homework 01\n\nPart 1: I wrote a benchmark (addsqevenodd.bril) that computes the sum of squares of even and odd numbers from 1 to 10 separately. I used bril2json to convert the program into JSON and ran it with brili. I also used turnt to create an automated test for the benchmark.\nPart 2: I created a Python tool to analyze the Bril program. The tool counts add and print instructions in the JSON representation of the Bril program. I tested the tool using turnt, ensuring it ran correctly.\n\n\n\nTest and Results:\nTo verify this analyzer I tested with 3 example: (obtained the later two examples from (https://github.com/sampsyo/bril/tree/main/benchmarks)\n\nInitially, I used my benchmark to test the implementation, that is, using both the addsqevenodd.bril file and its corresponding json file (addsqevenodd.json). The analyzed correctly counted 3 add instructions and 2 print instructions.\nAnd then, I verified using bubblesort.bril, loading it’s json file and analyzed correctly as 8 add instructions and 1 print instruction.\nFinally, I verifies using mat-inv.bril, loading it’s json file and analyzed correctly as 12 add instruction and 2 print instruction.\n\n\n\nChallenges Faced and Solution:\nThe hardest part of this task was dealing with the restriction on directly using constants in core Bril instructions. I initially overlooked this, but after debugging, I realized that every constant had to be initialized in a separate instruction. This helped me better understand Bril’s structure and rules. Moreover, learning to use turnt for automating tests was a valuable lesson, as it streamlines the testing process significantly.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 01 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-11-01-Sharmila-HW05.html",
    "href": "blogs/sharmila/2024-11-01-Sharmila-HW05.html",
    "title": "Compiler Homework 05 - LLVM Pass",
    "section": "",
    "text": "In this blog, I’ll walk through the process of creating an LLVM pass to detect floating-point divisions within a C++ program. This project involves using the LLVM framework to analyze the Intermediate Representation (IR) code generated from a C++ program and detecting instances of floating-point division operations\n\nImplementation:\nFor each instruction in the basic block, we check if it’s a BinaryOperator with the opcode Instruction::FDiv, which represents a floating-point division in LLVM IR.\n\n\nTesting :\nI tested my pass using the below example:\n#include &lt;iostream&gt;\n#include &lt;stdio.h&gt;\n\ndouble divide(double a, double b) {\n    return a / b;\n}\n\nint main() {\n    double result1 = divide(10.0, 2.0);\n    double result2 = divide(19.0, 3.0);\n\n    if (result1 &gt; result2) {\n        double result3 = divide(result1, result2);  // Division in if branch\n    } else {\n        double result4 = divide(result2, result1);  // Division in else branch\n    }\n\n    return 0;\n}\nTo look at LLVM IR of this example I used “clang -emit-llvm -S -o - test.cpp”\nAnalyzing Function: divided\nFloating point division detected in Basic Block: %0\n  Instruction:   %7 = fdiv double %5, %6\nAnalyzing Function: main\nNo floating point divisions found in function.\nAnalyzing Function: _GLOBAL__sub_I_test.cpp\nNo floating point divisions found in function.\n; ModuleID = '../test.cpp'\nsource_filename = \"../test.cpp\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n%\"class.std::ios_base::Init\" = type { i8 }\n\n@_ZStL8__ioinit = internal global %\"class.std::ios_base::Init\" zeroinitializer, align 1\n@__dso_handle = external hidden global i8\n@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 65535, void ()* @_GLOBAL__sub_I_test.cpp, i8* null }]\n\n; Function Attrs: noinline uwtable\ndefine internal void @__cxx_global_var_init() #0 section \".text.startup\" {\n  call void @_ZNSt8ios_base4InitC1Ev(%\"class.std::ios_base::Init\"* @_ZStL8__ioinit)\n  %1 = call i32 @__cxa_atexit(void (i8*)* bitcast (void (%\"class.std::ios_base::Init\"*)* @_ZNSt8ios_base4InitD1Ev to void (i8*)*), i8* getelementptr inbounds (%\"class.std::ios_base::Init\", %\"class.std::ios_base::Init\"* @_ZStL8__ioinit, i32 0, i32 0), i8* @__dso_handle) #3\n  ret void\n}\n\ndeclare dso_local void @_ZNSt8ios_base4InitC1Ev(%\"class.std::ios_base::Init\"*) unnamed_addr #1\n\n; Function Attrs: nounwind\ndeclare dso_local void @_ZNSt8ios_base4InitD1Ev(%\"class.std::ios_base::Init\"*) unnamed_addr #2\n\n; Function Attrs: nounwind\ndeclare dso_local i32 @__cxa_atexit(void (i8*)*, i8*, i8*) #3\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local double @_Z6dividedd(double %0, double %1) #4 {\n  %3 = alloca double, align 8\n  %4 = alloca double, align 8\n  store double %0, double* %3, align 8\n  store double %1, double* %4, align 8\n  %5 = load double, double* %3, align 8\n  %6 = load double, double* %4, align 8\n  %7 = fdiv double %5, %6\n  ret double %7\n}\n\n; Function Attrs: noinline norecurse nounwind optnone uwtable\ndefine dso_local i32 @main() #5 {\n  %1 = alloca i32, align 4\n  %2 = alloca double, align 8\n  %3 = alloca double, align 8\n  %4 = alloca double, align 8\n  %5 = alloca double, align 8\n  store i32 0, i32* %1, align 4\n  %6 = call double @_Z6dividedd(double 1.000000e+01, double 2.000000e+00)\n  store double %6, double* %2, align 8\n  %7 = call double @_Z6dividedd(double 1.900000e+01, double 3.000000e+00)\n  store double %7, double* %3, align 8\n  %8 = load double, double* %2, align 8\n  %9 = load double, double* %3, align 8\n  %10 = fcmp ogt double %8, %9\n  br i1 %10, label %11, label %15\n\n11:                                               ; preds = %0\n  %12 = load double, double* %2, align 8\n  %13 = load double, double* %3, align 8\n  %14 = call double @_Z6dividedd(double %12, double %13)\n  store double %14, double* %4, align 8\n  br label %19\n\n15:                                               ; preds = %0\n  %16 = load double, double* %3, align 8\n  %17 = load double, double* %2, align 8\n  %18 = call double @_Z6dividedd(double %16, double %17)\n  store double %18, double* %5, align 8\n  br label %19\n\n19:                                               ; preds = %15, %11\n  ret i32 0\n}\n\n; Function Attrs: noinline uwtable\ndefine internal void @_GLOBAL__sub_I_test.cpp() #0 section \".text.startup\" {\n  call void @__cxx_global_var_init()\n  ret void\n}\n\nattributes #0 = { noinline uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\nattributes #1 = { \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"no-infs-fp-math\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\nattributes #2 = { nounwind \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"no-infs-fp-math\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\nattributes #3 = { nounwind }\nattributes #4 = { noinline nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\nattributes #5 = { noinline norecurse nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\n\n!llvm.module.flags = !{!0}\n!llvm.ident = !{!1}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{!\"clang version 10.0.0-4ubuntu1 \"}\nTo run this pass I used “clang -fpass-plugin=Homework5/build/FloatDivPass.so test.cpp”\nNo floating point divisions found in function.\nAnalyzing Function: divided\nFloating point division detected in Basic Block: %0\n  Instruction:   %7 = fdiv double %5, %6\nAnalyzing Function: main\nNo floating point divisions found in function.\nAnalyzing Function: _GLOBAL__sub_I_test.cpp\nNo floating point divisions found in function.\n\n\nChallenges Faced:\nInitially, I faced many challenges while setting up the llvm and during build and cmake stage. Then, I fond it difficult in llvm pass code. Because even cout can’t be mentioned as it is instead errs(). Even while testing I was able to see the output of the test file but not the LLVM pass.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 05 - LLVM Pass"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-28-Rohit-HW2.html",
    "href": "blogs/rohit/2024-09-28-Rohit-HW2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\nThe code should remove the instructions that are reassigned without being used.\nIf the value in being used in between the reassigning, then the instruction should be retained.\n\n\n\n\n\n\n\nThis function generates control flow blocks from a list of instructions.\nParameters: instrs - a list of instructions.\nProcess:\n\nIt iterates through each instruction.\nIf the instruction contains an operation (op), it adds it to the current block.\nIf the operation is a terminator (br, jmp, ret), it yields the current block and starts a new one.\nIf the instruction does not contain an operation, it yields the current block and starts a new one.\nAt the end, if there are any remaining instructions in the current block, it yields that block.\n\nReturns: Yields blocks of instructions.\n\n\n\n\n\nThis function removes instructions that are redefined without being used in a function.\nParameters: func - a dictionary representing a function with a list of instructions.\nProcess:\n\nIt repeatedly splits the function’s instructions into blocks using myCFG.\nFor each block, it tracks the last definition of each variable and identifies instructions to drop.\nIt removes instructions that are redefined without being used.\nIt updates the function’s instructions with the optimized blocks.\nThe loop continues until no more changes are made.\n\nReturns: None (modifies the function in place).\n\n\n\n\n\nThis is the main function that orchestrates the optimization process.\nProcess:\n\nIt reads a JSON object from standard input.\nFor each function in the JSON object, it applies remove_reassigned to optimize the instructions.\nIt writes the optimized JSON object to standard output.\n\n\n\n\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 42;\n    b: int = const 42;\n    }\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 42;\n    }",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 2"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-1-trivial-dead-code-elimination-which-you-delete-instructions-that-are-never-used-before-they-are-reassigned.",
    "href": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-1-trivial-dead-code-elimination-which-you-delete-instructions-that-are-never-used-before-they-are-reassigned.",
    "title": "Homework 2",
    "section": "",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\nThe code should remove the instructions that are reassigned without being used.\nIf the value in being used in between the reassigning, then the instruction should be retained.\n\n\n\n\n\n\n\nThis function generates control flow blocks from a list of instructions.\nParameters: instrs - a list of instructions.\nProcess:\n\nIt iterates through each instruction.\nIf the instruction contains an operation (op), it adds it to the current block.\nIf the operation is a terminator (br, jmp, ret), it yields the current block and starts a new one.\nIf the instruction does not contain an operation, it yields the current block and starts a new one.\nAt the end, if there are any remaining instructions in the current block, it yields that block.\n\nReturns: Yields blocks of instructions.\n\n\n\n\n\nThis function removes instructions that are redefined without being used in a function.\nParameters: func - a dictionary representing a function with a list of instructions.\nProcess:\n\nIt repeatedly splits the function’s instructions into blocks using myCFG.\nFor each block, it tracks the last definition of each variable and identifies instructions to drop.\nIt removes instructions that are redefined without being used.\nIt updates the function’s instructions with the optimized blocks.\nThe loop continues until no more changes are made.\n\nReturns: None (modifies the function in place).\n\n\n\n\n\nThis is the main function that orchestrates the optimization process.\nProcess:\n\nIt reads a JSON object from standard input.\nFor each function in the JSON object, it applies remove_reassigned to optimize the instructions.\nIt writes the optimized JSON object to standard output.\n\n\n\n\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 42;\n    b: int = const 42;\n    }\n\n\n\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 100;\n    b: int = const 42;\n    }\n\n\n\n    @main {\n    a: int = const 100;\n    print a;\n    a: int = const 42;\n    b: int = const 42;\n    }",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 2"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-2-implement-local-value-numbering",
    "href": "blogs/rohit/2024-09-28-Rohit-HW2.html#part-2-implement-local-value-numbering",
    "title": "Homework 2",
    "section": "PART 2: Implement local value numbering",
    "text": "PART 2: Implement local value numbering\n\nAbout local value numbering:\nDefinition: Local Value Numbering (LVN) is a compiler optimization technique used to eliminate redundant calculations by assigning unique numbers to equivalent expressions. This helps in identifying and reusing previously computed values, thus improving the efficiency of the code.\n\n\nImplementation:\n\ninit(self)\n\nThis is the constructor for the ImprovedLVN class. It initializes several dictionaries and counters used in the Local Value Numbering (LVN) process.\nself.var2num: Maps variables to their value numbers.\nself.value2num: Maps operations to value numbers.\nself.num2var: Maps value numbers to variable names.\nself.next_vn: Counter for the next value number.\nself.last_computed: Maps operations to their last computed variable.\n\n\n\nfresh_value_number(self)\n\nThis function generates a fresh value number.\nReturns: A new value number and increments the counter.\n\n\n\ncanonicalize(self, value)\n\nThis function canonicalizes commutative operations like addition and multiplication to ensure consistent ordering of arguments.\nParameters: value - a Value namedtuple representing an operation and its arguments.\nReturns: A canonicalized Value namedtuple.\n\n\n\nget_lvn_var(self, vn)\n\nThis function generates a variable name for a given value number.\nParameters: vn - a value number.\nReturns: A string representing the LVN variable name.\n\n\n\nprocess_block(self, block)\n\nThis function performs Local Value Numbering (LVN) on a single block of instructions.\nParameters: block - a list of instructions.\nProcess:\n\nIterates through each instruction in the block.\nIf the instruction has a destination (‘dest’), it processes the instruction:\n\nFetches value numbers for arguments.\nCreates a canonicalized value for the current instruction.\nChecks if the value is already computed:\n\nIf yes, it uses the previous result.\nIf no, it assigns a fresh value number and updates mappings.\n\n\nAdds the processed instruction to the new block.\n\nReturns: A new block of optimized instructions.\n\n\n\nrun_lvn(self, bril_program)\n\nThis function runs LVN on the entire program.\nParameters: bril_program - a dictionary representing the BRIL program.\nProcess:\n\nIterates through each function in the program.\nApplies process_block to the instructions of each function.\n\nReturns: The optimized BRIL program.\n\n\n\n\nExample:\n\nwith a b no permutted\n\nInput bril:\n    @main {\n        a: int = const 4;\n        b: int = const 2;\n        sum1: int = div a b;\n        sum2: int = div a b;\n        prod: int = mul sum1 sum2;\n        sum2: int = div a b;\n        print prod;\n    }\n\n\nOutput bril:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = div a b;\n    sum2 = id sum1;\n    prod: int = mul sum1 sum1;\n    sum2 = id sum1;\n    print prod;\n    }\n\n\n\npairing with dead code analysis:\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  sum1: int = div a b;\n  prod: int = mul sum1 sum1;\n  sum2 = id sum1;\n  print prod;\n}\n\n\n\n\nwith a b with permutted\n\nInput bril:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add b a;\n    prod: int = mul sum1 sum2;\n    sum2: int = add b a;\n    print prod;\n    }\n\n\n\nOutput bril:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2 = id sum1;\n    prod: int = mul sum1 sum1;\n    sum2 = id sum1;\n    print prod;\n    }\n\n\n\npairing with dead code analysis:\n    @main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = div a b;\n    prod: int = mul sum1 sum1;\n    sum2 = id sum1;\n    print prod;\n    }\n\nfull code: https://github.com/gurusamyanandakuma-r/bril/tree/main/HW/HW2_Rohit",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 2"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-11-02-Rohit-HW5.html",
    "href": "blogs/rohit/2024-11-02-Rohit-HW5.html",
    "title": "Homework 5",
    "section": "",
    "text": "code link: https://github.com/gurusamyanandakuma-r/bril/tree/main/HW/HW5_Rohit/llvm-div-check\n\n\nFor this homework, I implemented DivCheckPass which is an LLVM pass that identifies division instructions within functions. When a division instruction is found, the pass prints information about:\n\nThe function containing the division\nThe basic block containing the division\nThe division instruction itself\n\nThe pass is implemented as a Function Pass, meaning it operates on one function at a time. It uses LLVM’s instruction visitor pattern to examine each instruction and uses dyn_cast to identify binary operations that are specifically division operations.\n\n\n\nThe pass was tested by:\n\nCompiling a C++ Program: A test program (test.cpp) containing division operations was compiled with the pass plugin enabled.\nPass Output Analysis: The compilation output was examined to verify that the pass correctly identified and reported division instructions.\nMultiple Test Cases: The program included both safe divisions and potential divide-by-zero scenarios.\n\n\n\n#include &lt;stdio.h&gt;\nint divide(int a, int b) {\n    return a / b;\n}\nint main() {\n    int x = 10;\n    int y = 0;\n    return divide(x, y);\n}\n\n\n\n\n\nclang -Xclang -load -Xclang ./DivCheckPass.so -S -emit-llvm ../test.cpp -o -\nAnalyzing Function: _Z6divideii\n  Basic Block: %2\n    Found division instruction:   %7 = sdiv i32 %5, %6\nAnalyzing Function: main\n  Basic Block: %0\n; ModuleID = '../test.cpp'\nsource_filename = \"../test.cpp\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @_Z6divideii(i32 %0, i32 %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  store i32 %0, i32* %3, align 4\n  store i32 %1, i32* %4, align 4\n  %5 = load i32, i32* %3, align 4\n  %6 = load i32, i32* %4, align 4\n  %7 = sdiv i32 %5, %6\n  ret i32 %7\n}\n\n; Function Attrs: noinline norecurse nounwind optnone uwtable\ndefine dso_local i32 @main() #1 {\n  %1 = alloca i32, align 4\n  %2 = alloca i32, align 4\n  %3 = alloca i32, align 4\n  store i32 0, i32* %1, align 4\n  store i32 10, i32* %2, align 4\n  store i32 0, i32* %3, align 4\n  %4 = load i32, i32* %2, align 4\n  %5 = load i32, i32* %3, align 4\n  %6 = call i32 @_Z6divideii(i32 %4, i32 %5)\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\nattributes #1 = { noinline norecurse nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\n\n\n\nclang -Xclang -load -Xclang ./DivCheckPass.so ../test.cpp -o test ./test\nAnalyzing Function: _Z6divideii\n  Basic Block: %2\n    Found division instruction:   %7 = sdiv i32 %5, %6\nAnalyzing Function: main\n  Basic Block: %0\n\n\n\n\n\nThe pass successfully identified the division operation in the divide function\nIt correctly located the basic block containing the division\nIt properly printed the LLVM IR representation of the division instruction\n\n\n\n\n\n\nImplementing the pass presented several challenges, including understanding LLVM’s Intermediate Representation (IR) and the translation of high-level C++ constructs into LLVM IR.\nIntegrating the pass involved setting up the CMake build system, registering the pass correctly, and managing the pass loading mechanisms. Navigating LLVM’s type system to identify division operations and using dyn_cast for type safety also proved challenging. Currently, the implementation only detects division operations.\nFuture improvements could include inserting runtime checks for divide-by-zero, adding instrumentation for division operation statistics, handling floating-point divisions, and generating warnings for potential divide-by-zero scenarios.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 5"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-11-02-Rohit-HW5.html#llvm-division-check-pass-implementation",
    "href": "blogs/rohit/2024-11-02-Rohit-HW5.html#llvm-division-check-pass-implementation",
    "title": "Homework 5",
    "section": "",
    "text": "code link: https://github.com/gurusamyanandakuma-r/bril/tree/main/HW/HW5_Rohit/llvm-div-check\n\n\nFor this homework, I implemented DivCheckPass which is an LLVM pass that identifies division instructions within functions. When a division instruction is found, the pass prints information about:\n\nThe function containing the division\nThe basic block containing the division\nThe division instruction itself\n\nThe pass is implemented as a Function Pass, meaning it operates on one function at a time. It uses LLVM’s instruction visitor pattern to examine each instruction and uses dyn_cast to identify binary operations that are specifically division operations.\n\n\n\nThe pass was tested by:\n\nCompiling a C++ Program: A test program (test.cpp) containing division operations was compiled with the pass plugin enabled.\nPass Output Analysis: The compilation output was examined to verify that the pass correctly identified and reported division instructions.\nMultiple Test Cases: The program included both safe divisions and potential divide-by-zero scenarios.\n\n\n\n#include &lt;stdio.h&gt;\nint divide(int a, int b) {\n    return a / b;\n}\nint main() {\n    int x = 10;\n    int y = 0;\n    return divide(x, y);\n}\n\n\n\n\n\nclang -Xclang -load -Xclang ./DivCheckPass.so -S -emit-llvm ../test.cpp -o -\nAnalyzing Function: _Z6divideii\n  Basic Block: %2\n    Found division instruction:   %7 = sdiv i32 %5, %6\nAnalyzing Function: main\n  Basic Block: %0\n; ModuleID = '../test.cpp'\nsource_filename = \"../test.cpp\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @_Z6divideii(i32 %0, i32 %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  store i32 %0, i32* %3, align 4\n  store i32 %1, i32* %4, align 4\n  %5 = load i32, i32* %3, align 4\n  %6 = load i32, i32* %4, align 4\n  %7 = sdiv i32 %5, %6\n  ret i32 %7\n}\n\n; Function Attrs: noinline norecurse nounwind optnone uwtable\ndefine dso_local i32 @main() #1 {\n  %1 = alloca i32, align 4\n  %2 = alloca i32, align 4\n  %3 = alloca i32, align 4\n  store i32 0, i32* %1, align 4\n  store i32 10, i32* %2, align 4\n  store i32 0, i32* %3, align 4\n  %4 = load i32, i32* %2, align 4\n  %5 = load i32, i32* %3, align 4\n  %6 = call i32 @_Z6divideii(i32 %4, i32 %5)\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\nattributes #1 = { noinline norecurse nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"frame-pointer\"=\"all\" \"less-precise-fpmad\"=\"false\" \"min-legal-vector-width\"=\"0\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\n\n\n\nclang -Xclang -load -Xclang ./DivCheckPass.so ../test.cpp -o test ./test\nAnalyzing Function: _Z6divideii\n  Basic Block: %2\n    Found division instruction:   %7 = sdiv i32 %5, %6\nAnalyzing Function: main\n  Basic Block: %0\n\n\n\n\n\nThe pass successfully identified the division operation in the divide function\nIt correctly located the basic block containing the division\nIt properly printed the LLVM IR representation of the division instruction\n\n\n\n\n\n\nImplementing the pass presented several challenges, including understanding LLVM’s Intermediate Representation (IR) and the translation of high-level C++ constructs into LLVM IR.\nIntegrating the pass involved setting up the CMake build system, registering the pass correctly, and managing the pass loading mechanisms. Navigating LLVM’s type system to identify division operations and using dyn_cast for type safety also proved challenging. Currently, the implementation only detects division operations.\nFuture improvements could include inserting runtime checks for divide-by-zero, adding instrumentation for division operation statistics, handling floating-point divisions, and generating warnings for potential divide-by-zero scenarios.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 5"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-27-HW2-Kellner.html",
    "href": "blogs/oscar/2024-09-27-HW2-Kellner.html",
    "title": "HW2 - Minor Local Optimizations",
    "section": "",
    "text": "In this assignment, we try to inplement two common forms of local optimization: trivial dead code elimination and value numbering. In this context, local refers to optimizations within the block level, meaning optimizations are isolated between any kind of control flow, which may include unconditional branches. Despite the limited scope of the optimizations, these two methods are relatively inexpensive and can be used in conjunction with each other to reduce unnecessary instructions from a program.\nI had struggled a lot with this homework in particular, partially due to my insistence on using Lua (a comparable scripting language to Python but with less library support) to get more familiar with the language. This also required rewriting plenty of utility functions to achieve some of the same functionality that was previously given, such as “gen_blocks”. The time constraints have not been friendly.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW2 - Minor Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-27-HW2-Kellner.html#overview",
    "href": "blogs/oscar/2024-09-27-HW2-Kellner.html#overview",
    "title": "HW2 - Minor Local Optimizations",
    "section": "",
    "text": "In this assignment, we try to inplement two common forms of local optimization: trivial dead code elimination and value numbering. In this context, local refers to optimizations within the block level, meaning optimizations are isolated between any kind of control flow, which may include unconditional branches. Despite the limited scope of the optimizations, these two methods are relatively inexpensive and can be used in conjunction with each other to reduce unnecessary instructions from a program.\nI had struggled a lot with this homework in particular, partially due to my insistence on using Lua (a comparable scripting language to Python but with less library support) to get more familiar with the language. This also required rewriting plenty of utility functions to achieve some of the same functionality that was previously given, such as “gen_blocks”. The time constraints have not been friendly.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW2 - Minor Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-27-HW2-Kellner.html#part-1-trivial-dead-code-elimination-tdce",
    "href": "blogs/oscar/2024-09-27-HW2-Kellner.html#part-1-trivial-dead-code-elimination-tdce",
    "title": "HW2 - Minor Local Optimizations",
    "section": "Part 1: Trivial Dead Code Elimination (TDCE)",
    "text": "Part 1: Trivial Dead Code Elimination (TDCE)\nFor each of these optimizations, we will need to split our program into a series of blocks, which as mentioned before is separated between control flow instructions, such as jmp, ret, and br. Within these blocks, we can analyze what variables are used within this block and if any dead instructions are found. We can classify “trivial dead code” as those that write to a variable, and subsequently never use said variable in any accessible code path within the block.\nWe can run this process as many times as we like until our code converges to a point where no changes are further made after a round of execution (or “pass”). A single TDCE pass may not eliminate all dead code on the first iteration, as (for example) some useless variables may be used to assign other useless variables, which our TDCE detects as being “used” until the dependent dead variables are also eliminated.\nImplementing this was not too difficult - just simply iterate through all the instructions for a given block, and keep a table of used variables. Then, reconstruct the sequence of instructions, excluding any instructions that write to variables not within our table, and finally rewrite the trimmed block back to the original function. Repeat for all blocks, and you have a single TDCE pass. I opted to write an option for a user-specified number of passes if they like, with &lt; 1 defaulting to repeating the TDCE until the program detects that no more instructions were eliminated in a given pass.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW2 - Minor Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-27-HW2-Kellner.html#part-2-local-value-numbering-lvn",
    "href": "blogs/oscar/2024-09-27-HW2-Kellner.html#part-2-local-value-numbering-lvn",
    "title": "HW2 - Minor Local Optimizations",
    "section": "Part 2: Local Value Numbering (LVN)",
    "text": "Part 2: Local Value Numbering (LVN)\nLocal value numbering works somewhat similarly to TDCE in that it will iterate through the instructions for a given block and keep track of some statistics to determine what code to modify. In this case, LVN aims to reduce redundancy within a block, by enumaterating expressions (as opposed to variables) it encounters and eliminating any values that share the same operation and operands.\nThere are a few methods that can be employed in conjunction in order to remove redundancy:\n\nConstant folding: If operands within an instruction are constants, we can “fold” the result directly into the code so the machine does not have to recalculate it at runtime. This may also include algebraic identities, but I did not attempt to support it here.\nPropagation: Redundant variables can be eliminated if multiple variables are assigned to be equal to each other and are not each used for different purposes.\nOther properties: Making use various mathematical properties / boolean logic to find redundant expressions, such as (a + b) and (b + a), or (x == x).\n\nDebugging this code has proven to be very frustrating as most of the flow for execution involves piping in multiple commands through standard input / output (usually to accomodate for Turnt and Bril utilities), so any attempt to print debugging information onto the screen will modify the output and cause any subsequent programs to fail. Work became somewhat disorganized when I had opted to save a lot of intermediate output files and additional testing programs just to observe the outcome of a single change. I will admit that I had to restructure / rewrite a lot of code multiple times to find a good balance, and in doing so I had revised a lot of the code in accordance to the example program after having made my own attempts at implementation.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW2 - Minor Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-27-HW2-Kellner.html#testing",
    "href": "blogs/oscar/2024-09-27-HW2-Kellner.html#testing",
    "title": "HW2 - Minor Local Optimizations",
    "section": "Testing",
    "text": "Testing\nBecause Brili serves mostly to simulate code, our method of checking performance of our local optimization is to simply count the number of instructions reduced between the optimization passes. While this code does not aim specifically to target loops, it would be in our best interst to try and optimize repeated blocks of code so the gross number of instructions executed at runtime is reduced.\nI’m still struggling a lot to understand how turnt works. From my understanding, it doesn’t seem to work past one directory level? I’ve needed to copy all of my source files and also benchmark folders just to make the process a little more convenient, but it is still pretty frustrating.\nUnfortunately, there seems to be a few bugs in the local optimizations, as there are a select few programs that appear to fail the consistency check after optimizations (comparing to the existing .out file). There are two bril programs that are the culprits - mat-mul.bril and adj2csr.bril. Upon further inspection, both of these programs appear to use a random number generator of sorts, but the important constants may be filtered out before they are run. However, after optimizations, the rest of the programs I have tested on appear to produce an identical output. I have tested the TDCE and LVN programs, as well as the two chained after another, on all mem and core benchmarks.\nHere are some stats on the mem set of benchmarks:\nBaseline:\ntotal_dyn_inst: 56629\ntotal_dyn_inst: 6851\ntotal_dyn_inst: 78\ntotal_dyn_inst: 253\ntotal_dyn_inst: 121202\ntotal_dyn_inst: 88\ntotal_dyn_inst: 1006454\ntotal_dyn_inst: 121\ntotal_dyn_inst: 47\ntotal_dyn_inst: 1990407\ntotal_dyn_inst: 193\ntotal_dyn_inst: 677\ntotal_dyn_inst: 11029\ntotal_dyn_inst: 279\ntotal_dyn_inst: 27333\ntotal_dyn_inst: 264\ntotal_dyn_inst: 3482\ntotal_dyn_inst: 98\ntotal_dyn_inst: 86036\nTDCE only:\ntotal_dyn_inst: 56584\ntotal_dyn_inst: 6851\ntotal_dyn_inst: 75\ntotal_dyn_inst: 253\ntotal_dyn_inst: 120652\ntotal_dyn_inst: 88\ntotal_dyn_inst: 959702\ntotal_dyn_inst: 121\ntotal_dyn_inst: 47\ntotal_dyn_inst: 1990407\ntotal_dyn_inst: 193\ntotal_dyn_inst: 677\ntotal_dyn_inst: 11024\ntotal_dyn_inst: 279\ntotal_dyn_inst: 27011\ntotal_dyn_inst: 264\ntotal_dyn_inst: 3455\ntotal_dyn_inst: 88\ntotal_dyn_inst: 86036\nLVN only:\ntotal_dyn_inst: 56584\ntotal_dyn_inst: 6851\ntotal_dyn_inst: 78\ntotal_dyn_inst: 253\ntotal_dyn_inst: 121202\ntotal_dyn_inst: 88\ntotal_dyn_inst: 1006454\ntotal_dyn_inst: 121\ntotal_dyn_inst: 47\ntotal_dyn_inst: 1990407\ntotal_dyn_inst: 193\ntotal_dyn_inst: 677\ntotal_dyn_inst: 11029\ntotal_dyn_inst: 279\ntotal_dyn_inst: 27011\ntotal_dyn_inst: 264\ntotal_dyn_inst: 3482\ntotal_dyn_inst: 98\ntotal_dyn_inst: 86036\nLVN | TDCE:\ntotal_dyn_inst: 56584\ntotal_dyn_inst: 6851\ntotal_dyn_inst: 75\ntotal_dyn_inst: 253\ntotal_dyn_inst: 120652\ntotal_dyn_inst: 88\ntotal_dyn_inst: 959702\ntotal_dyn_inst: 121\ntotal_dyn_inst: 47\ntotal_dyn_inst: 1990407\ntotal_dyn_inst: 193\ntotal_dyn_inst: 677\ntotal_dyn_inst: 11024\ntotal_dyn_inst: 279\ntotal_dyn_inst: 27011\ntotal_dyn_inst: 264\ntotal_dyn_inst: 3455\ntotal_dyn_inst: 88\ntotal_dyn_inst: 86036\nUnfortunately, as it stands only TDCE seems to create a marginal difference in performance - ironically LVN tends to increase the number of instructions likely leading to worse performance. Though, with working within a small scope such as individual blocks, it may be expected that programs with a lot of control flow would not see much benefit from block-level optimization. Perhaps with more aggressive scheduling and more awareness of instruction count, I could get LVN to improve on its ability, however I have struggled a lot with the programming as it is given the time constraints.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW2 - Minor Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html",
    "href": "blogs/oscar/2024-09-20-HW1.html",
    "title": "HW1 - Trying Out Bril",
    "section": "",
    "text": "Bril is a very simple and educational instruction-based intermediate represnetation (IR) that is represented in JSON. It features a simple syntax that can be converted as JSON, and a suite of tools to execute the program.\nIn this assignment, we implement a basic benchmarking program with Bril, then write a simple analysis program that analyzes a Bril (JSON) program, as well as create tests for both of these using Turnt (a snapshot testing tool).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#overview",
    "href": "blogs/oscar/2024-09-20-HW1.html#overview",
    "title": "HW1 - Trying Out Bril",
    "section": "",
    "text": "Bril is a very simple and educational instruction-based intermediate represnetation (IR) that is represented in JSON. It features a simple syntax that can be converted as JSON, and a suite of tools to execute the program.\nIn this assignment, we implement a basic benchmarking program with Bril, then write a simple analysis program that analyzes a Bril (JSON) program, as well as create tests for both of these using Turnt (a snapshot testing tool).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#part-1-bril-benchmark-program",
    "href": "blogs/oscar/2024-09-20-HW1.html#part-1-bril-benchmark-program",
    "title": "HW1 - Trying Out Bril",
    "section": "Part 1: Bril Benchmark Program",
    "text": "Part 1: Bril Benchmark Program\nAfter reviewing the list of existing benchmark programs within the Bril repository (under the benchmarks directory), we notice that most benchmarks tend to consist of basic sample programs that runs a handwritten algorithm that returns some output value.\nIn keeping with this pattern, I had originally wanted to write a program that performs a single forward convolutional pass through a large matrix of data, however after noticing the tedious process of packing individual data values into large arrays, I felt that an implementation of this would be too messy. I had also wanted to test recusion in Bril, so naturally an implementation of Merge Sort would fit this purpose well. I chose an in-place version of the algorithm to reduce the complexity a little.\nAs mentioned earlier, creating arrays appear to require painstakingly pack all the individual values one at a time into memory. I had borrowed the @pack function from the bubblesort.bril benchmark to help create this array from the passed arguments for my program, 8 integer values to be stored into an unsorted array. These arguments are passed in when the program is called, as opposed to many other benchmark programs that hardcode the input values into the program.\nTaking an existing implementation of in-place merge sort written in C and converting it to a functional bril program was a relatively simple task, given the procedural and imperative nature of both languages. The difficulty mostly came down to writing proper control flow (inverting condition statements to support &gt;= and &lt;=), the verbosity of accessing individual elements in an array, and keeping track of what variables to modify. Keeping temporary notes in listing what variables are currently used within a certain scope helps keep track of how state may change in a program if a particular variable is used elsewhere.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#part-2-analysis-tool",
    "href": "blogs/oscar/2024-09-20-HW1.html#part-2-analysis-tool",
    "title": "HW1 - Trying Out Bril",
    "section": "Part 2: Analysis Tool",
    "text": "Part 2: Analysis Tool\nFor the second part of the assignment, we are tasked to write a small program that analyzes or modifies a Bril program in some way. I had originally tried to write my program in Zig for some extra practice, but time constraints locked me back to Python for convenience (JSON handling is a lot easier in Python).\nThe program I had written performs a couple of basic scans through the functions of the specified Bril program, and prints out the following for each function (if applicable):\n\nThe arguments of the function and their types\nThe list of all function calls made and their arguments\nIf recursion is present\nThe number of potential loops found within the function\n\nA potential loop is found by simply scanning for all unique labels that have a jmp or br instruction located somewhere after the label that jumps to said label.\nGathering these statistics for all functions could potentially help internally organize programs into a convenient structure and identify what the most dominating section of code is. I find that it provides a nice synopsis on what a high-level breakdown of a Bril program looks like.\nOriginally, I had also planned to add functionality that will analyze whether variables are unused, but it got needlessly complicated and felt more appropriate for dead code elimination in a later assignment.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-09-20-HW1.html#testing",
    "href": "blogs/oscar/2024-09-20-HW1.html#testing",
    "title": "HW1 - Trying Out Bril",
    "section": "Testing",
    "text": "Testing\nAn in-place merge sort implementation in Bril and a simple program to analyze Bril programs were developed. Both of these programs have associated Turnt tests to ensure that the outputs for these programs are matching the expected result when I had written them. For the analysis tool (flow_detect.py), I have included other existing benchmark Bril programs in testing for a variety of outputs.\nHere are some outputs for our Merge Sort program:\n$ bril2json &lt; mergesort-inplace.bril | brili -p 8 1 2 7 3 6 5 4\n1\n2\n3\n4\n5\n6\n7\n8\ntotal_dyn_inst: 677\n$ bril2json &lt; mergesort-inplace.bril | brili -p 8 7 6 5 4 3 2 1\n1\n2\n3\n4\n5\n6\n7\n8\ntotal_dyn_inst: 803\n$ bril2json &lt; mergesort-inplace.bril | brili -p 2 2 2 2 2 2 2 1\n1\n2\n2\n2\n2\n2\n2\n2\ntotal_dyn_inst: 486\nFor our analysis tool, I had selected a handful of benchmarks that have a variety of control flow. Here is the output for eight-queens:\nmain:\n    args:\n        int: input\n    function calls: 1\n        queen(zero, n, icount, site)\n\nqueen:\n    args:\n        int: n, queens, icount\n        int ptr: site\n    num potential loops: 1\n    function calls: 2\n        valid(n, site)\n        queen(n_1, queens, icount, site)\n    recursion present\n\nvalid:\n    args:\n        int: n\n        int ptr: site\n    num potential loops: 1\nAs shown, for each function a list of arguments, function calls, and indication of loops and/or recursion is demonstrated, if applicable. I have tested the program on my own Merge Sort file as well:\nmain:\n    args:\n        int: n1, n2, n3, n4, n5, n6, n7, n8\n    function calls: 3\n        pack(size, n1, n2, n3, n4, n5, n6, n7, n8)\n        merge_sort(array, zero, upper_bound)\n        print_array(array, size)\n\npack:\n    args:\n        int: size, n1, n2, n3, n4, n5, n6, n7, n8\n\nmerge:\n    args:\n        int ptr: arr\n        int: start, mid, end\n    num potential loops: 2\n\nmerge_sort:\n    args:\n        int ptr: arr\n        int: l, r\n    function calls: 3\n        merge_sort(arr, l, m)\n        merge_sort(arr, mp1, r)\n        merge(arr, l, m, r)\n    recursion present\n\nprint_array:\n    args:\n        int ptr: array\n        int: size\n    num potential loops: 1\nHere, the program correctly identifies the use of recursion in our @merge_sort function, as well as finding the two nested loops within @merge as well.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW1 - Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/aymane/readme4.html",
    "href": "blogs/aymane/readme4.html",
    "title": "Homework 4 – Implementing Dominance Algorithms",
    "section": "",
    "text": "I implemented the dominator functions inside dominator.py. There are some utility functions in the utils.py file. Functions to draw the graphs are located inside graph.py. To run the program, pass a bril file through stdin bril2json &lt; file.bril | python3 dominatory.py --doms --doms_tree --dom_frontier --test_dom --nodes nodeA nodeB\n--doms computes the dominators for each block and generates a cfg image. --dom_tree computes the dominator tree and generates the image. --dom_frontier computes the dominance frontier of all nodes and prints it out. --test_dom --nodes nodeA nodeB tests if nodeA dominates nodeB.\nKey Concepts\n•   Dominators: A block B1 dominates another block B2 if every path from the entry block to B2 must go through B1.\n•   Immediate Dominators: The closest dominator of a block B is called its immediate dominator (idom).\n•   Dominance Frontier: The set of blocks where the dominance relationship breaks.\nThe get_dominators() function returns a dictionary mapping a node to its dominators. We find a node’s dominators by finding the common ancestry of all it’s predecessors.\ndef get_dominators(blocks):\n    # get block list and block set structures\n    all_blks_l = list(blocks.keys())\n    all_blks_s = set(all_blks_l)\n\n    # get the firs block\n    entry = next(iter(blocks))\n\n    # init dominator dict\n    dom = {name: all_blks_s for name in blocks.keys()} \n    dom[entry] = {entry}\n\n    _, predecessors = generate_graph(blocks)\n\n    changed = True\n    while changed:\n        changed = False\n        # all vertices except the entry point\n        for v in all_blks_l[1:]:\n            intrsct = all_blks_s\n\n            # get the common ancestors of all predecessors\n            for pred in predecessors[v]:\n                intrsct = intrsct.intersection(dom[pred])\n\n            # self dominates\n            new_dom = intrsct.union({v})\n\n            # update the dominator tree entries\n            if new_dom != dom[v]:\n                dom[v] = new_dom\n                changed = True\n\n    return dom\nWe build the dominance tree by finding the immediate dominators of each block. A node a immediately dominates a node b if a != b and no node c (with c != a and c != b) exists such that a dominates c and c dominates b.\ndef strictly_dominates(b1, b2, doms):\n    return b1 in doms[b2] and b1 != b2\n\ndef build_dominance_tree(dom):\n    # init dominator tree\n    dom_tree = {node: [] for node in dom.keys()}\n\n    for a in dom.keys():\n        for b, b_doms in dom.items():\n            if a != b:\n                E_a_stric_dom_c = False\n                # look at all dominators of b\n                for c in b_doms:\n                    # c != b\n                    if c != b:\n                        # check if a strictly dominates any of b's dominators\n                        E_a_stric_dom_c = E_a_stric_dom_c or strictly_dominates(a, c, dom)\n\n                # b1 strictly dominates \n                if a in b_doms and not E_a_stric_dom_c:\n                    dom_tree[a].append(b)\n    return dom_tree\nFinally, the get_dominance_frontier() function returns a dictionary mapping each block to the blocks that lie within its dominance frontier. First we compute the intersection between the dominators of all predecessors of the node, then compute the union for the same set. Subtracting the intersection from the union results in the dominance frontier for a given node.\ndef get_dominance_frontier(blks):\n    # get predecessors and dominators for each block\n    _, p = generate_graph(blks)\n    doms = get_dominators(blks)\n\n    # init the frontier dict\n    frontier = {name: [] for name in doms.keys()}\n\n    # loop over all nodes\n    for node in doms:\n        # get the dominators of all predecessors of the current node\n        pred_doms = [doms[pred] for pred in p[node]]\n        # if none, we can skip to the next node\n        if len(pred_doms) == 0:\n            continue\n\n        # get the set intersection for dominators of all predecessors of current node\n        intersection = set.intersection(*map(set,pred_doms))\n        # get the set union for dominators of all predecessors of the current node\n        union = set.union(*map(set,pred_doms)) \n        frontier_set = union - intersection\n        \n        # add nodes to the frontier dict\n        for block in frontier_set:\n            frontier[block].append(node)\n\n    return frontier\n\nLet’s look at some examples.\ntest1.bril\n# ARGS: 8\n@main(input: int) {\n  value: int = id input;\n  v1: int = const 1;\n  result: int = id v1;\n  v3: int = id value;\n  i: int = id v3;\n.for.cond.2:\n  v4: int = id i;\n  v5: int = const 0;\n  v6: bool = gt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: int = id result;\n  v8: int = id i;\n  v9: int = mul v7 v8;\n  result: int = id v9;\n  v10: int = id i;\n  v11: int = const 1;\n  v12: int = sub v10 v11;\n  i: int = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: int = id result;\n  print v13;\n  v14: int = const 0;\n}\n\nCFG with Dominators\n #### Dominance Tree \nWe can run the following command to generate these two graphs, compute the dominance frontier and check whether node b1 dominates for.cond.2.\nbril2json &lt; test1.bril | python3 dominator.py --doms --dom_tree --dom_frontier --test_dom --nodes b1 for.cond.2\n\nDominance Frontier\n{'b1': [], 'for.cond.2': ['for.cond.2'], 'for.body.2': ['for.cond.2'], 'for.end.2': []}\n\nb1 dominates for.cond.2\ntest7.bril generates the same graph as one of the examples shown in the class slides.\n@main{\n.b0:\n    a: int = const 1;\n    b: int = const 0;\n    cond1: bool = a;\n    br cond1 .b5 .b1;\n.b5:\n    cond2: bool = a;\n    br cond1 .b6 .b7;\n.b1:\n    cond3: bool = a;\n    br cond1 .b2 .b3;\n.b2:\n    jmp .b4;\n.b4:\n    jmp .b8;\n.b6:\n    jmp .b4;\n.b3:\n    jmp .b8;\n.b7:\n    jmp .b8;\n.b8:\n    print a;\n}\nWe can verify that block b4 doesn’t dominate block b0 by running:\nbril2json &lt; test7.bril | python3 dominator.py --doms --dom_tree --test_dom --nodes b4 b0\nb4 doesn't dominate b0\n\n\nCFG with Dominators\n #### Dominance Tree \ntest4.bril incorporate phi nodes:\n@main {\n  x: int = const 1;\n  y: int = const 2;\n  \n.entry:\n  z: int = add x y;\n  \n.branch1:\n  cond1: bool = le x y;\n  br cond1 .then1 .else1;\n\n.then1:\n  t1: int = mul x z;\n  jmp .merge;\n\n.else1:\n  t2: int = sub y z;\n  \n.branch2:\n  cond2: bool = gt t2 x;\n  br cond2 .then2 .else2;\n\n.then2:\n  t3: int = add t2 x;\n  \n.else2:\n  t4: int = sub t2 y;\n\n.merge:\n  u: int = phi t1 .then1 t3 .then2 t4 .else2;\n  \n.exit:\n  print u;\n}\n\n\nCFG with Dominators\n #### Dominance Tree \n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 4 -- Implementing Dominance Algorithms"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html",
    "href": "blogs/aymane/mlir-transform-dialect.html",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "",
    "text": "I recently explored the MLIR (Multi-Level Intermediate Representation) Transform dialect. The framework enables control over compiler transformations, at different levels of abstraction. It also utilizes the concept of a schedule to manage complex transformation sequences within the IR. This approach provides engineers with fine grained control over transformations enabling the optimization of code for a wide range of architectures.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#what-is-the-transform-dialect",
    "href": "blogs/aymane/mlir-transform-dialect.html#what-is-the-transform-dialect",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "What is the Transform Dialect?",
    "text": "What is the Transform Dialect?\nThe MLIR transform dialect is designed to enable precise control over compiler transformations by using the compiler IR itself. This approach allows transformations to be embedded with the IR being transformed, an approach that doesn’t require rebuilding the compiler.\nThe main goal of the Transform dialect is to orchestrate fine-grain transformations on individual operations or sets of operations within the IR. Traditional compiler passes can be thought of as a “monolithic black box” that apply transformations to the entire program. Whereas the Transform dialect enables finer control over optimizations for a more targeted approach.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#why-the-transform-dialect",
    "href": "blogs/aymane/mlir-transform-dialect.html#why-the-transform-dialect",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "Why the Transform Dialect?",
    "text": "Why the Transform Dialect?\nIn order to fully utilize the hardware capabilities, target specific compiler optimizations must be leveraged. During compilation, domain specific knowledge can be incorporated to squeeze even more performance out of the hardware. Nowadays, programmers are mostly limited to using high level compiler directives like pragmas to influence passes. This rigid approach lacks modularity and extensibility, meaning that low level program optimizations must be performed for each and every target platform. Additionally, the Transform dialect incurs less than 2.6% compile time overhead while providing robust and scalable features.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#the-end-of-moores-law",
    "href": "blogs/aymane/mlir-transform-dialect.html#the-end-of-moores-law",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "The End of Moore’s Law",
    "text": "The End of Moore’s Law\nFor decades, computer performance was riding the transistor shrinking wave. As transistors got smaller, chips could pack more and more transistors per unit area. The slowing down of Moore’s law has left engineers looking for new ways of obtaining more performance improvements.\n\n\n\ncomputing_landscape\n\n\nThe end of Moore’s law paves the way for specialization and hardware acceleration. Since general purpose hardware is at a saturation point, computing systems now offload certain tasks and workloads to specialized units called accelerators. As opposed to general purpose processing units, accelerators are built with a single specific usage in mind. For example, we are experiencing firsthand the rise of SoCs that integrate all kinds of processors and different heterogeneous systems tailored for domain specific workloads.\nThe complexity needed to manage this ever growing compute platform diversity is not trivial. However, with the help of the compiler, we can bridge the gap between high level software constructs and lower level platform specific implementations. Given the current landscape, frameworks such as LLVM and MLIR aim to consolidate, standardize and solve many of the problems caused by the ever increasing number of specialized architectures.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#payload-and-schedule-approach",
    "href": "blogs/aymane/mlir-transform-dialect.html#payload-and-schedule-approach",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "Payload and Schedule Approach",
    "text": "Payload and Schedule Approach\nThe transform dialect is not the first to separate the payload (ie. program) from the schedule (ie. the transformations performed on the program), in fact frameworks such as Halide, TVM, and TACO have been using this concept before the existence of the Transform dialect. Although, they seperate the schedule from the payload, these frameworks focus on domain specific optimizations, have predefined software stacks and are not well integrated into a generic compiler unlike the Transform dialect. The goal is to provide a general purpose solution that can be deployed for various envrionments and targets.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#modularity-and-extensibility",
    "href": "blogs/aymane/mlir-transform-dialect.html#modularity-and-extensibility",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "Modularity and Extensibility",
    "text": "Modularity and Extensibility\nThe MLIR Transform dialect is designed with modularity at its core. Users have the ability to define new transformations that can integrate seamlessly into existing workflows. One of the standout features is its extensibility. Users can inject additional operations into the dialect using mechanisms like TransformDialectExtension, allowing for custom transformations without altering the core dialect. Additionally, users can compose new transformations by combining existing ones or creating entirely new operations. This allows for precise control over compiler transformations and facilitates the highly iterative workflows needed for research purposes.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#hardware-specific-optimizations-and-search-methods",
    "href": "blogs/aymane/mlir-transform-dialect.html#hardware-specific-optimizations-and-search-methods",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "Hardware Specific Optimizations and Search Methods",
    "text": "Hardware Specific Optimizations and Search Methods\nIn practice, the transform dialect can be used to perform a sequence of optimizations that result in efficient code generation for MLIR operations. The Transform Dialect is particularly effective in optimizing linear algebra computations such as matrix multiplication and convolution.\nComposing existing transformations can lead to highly efficient code tailored to specific architectures. Furthermore, the Transform dialect allows for the customization of compiler transformations to best use the characteristics of the target hardware such as the cache block size or the number of registers. This flexibility is crucial for maximizing performance across a wide range of accelerators.\nThe separation of the payload and schedule allows for the use of search methods to explore optimization spaces effectively. This enables autotuning transformation parameters with the goal of finding the most optimal set of parameters on specific workloads and for specific targets.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/mlir-transform-dialect.html#challenges-and-learning-curve",
    "href": "blogs/aymane/mlir-transform-dialect.html#challenges-and-learning-curve",
    "title": "Project Presentation - The MLIR Transform Dialect",
    "section": "Challenges and Learning Curve",
    "text": "Challenges and Learning Curve\nWhile the transform dialect offers powerful capabilities, it requires a solid understanding of MLIR’s infrastructure. Familiarity with existing transformation patterns and how they interact with the transform dialect is crucial for effectively leveraging its potential.\nFor most of my time, I have treated compilers as a black box, passing in an input file and getting a binary in return. Taking a compiler course has sparked my interest even further. More recently, I have been spending time reading about LLVM and MLIR. Despite the steep learning curve, I believe these to be important and promising frameworks I need to add to my arsenal.\nFor those interested in diving deeper, I recommend starting with MLIR’s basic tutorials before tackling the transform dialect. It’s a rewarding journey that opens up new possibilities in compiler design and optimization.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Project Presentation - The MLIR Transform Dialect"
    ]
  },
  {
    "objectID": "blogs/aymane/readme.html",
    "href": "blogs/aymane/readme.html",
    "title": "Homework 1 – Trying Out Bril",
    "section": "",
    "text": "To compile from typescript to bril and execute the program run the following:\n$ ts2bril bench.ts &gt; bench.bril && brili &lt; bench.bril\n727\nThe typescript benchmark I wrote performs a series of simple arithmetic, logical and alu operations. The function outputs 727 with the default input value 10.\n\n\nWhen writing the typescript benchmark, the input function argument was hardcoded to have value 10. So I couldn’t parametrized the turnt tests. I wanted to figure out a way to pass the input as a command line argument from stdin in order to generate different tests. Now I could do this by importing a typescript package to handle user input. But I’ve decided to manually modify my benchmark at the bril level.\nInitially, the typescript benchmark I wrote resulted in the following bril ir:\nbench.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"value\": 10,\n          \"dest\": \"v31\",\n          \"type\": \"int\"\n        },\n        ...\n      ]\n      \"args\": []\n    },\n    ...\n  ]\n}\nThe value 10 is passed in as a constant to main. In order to parametrize it, a few things need to be modified. First, we need to change the op field from const to id. As explained in the bril documentation, the id opcode is a type-insensitive identity we can use to pass variables around. Additonally, we also need specify the arguments passed to main. To do so, we pass a argument to the function. So the new bril representation becomes:\nbench-param.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"args\": [\n        {\n          \"name\": \"val\",\n          \"type\": \"int\"\n        }\n      ],\n      \"instrs\": [\n        {\n          \"args\": [\n            \"val\"\n          ],\n          \"dest\": \"v31\",\n          \"op\": \"id\",\n          \"type\": \"int\"\n        }, \n      ],\n    },\n    ...\n  ]\n}\n\nNow we can pass any value to the function:\n$ brili &lt; bench-param.bril 12\n2796\nTo more easily view these changes, let’s look at the text formatting of bril by running these commands to convert from json to text.\n$ bril2txt &lt; bench.bril &gt; bench.txt && bril2txt &lt; bench-param.bril &gt; bench-param.txt\nbench.txt\n@main {\n  v31: int = const 10;\n  ...\n}\nbench-param.txt\n@main(val: int) {\n  v31: int = id val;\n  ...\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/aymane/readme.html#passing-command-line-arugments",
    "href": "blogs/aymane/readme.html#passing-command-line-arugments",
    "title": "Homework 1 – Trying Out Bril",
    "section": "",
    "text": "When writing the typescript benchmark, the input function argument was hardcoded to have value 10. So I couldn’t parametrized the turnt tests. I wanted to figure out a way to pass the input as a command line argument from stdin in order to generate different tests. Now I could do this by importing a typescript package to handle user input. But I’ve decided to manually modify my benchmark at the bril level.\nInitially, the typescript benchmark I wrote resulted in the following bril ir:\nbench.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"value\": 10,\n          \"dest\": \"v31\",\n          \"type\": \"int\"\n        },\n        ...\n      ]\n      \"args\": []\n    },\n    ...\n  ]\n}\nThe value 10 is passed in as a constant to main. In order to parametrize it, a few things need to be modified. First, we need to change the op field from const to id. As explained in the bril documentation, the id opcode is a type-insensitive identity we can use to pass variables around. Additonally, we also need specify the arguments passed to main. To do so, we pass a argument to the function. So the new bril representation becomes:\nbench-param.bril:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"args\": [\n        {\n          \"name\": \"val\",\n          \"type\": \"int\"\n        }\n      ],\n      \"instrs\": [\n        {\n          \"args\": [\n            \"val\"\n          ],\n          \"dest\": \"v31\",\n          \"op\": \"id\",\n          \"type\": \"int\"\n        }, \n      ],\n    },\n    ...\n  ]\n}\n\nNow we can pass any value to the function:\n$ brili &lt; bench-param.bril 12\n2796\nTo more easily view these changes, let’s look at the text formatting of bril by running these commands to convert from json to text.\n$ bril2txt &lt; bench.bril &gt; bench.txt && bril2txt &lt; bench-param.bril &gt; bench-param.txt\nbench.txt\n@main {\n  v31: int = const 10;\n  ...\n}\nbench-param.txt\n@main(val: int) {\n  v31: int = id val;\n  ...\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html",
    "title": "Homework2 - local optimizations",
    "section": "",
    "text": "All codes are here: lvn_dce_project",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework2 - local optimizations",
    "section": "Explanation of the Code",
    "text": "Explanation of the Code\nThe code I wrote for this question implements a trivial dead code elimination (DCE) optimization for Bril programs. It works by iterating through the instructions in reverse order, maintaining a set of used variables. Instructions that define variables not in this set are eliminated. The algorithm adds variables used as arguments to the set and removes variables when their defining instruction is processed. This approach ensures that instructions defining unused variables are removed while preserving the program’s essential structure and functionality.\nOutput of the code with Example 1 as the input:\n\nimport json\nimport copy\n\n\ndef tdce(func):\n    used_vars = set()\n    instructions = func['instrs']\n    new_instructions = []\n\n    for instr in reversed(instructions):\n        if 'dest' in instr:\n            if instr['dest'] not in used_vars:\n                continue  # skip this instruction as its destination is never used\n            used_vars.remove(instr['dest'])\n        \n        if 'args' in instr:\n            used_vars.update(instr['args'])\n        \n        new_instructions.append(instr)\n    \n    func['instrs'] = list(reversed(new_instructions))\n    return func\n\ndef main(input_str):\n    prog = json.loads(example1)\n    \n    for func in prog['functions']:\n        func = tdce(func)\n    \n    return json.dumps(prog, indent=2)\n\n# Example 1 as a JSON string (after bril2json conversion)\nexample1 = '''\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n'''\n\nprint(\"Original program:\")\nprint(example1)\nprint(\"\\nOptimized program:\")\noptimized_prog = main(example1)\nprint(optimized_prog)\n\nOriginal program:\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n\n\nOptimized program:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 4\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"b\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"d\",\n          \"args\": [\n            \"a\",\n            \"b\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"d\"\n          ]\n        }\n      ]\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code",
    "title": "Homework2 - local optimizations",
    "section": "Testing the Code",
    "text": "Testing the Code\nAs we can see in above output, line 3 ‘c: int = const 1;’ is removed because c is assigned and never used. we can also further test the code with a bigger input:\nexample2:\n@main {\n  # Variables with different usage patterns\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;  # This is dead code\n  d: int = add a b;\n  e: int = add c d;  # 'c' is used here, but 'e' is never used\n  \n  # Reassignment\n  a: int = const 10;\n  a: int = const 200;  # This overwrites the previous 'a'\n  \n  # Prints to mark usage\n  print a;\n  print d;\n}\n\nimport json\nimport copy\n\n\ndef tdce(func):\n    used_vars = set()\n    instructions = func['instrs']\n    new_instructions = []\n\n    for instr in reversed(instructions):\n        if 'dest' in instr:\n            if instr['dest'] not in used_vars:\n                continue  # skip this instruction as its destination is never used\n            used_vars.remove(instr['dest'])\n        \n        if 'args' in instr:\n            used_vars.update(instr['args'])\n        \n        new_instructions.append(instr)\n    \n    func['instrs'] = list(reversed(new_instructions))\n    return func\n\ndef main(input_str):\n    prog = json.loads(example2)\n    \n    for func in prog['functions']:\n        func = tdce(func)\n    \n    return json.dumps(prog, indent=2)\n\n# Example 2 as a JSON string (after bril2json conversion)\nexample2 = '''\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"e\", \"args\": [\"c\", \"d\"] },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 10 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 200 },\n        { \"op\": \"print\", \"args\": [\"a\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n'''\n\nprint(\"Original program:\")\nprint(example2)\nprint(\"\\nOptimized program:\")\noptimized_prog = main(example2)\nprint(optimized_prog)\n\nOriginal program:\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 1 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"e\", \"args\": [\"c\", \"d\"] },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"d\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 10 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 200 },\n        { \"op\": \"print\", \"args\": [\"a\"] },\n        { \"op\": \"print\", \"args\": [\"d\"] }\n      ]\n    }\n  ]\n}\n\n\nOptimized program:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 4\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"b\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"d\",\n          \"args\": [\n            \"a\",\n            \"b\"\n          ]\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 200\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"a\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"d\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n\n\nAs we expect, we can see that line 3 ise removed, because c is assigned and used in line 5 for defining e but e is never used so these two lines are both dead code, also a is reassigned in line 6 and thus removed.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges-faced",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges-faced",
    "title": "Homework2 - local optimizations",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nOne of the challenges that I can think of in this question, is that for large and complex programs, the reverse iteration and set operations might become a performance bottleneck. Addressing these challenges would involve extending the algorithm, careful consideration of Bril’s semantics, and developing more sophisticated testing strategies.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#part-2",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#part-2",
    "title": "Homework2 - local optimizations",
    "section": "Part 2",
    "text": "Part 2",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "title": "Homework2 - local optimizations",
    "section": "Explanation of the Code",
    "text": "Explanation of the Code\nThe lvn code implements Local Value Numbering to optimize Bril programs by eliminating redundant computations within basic blocks. It processes each instruction, assigns value numbers to expressions based on their operations and operands, and maintains tables to track these values. When it encounters a redundant computation, it eliminates it by reusing the previously computed result, effectively reducing the number of instructions and optimizing the code.\nExample input:\n@main() {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}\n\nimport json\nimport sys\n\n\ndef lvn(func):\n    new_instrs = []\n    value_table = {}  \n    var_table = {}   \n\n    for instr in func['instrs']:\n        if 'op' in instr:\n            if instr['op'] == 'const':\n                value = instr['value']\n                value_num = get_value_number(value_table, ('const', value))\n                value_table[value_num] = ('const', value, instr['dest'])\n                var_table[instr['dest']] = value_num\n                new_instrs.append(instr)\n            elif instr['op'] == 'print':\n                new_instr = instr.copy()\n                if 'args' in new_instr:\n                    new_instr['args'] = [value_table[var_table[arg]][2] for arg in new_instr['args']]\n                new_instrs.append(new_instr)\n            else:\n                args = [var_table.get(arg, arg) for arg in instr.get('args', [])]\n                value_num = get_value_number(value_table, (instr['op'], tuple(args)))\n\n                if value_num in value_table:\n                    # Redundant computation found here!\n                    canonical_op, canonical_args, canonical_var = value_table[value_num]\n                    var_table[instr['dest']] = value_num\n                else:\n                    new_instr = instr.copy()\n                    new_instr['args'] = [value_table[arg][2] if arg in value_table else arg for arg in args]\n                    value_table[value_num] = (instr['op'], tuple(args), instr['dest'])\n                    var_table[instr['dest']] = value_num\n                    new_instrs.append(new_instr)\n        else:\n            new_instrs.append(instr)\n\n    func['instrs'] = new_instrs\n    return func\n\n       \ndef get_value_number(value_table, key):\n    for num, (op, args, var) in value_table.items():\n        if op == key[0] and args == key[1]:\n            return num\n    return len(value_table)\n\ndef main():\n    try:\n        bril_input = json.loads(example1)\n        for func in bril_input['functions']:\n            lvn(func)\n        json.dump(bril_input, sys.stdout, indent=2)\n        sys.stdout.flush()\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n\n\n# Example 1 as a JSON string (after bril2json conversion)\nexample1 = '''\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 4 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"sum1\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"sum2\", \"args\": [\"a\", \"b\"] },\n        { \"op\": \"mul\", \"type\": \"int\", \"dest\": \"prod\", \"args\": [\"sum1\", \"sum2\"] },\n        { \"op\": \"print\", \"args\": [\"prod\"] }\n      ]\n    }\n  ]\n}\n\n'''\n\nif __name__ == '__main__':\n    main()\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"a\",\n          \"value\": 4\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"b\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"sum1\",\n          \"args\": [\n            \"a\",\n            \"b\"\n          ]\n        },\n        {\n          \"op\": \"mul\",\n          \"type\": \"int\",\n          \"dest\": \"prod\",\n          \"args\": [\n            \"sum1\",\n            \"sum1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"prod\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n\n\nAs we can see in the output above, line 5 has been changed to prod: int = mul sum1 sum1;",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code-1",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#testing-the-code-1",
    "title": "Homework2 - local optimizations",
    "section": "Testing the Code",
    "text": "Testing the Code\nFor testing the correctness of the code, I used brench.py code in bril, and for that we need to have a brench.toml file (or a configuration file for brench.py) configures the Brench tool to run a Bril benchmark through four different pipelines: baseline (no optimization), DCE only, LVN only, and LVN followed by DCE. It then extracts the total number of dynamic instructions executed for each run, allowing us to compare the effectiveness of these optimizations. We use brench.toml with python3 ../brench/brench.py brench.toml &gt; results.csv\nexample test:\n@main {\n    a: int = const 1;\n    b: int = const 2;\n\n    c: int = add a b;\n    d: int = add a b;    # Redundant computation\n    e: int = add b a;    # Redundant due to commutativity\n    f: int = mul c d;\n    g: int = mul c e;    # Redundant computation\n\n    sum1: int = add a b; # Same as c, d, and e\n    sum2: int = add a b; # Same as c, d, e, and sum1\n    prod: int = mul sum1 sum2; # Uses two identical values\n\n    h: int = sub f g;    # Dead code: computed but never used\n    i: int = add a a;    # Dead code: computed but never used\n\n    print f;\n    print g;\n    print prod;\n}\nresults.csv:\nbenchmark,run,result\ntest_lvn,baseline,15\ntest_lvn,dce,13\ntest_lvn,lvn,11\ntest_lvn,lvn_dce,9\nBased on this analysis, let’s count the instructions that should remain after each optimization:\nBaseline: 15 instructions (all original instructions)\nDCE: 13 instructions (removes h and i)\nLVN: 11 instructions (keeps a, b, c, f, prod, and the three print statements)\nLVN + DCE: 9 instructions (same as LVN, but also removes h and i)\nTherefore, We can confirm the correctness of the implementations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges",
    "href": "blogs/Sana/09-27-2024-HW2-SanaTaghipourAnvari.html#challenges",
    "title": "Homework2 - local optimizations",
    "section": "Challenges",
    "text": "Challenges\nThe main challenges in lvn.py include handling commutative operations (like recognizing that add a b and add b a are equivalent) and ensuring that value numbering accurately tracks and replaces redundant computations without altering the program’s correct behavior.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework2 - local optimizations"
    ]
  },
  {
    "objectID": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html",
    "href": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html",
    "title": "Homework3 - data flow",
    "section": "",
    "text": "Link for the code: cfgnode",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework3 - data flow"
    ]
  },
  {
    "objectID": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework3 - data flow",
    "section": "Explanation of the code",
    "text": "Explanation of the code\nI implemented a generic data flow analysis framework that supports multiple analyses by designing a reusable structure for different types of data flow problems. The code includes:\nThis code implements a liveness analysis tool for Bril programs. It builds a control flow graph (CFG) from the program’s instructions, computes the in and out sets for each basic block based on variable usage (using the gen and kill sets), and then prints the liveness information for each block. The analysis helps track which variables are live at various points in the program.\n\nimport json\nimport sys\nfrom collections import defaultdict\n\nclass BrilLivenessAnalyzer:\n    def __init__(self):\n        self.cfg = defaultdict(lambda: {'instrs': [], 'succ': set(), 'pred': set()})\n        self.live_in = defaultdict(set)\n        self.live_out = defaultdict(set)\n\n    def analyze(self, program):\n        for function in program['functions']:\n            self.analyze_function(function)\n\n    def analyze_function(self, function):\n        self.build_cfg(function['instrs'])\n        self.compute_liveness()\n        self.print_results()\n\n    def build_cfg(self, instrs):\n        self.cfg.clear()\n        current_block = 'entry'\n\n        for i, instr in enumerate(instrs):\n            if 'label' in instr:\n                current_block = instr['label']\n            self.cfg[current_block]['instrs'].append(instr)\n\n            if instr.get('op') in ['jmp', 'br']:\n                if instr['op'] == 'jmp':\n                    target = instr['labels'][0]\n                    self.cfg[current_block]['succ'].add(target)\n                    self.cfg[target]['pred'].add(current_block)\n                elif instr['op'] == 'br':\n                    for label in instr['labels']:\n                        self.cfg[current_block]['succ'].add(label)\n                        self.cfg[label]['pred'].add(current_block)\n            elif instr.get('op') == 'ret':\n                pass \n            else:\n                if i + 1 &lt; len(instrs) and 'label' in instrs[i + 1]:\n                    next_block = instrs[i + 1]['label']\n                    self.cfg[current_block]['succ'].add(next_block)\n                    self.cfg[next_block]['pred'].add(current_block)\n\n    def compute_liveness(self):\n        changed = True\n        while changed:\n            changed = False\n            for block in self.cfg:\n                old_in = self.live_in[block].copy()\n                old_out = self.live_out[block].copy()\n\n                kill = set()\n                gen = set()\n\n                for instr in self.cfg[block]['instrs']:\n                    if 'dest' in instr:\n                        kill.add(instr['dest'])  \n                    if 'args' in instr:\n                        for arg in instr['args']:\n                            if arg not in kill:\n                                gen.add(arg)  \n\n                #  OUT{P} = Union of IN{Psuccessor}\n                self.live_out[block] = set()\n                for succ in self.cfg[block]['succ']:\n                    self.live_out[block] |= self.live_in[succ]\n\n                #  IN{P} = (OUT{P} - Kill{P}) U Gen{P}\n                self.live_in[block] = (self.live_out[block] - kill) | gen\n\n                if old_in != self.live_in[block] or old_out != self.live_out[block]:\n                    changed = True\n\n        self.live_in['entry'] = set()\n\n    def print_results(self):\n        for block in self.cfg:\n            print(f\"Block: {block}\")\n            print(f\"  In:  {sorted(self.live_in[block])}\")\n            print(f\"  Out: {sorted(self.live_out[block])}\")\n            print()\n\ndef main():\n    json_input = '''\n    {\n      \"functions\": [\n        {\n          \"name\": \"main\",\n          \"instrs\": [\n            { \"op\": \"const\", \"type\": \"int\", \"dest\": \"a\", \"value\": 3 },\n            { \"op\": \"const\", \"type\": \"int\", \"dest\": \"b\", \"value\": 5 },\n            { \"op\": \"const\", \"type\": \"int\", \"dest\": \"d\", \"value\": 4 },\n            { \"op\": \"const\", \"type\": \"int\", \"dest\": \"x\", \"value\": 100 },\n            { \"op\": \"br\", \"args\": [\"gt\", \"a\", \"b\"], \"labels\": [\"b2\", \"b3\"] },\n\n            { \"label\": \"b2\" },\n            { \"op\": \"add\", \"type\": \"int\", \"dest\": \"c\", \"args\": [\"a\", \"b\"] },\n            { \"op\": \"const\", \"type\": \"int\", \"dest\": \"d\", \"value\": 2 },\n            { \"op\": \"jmp\", \"labels\": [\"done\"] },\n\n            { \"label\": \"b3\" },\n            { \"op\": \"const\", \"type\": \"int\", \"dest\": \"c\", \"value\": 4 },\n\n            { \"label\": \"done\" },\n            { \"op\": \"mul\", \"type\": \"int\", \"dest\": \"result\", \"args\": [\"b\", \"d\"] },\n            { \"op\": \"add\", \"type\": \"int\", \"dest\": \"result\", \"args\": [\"result\", \"c\"] },\n            { \"op\": \"ret\", \"args\": [\"result\"] }\n          ]\n        }\n      ]\n    }\n    '''\n\n    program = json.loads(json_input)\n    \n    analyzer = BrilLivenessAnalyzer()\n    analyzer.analyze(program)\n\nif __name__ == \"__main__\":\n    main()\n\nBlock: entry\n  In:  []\n  Out: ['a', 'b', 'd']\n\nBlock: b2\n  In:  ['a', 'b']\n  Out: ['b', 'c', 'd']\n\nBlock: b3\n  In:  ['b', 'd']\n  Out: ['b', 'c', 'd']\n\nBlock: done\n  In:  ['b', 'c', 'd']\n  Out: []",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework3 - data flow"
    ]
  },
  {
    "objectID": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#how-we-testing-our-implementation",
    "href": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#how-we-testing-our-implementation",
    "title": "Homework3 - data flow",
    "section": "How we testing our implementation",
    "text": "How we testing our implementation\n# Bril Code (Block by Block)\n\n# Block: entry\nconst a: int = 3;\nconst b: int = 5;\nconst d: int = 4;\nconst x: int = 100;\nbr gt a b .b2 .b3;\n\n# Block: b2\nb2:\n  add c: int = a + b;\n  const d: int = 2;\n  jmp .done;\n\n# Block: b3\nb3:\n  const c: int = 4;\n\n# Block: done\ndone:\n  mul result: int = b * d;\n  add result: int = result + c;\n  ret result;",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework3 - data flow"
    ]
  },
  {
    "objectID": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#conclusion",
    "href": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#conclusion",
    "title": "Homework3 - data flow",
    "section": "Conclusion:",
    "text": "Conclusion:\nThe results generated by the liveness analysis are correct based on the Bril code provided. Each block correctly identifies the variables that are live before and after it, based on the definitions and uses of those variables within the block and across the program.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework3 - data flow"
    ]
  },
  {
    "objectID": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#hardest-part-of-the-task-and-how-we-addressed-it",
    "href": "blogs/Sana/10-11-2024-HW3-SanaTaghipourAnvari.html#hardest-part-of-the-task-and-how-we-addressed-it",
    "title": "Homework3 - data flow",
    "section": "Hardest Part of the Task and How We Addressed It",
    "text": "Hardest Part of the Task and How We Addressed It\nThe hardest part was ensuring that the liveness analysis results were correctly generalized without hardcoding specific variables. The challenge was to accurately compute the gen and kill sets for each block and propagate liveness across blocks.\n\nHow We Addressed It:\n\nGeneralized Propagation: We avoided manual exclusions and relied on computing gen and kill sets to ensure only the necessary variables appeared in the In and Out sets.\nFixed-Point Iteration: Liveness information was iteratively propagated until no changes occurred, ensuring accurate results.\nValidation: We compared the results for each block with expected outcomes to ensure correctness.\n\nThis approach ensured a generalized and correct liveness analysis.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework3 - data flow"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "",
    "text": "This assignment introduces trivial dead code elimination, and local value numbering. Python code which performs these optimizations are available at the link provided in the Code section.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#introduction",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "",
    "text": "This assignment introduces trivial dead code elimination, and local value numbering. Python code which performs these optimizations are available at the link provided in the Code section.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-1-trivial-dead-code-elimination",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-1-trivial-dead-code-elimination",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Part 1: Trivial Dead Code Elimination",
    "text": "Part 1: Trivial Dead Code Elimination\nIn the first part of this assignment, we implemented trivial dead code elimination. By this, we mean removing instructions which are not used before reassignment. Another way to say this, is that an instruction is not dead if it is used, or if it reaches the end of the basic block, before it is reassigned.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nThe primary challenge I faced here was in attempting to implement more sophisticated dead code elimination, such as at the global scope. I thought this would be interesting to explore, but abandoned it as it is out of scope for this assignment. What proved particularly challenging on this front was handling the case where a variable is used across blocks, where the control flow forms cycles. The code I wrote was considering certain instructions to be unused when there were possible paths in which the instructions were used. When only performing local DCE, this task became much more achievable.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Implementation",
    "text": "Implementation\nTo perform local DCE, first I wrote some code which could partition every function into blocks. With these blocks, we have all the code chunks which are candidates for local DCE. Then, determining dead code was simply determining which instructions are not used by any later instructions in the block. This was done repetitively, as some instructions may on first pass not be considered dead, however they are only used by a dead instruction which will be eliminated.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Testing",
    "text": "Testing\nMy initial line of testing was very curated, and used the following source code:\n@main {\n    a: int = const 4;           # Will be eliminated\n    prod: int = id a;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;        # Will be eliminated\n    prod: int = mul sum1 sum2;  # Will be eliminated\n    sum2: int = id a;\n    prod: int = id sum2;\n    print prod;\n}\nHere, we would expect that the first two instructions assigning prod would be eliminated, and then as a follow-on effect, the first assignment of sum2 also becomes dead code. What we observe aligns with these expectations, and is shown below:\n@main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = id a;\n    prod: int = id sum2;\n    print prod;\n}\nTo further test my dead code elimination, I leveraged the brench tool provided by bril. This tool allows for a pipeline to be created, which source code is passed through. Then, using turnt the results of running the optimized code can be compared to what is expected. In the code repository, there is a .csv file containing the results of running brench against all benchmarks in the bril repository. We observe that all tests pass (or timeout in the case of function_call, which times out with or without optimization). Further, and perhaps dissapointingly, we notice that the number of instructions does not change after optimization for these benchmarks. However, this may be unsurprising, as these benchmarks are in a public code-base, and are less likely to have trivial dead code.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-2-local-value-numbering",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#part-2-local-value-numbering",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Part 2: Local Value Numbering",
    "text": "Part 2: Local Value Numbering\nFor the second part of this assignment, we implemented local value numbering to optimize the number of dynamic instructions executed by a program. The strategy here is to identify where computations have happened before in the code, and where possible do not re-evaluate them, and instead favor a copy.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation-1",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#implementation-1",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Implementation",
    "text": "Implementation\nI used a very straightforward method of implementing LVN, as was discussed in our lectures as well as those from Cornell. The primary difference that one may notice in the code is that there is more significant exception handling which must be done to achieve consistent results.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced-1",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#challenges-faced-1",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nMy initial implementation appeared to work well on some programs, but returned incorrect results on others. This was quite puzzling, but looking at the code which was being produced, it quickly became clear what was going wrong. As a demonstration, consider the following code from dot-product.bril:\nvectorA: ptr&lt;int&gt; = alloc size;\n...\nvectorB: ptr&lt;int&gt; = alloc size;\nThis particular benchmark was failing when testing my initial code, and investigating the results showed the following:\nvectorA: ptr&lt;int&gt; = alloc size;\n...\nvectorB: ptr&lt;int&gt; = id vectorA;\nThis is not good! My hashing / replacement scheme was based entirely off of the instruction operation and the arguments involved, and so in this case, I registered the instruction alloc size as redundant and simply assigned vectorB to vectorA. For simpler instructions this makes sense, however as we are trying to have these vectors point at some dynamically allocated memory, this causes serious issues. So, to handle this, I created a list of special instructions which were not to be optimized in this manner, including functions like alloc.\nAfter this, all but one of the benchmarks was passing, with the lone failure being riemann.bril. Again, this appeared to be a result of the hash function I implemented. Consider the following code:\nleft: float = call @left_riemann a b n;\nprint left;\nmidpoint: float = call @midpoint_riemann a b n;\nprint midpoint;\nright: float = call @right_riemann a b n;\nMy setup was optimizing this code to the following:\nleft: float = call @left_riemann a b n;\nprint left;\nmidpoint: float = id @midpoint_riemann left;\nprint midpoint;\nright: float = id @right_riemann left;\nThis realization came much quicker, as it was clear I omitted certain important values in my hashing function, in this case being the function name which is called. Before this, my algorithm determined that left, midpoint, and right all hashed to callabn, indicating that they are the same value, when of course this is not the case.\nAfter these issues were resolved, everything worked quite well. I spent some time laying the groundwork for constant folding, however I was not able to finish this in reasonable time.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing-1",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#testing-1",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Testing",
    "text": "Testing\nThe primary line of testing for the LVN code was using brench, and using the code which I have developed for this assignment, in the repository linked below, it can be verified that all bril benchmarks pass through a brench test.\nWhat was interesting was that some benchmarks had a substantial decrease in number of dynamic instructions. One in particular was the quadratic.bril benchmark. What I noticed was that there were calls to @sqrt which took the same inputs, and then these were optimized out using local value numbering. This reduced the number of executed instructions from 785 to 412 (a 47.5% decrease!).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#dce-and-lvn",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#dce-and-lvn",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "DCE and LVN",
    "text": "DCE and LVN\nIn the code submitted with this assignment, the provided brench setup actually tests both optimizations, and passes the input code through dce.py first, followed by lvn.py. The results indicate that all tests still pass, and therefore we can say these optimizations work together!",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#code",
    "href": "blogs/michael/09-27-2024-HW2-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 2 – Local Optimizations",
    "section": "Code",
    "text": "Code\nThe code for this assignment is contained in a public GitHub repository which I set up. Notably, to run brench using the provided brench_config.toml file, bril is expected to be two directories above this one. This can be changed by modifying the benchmarks variable in brench_config.toml.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 2 -- Local Optimizations"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "",
    "text": "This assignment asks us to develop code to find the dominators for a basic block, construct the dominance tree, and compute the dominance frontier for each basic block in the program.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#introduction",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "",
    "text": "This assignment asks us to develop code to find the dominators for a basic block, construct the dominance tree, and compute the dominance frontier for each basic block in the program.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#dominance",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#dominance",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "Dominance",
    "text": "Dominance\nA basic block A dominates another basic block B when there is no path in the program which reaches B and does not pass through A. Understanding the dominance relationship between basic blocks can be quite useful for program analysis, and so it is useful to have this tool with which we may determine the dominance relationships in a given program. Additionally, it’s useful to know where a basic block’s dominance “ends” for program analysis techniques. Dominance relationships can further be represented in a graph, which we call a dominance tree. The dominance tree does not always indicate the dominance frontier, particularly in the case of loops. Here, we will show these graphs as Mermaid diagrams.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#implementation",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#implementation",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "Implementation",
    "text": "Implementation\nThe implementation for this program is a set of short python scripts, which can be found using the link at the bottom of this page. To do this effectively, we defined a class for a control flow graph, and gave it four important methods. The first identifies the dominators of a block (compute_dominators()). The dominators of a block are the intersection of all blocks which dominate the predecessors of said block, as well as the block itself. To do this algorithmically, we must iterate at least once through all nodes in the graph. We may iterate more times particularly if there are loops in the control flow, and we can iterate util we reach convergence at an answer. The second identifies the strict dominators of a block (compute_strict_dominators()). Strict dominance is simply dominance but without the property of reflexivity. We compute the strict dominators of a block by taking its dominators and removing itself. The third identifies the immediate dominators of a block. Immediate dominators are the direct parents of blocks in the dominator tree, and indicate when a block strictly dominates another block, but does not dominate any other node which strictly dominates this block. The fourth is a method for computing the dominance frontier of a block. This is done by taking a block, and first investigating whether its successors are dominated by this block. If they are not, then they are included in the dominance frontier. If they are, then we need to investigate the successors of said block. We continue this until we’ve investigated all blocks.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nOne challenge I faced was simply in understanding how to efficiently compute the dominators of a basic block. It is fairly clear when considering the physical representation of a graph what the dominators of a node are, however it took me a moment to determine it using mathematical representations of graphs. Another challenge I faced was when computing the dominance frontiers, I at first implemented an algorithm which did not properly allow nodes to be their own dominance frontiers in certain scenarios. However, this proved to be a relatively easy fix.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#testing",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "Testing",
    "text": "Testing\nI tested my program on five different program inputs, generated in part courtesy of large language models. The programs which I used as test cases have varying types of control flow, and appear to give good coverage of possible program inputs.\nThe first, and most basic code I tested was a program containing a simple if statement.\n@main {\n  x: int = const 5;\n  zero: int = const 0;\n  cond: bool = gt x zero;\n  br cond .true .continue;\n.true:\n  one: int = const 1;\n  x: int = add x one;\n.continue:\n  one: int = const 1;\n  x: int = sub x one;\n  ret x;\n}\n\nWhich has the following CFG:\n\n\n\n\n\ngraph TD\n    true --&gt; continue\n    .start --&gt; continue\n    .start --&gt; true\n\n\n\n\n\n\nHere, we expect that .start strictly dominates both true and continue, and neither true nor continue strictly dominate any nodes. Further, the dominance frontier for all nodes should be empty.\nThis generated the following output:\nNodes and their dominators:\n{'true': {'.start', 'true'}, 'continue': {'continue', '.start'}, '.start': {'.start'}}\n\nNodes and their strict dominators:\n{'true': {'.start'}, 'continue': {'.start'}, '.start': set()}\n\nNodes and their immediate dominators:\n{'true': '.start', 'continue': '.start', '.start': None}\n\nNodes and their dominance frontiers:\n{'true': {'continue'}, 'continue': set(), '.start': set()}\nAnd the following dominance tree:\n\n\n\n\n\ngraph TD\n    .start --&gt; true\n    .start --&gt; continue\n\n\n\n\n\n\nThese results are as expected. One note, is in the printed results from this program, an empty set (set()) and None are used interchangably.\nNext, I examined a program with control flow similar to a switch statement, shown below:\n@main {\n  x: int = const 2;\n  one: int = const 1;\n  two: int = const 2;\n  cond1: bool = eq x one;\n  br cond1 .case1 .check_case2;\n.check_case2:\n  cond2: bool = eq x two;\n  br cond2 .case2 .default;\n.case1:\n  ret one;\n.case2:\n  ret two;\n.default:\n  zero: int = const 0;\n  ret zero;\n}\nWith the following CFG:\n\n\n\n\n\ngraph TD\n    check_case2 --&gt; default\n    check_case2 --&gt; case2\n    .start --&gt; case1\n    .start --&gt; check_case2\n\n\n\n\n\n\nWhat’s interesting here is we expect the dominance graph to look the same as the CFG, because there is no re-connection of branches. Using this as input, we get the following results:\nNodes and their dominators:\n{'case1': {'case1', '.start'}, 'check_case2': {'.start', 'check_case2'}, '.start': {'.start'}, 'case2': {'case2', '.start', 'check_case2'}, 'default': {'default', '.start', 'check_case2'}}\n\nNodes and their strict dominators:\n{'case1': {'.start'}, 'check_case2': {'.start'}, '.start': set(), 'case2': {'.start', 'check_case2'}, 'default': {'.start', 'check_case2'}}\n\nNodes and their immediate dominators:\n{'case1': '.start', 'check_case2': '.start', '.start': None, 'case2': 'check_case2', 'default': 'check_case2'}\n\nNodes and their dominance frontiers:\n{'case1': set(), 'check_case2': set(), '.start': set(), 'case2': set(), 'default': set()}\nWith the dominance graph:\n\n\n\n\n\ngraph TD\n    .start --&gt; case1\n    .start --&gt; check_case2\n    check_case2 --&gt; case2\n    check_case2 --&gt; default\n\n\n\n\n\n\nAs we can see, this graph is the same as the CFG (though mirrored on the vertical axis in this case).\nThe next program I examined was that of a while loop:\n@main {\n  x: int = const 0;\n.loop:\n  ten: int = const 10;\n  cond: bool = lt x ten;\n  br cond .body .exit;\n.body:\n  one: int = const 1;\n  x: int = add x one;\n  jmp .loop;\n.exit:\n  ret x;\n}\nWhich has the CFG:\n\n\n\n\n\ngraph TD\n    .start --&gt; loop\n    loop --&gt; exit\n    loop --&gt; body\n    body --&gt; loop\n\n\n\n\n\n\nHere, we expect that .start dominates all nodes, loop dominates all nodes but .start, and exit and body do not strictly dominate any nodes. Further, the dominance frontier for .start and exit should be no nodes, however loop and body should both have a dominance frontier of loop. This is due to the loop structure of this function. Analyizing this program, we get the following results:\nNodes and their dominators:\n{'.start': {'.start'}, 'loop': {'.start', 'loop'}, 'body': {'.start', 'body', 'loop'}, 'exit': {'.start', 'exit', 'loop'}}\n\nNodes and their strict dominators:\n{'.start': set(), 'loop': {'.start'}, 'body': {'.start', 'loop'}, 'exit': {'.start', 'loop'}}\n\nNodes and their immediate dominators:\n{'.start': None, 'loop': '.start', 'body': 'loop', 'exit': 'loop'}\n\nNodes and their dominance frontiers:\n{'.start': set(), 'loop': {'loop'}, 'body': {'loop'}, 'exit': set()}\n\n\n\n\n\ngraph TD\n    .start --&gt; loop\n    loop --&gt; body\n    loop --&gt; exit\n\n\n\n\n\n\nThese results align with what we expect.\nNow for a more complex looping program, we investigate a program with a loop which contains a branch internally, seen below:\n@main {\n  x: int = const 0;\n.loop:\n  ten: int = const 10;\n  cond: bool = lt x ten;\n  br cond .body .exit;\n.body:\n  two: int = const 2;\n  mod: int = mod x two;\n  zero: int = const 0;\n  cond2: bool = eq mod zero;\n  br cond2 .even .odd;\n.even:\n  two: int = const 2;\n  x: int = add x two;\n  jmp .merge;\n.odd:\n  one: int = const 1;\n  x: int = add x one;\n  jmp .merge;\n.merge:\n  jmp .loop;\n.exit:\n  ret x;\n}\n\n\n\n\n\ngraph TD\n    .start --&gt; loop\n    loop --&gt; body\n    loop --&gt; exit\n    body --&gt; odd\n    body --&gt; even\n    even --&gt; merge\n    odd --&gt; merge\n    merge --&gt; loop\n\n\n\n\n\n\nHere we expect that start dominates all directly connected successors, as do loop and body. Even, odd, and merge should strictly dominate no nodes, and should all have the immediate dominator of body. The dominance frontier of start and exit should both be empty, whereas body, loop, and merge should have a dominance frontier of only loop. Even and odd should contain merge as their dominance frontier.\nWe generate the following results, which align with our expectations:\nNodes and their dominators:\n{'.start': {'.start'}, 'loop': {'.start', 'loop'}, 'body': {'.start', 'loop', 'body'}, 'exit': {'exit', '.start', 'loop'}, 'even': {'even', '.start', 'loop', 'body'}, 'odd': {'odd', '.start', 'loop', 'body'}, 'merge': {'merge', '.start', 'loop', 'body'}}\n\nNodes and their strict dominators:\n{'.start': set(), 'loop': {'.start'}, 'body': {'.start', 'loop'}, 'exit': {'.start', 'loop'}, 'even': {'.start', 'loop', 'body'}, 'odd': {'.start', 'loop', 'body'}, 'merge': {'.start', 'loop', 'body'}}\n\nNodes and their immediate dominators:\n{'.start': None, 'loop': '.start', 'body': 'loop', 'exit': 'loop', 'even': 'body', 'odd': 'body', 'merge': 'body'}\n\nNodes and their dominance frontiers:\n{'.start': set(), 'loop': {'loop'}, 'body': {'loop'}, 'exit': set(), 'even': {'merge'}, 'odd': {'merge'}, 'merge': {'loop'}}\n\n\n\n\n\ngraph TD\n    .start --&gt; loop\n    loop --&gt; body\n    loop --&gt; exit\n    body --&gt; even\n    body --&gt; odd\n    body --&gt; merge\n\n\n\n\n\n\nNow, finally, we investigate a program which contains a nested loop:\n@main {\n  x: int = const 0;\n  y: int = const 0;\n.outer_loop:\n  ten: int = const 10;\n  cond_outer: bool = lt x ten;\n  br cond_outer .inner_loop .exit;\n.inner_loop:\n  five: int = const 5;\n  cond_inner: bool = lt y five;\n  br cond_inner .inner_body .increment_outer;\n.inner_body:\n  one: int = const 1;\n  y: int = add y one;\n  jmp .inner_loop;\n.increment_outer:\n  one: int = const 1;\n  x: int = add x one;\n  y: int = const 0;\n  jmp .outer_loop;\n.exit:\n  ret x;\n}\n\n\n\n\n\ngraph TD\n    .start --&gt; outer_loop\n    outer_loop --&gt; inner_loop\n    outer_loop --&gt; exit\n    inner_loop --&gt; inner_body\n    inner_loop --&gt; increment_outer\n    inner_body --&gt; inner_loop\n    increment_outer --&gt; outer_loop\n\n\n\n\n\n\nHere, we expect that start and outer_loop strictly dominate all successor nodes, and the successors of those nodes. Exit should only dominate itself, as should inner_body and increment_outer. inner_loop should strictly dominate inner_body and increment_outer. .start and exit should have an empty dominance frontier. inner_loop, increment_outer, and outer_loop should contain outer_loop in their dominance frontiers. inner_body should have inner_loop as its dominance frontier. The results of our program are shown below:\nNodes and their dominators:\n{'.start': {'.start'}, 'outer_loop': {'.start', 'outer_loop'}, 'inner_loop': {'inner_loop', '.start', 'outer_loop'}, 'exit': {'.start', 'exit', 'outer_loop'}, 'inner_body': {'inner_body', 'inner_loop', '.start', 'outer_loop'}, 'increment_outer': {'inner_loop', '.start', 'increment_outer', 'outer_loop'}}\n\nNodes and their strict dominators:\n{'.start': set(), 'outer_loop': {'.start'}, 'inner_loop': {'.start', 'outer_loop'}, 'exit': {'.start', 'outer_loop'}, 'inner_body': {'inner_loop', '.start', 'outer_loop'}, 'increment_outer': {'inner_loop', '.start', 'outer_loop'}}\n\nNodes and their immediate dominators:\n{'.start': None, 'outer_loop': '.start', 'inner_loop': 'outer_loop', 'exit': 'outer_loop', 'inner_body': 'inner_loop', 'increment_outer': 'inner_loop'}\n\nNodes and their dominance frontiers:\n{'.start': set(), 'outer_loop': {'outer_loop'}, 'inner_loop': {'inner_loop', 'outer_loop'}, 'exit': set(), 'inner_body': {'inner_loop'}, 'increment_outer': {'outer_loop'}}\n\n\n\n\n\ngraph TD\n    .start --&gt; outer_loop\n    outer_loop --&gt; inner_loop\n    outer_loop --&gt; exit\n    inner_loop --&gt; inner_body\n    inner_loop --&gt; increment_outer",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#code",
    "href": "blogs/michael/10-18-2024-HW4-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 4 – Dominance",
    "section": "Code",
    "text": "Code\nThe code used to generate the above results can be found here. Some of the test cases were initially generated by ChatGPT, but were modified to create better test cases (and for correctness).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 4 -- Dominance"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "",
    "text": "This assignment prompts us to explore LLVM, and to write a basic pass which either analyzes or modifies some input source code.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#introduction",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "",
    "text": "This assignment prompts us to explore LLVM, and to write a basic pass which either analyzes or modifies some input source code.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#llvm",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#llvm",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "LLVM",
    "text": "LLVM\nWe are interested in hacking the LLVM compiler in this assignment, specificially by writing a pass. LLVM gives interested developers a straightforward interface by which to do this, namely by building a shared library object which users can prompt clang/LLVM to dynamically link against. One of the reasons LLVM has become so popular is because of this ability, as well as being used by the largest company in the world.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#design",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#design",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "Design",
    "text": "Design\nHere, I developed a llvm pass which identifies all floating-point arithmetic operations in the llvm-IR. It simply prints these out to stdout. This is not a complex pass by any means, but it does require understanding how to use the LLVM libraries to develop a pass.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nOne challenge I faced was when attempting to implement constant folding. I wrote up the appropriate llvm library to perform constant folding, but was not seeing any code modifications no matter what input I provided. Shortly after, I learned that Clang does constant folding automatically in the frontend, and this feature cannot be turned off.\nA second challenge I faced was when performing the extension of constant folding, which was to put together a constant propagation optimizer. The problem here, unfortunately, I believe lies between chair and keyboard, as I was having issues which I believe are related to my pointer usage. Admittedly, I think I could have finished this (and still may in the future), but ran out of steam to get it done by this assignment deadline.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#testing",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "Testing",
    "text": "Testing\nI tested my program on five different programatic inputs, all which contain a handful of floating point operations. These programs included one addition heavy program, one which had subtraction and division, one which had many multiplications, and two which had floating point arithmetic but also more complex control flow. These programs were largely created by ChatGPT and edited by myself for usefulness and correctness.\nAdditionally, I generated expected test results by writing a basic python text parsing tool, which isolated all floating point arithmetic instructions from the program’s emmitted LLVM. This digest was then directed into .out files, which could be used with turnt. This allowed for easy automated testing, comparing the results delivered by the compiler pass to those delivered by the python script (which is easier to confirm by hand).\nThe test results are shown in the Appendix rather than here, as the program itself is fairly trivial and results are as well. The code can be further verified using the link in the next section.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#code",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "Code",
    "text": "Code\nThe code used to generate the above results, as well as the test cases and tooling, can be found here.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#appendix-test-results",
    "href": "blogs/michael/11-01-2024-HW5-MichaelMaurer.html#appendix-test-results",
    "title": "EECE7309 Homework 5 – LLVM",
    "section": "Appendix: Test Results",
    "text": "Appendix: Test Results\nBelow, we will review the test cases and expected results.\nFirst, let’s look at a simple program which does a floating point addition and a floating point multiplication.\naddition.c\n#include &lt;stdio.h&gt;\n\nint main() {\n    float a = 3.5, b = 2.5, c;\n    c = a + b;\n    c = c * 1.5;\n    printf(\"Result: %f\\n\", c);\n    return 0;\n}\nWith the resulting llvm.\naddition.s\n; ModuleID = 'tests/addition.c'\nsource_filename = \"tests/addition.c\"\ntarget datalayout = \"e-m:o-i64:64-i128:128-n32:64-S128\"\ntarget triple = \"arm64-apple-macosx15.0.0\"\n\n@.str = private unnamed_addr constant [12 x i8] c\"Result: %f\\0A\\00\", align 1\n\n; Function Attrs: noinline nounwind optnone ssp uwtable(sync)\ndefine i32 @main() #0 {\n  %1 = alloca i32, align 4\n  %2 = alloca float, align 4\n  %3 = alloca float, align 4\n  %4 = alloca float, align 4\n  store i32 0, ptr %1, align 4\n  store float 3.500000e+00, ptr %2, align 4\n  store float 2.500000e+00, ptr %3, align 4\n  %5 = load float, ptr %2, align 4\n  %6 = load float, ptr %3, align 4\n  %7 = fadd float %5, %6\n  store float %7, ptr %4, align 4\n  %8 = load float, ptr %4, align 4\n  %9 = fpext float %8 to double\n  %10 = fmul double %9, 1.500000e+00\n  %11 = fptrunc double %10 to float\n  store float %11, ptr %4, align 4\n  %12 = load float, ptr %4, align 4\n  %13 = fpext float %12 to double\n  %14 = call i32 (ptr, ...) @printf(ptr noundef @.str, double noundef %13)\n  ret i32 0\n}\n\ndeclare i32 @printf(ptr noundef, ...) #1\n\nattributes #0 = { noinline nounwind optnone ssp uwtable(sync) \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\nattributes #1 = { \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3}\n!llvm.ident = !{!4}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 8, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"uwtable\", i32 1}\n!3 = !{i32 7, !\"frame-pointer\", i32 1}\n!4 = !{!\"Homebrew clang version 18.1.8\"}\nThis gives the following result, as expected given that there are only two floating point operations.\naddition.out\n  %7 = fadd float %5, %6\n  %10 = fmul double %9, 1.500000e+00\nNow for a program with floating point division and subtraction:\ndivision.c\n#include &lt;stdio.h&gt;\n\nint main() {\n    float a = 10.0, b = 4.0, result;\n    result = a / b;\n    result = result - 1.5;\n    printf(\"Result: %f\\n\", result);\n    return 0;\n}\nwhich has the following llvm:\ndivision.s\n; ModuleID = 'tests/division.c'\nsource_filename = \"tests/division.c\"\ntarget datalayout = \"e-m:o-i64:64-i128:128-n32:64-S128\"\ntarget triple = \"arm64-apple-macosx15.0.0\"\n\n@.str = private unnamed_addr constant [12 x i8] c\"Result: %f\\0A\\00\", align 1\n\n; Function Attrs: noinline nounwind optnone ssp uwtable(sync)\ndefine i32 @main() #0 {\n  %1 = alloca i32, align 4\n  %2 = alloca float, align 4\n  %3 = alloca float, align 4\n  %4 = alloca float, align 4\n  store i32 0, ptr %1, align 4\n  store float 1.000000e+01, ptr %2, align 4\n  store float 4.000000e+00, ptr %3, align 4\n  %5 = load float, ptr %2, align 4\n  %6 = load float, ptr %3, align 4\n  %7 = fdiv float %5, %6\n  store float %7, ptr %4, align 4\n  %8 = load float, ptr %4, align 4\n  %9 = fpext float %8 to double\n  %10 = fsub double %9, 1.500000e+00\n  %11 = fptrunc double %10 to float\n  store float %11, ptr %4, align 4\n  %12 = load float, ptr %4, align 4\n  %13 = fpext float %12 to double\n  %14 = call i32 (ptr, ...) @printf(ptr noundef @.str, double noundef %13)\n  ret i32 0\n}\n\ndeclare i32 @printf(ptr noundef, ...) #1\n\nattributes #0 = { noinline nounwind optnone ssp uwtable(sync) \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\nattributes #1 = { \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3}\n!llvm.ident = !{!4}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 8, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"uwtable\", i32 1}\n!3 = !{i32 7, !\"frame-pointer\", i32 1}\n!4 = !{!\"Homebrew clang version 18.1.8\"}\nAgain, we see quickly that there are only two floating point arithmetic operations. We do see that there are a few floating point operations that are not arithmetic, such as fpext and fptrunc, but these were not omitted in our analysis. That said, it would be trivial to add them to our analysis, as it just expands the size of the switch statement in use.\ndivision.out\n  %7 = fdiv float %5, %6\n  %10 = fsub double %9, 1.500000e+00\nNext, we can try a program which has nested conditionals, to see if this analysis works even with multiple basic blocks.\nnested-conditionals.c\n#include &lt;stdio.h&gt;\n#include &lt;math.h&gt;\n\nint main() {\n    float a = 3.7, b = 2.5, result = 0.0;\n\n    if (a &gt; b) {\n        result = pow(a, 2) - sqrt(b);\n    } else {\n        result = log(a + b) * sin(a);\n    }\n\n    if (result &gt; 5.0) {\n        result /= 2.0;\n    } else if (result &lt; -5.0) {\n        result *= -1.0;\n    } else {\n        result += 1.5;\n    }\n\n    printf(\"Final result: %f\\n\", result);\n    return 0;\n}\nnested-conditionals.s\n; ModuleID = 'tests/nested-conditionals.c'\nsource_filename = \"tests/nested-conditionals.c\"\ntarget datalayout = \"e-m:o-i64:64-i128:128-n32:64-S128\"\ntarget triple = \"arm64-apple-macosx15.0.0\"\n\n@.str = private unnamed_addr constant [18 x i8] c\"Final result: %f\\0A\\00\", align 1\n\n; Function Attrs: noinline nounwind optnone ssp uwtable(sync)\ndefine i32 @main() #0 {\n  %1 = alloca i32, align 4\n  %2 = alloca float, align 4\n  %3 = alloca float, align 4\n  %4 = alloca float, align 4\n  store i32 0, ptr %1, align 4\n  store float 0x400D9999A0000000, ptr %2, align 4\n  store float 2.500000e+00, ptr %3, align 4\n  store float 0.000000e+00, ptr %4, align 4\n  %5 = load float, ptr %2, align 4\n  %6 = load float, ptr %3, align 4\n  %7 = fcmp ogt float %5, %6\n  br i1 %7, label %8, label %17\n\n8:                                                ; preds = %0\n  %9 = load float, ptr %2, align 4\n  %10 = fpext float %9 to double\n  %11 = call double @llvm.pow.f64(double %10, double 2.000000e+00)\n  %12 = load float, ptr %3, align 4\n  %13 = fpext float %12 to double\n  %14 = call double @llvm.sqrt.f64(double %13)\n  %15 = fsub double %11, %14    \n  %16 = fptrunc double %15 to float\n  store float %16, ptr %4, align 4\n  br label %28\n\n17:                                               ; preds = %0\n  %18 = load float, ptr %2, align 4\n  %19 = load float, ptr %3, align 4\n  %20 = fadd float %18, %19\n  %21 = fpext float %20 to double\n  %22 = call double @llvm.log.f64(double %21)\n  %23 = load float, ptr %2, align 4\n  %24 = fpext float %23 to double\n  %25 = call double @llvm.sin.f64(double %24)\n  %26 = fmul double %22, %25\n  %27 = fptrunc double %26 to float\n  store float %27, ptr %4, align 4\n  br label %28\n\n28:                                               ; preds = %17, %8\n  %29 = load float, ptr %4, align 4\n  %30 = fpext float %29 to double\n  %31 = fcmp ogt double %30, 5.000000e+00\n  br i1 %31, label %32, label %37\n\n32:                                               ; preds = %28\n  %33 = load float, ptr %4, align 4\n  %34 = fpext float %33 to double\n  %35 = fdiv double %34, 2.000000e+00\n  %36 = fptrunc double %35 to float\n  store float %36, ptr %4, align 4\n  br label %52\n\n37:                                               ; preds = %28\n  %38 = load float, ptr %4, align 4\n  %39 = fpext float %38 to double\n  %40 = fcmp olt double %39, -5.000000e+00\n  br i1 %40, label %41, label %46\n\n41:                                               ; preds = %37\n  %42 = load float, ptr %4, align 4\n  %43 = fpext float %42 to double\n  %44 = fmul double %43, -1.000000e+00\n  %45 = fptrunc double %44 to float\n  store float %45, ptr %4, align 4\n  br label %51\n\n46:                                               ; preds = %37\n  %47 = load float, ptr %4, align 4\n  %48 = fpext float %47 to double\n  %49 = fadd double %48, 1.500000e+00\n  %50 = fptrunc double %49 to float\n  store float %50, ptr %4, align 4\n  br label %51\n\n51:                                               ; preds = %46, %41\n  br label %52\n\n52:                                               ; preds = %51, %32\n  %53 = load float, ptr %4, align 4\n  %54 = fpext float %53 to double\n  %55 = call i32 (ptr, ...) @printf(ptr noundef @.str, double noundef %54)\n  ret i32 0\n}\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare double @llvm.pow.f64(double, double) #1\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare double @llvm.sqrt.f64(double) #1\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare double @llvm.log.f64(double) #1\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare double @llvm.sin.f64(double) #1\n\ndeclare i32 @printf(ptr noundef, ...) #2\n\nattributes #0 = { noinline nounwind optnone ssp uwtable(sync) \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\nattributes #1 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }\nattributes #2 = { \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3}\n!llvm.ident = !{!4}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 8, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"uwtable\", i32 1}\n!3 = !{i32 7, !\"frame-pointer\", i32 1}\n!4 = !{!\"Homebrew clang version 18.1.8\"}\nAnd as we can see, the program finds the floating point arithmetic operations in question.\nnested-conditionals.out\n  %15 = fsub double %11, %14\n  %20 = fadd float %18, %19\n  %26 = fmul double %22, %25\n  %35 = fdiv double %34, 2.000000e+00\n  %44 = fmul double %43, -1.000000e+00\n  %49 = fadd double %48, 1.500000e+00\nThe next program contains many multiplication operations, so we expect the result to contain ten fmul operations.\nmultiplication.c\n#include &lt;stdio.h&gt;\n\nint main()\n{\n    float a = 1.1, b = 2.2, c = 3.3, d = 4.4, e = 5.5;\n    float f = 6.6, g = 7.7, h = 8.8, i = 9.9, j = 10.1;\n\n    float result1 = a * b;\n    float result2 = c * d;\n    float result3 = e * f;\n    float result4 = g * h;\n    float result5 = i * j;\n\n    float result6 = a * c;\n    float result7 = e * g;\n    float result8 = i * a;\n    float result9 = b * f;\n    float result10 = d * h;\n\n    return 0;\n}\nmultiplication.s\n; ModuleID = 'tests/multiplication.c'\nsource_filename = \"tests/multiplication.c\"\ntarget datalayout = \"e-m:o-i64:64-i128:128-n32:64-S128\"\ntarget triple = \"arm64-apple-macosx15.0.0\"\n\n; Function Attrs: noinline nounwind optnone ssp uwtable(sync)\ndefine i32 @main() #0 {\n  %1 = alloca i32, align 4\n  %2 = alloca float, align 4\n  %3 = alloca float, align 4\n  %4 = alloca float, align 4\n  %5 = alloca float, align 4\n  %6 = alloca float, align 4\n  %7 = alloca float, align 4\n  %8 = alloca float, align 4\n  %9 = alloca float, align 4\n  %10 = alloca float, align 4\n  %11 = alloca float, align 4\n  %12 = alloca float, align 4\n  %13 = alloca float, align 4\n  %14 = alloca float, align 4\n  %15 = alloca float, align 4\n  %16 = alloca float, align 4\n  %17 = alloca float, align 4\n  %18 = alloca float, align 4\n  %19 = alloca float, align 4\n  %20 = alloca float, align 4\n  %21 = alloca float, align 4\n  store i32 0, ptr %1, align 4\n  store float 0x3FF19999A0000000, ptr %2, align 4\n  store float 0x40019999A0000000, ptr %3, align 4\n  store float 0x400A666660000000, ptr %4, align 4\n  store float 0x40119999A0000000, ptr %5, align 4\n  store float 5.500000e+00, ptr %6, align 4\n  store float 0x401A666660000000, ptr %7, align 4\n  store float 0x401ECCCCC0000000, ptr %8, align 4\n  store float 0x40219999A0000000, ptr %9, align 4\n  store float 0x4023CCCCC0000000, ptr %10, align 4\n  store float 0x4024333340000000, ptr %11, align 4\n  %22 = load float, ptr %2, align 4\n  %23 = load float, ptr %3, align 4\n  %24 = fmul float %22, %23\n  store float %24, ptr %12, align 4\n  %25 = load float, ptr %4, align 4\n  %26 = load float, ptr %5, align 4\n  %27 = fmul float %25, %26\n  store float %27, ptr %13, align 4\n  %28 = load float, ptr %6, align 4\n  %29 = load float, ptr %7, align 4\n  %30 = fmul float %28, %29\n  store float %30, ptr %14, align 4\n  %31 = load float, ptr %8, align 4\n  %32 = load float, ptr %9, align 4\n  %33 = fmul float %31, %32\n  store float %33, ptr %15, align 4\n  %34 = load float, ptr %10, align 4\n  %35 = load float, ptr %11, align 4\n  %36 = fmul float %34, %35\n  store float %36, ptr %16, align 4\n  %37 = load float, ptr %2, align 4\n  %38 = load float, ptr %4, align 4\n  %39 = fmul float %37, %38\n  store float %39, ptr %17, align 4\n  %40 = load float, ptr %6, align 4\n  %41 = load float, ptr %8, align 4\n  %42 = fmul float %40, %41\n  store float %42, ptr %18, align 4\n  %43 = load float, ptr %10, align 4\n  %44 = load float, ptr %2, align 4\n  %45 = fmul float %43, %44\n  store float %45, ptr %19, align 4\n  %46 = load float, ptr %3, align 4\n  %47 = load float, ptr %7, align 4\n  %48 = fmul float %46, %47\n  store float %48, ptr %20, align 4\n  %49 = load float, ptr %5, align 4\n  %50 = load float, ptr %9, align 4\n  %51 = fmul float %49, %50\n  store float %51, ptr %21, align 4\n  ret i32 0\n}\n\nattributes #0 = { noinline nounwind optnone ssp uwtable(sync) \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3}\n!llvm.ident = !{!4}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 8, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"uwtable\", i32 1}\n!3 = !{i32 7, !\"frame-pointer\", i32 1}\n!4 = !{!\"Homebrew clang version 18.1.8\"}\nAnd we observe what is expected: multiplication.out\n  %24 = fmul float %22, %23\n  %27 = fmul float %25, %26\n  %30 = fmul float %28, %29\n  %33 = fmul float %31, %32\n  %36 = fmul float %34, %35\n  %39 = fmul float %37, %38\n  %42 = fmul float %40, %41\n  %45 = fmul float %43, %44\n  %48 = fmul float %46, %47\n  %51 = fmul float %49, %50\nFinally, we look at a program with a looping control flow, whihc performs floating point divisions, additions, and multiplications. looping_addition.c\n#include &lt;stdio.h&gt;\n\nint main() {\n    float x = 1.0, sum = 0.0;\n    for (int i = 0; i &lt; 5; i++) {\n        sum += x / (i + 1);\n        if (sum &gt; 2.0) {\n            sum *= 0.5;\n        }\n        x += 1.0;\n    }\n    printf(\"Final sum: %f\\n\", sum);\n    return 0;\n}\nlooping_addition.s\n; ModuleID = 'tests/looping_addition.c'\nsource_filename = \"tests/looping_addition.c\"\ntarget datalayout = \"e-m:o-i64:64-i128:128-n32:64-S128\"\ntarget triple = \"arm64-apple-macosx15.0.0\"\n\n@.str = private unnamed_addr constant [15 x i8] c\"Final sum: %f\\0A\\00\", align 1\n\n; Function Attrs: noinline nounwind optnone ssp uwtable(sync)\ndefine i32 @main() #0 {\n  %1 = alloca i32, align 4\n  %2 = alloca float, align 4\n  %3 = alloca float, align 4\n  %4 = alloca i32, align 4\n  store i32 0, ptr %1, align 4\n  store float 1.000000e+00, ptr %2, align 4\n  store float 0.000000e+00, ptr %3, align 4\n  store i32 0, ptr %4, align 4\n  br label %5\n\n5:                                                ; preds = %29, %0\n  %6 = load i32, ptr %4, align 4\n  %7 = icmp slt i32 %6, 5\n  br i1 %7, label %8, label %32\n\n8:                                                ; preds = %5\n  %9 = load float, ptr %2, align 4\n  %10 = load i32, ptr %4, align 4\n  %11 = add nsw i32 %10, 1\n  %12 = sitofp i32 %11 to float\n  %13 = fdiv float %9, %12\n  %14 = load float, ptr %3, align 4\n  %15 = fadd float %14, %13\n  store float %15, ptr %3, align 4\n  %16 = load float, ptr %3, align 4\n  %17 = fpext float %16 to double\n  %18 = fcmp ogt double %17, 2.000000e+00\n  br i1 %18, label %19, label %24\n\n19:                                               ; preds = %8\n  %20 = load float, ptr %3, align 4\n  %21 = fpext float %20 to double\n  %22 = fmul double %21, 5.000000e-01\n  %23 = fptrunc double %22 to float\n  store float %23, ptr %3, align 4\n  br label %24\n\n24:                                               ; preds = %19, %8\n  %25 = load float, ptr %2, align 4\n  %26 = fpext float %25 to double\n  %27 = fadd double %26, 1.000000e+00\n  %28 = fptrunc double %27 to float\n  store float %28, ptr %2, align 4\n  br label %29\n\n29:                                               ; preds = %24\n  %30 = load i32, ptr %4, align 4\n  %31 = add nsw i32 %30, 1\n  store i32 %31, ptr %4, align 4\n  br label %5, !llvm.loop !5\n\n32:                                               ; preds = %5\n  %33 = load float, ptr %3, align 4\n  %34 = fpext float %33 to double\n  %35 = call i32 (ptr, ...) @printf(ptr noundef @.str, double noundef %34)\n  ret i32 0\n}\n\ndeclare i32 @printf(ptr noundef, ...) #1\n\nattributes #0 = { noinline nounwind optnone ssp uwtable(sync) \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\nattributes #1 = { \"frame-pointer\"=\"non-leaf\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"apple-m1\" \"target-features\"=\"+aes,+complxnum,+crc,+dotprod,+fp-armv8,+fp16fml,+fullfp16,+jsconv,+lse,+neon,+pauth,+ras,+rcpc,+rdm,+sha2,+sha3,+v8.1a,+v8.2a,+v8.3a,+v8.4a,+v8.5a,+v8a,+zcm,+zcz\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3}\n!llvm.ident = !{!4}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 8, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"uwtable\", i32 1}\n!3 = !{i32 7, !\"frame-pointer\", i32 1}\n!4 = !{!\"Homebrew clang version 18.1.8\"}\n!5 = distinct !{!5, !6}\n!6 = !{!\"llvm.loop.mustprogress\"}\nAnd we see all four floating point arithmetic operations are found. looping_addition.out\n  %13 = fdiv float %9, %12\n  %15 = fadd float %14, %13\n  %22 = fmul double %21, 5.000000e-01\n  %27 = fadd double %26, 1.000000e+00",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 5 -- LLVM"
    ]
  },
  {
    "objectID": "check-links.html",
    "href": "check-links.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "# check all the links - get a list of all internal links\n# find all the files that are not used\n\n\nimport os\n\ndef get_all_files(base):\n    \"\"\"Returns a set of all paths to all files below base.\"\"\"\n    all_files = set()\n    skips = ['.git', '_site', \".quarto\"]\n    for root, dirs, files in os.walk(base):\n        for skip in skips:\n            if skip in dirs:\n                dirs.remove(skip)\n        for file in files:\n            all_files.add(os.path.join(root, file)[2:])\n    return all_files\n\n\nextra_files = get_all_files(\".\")\n\nprint(extra_files)\n\n{'lectures/images/StaticSingleAssignment_Part48.jpg', 'lectures/images/StaticSingleAssignment_Part73.jpg', 'issues', 'runfirst.py', 'lectures/images/StaticSingleAssignment_Part71.jpg', 'lectures/12_memory.qmd', 'Class_Overview/sylibus.qmd', 'lectures/03b_local_value_numbering.qmd', 'lectures/02b_bril.qmd.saved', 'lectures/100_mlir.qmd', 'lectures/03_local.qmd', 'lectures/05_global.qmd', 'description.txt', 'Class_Overview/about.qmd', 'lectures/04_data_flow.qmd', 'lectures/images/StaticSingleAssignment_Part69.jpg', 'index.qmd', 'notebooks/representation.ipynb', 'lectures/13_dynamic_compilers.qmd', 'lectures/images/my_ast', 'lectures/images/StaticSingleAssignment_Part40.jpg', 'lectures/images/add.json', 'lectures/images/Grace_Hopper_and_UNIVAC.jpg', 'lectures/08_classic_loop_ops.qmd', 'weekly.qmd', 'found_links.csv', 'lectures/02b_bril.qmd', 'lectures/14_gpu_compilers.qmd', 'Links-21-6-2024 83848.csv', 'lectures/junk.qmd', 'lectures/images/StaticSingleAssignment_Part40.pdf', 'Links-21-6-2024 84630.csv', 'notebooks/possible_papers.qmd', 'about.qmd', 'notebooks/02aa_reps.ipynb', 'lectures/images/Digraph.gv', 'Links-21-6-2024 84311.csv', 'lectures/images/StaticSingleAssignment_Part41.jpg', 'lectures/bril.qmd', 'lectures/images/StaticSingleAssignment_Part70.jpg', 'notebooks/llvm.ipynb', '.github/workflows/publish.yml', 'lectures/110_whole_program.qmd', 'lectures/images/Digraph.gv.png', 'requirements.txt', 'lectures/02a_representation.qmd.saved', 'lectures/02a_representation.qmd', 'lectures/06_ssa.qmd', 'lectures/images/StaticSingleAssignment_Part46.jpg', 'lectures/01a_performance_measurement.qmd', '.gitignore', 'lectures/images/toy.ts', '.vscode/settings.json', 'setenv.sh', 'lectures/images/StaticSingleAssignment_Part43.jpg', 'lectures/images/my_ast.png', 'styles.css', 'notebooks/02_reps.ipynb', 'Links-21-6-2024 84544.csv', 'check-links.ipynb', 'Links-21-6-2024 8400.csv', 'Class_Overview/schedule.qmd', 'lectures/02b_bril.ipynb', 'lectures/05b_licm.qmd', 'Links-21-6-2024 84235.csv', '_quarto.yml', 'lectures/09_poly.qmd', 'Class_Overview/What_to_do.qmd', 'lectures/07_llvm.ipynb', 'lectures/images/cfg.png', 'lectures/010_compiler_overview.qmd', 'notebooks/bril.ipynb', 'lectures/02a_representation.ipynb'}\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\nclass ctx():\n    def __init__(self, top):\n        self.top = top\n        self.external_links = set()\n        self.missing_files = set()\n        self.extra_files = set()\n        self.seen_urls = set()\n        self.seen_links = set()\n\n\n\n\ndef parseLinks(pageHtml, pageUrl, ctx):\n    soup = BeautifulSoup(pageHtml, 'html.parser')\n\n    #get all the &lt;a&gt; elements from the HTML page\n    allLinks = soup.find_all('a')\n\n    extIntLinks(allLinks, pageUrl, ctx)\n\n\ndef requestMaker(url, ctx):\n    if (url in ctx.seen_urls):\n        return\n    ctx.seen_urls.add(url)\n    try:\n        #make the get request to the url\n        response = requests.get(url)\n\n        #if the request is successful\n        if response.status_code in range(200, 300):\n            #extract the page html content for parsing the links\n            pageHtml = response.text\n            pageUrl = response.url\n\n            #call the parseLink function\n            parseLinks(pageHtml, pageUrl, ctx)\n        \n        else:\n            print(\"Sorry Could not fetch the result status code {response.status_code}!\")\n\n    except Exception as e:\n        print(f\"{e} Could Not Connect to url {url}\")\n\n\nfrom sympy import I\n\n\ndef extIntLinks(allLinks, pageUrl, ctx):\n\n    #go through all the &lt;a&gt; elements list \n    for anchor in allLinks:\n        link = anchor.get(\"href\")   #get the link from the &lt;a&gt; element\n\n        link_orig = link\n\n        if link is None:\n            continue\n        print(f\"link {link}\")\n\n        if link.startswith(\".\"):\n            if link == \"./\":\n                continue\n\n            if link in ctx.seen_links:\n                continue\n            ctx.seen_links.add(link)\n            file = link[2:] # remove ./\n            ## deal with the possible enddings \n\n            if file.startswith(\"revealjs-\"):\n                file = file[10:]\n\n            if file.endswith(\".html\"):\n                file_qmd =  file[:-4]+ \"qmd\"\n                if file_qmd in extra_files:\n                    extra_files.remove(file_qmd)\n                    newurl = ctx.top + '/' + file\n                    requestMaker(newurl, ctx)\n                    continue\n\n        elif link.startswith(ctx.top):\n            print(\"starts with top\")\n            continue\n\n        \n        elif link.startswith(\"#\") :\n            print(\"ref link\")\n\n        elif link.startswith(\"https://capra\"):\n            ctx.external_links.add(link)\n\n        elif link.startswith(\"https://github.com\"):\n            ctx.external_links.add(link)\n\n        elif link.startswith(\"https://quarto.org\"):\n            ctx.external_links.add(link)\n        \n        else: \n            print(\"else \", link, link_orig)\n\n     \n\n\nurl = \"https://normrubin.github.io\"\nrequestMaker(url, ctx(url))\n\nlink ./\nlink ./weekly.html\nlink ./weekly.html\nlink ./weekly.html\nlink ./\nlink ./weekly.html\nlink ./Class_Overview/about.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/about.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/about.html\nlink ../weekly.html\nlink ../Class_Overview/schedule.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/about.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/schedule.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.ipynb\nlink ../lectures/02b_bril.ipynb\nlink ../lectures/03_local.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/schedule.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/sylibus.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.ipynb\nlink ../lectures/02b_bril.ipynb\nlink ../lectures/03_local.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/What_to_do.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/sylibus.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/What_to_do.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/What_to_do.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/What_to_do.html\nlink https://quarto.org/\nlink ../Class_Overview/sylibus.html\nlink ../lectures/010_compiler_overview.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/What_to_do.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./lectures/010_compiler_overview.html\nlink ../weekly.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/010_compiler_overview.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink revealjs-compiler_overview.html\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Class_Overview/What_to_do.html",
    "href": "Class_Overview/What_to_do.html",
    "title": "How to submit assignments",
    "section": "",
    "text": "Assignments get submitted as blog postings. In setting up the class web site I used quarto which lets you write a blog post in markdown (no messy html required). I recommend you use it as well. quarto converts markdown files to html and revealjs (for slides)",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "href": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "title": "How to submit assignments",
    "section": "",
    "text": "Assignments get submitted as blog postings. In setting up the class web site I used quarto which lets you write a blog post in markdown (no messy html required). I recommend you use it as well. quarto converts markdown files to html and revealjs (for slides)",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "href": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "title": "How to submit assignments",
    "section": "Submitting via pull requests",
    "text": "Submitting via pull requests\nTo add a blog post (which you must do for homework, discussion leading, and project reports), use a pull request.\nYou’ll want to create a text file in the blog directory with your new post. Use a filename like YYYY-MM-DD-title.qmd, where the date is the discussion day or the project deadline and the title is up to you.\nEach quarto file starts with some meta data. For example the sample file has\n---\nformat:\n\n\n\n\n---\nauthor: norm\nformat:\n html: default\ntitle: sample blog\n---\n\n\n\n\n\nThe rest of the text file is the Markdown text of your blog post.\nIf you want to use math in your blog post, you can use latex dollar signs like $\\pi$ for \\(\\pi\\) for inline math and $$ e^{i\\pi} + 1 = 0 $$ for \\[ e^{i\\pi} + 1 = 0 \\].\nTo include images or other resources in your post, make your post into a directory. That is, make a new directory called YYYY-MM-DD-title inside blog. Then, put your text in a file called index.qmd inside that. Put your images in the same directory and refer to them with relative paths. See the QUARTO docs on for more details.\nYou can preview your writing with any Markdown renderer. To see what it will look like when published, install quarto and type quarto render to preview the entire site. Visual code has a really nice quarto extension that can preview pages.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#homework",
    "href": "Class_Overview/What_to_do.html#homework",
    "title": "How to submit assignments",
    "section": "Homework",
    "text": "Homework\nTo reinforce the specific compiler techniques we cover in class, you will implement them on your own. In lessons, we will discuss the high-level ideas and provide pseudo-code; your task is to translate these into working code and collect empirical evidence to demonstrate their effectiveness. Completing these implementations will reveal practical challenges that are not apparent from a high-level overview.\nTesting your implementation is crucial. Your goal is to provide convincing evidence that your implementation performs as intended. For instance, an optimization should generally make programs faster without causing any errors. While formal proofs of these properties are likely out of scope, you will need to find alternative ways to gather evidence. Avoid relying solely on existing test cases in the Bril repository, as they are typically insufficient. instead, consider using all the benchmarks available in the repo.\nYou may work individually or in groups of 2–3 students. Upon completing an implementation, follow these steps:\n\nConsider putting all your code online in an open-source repository, such as GitHub (optional but recommended). Create a fork of the class repository if desired.\nSubmit the assignment on Canvas by providing a text file with a URL to your open-source implementation. If you prefer not to open-source your code, you can upload the code itself.\nWrite a brief post in the lesson’s associated GitHub Discussions thread, covering the following topics (one paragraph each is sufficient):\n\nSummarize what you did.\nExplain how you tested your implementation. What test inputs did you use? Do you have any quantitative results?\nDescribe the hardest part of the task and how you addressed this challenge.\n\n\nEnsure all implementation tasks are your own work or done with your group. Although sample implementations for many tasks are available in the GitHub repository, you are not allowed to use this code. Similarly, you may not use implementations open-sourced by past students. I recommend not looking at these implementations while working on your tasks to ensure you genuinely learn the material. However, if you absolutely need to refer to them, you are responsible for managing your own learning process.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#paper-reading-discussion",
    "href": "Class_Overview/What_to_do.html#paper-reading-discussion",
    "title": "How to submit assignments",
    "section": "Paper Reading & Discussion",
    "text": "Paper Reading & Discussion\nPaper discussions are on GitHub Discussions.\nAnother part of this course involves reading and discussing research papers. For each paper (see the schedule), everyone will participate in the discussion in two ways: asynchronously on GitHub Discussions threads before class, and synchronously in class. For every paper, there will be a Discussions topic; post at least one message with your thoughts on the paper before the class discussion. Your comment doesn’t need to be long—just a couple of sentences is fine. You can also respond to others’ thoughts on the thread.\nFor some papers, you will be the discussion leader. Leaders have three extra responsibilities: monitoring and replying to the asynchronous discussion, moderating and guiding the in-class discussion, and synthesizing ideas into a blog post afterward.\nLeader Responsibilities\nAt least a week before the discussion day:\n1) Create a GitHub Discussions thread in the Reading category for your topic.\nDuring the lead-up to the discussion day:\n1) Monitor the GitHub Discussions thread for your topic. Answer questions and offer additional insights as needed.\n1) Collect a list of questions for the in-class discussion. You can create your own or select the best from the online discussion.\nOn the discussion day:\nModerate the discussion. Provide enough background to get to the discussion questions and facilitate the conversation.\nDue one week after the discussion day:\n\nWrite a post about the paper for our course blog. The post should include:\n\nBackground information necessary to understand the paper.\nA detailed summary of the main contributions.\nCritical analysis of the merits and shortcomings of the work.\nDiscussion of the paper’s role in history and its connections to the current computing landscape.\n\n\nIncorporate the best ideas from the online and in-class discussions. You can present your own opinions, the class consensus, or both.\n\n\nWriting the Blog Post\nWhile summarizing the paper, avoid letting direct summary dominate your post. Keep the technical explanation to about a quarter of the length. Prioritize breadth over depth in your summary, and highlight specific contributions instead of covering the entire paper.\nFocus most of your writing on your own commentary: context, criticism, and discussion. Choose a title for your blog post that reflects the main point you want to make about the paper, rather than just the paper’s title.\nFor inspiration, check out previous cs6120 blog posts. However, avoid reading posts about your paper, if they exist.\nPublishing\nPublish the post to the course GitHub repository by opening a pull request. Once your PR is open, announce it on the appropriate Discussions thread to let others know.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#project-proposal",
    "href": "Class_Overview/What_to_do.html#project-proposal",
    "title": "How to submit assignments",
    "section": "project Proposal",
    "text": "project Proposal\nThe first deadline is the project proposal. Open a GitHub issue answering these three questions:\nWhat will you do? How will you do it? How will you empirically measure success?\nYou should also list the GitHub usernames of everyone in the group. After you send the PR, submit its URL to the “Project Proposal” assignment on canvas.\nThe instructor will have feedback on how to approach your project.\nImplementation\nThe main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nI strongly recommend that you develop your code as an open-source project. Use a publicly-visible version control repository on a host like GitHub, and include an open source license. When you create your repository, comment on your proposal GitHub issue with a link. (If you have a specific objection to open-sourcing your code, that’s OK—include a description of how you’ll share your code privately with me.)\nEvaluation\nA major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\nWhere will you get the input code you’ll use in your evaluation? How will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs. How will you measure the benefit (in performance, energy, complexity, etc.) of your implementation?\nHow will you present the data you collect from your empirical evaluation? Other questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#project-experience-report",
    "href": "Class_Overview/What_to_do.html#project-experience-report",
    "title": "How to submit assignments",
    "section": "project Experience Report",
    "text": "project Experience Report\nFor the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions in excruciating, exhaustive detail:\nWhat was the goal? What did you do? (Include both the design and the implementation.) What were the hardest parts to get right? Were you successful? (Report rigorously on your empirical evaluation.) As with paper discussions, you can optionally include a video to go along with your blog post.\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog. In your PR description, please include “closes #N” where N is the issue number for your proposal",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "machine learning",
    "section": "",
    "text": "Start with compiler data structures\nSSA, DDG, CFG\nHuman expert maps these to a feature vector\n\nnumber of instructions\nmean dependence depth\nbranch count\nloop next\n…\ntrip count\n\ncollect many examples of programs - calculate feature vector"
  },
  {
    "objectID": "ai.html#pre---ai-methods",
    "href": "ai.html#pre---ai-methods",
    "title": "machine learning",
    "section": "",
    "text": "Start with compiler data structures\nSSA, DDG, CFG\nHuman expert maps these to a feature vector\n\nnumber of instructions\nmean dependence depth\nbranch count\nloop next\n…\ntrip count\n\ncollect many examples of programs - calculate feature vector"
  },
  {
    "objectID": "notebooks/02aa_reps.html",
    "href": "notebooks/02aa_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02aa_reps.html#a-more-regular-representation",
    "href": "notebooks/02aa_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02_reps.html",
    "href": "notebooks/02_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02_reps.html#a-more-regular-representation",
    "href": "notebooks/02_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "homework/dynamic.html",
    "href": "homework/dynamic.html",
    "title": "homework 7 dynamic compile",
    "section": "",
    "text": "This task is to implement a trace-based speculative optimizer for Bril. You’ll implement the same concept as in a tracing JIT, but in a profile-guided AOT setting: profiling, transformation, and execution will be distinct phases. The idea is to implement the “heavy lifting” for a trace-based JIT without needing all the scaffolding that a complete JIT requires, such as on-stack replacement.\nConcretely, there are three main phases:\n\nModify the reference interpreter to produce traces.\nBuild an optimizer that injects traces back into the original program using the speculation extension to provide a “fast path.”\nCheck that the whole process is correct and had some effect on performance (it needn’t actually be good!).\n\nStart by reading the documentation for the speculation extension (and watch the video!). That should give you an idea of what’s required to augment a program with a speculative execution of an extracted trace. Then make a plan for how you’ll hack the interpreter to produce one of those traces.\nHere’s a recipe:\n\nStart interpreting normally.\nAt some point during execution (at the very beginning of main, for example, or when reaching a backedge), start tracing.\nWhile tracing, record every instruction as it executes. Eliminate jumps; replace branches with guard instructions. Feel free to do the interprocedural version, and to bail out on any other instruction you don’t want to handle.\nStop tracing at some point (after a fixed number of instructions, for example, or at the next backedge) and save the trace to a file.\nFor bonus “points,” statically optimize the trace by eliminating instructions that depend on foregone conclusions enforced by guards.\nTransform the program to stitch the trace back into the program using speculate and commit instructions.\nFor these tasks, unlike some previous lessons, I recommend not attempting to support all the benchmarks. It’s more important that you understand a few programs well than you apply your transformation to a large body of code. (In other words, I recommend that you work depth-first instead of breadth-first.)\n\nIn particular, you do not need to support Bril’s memory extension, which makes things more complicated because it doesn’t get automatically rolled back on speculation aborts. If you are feeling very ambitious, you can try devising a scheme to manually roll back memory modifications on aborts (consider an “undo log” or “redo log,” which are concepts from databases).\nFinally, evaluate your work:\n\nCheck that you didn’t break programs. For at least one benchmark (and ideally a few), create multiple inputs to the program that result in different outputs. Use one input to generate the trace and optimize the program, and use other inputs to check correctness. This approach guards against cases where your tracing optimization “overfits” and you end up with code that only works on one input. Measure performance impact, i.e., the effect of your transformation on the dynamic instruction count.\nfor at least one benchmark, use at least two inputs to evaluate tracing’s impact on executions that are not identical to the traced execution. If you implemented optimizations on the traced code, consider comparing the optimized vs. un-optimized versions. (It’s OK if your tracing apparatus makes programs slower, especially on unseen inputs! We just want to measure the difference.)\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "homework 7 dynamic compile"
    ]
  },
  {
    "objectID": "homework/3_hw.html",
    "href": "homework/3_hw.html",
    "title": "Homework 4 data flow",
    "section": "",
    "text": "Implement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework  4 data flow"
    ]
  },
  {
    "objectID": "homework/1.hw.html",
    "href": "homework/1.hw.html",
    "title": "Homework 1 trying out bril",
    "section": "",
    "text": "you will write a blog post and put in in github using a pull request\nThen will put the name of the blog post into canvas\nYou can ask questions on github discussions\n\nYour goal is to get familiar with Bril.\nPart 1\nWrite a new benchmark.\nYou can write it by hand, use the TypeScript compiler, or generate it some other way. Try running it with brili.\nOpen a pull request to add your new benchmark. ??? Add your code to the the benchmarks directory.\nUse turnt –save yours.bril to create the test outputs for your new benchmark. (See the Turnt README for details.) Mention it in the docs.\npart 2\nWrite a program to analyze or transform Bril programs in some small way. Pick your favorite programming language—there is no “starter code,” so you can start from scratch.\nLoad up a JSON file. You can start with this tiny one! Read the docs.\nDo something unambitious with it: count the number of add instructions, or add a print instruction before every jump, or whatever. Pick something small and contrived! Use Turnt to test your new tool.\nAlong the way, you will run into problems! Ask questions on ???, and open issues and pull requests to describe or fix problems. For example, even super simple benchmarks you might imagine probably can’t be written easily because Bril is too simple. Mention this on ??? discussions, and consider pitching in to help add features.\nThink about how to write a good test, and finally write a post describing your work and submit it to github and submit the name to canvas\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 1 trying out bril"
    ]
  },
  {
    "objectID": "homework/6_extra_credit.html",
    "href": "homework/6_extra_credit.html",
    "title": "Homework 6 loop optimization",
    "section": "",
    "text": "Implement and evaluate a loop optimization, either start with Bril or LLVM, you can use the ssa form of Bril if you want. If you use Bril you will have to find the natural loops, if you use LLVM you can call LoopPass but other parts of the implementation will be tricker, Pick an optimization (I’d suggest loop invariant code motion) but any of the others mentioned in class would be fine. Evaluate its performance, in Bril you can use the Bril benchmarks, in LLVM select an existing benchmark such as Embench and feel free to violate the sigplan guidelines SIGPLAN empirical evaluation guidelines by cherry-picking a convenient subset.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 6 loop optimization"
    ]
  },
  {
    "objectID": "homework/5_hw.html",
    "href": "homework/5_hw.html",
    "title": "Homework 5 ssa",
    "section": "",
    "text": "Implement the into SSA and out of SSA transformations on Bril functions. Watch out for variables that are undefined on some paths. The script “is_ssa.py can check if a program is really in SSA and the Bril interpreter bili supports phi functions so you can execute code in the midpoint of your round trip. Measure the overhead (does the final program have more instructions (static or dynamic) the original, be sure to report the overhead in your writeup.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 5 ssa"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html",
    "href": "lectures/02a_representation.html",
    "title": "Representation of programs",
    "section": "",
    "text": "The representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#how-do-we-represent-programs",
    "href": "lectures/02a_representation.html#how-do-we-represent-programs",
    "title": "Representation of programs",
    "section": "",
    "text": "The representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#concrete-syntax",
    "href": "lectures/02a_representation.html#concrete-syntax",
    "title": "Representation of programs",
    "section": "Concrete Syntax",
    "text": "Concrete Syntax\nConcrete syntax, or surface syntax, represents programs as they are written\nPrograms are text or surface syntax- just what you would type into an editor.\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction?\nHow do you understand the semantics.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#abstract-syntax",
    "href": "lectures/02a_representation.html#abstract-syntax",
    "title": "Representation of programs",
    "section": "Abstract syntax",
    "text": "Abstract syntax\nAbstract syntax represents programs as tree structures, focusing on the nodes and their connections.\n\nNodes are parts of the program,\nEdges show how they are connected.\n\nWe can write this as a list or a graph\n\n\ndef pgm():\n    value = 8\n    result = 1\n    for i in range(value):\n        result = result * i\n    print(result)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#ast-tree-representation",
    "href": "lectures/02a_representation.html#ast-tree-representation",
    "title": "Representation of programs",
    "section": "AST tree representation",
    "text": "AST tree representation\nAn AST is a tree structure, nodes like ‘if’, ‘test’, ‘body’, assign’.\nEach node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter.\nSimple (non optimizing) compilers often use this format.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#a-more-regular-representation",
    "href": "lectures/02a_representation.html#a-more-regular-representation",
    "title": "Representation of programs",
    "section": "A more regular representation",
    "text": "A more regular representation\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\nts2bril images/toy.ts | bril2txt\n\n\n    //typescript program \n    let value = 8\n    let result = 1\n    for (let i = 0; i &lt; value;\n         i = i+1)\n    {\n        result = result * i\n    }\n    console.log(result)\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#bril",
    "href": "lectures/02a_representation.html#bril",
    "title": "Representation of programs",
    "section": "bril",
    "text": "bril\n\nLooks like assembly\nno limit on registers,\nno condition codes.\nfully typed,\nno complex addressing modes.\neasy to extend",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#bril-syntax",
    "href": "lectures/02a_representation.html#bril-syntax",
    "title": "Representation of programs",
    "section": "Bril syntax",
    "text": "Bril syntax\nDeclare functions, labels, instructions\ninstruction:\n\nvariable type = opcode arguments\nopcode list of arguments\n\nForm 1, variable is the destination, like a: int = add b, c\nForm 2, no destination, like print a\nwhat is good and what is about this representation?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#control-flow-graph-cfg-version-1",
    "href": "lectures/02a_representation.html#control-flow-graph-cfg-version-1",
    "title": "Representation of programs",
    "section": "control flow graph (CFG) (version 1)",
    "text": "control flow graph (CFG) (version 1)\nRepresentation is a directed graph.\n\nNodes are instructions,\nedges indicate possible flow of control,\none entry and one exit node.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#example-one",
    "href": "lectures/02a_representation.html#example-one",
    "title": "Representation of programs",
    "section": "Example one",
    "text": "Example one\n@main {\n    v: int = const 5;\n    print v;\n}\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#second-example",
    "href": "lectures/02a_representation.html#second-example",
    "title": "Representation of programs",
    "section": "second example",
    "text": "second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\n. . .\nnotice label does not produce a node\nEasy to see a dead instruction.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#third-example",
    "href": "lectures/02a_representation.html#third-example",
    "title": "Representation of programs",
    "section": "Third example:",
    "text": "Third example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\n. . .\nwhich is the true edge and which is the false edge , could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#cfg-cfg-form-2",
    "href": "lectures/02a_representation.html#cfg-cfg-form-2",
    "title": "Representation of programs",
    "section": "CFG (cfg form 2)",
    "text": "CFG (cfg form 2)\n\nnodes ares sequences of instructions.\njumps and branches can only be at the end of a sequence\nonly label has to be at the start\nevery instruction in the sequence executes the same number of times",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#construct-cfg",
    "href": "lectures/02a_representation.html#construct-cfg",
    "title": "Representation of programs",
    "section": "construct cfg",
    "text": "construct cfg\nwalk over the instructions:\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of \\(b\\) are the blocks \\(b_{in}\\) where there is an edge \\(b_{in}-&gt;b\\). And the successors of \\(b\\) are the \\(b_{out}\\) where \\(b-&gt;b_{out}\\) is an edge.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "lectures/02a_representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation of programs",
    "section": "What is an algorithm that forms a cfg",
    "text": "What is an algorithm that forms a cfg\n. . .\n\njust find all the basic blocks\nadd the control flow edges",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html#pseudo-code-to-construct-cfg",
    "href": "lectures/02a_representation.html#pseudo-code-to-construct-cfg",
    "title": "Representation of programs",
    "section": "pseudo code to construct cfg",
    "text": "pseudo code to construct cfg\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Representation of programs"
    ]
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#how-do-we-represent-programs",
    "href": "lectures/revealjs_02a_representation.qmd.html#how-do-we-represent-programs",
    "title": "Representation of programs",
    "section": "How do we represent programs",
    "text": "How do we represent programs\nThe representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\n\nCode\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#concrete-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#concrete-syntax",
    "title": "Representation of programs",
    "section": "Concrete Syntax",
    "text": "Concrete Syntax\nConcrete syntax, or surface syntax, represents programs as they are written\nPrograms are text or surface syntax- just what you would type into an editor.\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction?\nHow do you understand the semantics."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#abstract-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#abstract-syntax",
    "title": "Representation of programs",
    "section": "Abstract syntax",
    "text": "Abstract syntax\nAbstract syntax represents programs as tree structures, focusing on the nodes and their connections.\n\nNodes are parts of the program,\nEdges show how they are connected.\n\nWe can write this as a list or a graph\n\n\ndef pgm():\n    value = 8\n    result = 1\n    for i in range(value):\n        result = result * i\n    print(result)"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#ast-tree-representation",
    "href": "lectures/revealjs_02a_representation.qmd.html#ast-tree-representation",
    "title": "Representation of programs",
    "section": "AST tree representation",
    "text": "AST tree representation\nAn AST is a tree structure, nodes like ‘if’, ‘test’, ‘body’, assign’.\nEach node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter.\nSimple (non optimizing) compilers often use this format."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#a-more-regular-representation",
    "href": "lectures/revealjs_02a_representation.qmd.html#a-more-regular-representation",
    "title": "Representation of programs",
    "section": "A more regular representation",
    "text": "A more regular representation\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\nts2bril images/toy.ts | bril2txt\n\n\n    //typescript program \n    let value = 8\n    let result = 1\n    for (let i = 0; i &lt; value;\n         i = i+1)\n    {\n        result = result * i\n    }\n    console.log(result)\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#bril",
    "href": "lectures/revealjs_02a_representation.qmd.html#bril",
    "title": "Representation of programs",
    "section": "bril",
    "text": "bril\n\nLooks like assembly\nno limit on registers,\nno condition codes.\nfully typed,\nno complex addressing modes.\neasy to extend"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#bril-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#bril-syntax",
    "title": "Representation of programs",
    "section": "Bril syntax",
    "text": "Bril syntax\nDeclare functions, labels, instructions\ninstruction:\n\nvariable type = opcode arguments\nopcode list of arguments\n\nForm 1, variable is the destination, like a: int = add b, c\nForm 2, no destination, like print a\nwhat is good and what is about this representation?"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#control-flow-graph-cfg-version-1",
    "href": "lectures/revealjs_02a_representation.qmd.html#control-flow-graph-cfg-version-1",
    "title": "Representation of programs",
    "section": "control flow graph (CFG) (version 1)",
    "text": "control flow graph (CFG) (version 1)\nRepresentation is a directed graph.\n\nNodes are instructions,\nedges indicate possible flow of control,\none entry and one exit node."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#example-one",
    "href": "lectures/revealjs_02a_representation.qmd.html#example-one",
    "title": "Representation of programs",
    "section": "Example one",
    "text": "Example one\n@main {\n    v: int = const 5;\n    print v;\n}\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#second-example",
    "href": "lectures/revealjs_02a_representation.qmd.html#second-example",
    "title": "Representation of programs",
    "section": "second example",
    "text": "second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#third-example",
    "href": "lectures/revealjs_02a_representation.qmd.html#third-example",
    "title": "Representation of programs",
    "section": "Third example:",
    "text": "Third example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\n\n\nwhich is the true edge and which is the false edge , could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#cfg-cfg-form-2",
    "href": "lectures/revealjs_02a_representation.qmd.html#cfg-cfg-form-2",
    "title": "Representation of programs",
    "section": "CFG (cfg form 2)",
    "text": "CFG (cfg form 2)\n\nnodes ares sequences of instructions.\njumps and branches can only be at the end of a sequence\nonly label has to be at the start\nevery instruction in the sequence executes the same number of times"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#construct-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#construct-cfg",
    "title": "Representation of programs",
    "section": "construct cfg",
    "text": "construct cfg\nwalk over the instructions:\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of \\(b\\) are the blocks \\(b_{in}\\) where there is an edge \\(b_{in}-&gt;b\\). And the successors of \\(b\\) are the \\(b_{out}\\) where \\(b-&gt;b_{out}\\) is an edge."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation of programs",
    "section": "What is an algorithm that forms a cfg",
    "text": "What is an algorithm that forms a cfg\n\n\njust find all the basic blocks\nadd the control flow edges"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#pseudo-code-to-construct-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#pseudo-code-to-construct-cfg",
    "title": "Representation of programs",
    "section": "pseudo code to construct cfg",
    "text": "pseudo code to construct cfg\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []"
  },
  {
    "objectID": "lectures/05b_licm.html",
    "href": "lectures/05b_licm.html",
    "title": "loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#licm",
    "href": "lectures/05b_licm.html#licm",
    "title": "loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#a-very-common-case-for-this-is-matrix-addressing",
    "href": "lectures/05b_licm.html#a-very-common-case-for-this-is-matrix-addressing",
    "title": "loop invariant code motion",
    "section": "A very common case for this is matrix addressing",
    "text": "A very common case for this is matrix addressing\na[i,j] might expand to to \\(i*4*\\operatorname{stride_{a}} + j *4\\)\nfor j \n  a[i,j] = f(a[i,j+1])\nturns into\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#when-is-a-computation-loop-invariant",
    "href": "lectures/05b_licm.html#when-is-a-computation-loop-invariant",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\nf(a,b)\n\na,b are constants\na,b are defined outside the loop,\na,b are loop invariant\n\nif in ssa there is only one reaching def\nfor non ssa, we need\n\nall reaching defs of a,b defined outside of the loop\nonly one def of a,b reaches the computation and that def is loop invariant",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#when-is-a-computation-loop-invariant-1",
    "href": "lectures/05b_licm.html#when-is-a-computation-loop-invariant-1",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\na defined outside of the loop (need one definition or ssa )\n\nb = a*2 \n\nd = 5 + b is loop invariant if b\nIn ssa a variable is loop invariant if it does not have a phi function at the header of the loop, or it is defined by a phi function and all the inputs are loop constants\nSSA If we find a loop-invariant computation in SSA form, then we just move it out of the loop to a block before the loop. When moving a (side effect-free) SSA loop-invariant computation to a previous position, nothing can go wrong, because the value it computes cannot be overwritten later and the values it depends on cannot have been changed",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#pre-steps---reshape-the-cfg",
    "href": "lectures/05b_licm.html#pre-steps---reshape-the-cfg",
    "title": "loop invariant code motion",
    "section": "pre steps - reshape the cfg",
    "text": "pre steps - reshape the cfg\n\nfind the natural loops\nadd pre-header\n\nif we are going to move code we often need to add a special basic block which is called a landing pad or a pre-header create a new block b. change all the preds of the loop header to point to the pre-header, add an edge from b to the loop header",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#pre-header-can-change-phi-nodes",
    "href": "lectures/05b_licm.html#pre-header-can-change-phi-nodes",
    "title": "loop invariant code motion",
    "section": "pre-header can change phi nodes",
    "text": "pre-header can change phi nodes\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "href": "lectures/05b_licm.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "title": "loop invariant code motion",
    "section": "while loop may not execute, we can restructure into a do-while",
    "text": "while loop may not execute, we can restructure into a do-while\n\n\nwhile(e) {\n  s(j) \n}\n\nif (e) {\n  t  = j loopinv \n  do {\n    s\n  } while(e)\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#check-for-zero-trip-count",
    "href": "lectures/05b_licm.html#check-for-zero-trip-count",
    "title": "loop invariant code motion",
    "section": "check for zero trip count",
    "text": "check for zero trip count\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#when-is-ok-to-move-a-computation",
    "href": "lectures/05b_licm.html#when-is-ok-to-move-a-computation",
    "title": "loop invariant code motion",
    "section": "when is ok to move a computation",
    "text": "when is ok to move a computation\n\nno side effects - cannot move alloc 10 outside of loop;\nin non ssa, computation d dominates all loop exits where d is live\nin non ssa only one def of d in the loop\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#find-loop-invariant-instructions",
    "href": "lectures/05b_licm.html#find-loop-invariant-instructions",
    "title": "loop invariant code motion",
    "section": "find loop invariant instructions,",
    "text": "find loop invariant instructions,",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#naturally-iterative",
    "href": "lectures/05b_licm.html#naturally-iterative",
    "title": "loop invariant code motion",
    "section": "naturally iterative",
    "text": "naturally iterative\niterate to convergence\n for each instr in  the loop\n   see if it is loop invar \n   if it is - move it",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html#nested-loops",
    "href": "lectures/05b_licm.html#nested-loops",
    "title": "loop invariant code motion",
    "section": "nested loops",
    "text": "nested loops\nwe want to process inner loops first\n\nadd all the pre-headers\nwalk the dominator tree in reverse post order - saving all the loop headers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#licm",
    "href": "lectures/revealjs_05b_licm.qmd.html#licm",
    "title": "loop invariant code motion",
    "section": "licm",
    "text": "licm\nLoop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop."
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#a-very-common-case-for-this-is-matrix-addressing",
    "href": "lectures/revealjs_05b_licm.qmd.html#a-very-common-case-for-this-is-matrix-addressing",
    "title": "loop invariant code motion",
    "section": "A very common case for this is matrix addressing",
    "text": "A very common case for this is matrix addressing\na[i,j] might expand to to \\(i*4*\\operatorname{stride_{a}} + j *4\\)\nfor j \n  a[i,j] = f(a[i,j+1])\nturns into\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant",
    "href": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\nf(a,b)\n\na,b are constants\na,b are defined outside the loop,\na,b are loop invariant\n\nif in ssa there is only one reaching def\nfor non ssa, we need\n\nall reaching defs of a,b defined outside of the loop\nonly one def of a,b reaches the computation and that def is loop invariant"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant-1",
    "href": "lectures/revealjs_05b_licm.qmd.html#when-is-a-computation-loop-invariant-1",
    "title": "loop invariant code motion",
    "section": "when is a computation loop invariant",
    "text": "when is a computation loop invariant\na defined outside of the loop (need one definition or ssa )\n\nb = a*2 \n\nd = 5 + b is loop invariant if b\nIn ssa a variable is loop invariant if it does not have a phi function at the header of the loop, or it is defined by a phi function and all the inputs are loop constants\nSSA If we find a loop-invariant computation in SSA form, then we just move it out of the loop to a block before the loop. When moving a (side effect-free) SSA loop-invariant computation to a previous position, nothing can go wrong, because the value it computes cannot be overwritten later and the values it depends on cannot have been changed"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#pre-steps---reshape-the-cfg",
    "href": "lectures/revealjs_05b_licm.qmd.html#pre-steps---reshape-the-cfg",
    "title": "loop invariant code motion",
    "section": "pre steps - reshape the cfg",
    "text": "pre steps - reshape the cfg\n\nfind the natural loops\nadd pre-header\n\nif we are going to move code we often need to add a special basic block which is called a landing pad or a pre-header create a new block b. change all the preds of the loop header to point to the pre-header, add an edge from b to the loop header"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#pre-header-can-change-phi-nodes",
    "href": "lectures/revealjs_05b_licm.qmd.html#pre-header-can-change-phi-nodes",
    "title": "loop invariant code motion",
    "section": "pre-header can change phi nodes",
    "text": "pre-header can change phi nodes\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nC[\"x2=phi(x1,x3)\\ny3=phi(y1,y2,y3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt; C\nB2--&gt; C\nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"x1 = 3\"]\nB1[\"y1 = 4\"]\nB2[\"y2 = 5\"]\nLP[\"y3=phi(y1,y2)\"]\nC[\"x2=phi(x1,x3)\\nz1=x2*x3\\nq1=y3*y3\\nw1=y3+2\"]\nD[\"w2=w1+5\"]\nE[\"w3=phi(w1,w2)\\np1=w3+y3\\nx3=x2+1\\nq2=q1+1\"]\nA--&gt; B1\nA--&gt; B2\nB1--&gt;LP --&gt; C\nB2--&gt;LP \nC--&gt;D\nD--&gt; E\nC--&gt; E\nE--&gt; C\nE--&gt; After"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "href": "lectures/revealjs_05b_licm.qmd.html#while-loop-may-not-execute-we-can-restructure-into-a-do-while",
    "title": "loop invariant code motion",
    "section": "while loop may not execute, we can restructure into a do-while",
    "text": "while loop may not execute, we can restructure into a do-while\n\n\nwhile(e) {\n  s(j) \n}\n\nif (e) {\n  t  = j loopinv \n  do {\n    s\n  } while(e)\n}"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#check-for-zero-trip-count",
    "href": "lectures/revealjs_05b_licm.qmd.html#check-for-zero-trip-count",
    "title": "loop invariant code motion",
    "section": "check for zero trip count",
    "text": "check for zero trip count\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA;\nB[\"if e\"]\nS\nendloop\nnext\nA--&gt; B\nB--&gt; next\nB--&gt; S\nS--&gt; endloop\nendloop --&gt; B\n\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npretest[\"if e\"]\npretest--&gt;next \ndo\ns\nendloop\nposttest[\"if e\"]\nnext\npretest--&gt;do\ndo --&gt; s\ns--&gt; endloop\nendloop--&gt; posttest\nposttest --&gt; do\nposttest --&gt; next"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#when-is-ok-to-move-a-computation",
    "href": "lectures/revealjs_05b_licm.qmd.html#when-is-ok-to-move-a-computation",
    "title": "loop invariant code motion",
    "section": "when is ok to move a computation",
    "text": "when is ok to move a computation\n\nno side effects - cannot move alloc 10 outside of loop;\nin non ssa, computation d dominates all loop exits where d is live\nin non ssa only one def of d in the loop\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"if i &gt; n\" ]\nloop1[\"i = i +1\"]\nd[\"d = a op b\"]\nuse[\"  =d \"]\nnext[\" = d\"]\n\npre--&gt; L1\nL1--&gt; loop1\nloop1--&gt; d\nd--&gt; use \nuse --&gt; L1\nL1 --&gt; next\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\npre[\"d = 0\"]\nL1[\"i = i +1\\n d= a op b\\n use d\"]\nL2[\"d = 2\\n use d\"]\nL3[\"if (i &lt; n)\"]\npre--&gt; L1\nL1--&gt; L2\nL2--&gt; L3\nL3--&gt; after\nL3 --&gt; L1"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#find-loop-invariant-instructions",
    "href": "lectures/revealjs_05b_licm.qmd.html#find-loop-invariant-instructions",
    "title": "loop invariant code motion",
    "section": "find loop invariant instructions,",
    "text": "find loop invariant instructions,"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#naturally-iterative",
    "href": "lectures/revealjs_05b_licm.qmd.html#naturally-iterative",
    "title": "loop invariant code motion",
    "section": "naturally iterative",
    "text": "naturally iterative\niterate to convergence\n for each instr in  the loop\n   see if it is loop invar \n   if it is - move it"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#nested-loops",
    "href": "lectures/revealjs_05b_licm.qmd.html#nested-loops",
    "title": "loop invariant code motion",
    "section": "nested loops",
    "text": "nested loops\nwe want to process inner loops first\n\nadd all the pre-headers\nwalk the dominator tree in reverse post order - saving all the loop headers"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html",
    "href": "lectures/14_gpu_compilers.html",
    "title": "GPU Compilers",
    "section": "",
    "text": "Architectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#challenges-in-learning-about-gpus",
    "href": "lectures/14_gpu_compilers.html#challenges-in-learning-about-gpus",
    "title": "GPU Compilers",
    "section": "",
    "text": "Architectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware-styles-nvidia-model",
    "href": "lectures/14_gpu_compilers.html#hardware-styles-nvidia-model",
    "title": "GPU Compilers",
    "section": "hardware styles NVIDIA model",
    "text": "hardware styles NVIDIA model\n\ncompute and graphics parts have same programmable parts, compute leaves out non-programmable features\ngraphics customers pay a tax for the compute instructions\nmore transistors for compute instructions\none big die",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware-styles-amd-model",
    "href": "lectures/14_gpu_compilers.html#hardware-styles-amd-model",
    "title": "GPU Compilers",
    "section": "hardware styles AMD model",
    "text": "hardware styles AMD model\n\ncompute has extra instructions (no tax on graphics customers to support compute)\nchiplet model (great engineering!)\nR series is graphics, C series is compute",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#programming-model",
    "href": "lectures/14_gpu_compilers.html#programming-model",
    "title": "GPU Compilers",
    "section": "programming model",
    "text": "programming model\nboth vendors use the CUDA programming model. AMD supports a variation of the CUDA language\nmachines have multiple SIMD processors, each SIMD can be running a different instruction but each lane of a SIMD runs the same instruction\na lane of a SIMD is called a thread\n\nthe programming model is SIMT (single instruction multiple threads)\nUser writes a scalar program, compiler maps that program to a lane of a SIMD, many instances of the program run at once, hardware combines copies of the scalar program into warps, hardware schedules warps into the SIMD engines\nprograms are called kernels",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#threading-model",
    "href": "lectures/14_gpu_compilers.html#threading-model",
    "title": "GPU Compilers",
    "section": "threading model",
    "text": "threading model",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#warps-waveswavefronts",
    "href": "lectures/14_gpu_compilers.html#warps-waveswavefronts",
    "title": "GPU Compilers",
    "section": "warps/ waves/wavefronts",
    "text": "warps/ waves/wavefronts\n\nthreads are grouped together into warps.\nSize is fixed by hardware (usually 32), programmers know this and often make data set sizes a multiple of 32.\nsince all threads in a warp are running the same instruction, there is no need for explicit synchronization\nthere are a few instructions that work across a warp, - which break the model and give the compiler problems",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#thread-blocks-groups-of-warps",
    "href": "lectures/14_gpu_compilers.html#thread-blocks-groups-of-warps",
    "title": "GPU Compilers",
    "section": "thread blocks groups of warps,",
    "text": "thread blocks groups of warps,\n\nthreads within a block can access a fast scratchpad memory (called shared or LDS) - Violates the C memory model.\n\nthreads are identified by a 3d index inside a block\nthread blocks need synchronization operations.\n\nhardware schedules each block into execution units. Max block size is limited by the size of a execution unit.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#grid-groups-of-blocks",
    "href": "lectures/14_gpu_compilers.html#grid-groups-of-blocks",
    "title": "GPU Compilers",
    "section": "grid groups of blocks,",
    "text": "grid groups of blocks,\n\n3d collection of blocks,\nusually hardware limits mean that all the threads in a grid do not run at the same time\nprogrammers need to make grids big enough to fill the hardware\nsoftware launches a grid and a program\nthreads within a grid but in different blocks do not have sync operations",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#heterogeneous-programming",
    "href": "lectures/14_gpu_compilers.html#heterogeneous-programming",
    "title": "GPU Compilers",
    "section": "Heterogeneous programming",
    "text": "Heterogeneous programming\nthe cpu is called the host\nthe gpu is called the device\ncpu launches grids and kernels to gpu\nComputations launched on the device execute asynchronously with respect to the host, and it is the user’s responsibility to synchronize",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#memory-spaces",
    "href": "lectures/14_gpu_compilers.html#memory-spaces",
    "title": "GPU Compilers",
    "section": "memory spaces",
    "text": "memory spaces\n\ncpu and gpu have different memory spaces (cpu can copy from one to the other). Some amount of combined memory (slower then not combined)\ngpu has shared/lds memory which can be accessed by threads within a block, passing an address to a different block does not work\nmain gpu memory is called global accessible by all threads\ngpu has per thread memory called local or scratch or private memory - unlike C, passing an address in local memory to another thread does not work. (under some restrictions AMD implements part of the C memory model)\na few special gpu memory types: constant, texture, surface (left over from graphics)\ngpu can treat registers as fast memory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware",
    "href": "lectures/14_gpu_compilers.html#hardware",
    "title": "GPU Compilers",
    "section": "Hardware",
    "text": "Hardware\nNVIDIA\n\n\n\nnv image level 0\n\n\nEach box here is hardware, an int32/fp32/fp64 can perform one operation, so here we have 32 fp32 units which can do 32 float operations in parallel as well as 16 int32 and 16 fp64 units , there are also 8 units can do loads or stores and a final special function unit that can do transcendental operations like sin/cos\nunder some conditions two instructions (a float and an int) from the same warp can execute at the same time\nI’m not going to talk much about the tensor cores\nall these units execute the same instruction (SIMT) Simple instruction multiple thread (not the same as SIMD but related )",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#one-instruction-does-vector-work",
    "href": "lectures/14_gpu_compilers.html#one-instruction-does-vector-work",
    "title": "GPU Compilers",
    "section": "one instruction does vector work",
    "text": "one instruction does vector work\nadd 32 float32 values (all coming from registers) and store the result in 32 other registers\nNotice no branch prediction, no out of order execution\ngreat at switching a warp holds the instruction, it knows which registers it owns (continuous set, so it just needs a start and length) switching to a different warp, means changing these two numbers and the pc (this is done by the dispatch unt )\nWhen we do a load, we need to wait for the result. CPU might do some kind of out of order execution, a gpu switches to another warp\nfinally we need to pick the warp to switch to, this is done by the warp scheduler (half of the hardware scheduler)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#streaming-multiprocessors-sm",
    "href": "lectures/14_gpu_compilers.html#streaming-multiprocessors-sm",
    "title": "GPU Compilers",
    "section": "streaming multiprocessors (SM)",
    "text": "streaming multiprocessors (SM)\nnvidia packs 4 execution engines into a SM (streaming multi-processor) ands an L1 instruction cache, a special memory accelerator for tensors and 256kb l1 data cache/ shared memory block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#pack-sms-together",
    "href": "lectures/14_gpu_compilers.html#pack-sms-together",
    "title": "GPU Compilers",
    "section": "pack sm’s together",
    "text": "pack sm’s together",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#amd",
    "href": "lectures/14_gpu_compilers.html#amd",
    "title": "GPU Compilers",
    "section": "AMD",
    "text": "AMD",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#and",
    "href": "lectures/14_gpu_compilers.html#and",
    "title": "GPU Compilers",
    "section": "and",
    "text": "and\n\nAMD has a similar block with some important differences\n\nAt the bottom of a compute core there are 4 general purpose simd engines each of length 16 and one scalar engine\n\nGiven 5 waves, this compute core can execute 4 vector instructions and one scalar instruction per clock Two instructions from the same wave never execute at the same time\nThe SIMD engines can execute different instructions\nThe simd sizes vary over different chips",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#amd-cdna",
    "href": "lectures/14_gpu_compilers.html#amd-cdna",
    "title": "GPU Compilers",
    "section": "amd CDNA",
    "text": "amd CDNA",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#packing-sms",
    "href": "lectures/14_gpu_compilers.html#packing-sms",
    "title": "GPU Compilers",
    "section": "packing sms",
    "text": "packing sms",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#simd-and-control-flow",
    "href": "lectures/14_gpu_compilers.html#simd-and-control-flow",
    "title": "GPU Compilers",
    "section": "simd and control flow",
    "text": "simd and control flow\nto execute an if then else\n\ncompute the if condition\nturn off the lanes where the condition is false\nexecute the if side\nflip the lanes\nexecute the else side\n\ntime is the sum of the times for then and the else",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#number-of-warps-in-flight",
    "href": "lectures/14_gpu_compilers.html#number-of-warps-in-flight",
    "title": "GPU Compilers",
    "section": "number of warps in flight",
    "text": "number of warps in flight\nsince an entire block has to fit on one compute unit/sm, the resources used in the block limit the number of warps on a sm,\nif a warp needs 100 registers and there are 256 vector registers on the compute unit, then two warps can run at once, compiler controls number of registers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#latency",
    "href": "lectures/14_gpu_compilers.html#latency",
    "title": "GPU Compilers",
    "section": "latency",
    "text": "latency\ngpu is a throughput machine- how many threads finish in a unit of time not how long a single thread takes to finish\nunlike the cpu, gpu can have lots of loads in flight, time for these loads overlap so compiler tries to group loads together, but this needs extra registers\n\na warp issues a group of loads\nwarp issues a wait for loads to finish (hardware in cpu, software in gpu)\nhardware switches to another warp (if there is on), good to have a lot of warps 1, if all warps waiting for memory, alu units are idle",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#compiler-model",
    "href": "lectures/14_gpu_compilers.html#compiler-model",
    "title": "GPU Compilers",
    "section": "compiler model",
    "text": "compiler model\n\nlike a regular compiler for a scalar machine\nnew problem: registers used in warp limits number of warps in flight, so ra is different\nnew problem: control flow is more critical\nnew problem: latency means grouping loads but not to much\nnew problem: arch keeps changing",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#thread-coarsening",
    "href": "lectures/14_gpu_compilers.html#thread-coarsening",
    "title": "GPU Compilers",
    "section": "thread coarsening",
    "text": "thread coarsening\nSuppose we are computing a matrix multiply\nwe could say each thread writes one result so a 32 x 32 matrix would need 32 * 32 threads each thread reads one column and one row of the input,\nwe have a lot of reuse (redundant loads of data )\nwe could say each thread writes 4 results, so we need 1/4 of the threads each thread reads a raw and 4 columns",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#technique",
    "href": "lectures/14_gpu_compilers.html#technique",
    "title": "GPU Compilers",
    "section": "technique",
    "text": "technique\n\nmerge multiple threads so each resulting thread writes multiple outputs\ndo the redundant work once and save in registers\nuse the registers for computing all the outputs\n\nBut\n\nneeds extra registers\nincreased efficiency but reduced parallelism\n\nAfter thread coarsening, computation from merged threads can see each others results",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#doing-this-by-hand",
    "href": "lectures/14_gpu_compilers.html#doing-this-by-hand",
    "title": "GPU Compilers",
    "section": "doing this by hand",
    "text": "doing this by hand\nfor (atomid=0; atomid&lt;numatoms; atomid++) { \n  float dy = coory - atominfo[atomid].y; \n  float dysqpdzsq = (dy * dy) + atominfo[atomid].z; \n  float dx1 = coorx1 - atominfo[atomid].x; \n  float dx2 = coorx2 - atominfo[atomid].x; \n  float dx3 = coorx3 - atominfo[atomid].x; \n  float dx4 = coorx4 - atominfo[atomid].x; \n  energyvalx1 += atominfo[atomid].w * (1.0f / sqrtf(dx1*dx1 + dysqpdzsq));\n  energyvalx2 += atominfo[atomid].w * (1.0f / sqrtf(dx2*dx2 + dysqpdzsq)); \n  energyvalx3 += atominfo[atomid].w * (1.0f / sqrtf(dx3*dx3 + dysqpdzsq)); \n  energyvalx4 += atominfo[atomid].w * (1.0f / sqrtf(dx4*dx4 + dysqpdzsq)); } …",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "GPU Compilers"
    ]
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#challenges-in-learning-about-gpus",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#challenges-in-learning-about-gpus",
    "title": "GPU Compilers",
    "section": "Challenges in Learning About GPUs",
    "text": "Challenges in Learning About GPUs\n\nArchitectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc."
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-nvidia-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-nvidia-model",
    "title": "GPU Compilers",
    "section": "hardware styles NVIDIA model",
    "text": "hardware styles NVIDIA model\n\ncompute and graphics parts have same programmable parts, compute leaves out non-programmable features\ngraphics customers pay a tax for the compute instructions\nmore transistors for compute instructions\none big die"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-amd-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-amd-model",
    "title": "GPU Compilers",
    "section": "hardware styles AMD model",
    "text": "hardware styles AMD model\n\ncompute has extra instructions (no tax on graphics customers to support compute)\nchiplet model (great engineering!)\nR series is graphics, C series is compute"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#programming-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#programming-model",
    "title": "GPU Compilers",
    "section": "programming model",
    "text": "programming model\nboth vendors use the CUDA programming model. AMD supports a variation of the CUDA language\nmachines have multiple SIMD processors, each SIMD can be running a different instruction but each lane of a SIMD runs the same instruction\na lane of a SIMD is called a thread"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#threading-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#threading-model",
    "title": "GPU Compilers",
    "section": "threading model",
    "text": "threading model"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#warps-waveswavefronts",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#warps-waveswavefronts",
    "title": "GPU Compilers",
    "section": "warps/ waves/wavefronts",
    "text": "warps/ waves/wavefronts\n\nthreads are grouped together into warps.\nSize is fixed by hardware (usually 32), programmers know this and often make data set sizes a multiple of 32.\nsince all threads in a warp are running the same instruction, there is no need for explicit synchronization\nthere are a few instructions that work across a warp, - which break the model and give the compiler problems"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-blocks-groups-of-warps",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-blocks-groups-of-warps",
    "title": "GPU Compilers",
    "section": "thread blocks groups of warps,",
    "text": "thread blocks groups of warps,\n\nthreads within a block can access a fast scratchpad memory (called shared or LDS) - Violates the C memory model.\n\nthreads are identified by a 3d index inside a block\nthread blocks need synchronization operations.\n\nhardware schedules each block into execution units. Max block size is limited by the size of a execution unit."
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#grid-groups-of-blocks",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#grid-groups-of-blocks",
    "title": "GPU Compilers",
    "section": "grid groups of blocks,",
    "text": "grid groups of blocks,\n\n3d collection of blocks,\nusually hardware limits mean that all the threads in a grid do not run at the same time\nprogrammers need to make grids big enough to fill the hardware\nsoftware launches a grid and a program\nthreads within a grid but in different blocks do not have sync operations"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#heterogeneous-programming",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#heterogeneous-programming",
    "title": "GPU Compilers",
    "section": "Heterogeneous programming",
    "text": "Heterogeneous programming\nthe cpu is called the host\nthe gpu is called the device\ncpu launches grids and kernels to gpu\nComputations launched on the device execute asynchronously with respect to the host, and it is the user’s responsibility to synchronize"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#memory-spaces",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#memory-spaces",
    "title": "GPU Compilers",
    "section": "memory spaces",
    "text": "memory spaces\n\ncpu and gpu have different memory spaces (cpu can copy from one to the other). Some amount of combined memory (slower then not combined)\ngpu has shared/lds memory which can be accessed by threads within a block, passing an address to a different block does not work\nmain gpu memory is called global accessible by all threads\ngpu has per thread memory called local or scratch or private memory - unlike C, passing an address in local memory to another thread does not work. (under some restrictions AMD implements part of the C memory model)\na few special gpu memory types: constant, texture, surface (left over from graphics)\ngpu can treat registers as fast memory"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware",
    "title": "GPU Compilers",
    "section": "Hardware",
    "text": "Hardware\nNVIDIA\n\nnv image level 0Each box here is hardware, an int32/fp32/fp64 can perform one operation, so here we have 32 fp32 units which can do 32 float operations in parallel as well as 16 int32 and 16 fp64 units , there are also 8 units can do loads or stores and a final special function unit that can do transcendental operations like sin/cos\nunder some conditions two instructions (a float and an int) from the same warp can execute at the same time\nI’m not going to talk much about the tensor cores\nall these units execute the same instruction (SIMT) Simple instruction multiple thread (not the same as SIMD but related )"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#one-instruction-does-vector-work",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#one-instruction-does-vector-work",
    "title": "GPU Compilers",
    "section": "one instruction does vector work",
    "text": "one instruction does vector work\nadd 32 float32 values (all coming from registers) and store the result in 32 other registers\nNotice no branch prediction, no out of order execution\ngreat at switching a warp holds the instruction, it knows which registers it owns (continuous set, so it just needs a start and length) switching to a different warp, means changing these two numbers and the pc (this is done by the dispatch unt )\nWhen we do a load, we need to wait for the result. CPU might do some kind of out of order execution, a gpu switches to another warp\nfinally we need to pick the warp to switch to, this is done by the warp scheduler (half of the hardware scheduler)"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#streaming-multiprocessors-sm",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#streaming-multiprocessors-sm",
    "title": "GPU Compilers",
    "section": "streaming multiprocessors (SM)",
    "text": "streaming multiprocessors (SM)\nnvidia packs 4 execution engines into a SM (streaming multi-processor) ands an L1 instruction cache, a special memory accelerator for tensors and 256kb l1 data cache/ shared memory block"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#pack-sms-together",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#pack-sms-together",
    "title": "GPU Compilers",
    "section": "pack sm’s together",
    "text": "pack sm’s together"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#amd",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#amd",
    "title": "GPU Compilers",
    "section": "AMD",
    "text": "AMD"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#and",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#and",
    "title": "GPU Compilers",
    "section": "and",
    "text": "and\n\nAMD has a similar block with some important differences\n\nAt the bottom of a compute core there are 4 general purpose simd engines each of length 16 and one scalar engine\n\nGiven 5 waves, this compute core can execute 4 vector instructions and one scalar instruction per clock Two instructions from the same wave never execute at the same time\nThe SIMD engines can execute different instructions\nThe simd sizes vary over different chips"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#amd-cdna",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#amd-cdna",
    "title": "GPU Compilers",
    "section": "amd CDNA",
    "text": "amd CDNA"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#packing-sms",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#packing-sms",
    "title": "GPU Compilers",
    "section": "packing sms",
    "text": "packing sms"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#simd-and-control-flow",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#simd-and-control-flow",
    "title": "GPU Compilers",
    "section": "simd and control flow",
    "text": "simd and control flow\nto execute an if then else\n\ncompute the if condition\nturn off the lanes where the condition is false\nexecute the if side\nflip the lanes\nexecute the else side\n\ntime is the sum of the times for then and the else"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#number-of-warps-in-flight",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#number-of-warps-in-flight",
    "title": "GPU Compilers",
    "section": "number of warps in flight",
    "text": "number of warps in flight\nsince an entire block has to fit on one compute unit/sm, the resources used in the block limit the number of warps on a sm,\nif a warp needs 100 registers and there are 256 vector registers on the compute unit, then two warps can run at once, compiler controls number of registers"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#latency",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#latency",
    "title": "GPU Compilers",
    "section": "latency",
    "text": "latency\ngpu is a throughput machine- how many threads finish in a unit of time not how long a single thread takes to finish\nunlike the cpu, gpu can have lots of loads in flight, time for these loads overlap so compiler tries to group loads together, but this needs extra registers\n\na warp issues a group of loads\nwarp issues a wait for loads to finish (hardware in cpu, software in gpu)\nhardware switches to another warp (if there is on), good to have a lot of warps 1, if all warps waiting for memory, alu units are idle"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#compiler-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#compiler-model",
    "title": "GPU Compilers",
    "section": "compiler model",
    "text": "compiler model\n\nlike a regular compiler for a scalar machine\nnew problem: registers used in warp limits number of warps in flight, so ra is different\nnew problem: control flow is more critical\nnew problem: latency means grouping loads but not to much\nnew problem: arch keeps changing"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-coarsening",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-coarsening",
    "title": "GPU Compilers",
    "section": "thread coarsening",
    "text": "thread coarsening\nSuppose we are computing a matrix multiply\nwe could say each thread writes one result so a 32 x 32 matrix would need 32 * 32 threads each thread reads one column and one row of the input,\nwe have a lot of reuse (redundant loads of data )\nwe could say each thread writes 4 results, so we need 1/4 of the threads each thread reads a raw and 4 columns"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#technique",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#technique",
    "title": "GPU Compilers",
    "section": "technique",
    "text": "technique\n\nmerge multiple threads so each resulting thread writes multiple outputs\ndo the redundant work once and save in registers\nuse the registers for computing all the outputs\n\nBut\n\nneeds extra registers\nincreased efficiency but reduced parallelism\n\nAfter thread coarsening, computation from merged threads can see each others results"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#doing-this-by-hand",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#doing-this-by-hand",
    "title": "GPU Compilers",
    "section": "doing this by hand",
    "text": "doing this by hand\nfor (atomid=0; atomid&lt;numatoms; atomid++) { \n  float dy = coory - atominfo[atomid].y; \n  float dysqpdzsq = (dy * dy) + atominfo[atomid].z; \n  float dx1 = coorx1 - atominfo[atomid].x; \n  float dx2 = coorx2 - atominfo[atomid].x; \n  float dx3 = coorx3 - atominfo[atomid].x; \n  float dx4 = coorx4 - atominfo[atomid].x; \n  energyvalx1 += atominfo[atomid].w * (1.0f / sqrtf(dx1*dx1 + dysqpdzsq));\n  energyvalx2 += atominfo[atomid].w * (1.0f / sqrtf(dx2*dx2 + dysqpdzsq)); \n  energyvalx3 += atominfo[atomid].w * (1.0f / sqrtf(dx3*dx3 + dysqpdzsq)); \n  energyvalx4 += atominfo[atomid].w * (1.0f / sqrtf(dx4*dx4 + dysqpdzsq)); } …"
  },
  {
    "objectID": "lectures/diverg.html",
    "href": "lectures/diverg.html",
    "title": "divergent flow",
    "section": "",
    "text": "__global__ void dec2zero(int* v, int N) { \n    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   \n    if (xIndex &lt; N) {\n             while (v[xIndex] &gt; 0) { v[xIndex]--;     \n             }     \n        } \n} \nDepending on how we initialize the vector, we get different times and different subtracts\n\nSize of array 1048576\nThreads Per Block = 256\nBlocks In Grid = 4096\n\n256 threads means 8 warps\neach warp start running - calculates a unique index\neach thread checks if v[index]&gt; 0 giving a mask, each thread read v[xindex] decrements the value and if the mask is on, updates, if the mask bit is off, the thread does not write\nif half the masks are on, half the threads do work, the other half don’t so 50% active",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#what-is-the-cost-of-divergence",
    "href": "lectures/diverg.html#what-is-the-cost-of-divergence",
    "title": "divergent flow",
    "section": "",
    "text": "__global__ void dec2zero(int* v, int N) { \n    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   \n    if (xIndex &lt; N) {\n             while (v[xIndex] &gt; 0) { v[xIndex]--;     \n             }     \n        } \n} \nDepending on how we initialize the vector, we get different times and different subtracts\n\nSize of array 1048576\nThreads Per Block = 256\nBlocks In Grid = 4096\n\n256 threads means 8 warps\neach warp start running - calculates a unique index\neach thread checks if v[index]&gt; 0 giving a mask, each thread read v[xindex] decrements the value and if the mask is on, updates, if the mask bit is off, the thread does not write\nif half the masks are on, half the threads do work, the other half don’t so 50% active",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#some-initializers",
    "href": "lectures/diverg.html#some-initializers",
    "title": "divergent flow",
    "section": "some initializers",
    "text": "some initializers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#constant",
    "href": "lectures/diverg.html#constant",
    "title": "divergent flow",
    "section": "constant",
    "text": "constant\n  // all 1\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 1; \n  }\n. . .\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#decreasing",
    "href": "lectures/diverg.html#decreasing",
    "title": "divergent flow",
    "section": "decreasing",
    "text": "decreasing\n// decreasing values from n-1 to 0\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n - i - 1;  // count should be N*(n+1)/2 = 54975572...\n  }\n. . .\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1\n\n\ndecreasing\n549755289600\n45.7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#middle-value",
    "href": "lectures/diverg.html#middle-value",
    "title": "divergent flow",
    "section": "middle value",
    "text": "middle value\n// Fill function to set all elements of the array to the middle value of n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n / 2;  // count should be N*N/2 54975572...\n  }\n. . .\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1\n\n\ndecreasing\n549755289600\n45.7\n\n\nmiddle value\n549755813888\n45.6",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#alternate-values",
    "href": "lectures/diverg.html#alternate-values",
    "title": "divergent flow",
    "section": "alternate values",
    "text": "alternate values\n// Fill function to set alternate elements to 0 or n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 0;\n    if (i%2){ A[i] = n;} \n  }\n. . .\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1\n\n\ndecreasing\n549755289600\n45.7\n\n\nmiddle value\n549755813888\n45.6\n\n\nalternate\n549755813888\n83.9",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#divergence-example",
    "href": "lectures/diverg.html#divergence-example",
    "title": "divergent flow",
    "section": "divergence example",
    "text": "divergence example\n\n\n__global__ void example(float* v){\n    if (v[tid]) &lt; 0.0){\n        v[tid] = /=2;\n    } else {\n        v[tid] = 0;\n    }\n}\n\nstart: \nr1 = addr v[tid]\nf1 = load r1\np1 = set.lt f0, 0.0\n\n@p1? less: f2 = div f1, 2\n@p1? less2: jmp Bstore\n\n!@p1? ge: f2 = 0.0\n\nBstore: store r1, f2",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#cfg",
    "href": "lectures/diverg.html#cfg",
    "title": "divergent flow",
    "section": "cfg",
    "text": "cfg\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nstart --&gt; less\nless--&gt; less2\nless2  --&gt; bstore\nless2 --&gt; ge\nge--&gt; bstore\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nstart --&gt; less\nless--&gt; less2\nless2  --&gt; bstore\nless2 --&gt; ge\nge--&gt; bstore\n\n\n\n\n\n\n\nstart: \nr1 = addr v[tid]\nf1 = load r1\np1 = set.lt f0, 0.0\n\n@p1? less: f2 = div f1, 2\n@p1? less2: jmp Bstore\n\n!@p1? ge: f2 = 0.0\n\nBstore: store r1, f2\n\n\n\nsimt\n##simple if -\nassume warp size is 4\nexecution mask per thread - if 1 perform instruction if 0 do nothing \n\noperation                active \nif      cond             r r r r  assume first two threads get true\nreset active to cond     r r - -\nthen statements          r r - - \ninvert active cond       --  r r \nelse statements          - - r r \njoin                     r r r r \nrestore active \ncontrol is uniform when all threads in warp - take the same path\ncontrol is divergent when different threads take different paths\nsuppose all threads take the same path",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#nested-if",
    "href": "lectures/diverg.html#nested-if",
    "title": "divergent flow",
    "section": "nested if",
    "text": "nested if\noperation                active \nif      cond             r r r r \nreset active to cond     r r - -\ninner if                 r r - -   assume first thread gets true \nreset active             r - - - \ninner then               r - - - \ninvert mask              - r - -\ninner else               - r - - \njoin                     r r - - \ninvert active cond       --  r r \nelse statements          - - r r \njoin                     r r r r \nrestore active \nWhen we start the then we need to know the new mask\nWhen we change from then to else - we need the new mask and we need to know the pc (for else)\nwhen we change from the else to the endif we need the new mask and we need to know the pc (for reconvergance)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#stack-verison",
    "href": "lectures/diverg.html#stack-verison",
    "title": "divergent flow",
    "section": "stack verison",
    "text": "stack verison\nhow do we do this in general\none way is a stack of masks\neach stack entry has 3 parts - reconvergence pc, next pc, mask when current pc == reconvergence pc, set pc to next pc, set mask, pop the stack\nwhen we have a branch\n\npush reconverge, next pc of then, mask\npush reconverge, next pc of else, mask\n\nwhen pc matches the reconverge point at tos, go to next pc and pop the stack",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#another-option",
    "href": "lectures/diverg.html#another-option",
    "title": "divergent flow",
    "section": "another option",
    "text": "another option\nuse a scalar processor with scalar registers that hold the mask",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#special-cases",
    "href": "lectures/diverg.html#special-cases",
    "title": "divergent flow",
    "section": "special cases",
    "text": "special cases\nspecial case if all threads go the same way, one of the masks has to be zero, ignore it",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#loop-case",
    "href": "lectures/diverg.html#loop-case",
    "title": "divergent flow",
    "section": "loop case",
    "text": "loop case\nloops - keep looping till all threads exit the loop\ni = 0\nwile (i &lt; tid){\n  i++\n}\nprint(i)\nfour threads\ni = 0  i&lt; tid      0 r r r \n       i           0 0 0 0\n\ni++    i &lt; tid     0 0  1 1\n       i           0 1 1 1 \n\ni++     i          0 1 2 2 \n        i&lt; tid     0 0 0  1\ni++     i          0 1 2 3 \n        i&lt; tid     0 0 0 0 \nno active threads restore mask and exit loop\nprint(i)   i   0 1 2 3 \nmask           1 1 1 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#kinds-of-flow",
    "href": "lectures/diverg.html#kinds-of-flow",
    "title": "divergent flow",
    "section": "kinds of flow",
    "text": "kinds of flow\nStructured control flow:\n\nsingle-entry, single exit\nproperly nested Conditionals: if-then-else\nSingle-entry, single-exit loops: while, do-while, for…\nFunction call-return\n\nUnstructured control flow:\n\nbreak,\ncontinue\n&& || short-circuit evaluation",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#short-circuit-if",
    "href": "lectures/diverg.html#short-circuit-if",
    "title": "divergent flow",
    "section": "short circuit if",
    "text": "short circuit if\nif (c || d) {\n   S1; \n   } else { \n   S2; \n   } \nS3;\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nc -- t1 t2 --&gt; s1\nd -- t3 --&gt; s1\nd  --t4 --&gt; s2\ns1 -- t1 t2 t3 --&gt; s3\ns2 -- t4--&gt; s3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nc -- t1 t2 --&gt; s1\nd -- t3 --&gt; s1\nd  --t4 --&gt; s2\ns1 -- t1 t2 t3 --&gt; s3\ns2 -- t4--&gt; s3\n\n\n\n\n\n\nc has a post dominator at s3\nforces s1 to run twice\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nd  --t4 --&gt; s2 \nc -- t1 t2 --&gt; ptest\nd -- t3 --&gt; p1[p1=1]\n\ns2--&gt; p2[p1=0]\np1--&gt; null\np2--&gt; null\nnull --&gt; ptest\nptest -- t1 t2 t3 --&gt; s1\nptest --t4 --&gt; s3\ns1 -- t1 t2 t3 --&gt; s3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nd  --t4 --&gt; s2 \nc -- t1 t2 --&gt; ptest\nd -- t3 --&gt; p1[p1=1]\n\ns2--&gt; p2[p1=0]\np1--&gt; null\np2--&gt; null\nnull --&gt; ptest\nptest -- t1 t2 t3 --&gt; s1\nptest --t4 --&gt; s3\ns1 -- t1 t2 t3 --&gt; s3\n\n\n\n\n\n\nexpansion by adding flags to get to reducible flow\nThe basic idea is to insert predicate assignments (p:=0and p :=1) and branches (p?) such that all splits and joins are properly nested, and the resultingCFG is structured. This\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nc1 --&gt; stmt1\nstmt1--&gt; past\nstmt2--&gt; past\nc1 --&gt; c2\nc2 --&gt; stmt2\nc2 --&gt; past\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nc1 --&gt; stmt1\nstmt1--&gt; past\nstmt2--&gt; past\nc1 --&gt; c2\nc2 --&gt; stmt2\nc2 --&gt; past\n\n\n\n\n\n\n\nstmt runs twice for different threads \n\n\n## simt deadlock problems\n\n\nforward progress cases \n\nproducer consummer cases \n\nhow can threads syncronize- \n\n1: *mutex = 0; 2: while(!atomicCAS(mutex,0,1)); 3: // Critical Section 4: atomicExch(mutex,0);\n\nNothing make sure threads make forward progress\n\n\n1. for a critical section- thread0 gets the lock\n2. other threads keep looping waiting for the lock to be released \n1, thread 0 never runs again- lock is never released \n\n\n\n## mask stacks vs per-thread pc\n\nstacks:\n1. O(n) memory \n1. structured control flow only \n\nper threadd pc:\n1. o(1) memory \n1. more expensive to implement \n\n\nnested control flow and skipped control flow \n\n\n\n\n\n# when does threading model break down?\n\nsome code deadlocks:\n\n\n\n## volta and newer \n\n[possible structure](https://arxiv.org/pdf/2407.02944)\n\nHandles unstructured code nicely \nalways makes forward progress \n\n\n## an example \n\nA: if (tid %4 &lt;2) { B C } else { D E } F\n\n\n## volta and later \n\nhardware keeps a pc for each thread\n\nat any time step, hardware picks an active pc and runs a step of all threads that have that pc\n\nstep    | mask  \n--|--|--\nA    | 1 1 1 \nB    |  1 1 00 \nD    |  00  11   \nc     |  1100 \nD   |    0011   \nF    | 1111   \n\n\n\n\n\n\n\n\n## what does this solve \n\nThe Volta architecture introduces Independent Thread Scheduling among threads in a warp. This feature enables intra-warp synchronization patterns previously unavailable and simplifies code changes when porting CPU code. However, Independent Thread Scheduling can also lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity of previous hardware architectures.\n\n\n## changes \n\nWhen porting existing codes to Volta, the following three code patterns need careful attention. For more details see the CUDA C++ Programming Guide.\n\n## cross warp operations \nTo avoid data corruption, applications using warp intrinsics (__shfl*, __any, __all, and __ballot) should transition to the new, safe, synchronizing counterparts, with the *_sync suffix. The new warp intrinsics take in a mask of threads that explicitly define which lanes (threads of a warp) must participate in the warp intrinsic.\n\n\n## memory access \n\nApplications that assume reads and writes are implicitly visible to other threads in the same warp need to insert the new __syncwarp() warp-wide barrier synchronization instruction between steps where data is exchanged between threads via global or shared memory. Assumptions that code is executed in lockstep or that reads/writes from separate threads are visible across a warp without synchronization are invalid.\n\n## barriers \n\nApplications using __syncthreads() or the PTX bar.sync (and their derivatives) in such a way that a barrier will not be reached by some non-exited thread in the thread block must be modified to ensure that all non-exited threads reach the barrier.\n\n\n## AMD scalar processor compiler challenge \n\nprograming language does not talk about scalar processor. Compiler has to figure out where to use it.  \n\n## what does this do to control flow graph \n\ntwo kinds of edges- vector view and scalar view. \n\n```{mermaid}\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nif--&gt; then \nif--&gt; else\nthen --&gt; join\nelse --&gt; join\nif .-&gt; then\nthen.-&gt; else\nelse.-&gt; join",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#static-detection-of-divergences",
    "href": "lectures/diverg.html#static-detection-of-divergences",
    "title": "divergent flow",
    "section": "static detection of divergences",
    "text": "static detection of divergences\ncan we determine which branches may cause divergences and which branches are uniform?\nat a dirergent branch some threads go one way, some the other, we will need to insert instructions for reconvergence at a uniform branch all threads go the same way",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#divergent-and-uniform-variables",
    "href": "lectures/diverg.html#divergent-and-uniform-variables",
    "title": "divergent flow",
    "section": "divergent and uniform variables",
    "text": "divergent and uniform variables\nA program variable is divergent if different threads see different values.\nIf different threads always see that variable with the same value, then the variable is uniform\ndivergent variables\n\nv = tid\natomic()\nv is data dependent on a divergent variable\nv is control dependent on a divergent variable",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#thread-id-is-always-divergent",
    "href": "lectures/diverg.html#thread-id-is-always-divergent",
    "title": "divergent flow",
    "section": "thread id is always divergent",
    "text": "thread id is always divergent\n __global__ \n void saxpy (int n, float alpha, float *x, float *y) {\n   int i = blockIdx.x * blockDim.x + threadIdx.x;  \n  if (i &lt; n) y[i] = alpha * x[i] + y[i]; } \nEach thread sees a different value\nThreads in different blocks see the same threadid - is that a problem?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#variables-defined-by-atomic-operations",
    "href": "lectures/diverg.html#variables-defined-by-atomic-operations",
    "title": "divergent flow",
    "section": "variables defined by atomic operations",
    "text": "variables defined by atomic operations\n__global__ void ex_atomic (int index, float* v) {\n   int i = 0; \n   i = ATOMINC( v[index] ); }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#dependences",
    "href": "lectures/diverg.html#dependences",
    "title": "divergent flow",
    "section": "dependences",
    "text": "dependences\nTwo types of dependences: data and control.\nIf the program contains an assignment such as v = f(v1, v2, …, vn), then v is data dependent on the arguments v1,v2 …\nIf the value assigned to variable v depends on a branch controlled by p, then we say that v is control dependent on p. \nDivergences propagate transitively on the graph determined by the dependence relation.\nA variable might be divergent at one program point and uniform at another",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#an-example",
    "href": "lectures/diverg.html#an-example",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph\nb0[\"bo: i0 = ld v[tid]\\n j0 = 0\"]\nb1[\"b1: i = phi(i0,i1)\\nj=phi(j0,j3\\np0 = i &lt; 100\\n branch p0 B2\"]\nb0 --&gt; b1\nb1--&gt; b2\nb2[\"b2: i1= i +1\\n j1 = j +1\\n t0 = j1 mod2 \\n p1 = t0 ==0\\n branch b1, b4\"]\nb5[\"b5: sync\\np2 = j &lt; 100\\n, branch p2, b7\"]\nb2--&gt; b3[\"b3:j2 = j1 -3\"]\nb2 --&gt; b4[\"b4: j3= phi(j2, j1)\\n jump b1\"]\nb4 --&gt; b1\nb3--&gt; b4\nb1--&gt; b5\nb5--&gt; b6[\"b6:x0 =1\\n jump b8\"]\nb5--&gt; b7[x1 =2]\nb7 --&gt; b8\nb6--&gt; b8[\"b8:x = phi(x0,x1)\\n sync\\st v[tid] = x0\"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph\nb0[\"bo: i0 = ld v[tid]\\n j0 = 0\"]\nb1[\"b1: i = phi(i0,i1)\\nj=phi(j0,j3\\np0 = i &lt; 100\\n branch p0 B2\"]\nb0 --&gt; b1\nb1--&gt; b2\nb2[\"b2: i1= i +1\\n j1 = j +1\\n t0 = j1 mod2 \\n p1 = t0 ==0\\n branch b1, b4\"]\nb5[\"b5: sync\\np2 = j &lt; 100\\n, branch p2, b7\"]\nb2--&gt; b3[\"b3:j2 = j1 -3\"]\nb2 --&gt; b4[\"b4: j3= phi(j2, j1)\\n jump b1\"]\nb4 --&gt; b1\nb3--&gt; b4\nb1--&gt; b5\nb5--&gt; b6[\"b6:x0 =1\\n jump b8\"]\nb5--&gt; b7[x1 =2]\nb7 --&gt; b8\nb6--&gt; b8[\"b8:x = phi(x0,x1)\\n sync\\st v[tid] = x0\"]\n\n\n\n\n\n\n\nWe can construct the data dependenc graph\n\na node for each variable\nan edge from u to v, if v is data depedent on u",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#dd-graph",
    "href": "lectures/diverg.html#dd-graph",
    "title": "divergent flow",
    "section": "dd graph",
    "text": "dd graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph \ntid --&gt; i0\ni0--&gt; i\ni1--&gt; i\nj0--&gt; j\nj3--&gt; j\ni--&gt; p0\ni--&gt; i1\nj--&gt; j1\nj1--&gt; t0\nj--&gt; p2\nj1--&gt; j2\nj2--&gt; j3\nj1--&gt; j3\nx0--&gt; x\nx1--&gt; x \nt0--&gt; t1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph \ntid --&gt; i0\ni0--&gt; i\ni1--&gt; i\nj0--&gt; j\nj3--&gt; j\ni--&gt; p0\ni--&gt; i1\nj--&gt; j1\nj1--&gt; t0\nj--&gt; p2\nj1--&gt; j2\nj2--&gt; j3\nj1--&gt; j3\nx0--&gt; x\nx1--&gt; x \nt0--&gt; t1\n\n\n\n\n\n\n\nThe data divergences show that not all the nodes are data dependent on tid\nis j in b5 divergent?\ni is divergent, p0 is divergent so threads go though the loop diferent number of times so j varies\nwhat about x in block 8? efected by p2 which depends of j",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#memory-operations",
    "href": "lectures/diverg.html#memory-operations",
    "title": "divergent flow",
    "section": "memory operations",
    "text": "memory operations\nThe C semantics assume that (within a single thread) all loads and stores stay in order. That is is not allowed to re-order a store past a load of the same address.\nin ssa each argument of an instruction is a pointer to the source instruction. These edges force serialization of the code.\nWe want to apply this to loads and stores this will make ordering explicit\nIn Static Single Assignment (SSA) form, memory tokens, representing stores or loads to memory, are typically handled by introducing memory state variables\n\nload: dest = load addrs, memory_token\nstore memory_token = store value, address, memory_token\ncalls to functions that might modify memory also need to read and write memory tokens\n\ntreat a store as though it created a new copy of memory\nwe can use phi functions on memory tokens\nMaintaining Correct Memory Order: By tracking memory states explicitly in SSA form (through these memory tokens and versioning), SSA ensures that memory operations respect the correct order, even if the control flow of the program is complex. This helps compilers optimize code by making memory dependencies explicit.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n\nOptimize loads/stores\nwalk backwards - load from store\n\nif we can prove the load address is the same as the store address- remove the load\nif we can prove the load address is different move the load up a store\notherwise go on",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#multi-threaded-programs",
    "href": "lectures/diverg.html#multi-threaded-programs",
    "title": "divergent flow",
    "section": "multi-threaded programs",
    "text": "multi-threaded programs\nCompilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#shared-memory-multi-threading",
    "href": "lectures/diverg.html#shared-memory-multi-threading",
    "title": "divergent flow",
    "section": "shared memory multi-threading",
    "text": "shared memory multi-threading\nThe most common parallel system is\n\nA single big memory\nmultiple threads address that memory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#what-is-sequential-consistency-sq",
    "href": "lectures/diverg.html#what-is-sequential-consistency-sq",
    "title": "divergent flow",
    "section": "what is sequential consistency SQ",
    "text": "what is sequential consistency SQ\nProgram Order is Maintained Within Threads:\nOperations (reads and writes) appear to occur in the order they are issued by each individual thread. If a thread performs a write followed by a read, the read cannot appear to happen before the write in the execution.\nGlobal Order of Operations Across Threads:\nAll threads see the effects of memory operations in the same sequential order. Every thread agrees on the order of reads and writes, though the specific order is not predefined—it just needs to be consistent across all threads. Interleaving of Operations:\nThe execution can be viewed as an interleaving of instructions from all threads. However, the interleaving must follow the program order within each thread.\nno real machine/compiler implements this",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#compiler-effects",
    "href": "lectures/diverg.html#compiler-effects",
    "title": "divergent flow",
    "section": "compiler effects",
    "text": "compiler effects\nCompiler transformations that break multi-thread sequential consistency (SC) often reorder or optimize instructions in ways that do not respect the original program order seen by other threads. These transformations can lead to subtle bugs in multithreaded programs where the expected interleaving of operations is violated.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#loadstore-reordering",
    "href": "lectures/diverg.html#loadstore-reordering",
    "title": "divergent flow",
    "section": "Load/Store Reordering",
    "text": "Load/Store Reordering\nTransformation: Compilers might reorder loads and stores to improve performance. Violation: In a multi-threaded environment, this can lead to a situation where one thread sees stale or unexpected data. Example:\nCopy code\n// Thread 1\nx = 1;     // Store\nr1 = y;    // Load\n\n// Thread 2\ny = 1;     // Store\nr2 = x;    // Load\nUnder sequential consistency, if thread 1’s x = 1 happens before thread 2’s r2 = x, then thread 2 should observe r2 == 1. But reordering could result in thread 2 reading x as 0.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#common-subexpression-elimination-cse",
    "href": "lectures/diverg.html#common-subexpression-elimination-cse",
    "title": "divergent flow",
    "section": "Common Subexpression Elimination (CSE)",
    "text": "Common Subexpression Elimination (CSE)\nTransformation: If a variable or expression is computed multiple times, the compiler may optimize by reusing the result of an earlier computation. Violation: This assumes that no other thread modifies shared variables between these uses. Example:\n// Original code\nr1 = x;\nr2 = x;\n\n// Transformed code (CSE applied)\ntemp = x;\nr1 = temp;\nr2 = temp;\nIf x is modified by another thread between the two reads, the transformed code will incorrectly assume the value of x hasn’t changed.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#dead-code-elimination-dce",
    "href": "lectures/diverg.html#dead-code-elimination-dce",
    "title": "divergent flow",
    "section": "Dead Code Elimination (DCE)",
    "text": "Dead Code Elimination (DCE)\nTransformation: The compiler may remove stores to variables that are not subsequently read in the same thread. Violation: If the variable is shared and accessed by other threads, removing the store could lead to unexpected behavior. Example:\n// Original code\nx = 1;\n\n// Transformed code (DCE applied)\n// x = 1 is removed because x is not used locally If another thread reads x, it expects the store to have happened, but DCE breaks this assumption.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#speculative-execution-out-of-order-execution",
    "href": "lectures/diverg.html#speculative-execution-out-of-order-execution",
    "title": "divergent flow",
    "section": "Speculative Execution (Out-of-Order Execution)",
    "text": "Speculative Execution (Out-of-Order Execution)\nTransformation: Compilers (or hardware) may execute instructions speculatively, assuming certain branches are likely to be taken. Violation: This can cause out-of-order writes or reads visible to other threads, breaking SC. Example:\nif (flag) {\n    r1 = x;\n}\nIf the compiler speculatively reads x before knowing the value of flag, another thread’s write to x might be missed or observed out-of-order.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#loop-invariant-code-motion",
    "href": "lectures/diverg.html#loop-invariant-code-motion",
    "title": "divergent flow",
    "section": "Loop Invariant Code Motion",
    "text": "Loop Invariant Code Motion\nTransformation: The compiler moves computations that are invariant inside a loop to outside the loop. Violation: If these computations involve shared variables modified by other threads within the loop, moving them outside could make the code see stale values. Example:\n// Original code\nwhile (condition) {\n    r = shared_variable;\n}\n\n// Transformed code (Loop Invariant Code Motion)\ntemp = shared_variable;\nwhile (condition) {\n    r = temp;\n}\nIf shared_variable is updated by another thread, the transformed code might keep using the old value.\n\nRegister Allocation (Caching Shared Variables in Registers)\nTransformation: Compilers can keep a shared variable in a register for efficiency rather than repeatedly loading it from memory. Violation: If another thread modifies that shared variable in memory, the compiler’s register optimization would cause the thread to read stale data. Example:\nwhile (flag == 0) {\n    // busy-wait\n}\nIf flag is cached in a register, updates to flag by another thread in memory won’t be reflected, breaking SC.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#instruction-fusion-combining-loadsstores",
    "href": "lectures/diverg.html#instruction-fusion-combining-loadsstores",
    "title": "divergent flow",
    "section": "Instruction Fusion (Combining Loads/Stores)",
    "text": "Instruction Fusion (Combining Loads/Stores)\nTransformation: The compiler may combine consecutive memory accesses into one, such as merging adjacent stores into a single store or combining two loads. Violation: If other threads expect these loads or stores to happen separately, they might see an inconsistent view of memory. Example:\n// Original code\nx = 1;\ny = 2;\n\n// Transformed code (store fusion)\n// x and y are stored together in a single transaction\nA thread expecting x and y to be updated separately might observe an inconsistent state if this transformation is applied.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#thread-libraries",
    "href": "lectures/diverg.html#thread-libraries",
    "title": "divergent flow",
    "section": "thread libraries",
    "text": "thread libraries\nstart out assuming single threaded, add a threads library like pthreads\nmultiple threads could access shared memory simultaneously, leading to race conditions, inconsistent data, and undefined behavior.\nModern CPUs and compilers perform optimizations like instruction reordering, which can break assumptions about the order of memory operations in multithreaded programs.\nMultithreaded code is harder to test because race conditions and bugs might only manifest under certain timing conditions.\nDebugging multithreaded programs is more difficult due to the unpredictable nature of thread execution and interactions.\nSome optimizations might reorder instructions in a way that is incompatible with multithreading, introducing subtle bugs or performance regressions.\nCaching, prefetching, or other memory optimizations need to account for the fact that multiple threads may be accessing the same memory, which a simple thread library does not handle.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#using-libraries",
    "href": "lectures/diverg.html#using-libraries",
    "title": "divergent flow",
    "section": "using libraries",
    "text": "using libraries\n\nFunctions such as pthread mutex lock() that are guaranteed by the standard to “synchronize memory” include hardware instructions (“memory barriers”) that prevent hardware reordering of memory operations around the call\nTo prevent the compiler from moving memory operations around calls to functions such as pthread mutex lock(), they are essentially treated as calls to opaque functions, about which the compiler has no information.\n\nThe compiler effectively assumes that pthread mutex lock() may read or write any global variable. Thus a memory reference cannot simply be moved across the call. This approach also ensures that transitive calls, e.g. a call to a function f() which then calls pthread mutex lock(), are handled in the same way more or less appropriately, i.e. memory operations are not moved across the call to f() either, whether or not the entire user program is being analyzed at once.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#adding-multi-threading-to-user-explaining-the-intent",
    "href": "lectures/diverg.html#adding-multi-threading-to-user-explaining-the-intent",
    "title": "divergent flow",
    "section": "adding multi-threading to user explaining the intent",
    "text": "adding multi-threading to user explaining the intent\nc++/c added atomics\nAtomic operations are operations that are completed as a single, uninterruptible action. No other thread can observe a partial update or interfere with the operation.\nThese operations ensure that read-modify-write sequences are safe without needing explicit locks.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#an-example-2",
    "href": "lectures/diverg.html#an-example-2",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n// Global spinlock using atomic_flag\nstd::atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid enter_critical_section() {\n    // Busy-wait (spin) until the lock is acquired\n    while (lock.test_and_set(std::memory_order_acquire)) {\n        // Spin and wait for the lock to become available\n    }\n}\n\nvoid leave_critical_section() {\n    // Release the lock\n    lock.clear(std::memory_order_release);\n}\n\n// Shared resource\nint shared_counter = 0;\n\nvoid critical_section_task(int num_increments) {\n    for (int i = 0; i &lt; num_increments; ++i) {\n        enter_critical_section();\n        // Begin critical section\n        ++shared_counter;\n        // End critical section\n        leave_critical_section();\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#load-acquire-needs-special-hardware",
    "href": "lectures/diverg.html#load-acquire-needs-special-hardware",
    "title": "divergent flow",
    "section": "load acquire (needs special hardware )",
    "text": "load acquire (needs special hardware )\nused by default with atomics not used for non-atomics\nall memory reads and writes after the load operation cannot be moved before the load. This ensures that after acquiring the value, any operations that depend on this value (like accessing shared data) will see consistent and up-to-date memory.\na one way fence - nothing can move up",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#write-release-needs-special-hardware",
    "href": "lectures/diverg.html#write-release-needs-special-hardware",
    "title": "divergent flow",
    "section": "write release (needs special hardware )",
    "text": "write release (needs special hardware )\nprevents the compiler or processor from reordering any memory operations (reads or writes) that appear before the release store. This guarantees that all operations that modify shared data before the release are visible to other threads that subsequently perform an acquire operation.\nalso a one way fence - nothing can move down\nload.acquire - \nloads and stores on non-atomics  - compiler picks the order for these operations \nstore.release",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#using-atomics",
    "href": "lectures/diverg.html#using-atomics",
    "title": "divergent flow",
    "section": "using atomics",
    "text": "using atomics\nAll operations appear to occur in a single total order that is consistent across all threads. This means that the results of operations are predictable and consistent as if all operations were executed in some sequential order.\nlimits the hardware and compiler because it prevents reordering",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#data-race-free",
    "href": "lectures/diverg.html#data-race-free",
    "title": "divergent flow",
    "section": "Data Race Free",
    "text": "Data Race Free\nData Race Free (DRF) means that a program is free from data races, which occur when:\n\nTwo or more threads access the same variable concurrently.\nAt least one of the accesses is a write.\n\nThere is no synchronization mechanism (like mutexes or atomic operations) to control the access. In a data race-free program, every shared variable is accessed in a way that ensures predictable results. C++ provides various synchronization primitives (such as mutexes and atomic types) to help developers write DRF code.\nAll shared variables must be accessed using synchronization to prevent concurrent threads from modifying shared data simultaneously without coordination.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#an-example-3",
    "href": "lectures/diverg.html#an-example-3",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nint shared_counter1 = 0;                  // First non-atomic shared variable\nint shared_counter2 = 0;                  // Second non-atomic shared variable\nstd::atomic&lt;bool&gt; lock_flag(false);       // Atomic flag to control access\n\nvoid safe_increment() {\n    for (int i = 0; i &lt; 1000; ++i) {\n        // Spin until the lock is acquired\n        while (lock_flag.exchange(true)) {\n            // Busy-wait (spin) until the lock is free\n        }\n\n        // Critical section: update the non-atomic shared variables\n        ++shared_counter1;\n        ++shared_counter2;\n\n        // Release the lock\n        lock_flag.store(false);\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#language-rules",
    "href": "lectures/diverg.html#language-rules",
    "title": "divergent flow",
    "section": "language rules",
    "text": "language rules\nC and C++\ndo not define what happens in the presence of data races. If a program has data races (e.g., multiple threads concurrently reading and writing to the same variable without synchronization), the behavior is considered undefined. This means that the program may produce unexpected results, crash, or behave inconsistently across different executions or platforms.\nJava\ntries to define what happens but definition is very complex and maybe inconsistent\nRust\nCompile-Time Guarantees: Rust’s ownership and borrowing system prevents data races at compile time. If a program is not DRF, the Rust compiler will typically refuse to compile it, enforcing memory safety guarantees.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#can-the-compiler-add-a-race-to-a-drf-program",
    "href": "lectures/diverg.html#can-the-compiler-add-a-race-to-a-drf-program",
    "title": "divergent flow",
    "section": "can the compiler add a race to a drf program",
    "text": "can the compiler add a race to a drf program\nnew rule, compiler cannot add a write to a shared variable\nif (x ==1) y++\n\nto \ny++\nif (x!=1) y--",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/diverg.html#how-does-this-effect-hardware",
    "href": "lectures/diverg.html#how-does-this-effect-hardware",
    "title": "divergent flow",
    "section": "how does this effect hardware?",
    "text": "how does this effect hardware?\nstruct { char a; char b; char c; char d;} s;\ns.a = 1\ns.c = 3\n\ncan a compiler do \nchar temp[4] = s // load 32 bits \ntemp[0] = 1\ntemp[2] = 3\ns = temp\nnot allowed - reads/writes b and d, so compiler incorrectly added writes\noptions are either have byte addressable hardware, or pad so that each char gets 32 bits\nVendors forced to add 8 byte loads/stores",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow"
    ]
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#what-is-the-cost-of-divergence",
    "href": "lectures/revealjs_diverg.qmd.html#what-is-the-cost-of-divergence",
    "title": "divergent flow",
    "section": "What is the cost of divergence",
    "text": "What is the cost of divergence\n__global__ void dec2zero(int* v, int N) { \n    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   \n    if (xIndex &lt; N) {\n             while (v[xIndex] &gt; 0) { v[xIndex]--;     \n             }     \n        } \n} \nDepending on how we initialize the vector, we get different times and different subtracts\n\nSize of array 1048576\nThreads Per Block = 256\nBlocks In Grid = 4096\n\n256 threads means 8 warps\neach warp start running - calculates a unique index\neach thread checks if v[index]&gt; 0 giving a mask, each thread read v[xindex] decrements the value and if the mask is on, updates, if the mask bit is off, the thread does not write\nif half the masks are on, half the threads do work, the other half don’t so 50% active"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#some-initializers",
    "href": "lectures/revealjs_diverg.qmd.html#some-initializers",
    "title": "divergent flow",
    "section": "some initializers",
    "text": "some initializers"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#constant",
    "href": "lectures/revealjs_diverg.qmd.html#constant",
    "title": "divergent flow",
    "section": "constant",
    "text": "constant\n  // all 1\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 1; \n  }\n\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#decreasing",
    "href": "lectures/revealjs_diverg.qmd.html#decreasing",
    "title": "divergent flow",
    "section": "decreasing",
    "text": "decreasing\n// decreasing values from n-1 to 0\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n - i - 1;  // count should be N*(n+1)/2 = 54975572...\n  }\n\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1\n\n\ndecreasing\n549755289600\n45.7"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#middle-value",
    "href": "lectures/revealjs_diverg.qmd.html#middle-value",
    "title": "divergent flow",
    "section": "middle value",
    "text": "middle value\n// Fill function to set all elements of the array to the middle value of n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = n / 2;  // count should be N*N/2 54975572...\n  }\n\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1\n\n\ndecreasing\n549755289600\n45.7\n\n\nmiddle value\n549755813888\n45.6"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#alternate-values",
    "href": "lectures/revealjs_diverg.qmd.html#alternate-values",
    "title": "divergent flow",
    "section": "alternate values",
    "text": "alternate values\n// Fill function to set alternate elements to 0 or n\n  for (int i = 0; i &lt; n; i++) {\n    A[i] = 0;\n    if (i%2){ A[i] = n;} \n  }\n\n\n\n\nkind\nsubtracts\ntime ms\n\n\n\n\nconstant one\n1048576\n0.1\n\n\ndecreasing\n549755289600\n45.7\n\n\nmiddle value\n549755813888\n45.6\n\n\nalternate\n549755813888\n83.9"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#divergence-example",
    "href": "lectures/revealjs_diverg.qmd.html#divergence-example",
    "title": "divergent flow",
    "section": "divergence example",
    "text": "divergence example\n\n\n__global__ void example(float* v){\n    if (v[tid]) &lt; 0.0){\n        v[tid] = /=2;\n    } else {\n        v[tid] = 0;\n    }\n}\n\nstart: \nr1 = addr v[tid]\nf1 = load r1\np1 = set.lt f0, 0.0\n\n@p1? less: f2 = div f1, 2\n@p1? less2: jmp Bstore\n\n!@p1? ge: f2 = 0.0\n\nBstore: store r1, f2"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#cfg",
    "href": "lectures/revealjs_diverg.qmd.html#cfg",
    "title": "divergent flow",
    "section": "cfg",
    "text": "cfg\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nstart --&gt; less\nless--&gt; less2\nless2  --&gt; bstore\nless2 --&gt; ge\nge--&gt; bstore\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nstart --&gt; less\nless--&gt; less2\nless2  --&gt; bstore\nless2 --&gt; ge\nge--&gt; bstore\n\n\n\n\n\n\n\nstart: \nr1 = addr v[tid]\nf1 = load r1\np1 = set.lt f0, 0.0\n\n@p1? less: f2 = div f1, 2\n@p1? less2: jmp Bstore\n\n!@p1? ge: f2 = 0.0\n\nBstore: store r1, f2"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#nested-if",
    "href": "lectures/revealjs_diverg.qmd.html#nested-if",
    "title": "divergent flow",
    "section": "nested if",
    "text": "nested if\noperation                active \nif      cond             r r r r \nreset active to cond     r r - -\ninner if                 r r - -   assume first thread gets true \nreset active             r - - - \ninner then               r - - - \ninvert mask              - r - -\ninner else               - r - - \njoin                     r r - - \ninvert active cond       --  r r \nelse statements          - - r r \njoin                     r r r r \nrestore active \nWhen we start the then we need to know the new mask\nWhen we change from then to else - we need the new mask and we need to know the pc (for else)\nwhen we change from the else to the endif we need the new mask and we need to know the pc (for reconvergance)"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#stack-verison",
    "href": "lectures/revealjs_diverg.qmd.html#stack-verison",
    "title": "divergent flow",
    "section": "stack verison",
    "text": "stack verison\nhow do we do this in general\none way is a stack of masks\neach stack entry has 3 parts - reconvergence pc, next pc, mask when current pc == reconvergence pc, set pc to next pc, set mask, pop the stack\nwhen we have a branch\n\npush reconverge, next pc of then, mask\npush reconverge, next pc of else, mask\n\nwhen pc matches the reconverge point at tos, go to next pc and pop the stack"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#another-option",
    "href": "lectures/revealjs_diverg.qmd.html#another-option",
    "title": "divergent flow",
    "section": "another option",
    "text": "another option\nuse a scalar processor with scalar registers that hold the mask"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#special-cases",
    "href": "lectures/revealjs_diverg.qmd.html#special-cases",
    "title": "divergent flow",
    "section": "special cases",
    "text": "special cases\nspecial case if all threads go the same way, one of the masks has to be zero, ignore it"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#loop-case",
    "href": "lectures/revealjs_diverg.qmd.html#loop-case",
    "title": "divergent flow",
    "section": "loop case",
    "text": "loop case\nloops - keep looping till all threads exit the loop\ni = 0\nwile (i &lt; tid){\n  i++\n}\nprint(i)\nfour threads\ni = 0  i&lt; tid      0 r r r \n       i           0 0 0 0\n\ni++    i &lt; tid     0 0  1 1\n       i           0 1 1 1 \n\ni++     i          0 1 2 2 \n        i&lt; tid     0 0 0  1\ni++     i          0 1 2 3 \n        i&lt; tid     0 0 0 0 \nno active threads restore mask and exit loop\nprint(i)   i   0 1 2 3 \nmask           1 1 1 1"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#kinds-of-flow",
    "href": "lectures/revealjs_diverg.qmd.html#kinds-of-flow",
    "title": "divergent flow",
    "section": "kinds of flow",
    "text": "kinds of flow\nStructured control flow:\n\nsingle-entry, single exit\nproperly nested Conditionals: if-then-else\nSingle-entry, single-exit loops: while, do-while, for…\nFunction call-return\n\nUnstructured control flow:\n\nbreak,\ncontinue\n&& || short-circuit evaluation"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#short-circuit-if",
    "href": "lectures/revealjs_diverg.qmd.html#short-circuit-if",
    "title": "divergent flow",
    "section": "short circuit if",
    "text": "short circuit if\nif (c || d) {\n   S1; \n   } else { \n   S2; \n   } \nS3;\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nc -- t1 t2 --&gt; s1\nd -- t3 --&gt; s1\nd  --t4 --&gt; s2\ns1 -- t1 t2 t3 --&gt; s3\ns2 -- t4--&gt; s3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nc -- t1 t2 --&gt; s1\nd -- t3 --&gt; s1\nd  --t4 --&gt; s2\ns1 -- t1 t2 t3 --&gt; s3\ns2 -- t4--&gt; s3\n\n\n\n\n\n\nc has a post dominator at s3\nforces s1 to run twice\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nd  --t4 --&gt; s2 \nc -- t1 t2 --&gt; ptest\nd -- t3 --&gt; p1[p1=1]\n\ns2--&gt; p2[p1=0]\np1--&gt; null\np2--&gt; null\nnull --&gt; ptest\nptest -- t1 t2 t3 --&gt; s1\nptest --t4 --&gt; s3\ns1 -- t1 t2 t3 --&gt; s3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry-- t1 t2 t3 t4 --&gt; c[c?]  --t3 t4--&gt; d[d?]\nd  --t4 --&gt; s2 \nc -- t1 t2 --&gt; ptest\nd -- t3 --&gt; p1[p1=1]\n\ns2--&gt; p2[p1=0]\np1--&gt; null\np2--&gt; null\nnull --&gt; ptest\nptest -- t1 t2 t3 --&gt; s1\nptest --t4 --&gt; s3\ns1 -- t1 t2 t3 --&gt; s3\n\n\n\n\n\n\nexpansion by adding flags to get to reducible flow\nThe basic idea is to insert predicate assignments (p:=0and p :=1) and branches (p?) such that all splits and joins are properly nested, and the resultingCFG is structured. This\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nc1 --&gt; stmt1\nstmt1--&gt; past\nstmt2--&gt; past\nc1 --&gt; c2\nc2 --&gt; stmt2\nc2 --&gt; past\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nc1 --&gt; stmt1\nstmt1--&gt; past\nstmt2--&gt; past\nc1 --&gt; c2\nc2 --&gt; stmt2\nc2 --&gt; past\n\n\n\n\n\n\n\nstmt runs twice for different threads \n\n\n## simt deadlock problems\n\n\nforward progress cases \n\nproducer consummer cases \n\nhow can threads syncronize- \n\n1: *mutex = 0; 2: while(!atomicCAS(mutex,0,1)); 3: // Critical Section 4: atomicExch(mutex,0);\n\nNothing make sure threads make forward progress\n\n\n1. for a critical section- thread0 gets the lock\n2. other threads keep looping waiting for the lock to be released \n1, thread 0 never runs again- lock is never released \n\n\n\n## mask stacks vs per-thread pc\n\nstacks:\n1. O(n) memory \n1. structured control flow only \n\nper threadd pc:\n1. o(1) memory \n1. more expensive to implement \n\n\nnested control flow and skipped control flow \n\n\n\n\n\n# when does threading model break down?\n\nsome code deadlocks:\n\n\n\n## volta and newer \n\n[possible structure](https://arxiv.org/pdf/2407.02944)\n\nHandles unstructured code nicely \nalways makes forward progress \n\n\n## an example \n\nA: if (tid %4 &lt;2) { B C } else { D E } F\n\n\n## volta and later \n\nhardware keeps a pc for each thread\n\nat any time step, hardware picks an active pc and runs a step of all threads that have that pc\n\nstep    | mask  \n--|--|--\nA    | 1 1 1 \nB    |  1 1 00 \nD    |  00  11   \nc     |  1100 \nD   |    0011   \nF    | 1111   \n\n\n\n\n\n\n\n\n## what does this solve \n\nThe Volta architecture introduces Independent Thread Scheduling among threads in a warp. This feature enables intra-warp synchronization patterns previously unavailable and simplifies code changes when porting CPU code. However, Independent Thread Scheduling can also lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity of previous hardware architectures.\n\n\n## changes \n\nWhen porting existing codes to Volta, the following three code patterns need careful attention. For more details see the CUDA C++ Programming Guide.\n\n## cross warp operations \nTo avoid data corruption, applications using warp intrinsics (__shfl*, __any, __all, and __ballot) should transition to the new, safe, synchronizing counterparts, with the *_sync suffix. The new warp intrinsics take in a mask of threads that explicitly define which lanes (threads of a warp) must participate in the warp intrinsic.\n\n\n## memory access \n\nApplications that assume reads and writes are implicitly visible to other threads in the same warp need to insert the new __syncwarp() warp-wide barrier synchronization instruction between steps where data is exchanged between threads via global or shared memory. Assumptions that code is executed in lockstep or that reads/writes from separate threads are visible across a warp without synchronization are invalid.\n\n## barriers \n\nApplications using __syncthreads() or the PTX bar.sync (and their derivatives) in such a way that a barrier will not be reached by some non-exited thread in the thread block must be modified to ensure that all non-exited threads reach the barrier.\n\n\n## AMD scalar processor compiler challenge \n\nprograming language does not talk about scalar processor. Compiler has to figure out where to use it.  \n\n## what does this do to control flow graph \n\ntwo kinds of edges- vector view and scalar view. \n\n```{mermaid}\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nif--&gt; then \nif--&gt; else\nthen --&gt; join\nelse --&gt; join\nif .-&gt; then\nthen.-&gt; else\nelse.-&gt; join"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#static-detection-of-divergences",
    "href": "lectures/revealjs_diverg.qmd.html#static-detection-of-divergences",
    "title": "divergent flow",
    "section": "static detection of divergences",
    "text": "static detection of divergences\ncan we determine which branches may cause divergences and which branches are uniform?\nat a dirergent branch some threads go one way, some the other, we will need to insert instructions for reconvergence at a uniform branch all threads go the same way"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#divergent-and-uniform-variables",
    "href": "lectures/revealjs_diverg.qmd.html#divergent-and-uniform-variables",
    "title": "divergent flow",
    "section": "divergent and uniform variables",
    "text": "divergent and uniform variables\nA program variable is divergent if different threads see different values.\nIf different threads always see that variable with the same value, then the variable is uniform\ndivergent variables\n\nv = tid\natomic()\nv is data dependent on a divergent variable\nv is control dependent on a divergent variable"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#thread-id-is-always-divergent",
    "href": "lectures/revealjs_diverg.qmd.html#thread-id-is-always-divergent",
    "title": "divergent flow",
    "section": "thread id is always divergent",
    "text": "thread id is always divergent\n __global__ \n void saxpy (int n, float alpha, float *x, float *y) {\n   int i = blockIdx.x * blockDim.x + threadIdx.x;  \n  if (i &lt; n) y[i] = alpha * x[i] + y[i]; } \nEach thread sees a different value\nThreads in different blocks see the same threadid - is that a problem?"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#variables-defined-by-atomic-operations",
    "href": "lectures/revealjs_diverg.qmd.html#variables-defined-by-atomic-operations",
    "title": "divergent flow",
    "section": "variables defined by atomic operations",
    "text": "variables defined by atomic operations\n__global__ void ex_atomic (int index, float* v) {\n   int i = 0; \n   i = ATOMINC( v[index] ); }"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#dependences",
    "href": "lectures/revealjs_diverg.qmd.html#dependences",
    "title": "divergent flow",
    "section": "dependences",
    "text": "dependences\nTwo types of dependences: data and control.\nIf the program contains an assignment such as v = f(v1, v2, …, vn), then v is data dependent on the arguments v1,v2 …\nIf the value assigned to variable v depends on a branch controlled by p, then we say that v is control dependent on p. \nDivergences propagate transitively on the graph determined by the dependence relation.\nA variable might be divergent at one program point and uniform at another"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#an-example",
    "href": "lectures/revealjs_diverg.qmd.html#an-example",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph\nb0[\"bo: i0 = ld v[tid]\\n j0 = 0\"]\nb1[\"b1: i = phi(i0,i1)\\nj=phi(j0,j3\\np0 = i &lt; 100\\n branch p0 B2\"]\nb0 --&gt; b1\nb1--&gt; b2\nb2[\"b2: i1= i +1\\n j1 = j +1\\n t0 = j1 mod2 \\n p1 = t0 ==0\\n branch b1, b4\"]\nb5[\"b5: sync\\np2 = j &lt; 100\\n, branch p2, b7\"]\nb2--&gt; b3[\"b3:j2 = j1 -3\"]\nb2 --&gt; b4[\"b4: j3= phi(j2, j1)\\n jump b1\"]\nb4 --&gt; b1\nb3--&gt; b4\nb1--&gt; b5\nb5--&gt; b6[\"b6:x0 =1\\n jump b8\"]\nb5--&gt; b7[x1 =2]\nb7 --&gt; b8\nb6--&gt; b8[\"b8:x = phi(x0,x1)\\n sync\\st v[tid] = x0\"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph\nb0[\"bo: i0 = ld v[tid]\\n j0 = 0\"]\nb1[\"b1: i = phi(i0,i1)\\nj=phi(j0,j3\\np0 = i &lt; 100\\n branch p0 B2\"]\nb0 --&gt; b1\nb1--&gt; b2\nb2[\"b2: i1= i +1\\n j1 = j +1\\n t0 = j1 mod2 \\n p1 = t0 ==0\\n branch b1, b4\"]\nb5[\"b5: sync\\np2 = j &lt; 100\\n, branch p2, b7\"]\nb2--&gt; b3[\"b3:j2 = j1 -3\"]\nb2 --&gt; b4[\"b4: j3= phi(j2, j1)\\n jump b1\"]\nb4 --&gt; b1\nb3--&gt; b4\nb1--&gt; b5\nb5--&gt; b6[\"b6:x0 =1\\n jump b8\"]\nb5--&gt; b7[x1 =2]\nb7 --&gt; b8\nb6--&gt; b8[\"b8:x = phi(x0,x1)\\n sync\\st v[tid] = x0\"]\n\n\n\n\n\n\n\nWe can construct the data dependenc graph\n\na node for each variable\nan edge from u to v, if v is data depedent on u"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#dd-graph",
    "href": "lectures/revealjs_diverg.qmd.html#dd-graph",
    "title": "divergent flow",
    "section": "dd graph",
    "text": "dd graph\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph \ntid --&gt; i0\ni0--&gt; i\ni1--&gt; i\nj0--&gt; j\nj3--&gt; j\ni--&gt; p0\ni--&gt; i1\nj--&gt; j1\nj1--&gt; t0\nj--&gt; p2\nj1--&gt; j2\nj2--&gt; j3\nj1--&gt; j3\nx0--&gt; x\nx1--&gt; x \nt0--&gt; t1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph \ntid --&gt; i0\ni0--&gt; i\ni1--&gt; i\nj0--&gt; j\nj3--&gt; j\ni--&gt; p0\ni--&gt; i1\nj--&gt; j1\nj1--&gt; t0\nj--&gt; p2\nj1--&gt; j2\nj2--&gt; j3\nj1--&gt; j3\nx0--&gt; x\nx1--&gt; x \nt0--&gt; t1\n\n\n\n\n\n\n\nThe data divergences show that not all the nodes are data dependent on tid\nis j in b5 divergent?\ni is divergent, p0 is divergent so threads go though the loop diferent number of times so j varies\nwhat about x in block 8? efected by p2 which depends of j"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#memory-operations",
    "href": "lectures/revealjs_diverg.qmd.html#memory-operations",
    "title": "divergent flow",
    "section": "memory operations",
    "text": "memory operations\nThe C semantics assume that (within a single thread) all loads and stores stay in order. That is is not allowed to re-order a store past a load of the same address.\nin ssa each argument of an instruction is a pointer to the source instruction. These edges force serialization of the code.\nWe want to apply this to loads and stores this will make ordering explicit\nIn Static Single Assignment (SSA) form, memory tokens, representing stores or loads to memory, are typically handled by introducing memory state variables\n\nload: dest = load addrs, memory_token\nstore memory_token = store value, address, memory_token\ncalls to functions that might modify memory also need to read and write memory tokens\n\ntreat a store as though it created a new copy of memory\nwe can use phi functions on memory tokens\nMaintaining Correct Memory Order: By tracking memory states explicitly in SSA form (through these memory tokens and versioning), SSA ensures that memory operations respect the correct order, even if the control flow of the program is complex. This helps compilers optimize code by making memory dependencies explicit.\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n\nOptimize loads/stores\nwalk backwards - load from store\n\nif we can prove the load address is the same as the store address- remove the load\nif we can prove the load address is different move the load up a store\notherwise go on"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#multi-threaded-programs",
    "href": "lectures/revealjs_diverg.qmd.html#multi-threaded-programs",
    "title": "divergent flow",
    "section": "multi-threaded programs",
    "text": "multi-threaded programs\nCompilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#shared-memory-multi-threading",
    "href": "lectures/revealjs_diverg.qmd.html#shared-memory-multi-threading",
    "title": "divergent flow",
    "section": "shared memory multi-threading",
    "text": "shared memory multi-threading\nThe most common parallel system is\n\nA single big memory\nmultiple threads address that memory"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#what-is-sequential-consistency-sq",
    "href": "lectures/revealjs_diverg.qmd.html#what-is-sequential-consistency-sq",
    "title": "divergent flow",
    "section": "what is sequential consistency SQ",
    "text": "what is sequential consistency SQ\nProgram Order is Maintained Within Threads:\nOperations (reads and writes) appear to occur in the order they are issued by each individual thread. If a thread performs a write followed by a read, the read cannot appear to happen before the write in the execution.\nGlobal Order of Operations Across Threads:\nAll threads see the effects of memory operations in the same sequential order. Every thread agrees on the order of reads and writes, though the specific order is not predefined—it just needs to be consistent across all threads. Interleaving of Operations:\nThe execution can be viewed as an interleaving of instructions from all threads. However, the interleaving must follow the program order within each thread.\nno real machine/compiler implements this"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#compiler-effects",
    "href": "lectures/revealjs_diverg.qmd.html#compiler-effects",
    "title": "divergent flow",
    "section": "compiler effects",
    "text": "compiler effects\nCompiler transformations that break multi-thread sequential consistency (SC) often reorder or optimize instructions in ways that do not respect the original program order seen by other threads. These transformations can lead to subtle bugs in multithreaded programs where the expected interleaving of operations is violated."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#loadstore-reordering",
    "href": "lectures/revealjs_diverg.qmd.html#loadstore-reordering",
    "title": "divergent flow",
    "section": "Load/Store Reordering",
    "text": "Load/Store Reordering\nTransformation: Compilers might reorder loads and stores to improve performance. Violation: In a multi-threaded environment, this can lead to a situation where one thread sees stale or unexpected data. Example:\nCopy code\n// Thread 1\nx = 1;     // Store\nr1 = y;    // Load\n\n// Thread 2\ny = 1;     // Store\nr2 = x;    // Load\nUnder sequential consistency, if thread 1’s x = 1 happens before thread 2’s r2 = x, then thread 2 should observe r2 == 1. But reordering could result in thread 2 reading x as 0."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#common-subexpression-elimination-cse",
    "href": "lectures/revealjs_diverg.qmd.html#common-subexpression-elimination-cse",
    "title": "divergent flow",
    "section": "Common Subexpression Elimination (CSE)",
    "text": "Common Subexpression Elimination (CSE)\nTransformation: If a variable or expression is computed multiple times, the compiler may optimize by reusing the result of an earlier computation. Violation: This assumes that no other thread modifies shared variables between these uses. Example:\n// Original code\nr1 = x;\nr2 = x;\n\n// Transformed code (CSE applied)\ntemp = x;\nr1 = temp;\nr2 = temp;\nIf x is modified by another thread between the two reads, the transformed code will incorrectly assume the value of x hasn’t changed."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#dead-code-elimination-dce",
    "href": "lectures/revealjs_diverg.qmd.html#dead-code-elimination-dce",
    "title": "divergent flow",
    "section": "Dead Code Elimination (DCE)",
    "text": "Dead Code Elimination (DCE)\nTransformation: The compiler may remove stores to variables that are not subsequently read in the same thread. Violation: If the variable is shared and accessed by other threads, removing the store could lead to unexpected behavior. Example:\n// Original code\nx = 1;\n\n// Transformed code (DCE applied)\n// x = 1 is removed because x is not used locally If another thread reads x, it expects the store to have happened, but DCE breaks this assumption."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#speculative-execution-out-of-order-execution",
    "href": "lectures/revealjs_diverg.qmd.html#speculative-execution-out-of-order-execution",
    "title": "divergent flow",
    "section": "Speculative Execution (Out-of-Order Execution)",
    "text": "Speculative Execution (Out-of-Order Execution)\nTransformation: Compilers (or hardware) may execute instructions speculatively, assuming certain branches are likely to be taken. Violation: This can cause out-of-order writes or reads visible to other threads, breaking SC. Example:\nif (flag) {\n    r1 = x;\n}\nIf the compiler speculatively reads x before knowing the value of flag, another thread’s write to x might be missed or observed out-of-order."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#loop-invariant-code-motion",
    "href": "lectures/revealjs_diverg.qmd.html#loop-invariant-code-motion",
    "title": "divergent flow",
    "section": "Loop Invariant Code Motion",
    "text": "Loop Invariant Code Motion\nTransformation: The compiler moves computations that are invariant inside a loop to outside the loop. Violation: If these computations involve shared variables modified by other threads within the loop, moving them outside could make the code see stale values. Example:\n// Original code\nwhile (condition) {\n    r = shared_variable;\n}\n\n// Transformed code (Loop Invariant Code Motion)\ntemp = shared_variable;\nwhile (condition) {\n    r = temp;\n}\nIf shared_variable is updated by another thread, the transformed code might keep using the old value.\nRegister Allocation (Caching Shared Variables in Registers)\nTransformation: Compilers can keep a shared variable in a register for efficiency rather than repeatedly loading it from memory. Violation: If another thread modifies that shared variable in memory, the compiler’s register optimization would cause the thread to read stale data. Example:\nwhile (flag == 0) {\n    // busy-wait\n}\nIf flag is cached in a register, updates to flag by another thread in memory won’t be reflected, breaking SC."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#instruction-fusion-combining-loadsstores",
    "href": "lectures/revealjs_diverg.qmd.html#instruction-fusion-combining-loadsstores",
    "title": "divergent flow",
    "section": "Instruction Fusion (Combining Loads/Stores)",
    "text": "Instruction Fusion (Combining Loads/Stores)\nTransformation: The compiler may combine consecutive memory accesses into one, such as merging adjacent stores into a single store or combining two loads. Violation: If other threads expect these loads or stores to happen separately, they might see an inconsistent view of memory. Example:\n// Original code\nx = 1;\ny = 2;\n\n// Transformed code (store fusion)\n// x and y are stored together in a single transaction\nA thread expecting x and y to be updated separately might observe an inconsistent state if this transformation is applied."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#thread-libraries",
    "href": "lectures/revealjs_diverg.qmd.html#thread-libraries",
    "title": "divergent flow",
    "section": "thread libraries",
    "text": "thread libraries\nstart out assuming single threaded, add a threads library like pthreads\nmultiple threads could access shared memory simultaneously, leading to race conditions, inconsistent data, and undefined behavior.\nModern CPUs and compilers perform optimizations like instruction reordering, which can break assumptions about the order of memory operations in multithreaded programs.\nMultithreaded code is harder to test because race conditions and bugs might only manifest under certain timing conditions.\nDebugging multithreaded programs is more difficult due to the unpredictable nature of thread execution and interactions.\nSome optimizations might reorder instructions in a way that is incompatible with multithreading, introducing subtle bugs or performance regressions.\nCaching, prefetching, or other memory optimizations need to account for the fact that multiple threads may be accessing the same memory, which a simple thread library does not handle."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#using-libraries",
    "href": "lectures/revealjs_diverg.qmd.html#using-libraries",
    "title": "divergent flow",
    "section": "using libraries",
    "text": "using libraries\n\nFunctions such as pthread mutex lock() that are guaranteed by the standard to “synchronize memory” include hardware instructions (“memory barriers”) that prevent hardware reordering of memory operations around the call\nTo prevent the compiler from moving memory operations around calls to functions such as pthread mutex lock(), they are essentially treated as calls to opaque functions, about which the compiler has no information.\n\nThe compiler effectively assumes that pthread mutex lock() may read or write any global variable. Thus a memory reference cannot simply be moved across the call. This approach also ensures that transitive calls, e.g. a call to a function f() which then calls pthread mutex lock(), are handled in the same way more or less appropriately, i.e. memory operations are not moved across the call to f() either, whether or not the entire user program is being analyzed at once."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#adding-multi-threading-to-user-explaining-the-intent",
    "href": "lectures/revealjs_diverg.qmd.html#adding-multi-threading-to-user-explaining-the-intent",
    "title": "divergent flow",
    "section": "adding multi-threading to user explaining the intent",
    "text": "adding multi-threading to user explaining the intent\nc++/c added atomics\nAtomic operations are operations that are completed as a single, uninterruptible action. No other thread can observe a partial update or interfere with the operation.\nThese operations ensure that read-modify-write sequences are safe without needing explicit locks."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#an-example-2",
    "href": "lectures/revealjs_diverg.qmd.html#an-example-2",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n// Global spinlock using atomic_flag\nstd::atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid enter_critical_section() {\n    // Busy-wait (spin) until the lock is acquired\n    while (lock.test_and_set(std::memory_order_acquire)) {\n        // Spin and wait for the lock to become available\n    }\n}\n\nvoid leave_critical_section() {\n    // Release the lock\n    lock.clear(std::memory_order_release);\n}\n\n// Shared resource\nint shared_counter = 0;\n\nvoid critical_section_task(int num_increments) {\n    for (int i = 0; i &lt; num_increments; ++i) {\n        enter_critical_section();\n        // Begin critical section\n        ++shared_counter;\n        // End critical section\n        leave_critical_section();\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#load-acquire-needs-special-hardware",
    "href": "lectures/revealjs_diverg.qmd.html#load-acquire-needs-special-hardware",
    "title": "divergent flow",
    "section": "load acquire (needs special hardware )",
    "text": "load acquire (needs special hardware )\nused by default with atomics not used for non-atomics\nall memory reads and writes after the load operation cannot be moved before the load. This ensures that after acquiring the value, any operations that depend on this value (like accessing shared data) will see consistent and up-to-date memory.\na one way fence - nothing can move up"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#write-release-needs-special-hardware",
    "href": "lectures/revealjs_diverg.qmd.html#write-release-needs-special-hardware",
    "title": "divergent flow",
    "section": "write release (needs special hardware )",
    "text": "write release (needs special hardware )\nprevents the compiler or processor from reordering any memory operations (reads or writes) that appear before the release store. This guarantees that all operations that modify shared data before the release are visible to other threads that subsequently perform an acquire operation.\nalso a one way fence - nothing can move down\nload.acquire - \nloads and stores on non-atomics  - compiler picks the order for these operations \nstore.release"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#using-atomics",
    "href": "lectures/revealjs_diverg.qmd.html#using-atomics",
    "title": "divergent flow",
    "section": "using atomics",
    "text": "using atomics\nAll operations appear to occur in a single total order that is consistent across all threads. This means that the results of operations are predictable and consistent as if all operations were executed in some sequential order.\nlimits the hardware and compiler because it prevents reordering"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#data-race-free",
    "href": "lectures/revealjs_diverg.qmd.html#data-race-free",
    "title": "divergent flow",
    "section": "Data Race Free",
    "text": "Data Race Free\nData Race Free (DRF) means that a program is free from data races, which occur when:\n\nTwo or more threads access the same variable concurrently.\nAt least one of the accesses is a write.\n\nThere is no synchronization mechanism (like mutexes or atomic operations) to control the access. In a data race-free program, every shared variable is accessed in a way that ensures predictable results. C++ provides various synchronization primitives (such as mutexes and atomic types) to help developers write DRF code.\nAll shared variables must be accessed using synchronization to prevent concurrent threads from modifying shared data simultaneously without coordination."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#an-example-3",
    "href": "lectures/revealjs_diverg.qmd.html#an-example-3",
    "title": "divergent flow",
    "section": "an example",
    "text": "an example\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nint shared_counter1 = 0;                  // First non-atomic shared variable\nint shared_counter2 = 0;                  // Second non-atomic shared variable\nstd::atomic&lt;bool&gt; lock_flag(false);       // Atomic flag to control access\n\nvoid safe_increment() {\n    for (int i = 0; i &lt; 1000; ++i) {\n        // Spin until the lock is acquired\n        while (lock_flag.exchange(true)) {\n            // Busy-wait (spin) until the lock is free\n        }\n\n        // Critical section: update the non-atomic shared variables\n        ++shared_counter1;\n        ++shared_counter2;\n\n        // Release the lock\n        lock_flag.store(false);\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#language-rules",
    "href": "lectures/revealjs_diverg.qmd.html#language-rules",
    "title": "divergent flow",
    "section": "language rules",
    "text": "language rules\nC and C++\ndo not define what happens in the presence of data races. If a program has data races (e.g., multiple threads concurrently reading and writing to the same variable without synchronization), the behavior is considered undefined. This means that the program may produce unexpected results, crash, or behave inconsistently across different executions or platforms.\nJava\ntries to define what happens but definition is very complex and maybe inconsistent\nRust\nCompile-Time Guarantees: Rust’s ownership and borrowing system prevents data races at compile time. If a program is not DRF, the Rust compiler will typically refuse to compile it, enforcing memory safety guarantees."
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#can-the-compiler-add-a-race-to-a-drf-program",
    "href": "lectures/revealjs_diverg.qmd.html#can-the-compiler-add-a-race-to-a-drf-program",
    "title": "divergent flow",
    "section": "can the compiler add a race to a drf program",
    "text": "can the compiler add a race to a drf program\nnew rule, compiler cannot add a write to a shared variable\nif (x ==1) y++\n\nto \ny++\nif (x!=1) y--"
  },
  {
    "objectID": "lectures/revealjs_diverg.qmd.html#how-does-this-effect-hardware",
    "href": "lectures/revealjs_diverg.qmd.html#how-does-this-effect-hardware",
    "title": "divergent flow",
    "section": "how does this effect hardware?",
    "text": "how does this effect hardware?\nstruct { char a; char b; char c; char d;} s;\ns.a = 1\ns.c = 3\n\ncan a compiler do \nchar temp[4] = s // load 32 bits \ntemp[0] = 1\ntemp[2] = 3\ns = temp\nnot allowed - reads/writes b and d, so compiler incorrectly added writes\noptions are either have byte addressable hardware, or pad so that each char gets 32 bits\nVendors forced to add 8 byte loads/stores"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html",
    "href": "lectures/03b_local_value_numbering.html",
    "title": "local value numbering",
    "section": "",
    "text": "slides from Phil Gibbons at CMU for more details and context on LVN\nValue numbering is a very powerful technique that removes redundancies, An instruction x + y is redundant inside a block if it has already been computed in the block, and no intervening operation redefines x or y. If the compiler finds a redundant expression, it can save that value at the first computation and replace any subsequent evaluations with references to the saved value.\n\nThe idea is simple - The algorithm executes the block, Each time it sees a new variable it gives it a value (represented as a number)\nEach time it sees an instruction it forms a hash of the op code and the value numbers of its operands and gives it a new value number.\nTwo instructions are redundant if they have same op code and operands, which means the same value number\n\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "href": "lectures/03b_local_value_numbering.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "title": "local value numbering",
    "section": "local value numbering covers lot of optimizations that look different",
    "text": "local value numbering covers lot of optimizations that look different\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#variables-vis-values",
    "href": "lectures/03b_local_value_numbering.html#variables-vis-values",
    "title": "local value numbering",
    "section": "variables vis values",
    "text": "variables vis values\nWe want to stop thinking about variables and think about values. Two instructions are redundant if they compute the same value.\n\nfor example in a JIT compiler we want computation to be fast so we can get rid of all the variables\nb: int const 1;\nc: int cont 2;\na:  int b c;  \nbecomes:\n[  int const 1\n   int const 2 \n   int 0 1\n]\nless storage, args are just pointers, instructions are smaller. faster because any use points to the corresponding def without any searching.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#value-numbering-continued",
    "href": "lectures/03b_local_value_numbering.html#value-numbering-continued",
    "title": "local value numbering",
    "section": "value numbering continued",
    "text": "value numbering continued",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#use-of-turnt",
    "href": "lectures/03b_local_value_numbering.html#use-of-turnt",
    "title": "local value numbering",
    "section": "use of turnt ",
    "text": "use of turnt \nturnt\nthere is a directory   bril/examples/test/tdce   which has some test programs \nand a file turnt.toml  that contains  one line \ncommand = “bril2json &lt; {filename} | python3 ../../tdce.py {args} | bril2txt”\nto execute \n(.venv) (base) norm@norm-ubuntu:~/bril/examples/test/tdce$ turnt *.bril 1..8 ok 1 - combo.bril ok 2 - diamond.bril ok 3 - double.bril ok 4 - double-pass.bril ok 5 - reassign.bril ok 6 - reassign-dkp.bril ok 7 - simple.bril ok 8 - skipped.bril",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#redundancy-elimination",
    "href": "lectures/03b_local_value_numbering.html#redundancy-elimination",
    "title": "local value numbering",
    "section": "redundancy elimination",
    "text": "redundancy elimination\nan expression x+y is redundant if and only if\n\nalong every path from the entry it has been evaluated and\nits subexpressions x and y have not been redefined\n\nif the compiler can prove an expression is redundant it can\n\npreserve the earlier evaluation\nreplace the redundant expression with a use of the preserved value",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#key-idea",
    "href": "lectures/03b_local_value_numbering.html#key-idea",
    "title": "local value numbering",
    "section": "key idea",
    "text": "key idea\nassign a number (value number) to each expression\n\ntwo expressions have the same value number if they always have the same value\nuse hashing to make this efficient",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#pseudo-code",
    "href": "lectures/03b_local_value_numbering.html#pseudo-code",
    "title": "local value numbering",
    "section": "pseudo code",
    "text": "pseudo code\nwalk each block, assign a distinct value number to each value the block computes.\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#pseudo-code-vn-version-1",
    "href": "lectures/03b_local_value_numbering.html#pseudo-code-vn-version-1",
    "title": "local value numbering",
    "section": "pseudo code vn version 1",
    "text": "pseudo code vn version 1\nwe have two tables - hash_table: expression to vn, variable holding the value variable to vn\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest \nAn example\na add b, c \nb sub a, d \nc add b, c\nd sub a, d  // d id b\nitem   vn       hash \nb      0/4\nc      1/5\n                add12  2    a \na      2 \nd      3\n\n                sub23 4     b\n                add41 5     c\n                \nPseudo code (similar to an interpreter)\n\nhash table constants and expressions of value numbers to value numbers and to a variable holding the value\nreverse map from variables to value numbers\n\n\n\n\n  main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mult sum1 sum2;\n    print prod\n\n  }\n\n\n\n\nkey\nvalue\ncanonical name\n\n\n\n\nconst 4\n1\na\n\n\nconst 2\n2\nb\n\n\nadd 1 2\n3\nsum1\n\n\nmul 3 3\n4\nprod\n\n\n\n\n\n\nname\nvalue\n\n\n\n\na\n1\n\n\nb\n2\n\n\nsum1\n3\n\n\nsum2\n3\n\n\nprod\n4\n\n\n\n\n\nextensions:\n\na: int id b\n\na gets the value number of b. No copy required\nCommutative operations Commutative operations that differ only in the order of their operands, such as a × b and b × a, should receive the same value numbers. As lvn constructs a hash key for the right-hand side of the current operation, it can sort the operands using some convenient scheme, such as ordering them by value number. This simple action will ensure that commutative variants receive the same value number.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#extension",
    "href": "lectures/03b_local_value_numbering.html#extension",
    "title": "local value numbering",
    "section": "extension",
    "text": "extension\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\nConstant folding If all the operands of an operation have known constant values, lvn can perform the operation and fold the answer directly into the code. lvn can store information about constants in the hash table, including their value. Before hash-key formation, it can test the operands and, if possible, evaluate them. If lvn discovers a constant expression, it can replace the operation with an immediate load of the result. Subsequent copy folding will clean up the code.\nAlgebraic identities: lvn can apply algebraic identities to simplify the code. For example, x + 0 and x should receive the same value number. Unfortunately, lvn needs special-case code for each identity. A series of tests, one per identity, can easily become long enough to produce an unacceptable slowdown in the algorithm. To ameliorate this problem, lvn should organize the tests into operator-specific decision trees.\na +0, a-0, a1 a0, a-a",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#vn-version-2",
    "href": "lectures/03b_local_value_numbering.html#vn-version-2",
    "title": "local value numbering",
    "section": "vn version 2",
    "text": "vn version 2\nadd a bit indicating that a variable is a constant\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  if all v's are constants, fold the operation \n  check for all the identities \n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#problem",
    "href": "lectures/03b_local_value_numbering.html#problem",
    "title": "local value numbering",
    "section": "problem:",
    "text": "problem:\na = x +y \nb = x + y\na = 17\nc = x +y \nkeep track of all variables that contain the value and select one\none option is to save the value, if x will be overwritten add a temp\nt = a+b\nx = t \nx = \n  = t",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#another-option-is-renaming",
    "href": "lectures/03b_local_value_numbering.html#another-option-is-renaming",
    "title": "local value numbering",
    "section": "another option is renaming",
    "text": "another option is renaming\n\n\na = x + y\nb = x + y\na = 17\nc = x +Y\n\na0 = x0 + y0\nb0 = x0+ y0\na1 = 17\nc0 = x0 +y0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#indirect-assignments",
    "href": "lectures/03b_local_value_numbering.html#indirect-assignments",
    "title": "local value numbering",
    "section": "indirect assignments",
    "text": "indirect assignments\nassignments via a pointer, or to an array element\na = b[i]\n...       no change to i \nc = b[i]\n\n\na = b[i]\ni=\nc = b[i]\n\n\na = b[i]\nb[k] =\n   =b[i]\n   =b[k]\nindexed stores\nwhen we see an assignment a[i] = exp\nwe have 3 value numbers a, i, exp\ngive the array a new value number give the array[i] operation the value number of the exp",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#local-value-numbering.",
    "href": "lectures/03b_local_value_numbering.html#local-value-numbering.",
    "title": "local value numbering",
    "section": "Local value numbering.",
    "text": "Local value numbering.\nYou can see one implementation in lvn.py in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#testing-your-optimizations",
    "href": "lectures/03b_local_value_numbering.html#testing-your-optimizations",
    "title": "local value numbering",
    "section": "Testing Your Optimizations",
    "text": "Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time.\n\n\nAs with every task in this class, part of the work is checking that you have done what you set out to do — in this case, that your optimizations do those two things.\nThink carefully about how to make a convincing case for each of those criteria.\n\nOne tempting methodology might be to hand write a few small test-case Bril programs (or, worse, borrow the woefully inadequate ones sitting around in the Bril git repository), run them through your optimizations, and look at them to check whether they look right. This does not amount to convincing evidence (maybe you can think of a few specific reasons why).\n\nWhile there are many ways to be convincing, a pretty good way might be to run your optimization on *every single available Bril benchmark, systematically check that it still produces the right output for at least one input, and collect aggregate statistics about some metric you’re interested in. This is a nice way to check for unexpected behavior in programs that you didn’t carefully write yourself to test the cases you’re thinking of.\n\nIf this is the route you choose, you can do it however you like, There is a simple tool that you can consider using, called Brench. Brench is not very fancy; it does three things:\n\nIt makes it easy to run a long list of inputs through several different commands. (For example, you can run a long list of Bril benchmarks through an “interpret” command and an “optimize-and-then-interpret” command.)\nIt checks that all the commands agree on their output. (So, in our use case, it checks that optimizing the benchmark doesn’t change its output when interpreted.)\nIt can collect a statistic from each command for comparison. (Like the number of dynamic instructions the interpreter executed, which is a pretty good metric for standard optimizations.)\n\nThose three things are probably what you want to do to make a convincing case for an optimization’s correctness and effectiveness, whether or not you use Brench. It’s there if you want it, but feel free to go your own way!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#homework-2",
    "href": "lectures/03b_local_value_numbering.html#homework-2",
    "title": "local value numbering",
    "section": "homework 2",
    "text": "homework 2\npart 1: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned.\npart2: Implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\nremember that the result is a blog post",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#crossing-blocks",
    "href": "lectures/03b_local_value_numbering.html#crossing-blocks",
    "title": "local value numbering",
    "section": "crossing blocks",
    "text": "crossing blocks\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#extended-basic-blocks",
    "href": "lectures/03b_local_value_numbering.html#extended-basic-blocks",
    "title": "local value numbering",
    "section": "extended basic blocks",
    "text": "extended basic blocks\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n\n\nhow do we extend the hash tables over the boundary\nwe need to do value numbering over each path\nworklist = {entry block}\nstack = {}\nwhile worklist is not empty \n   remove a block b from the worklist \n   evn(b)\n\nevn(b, stack)\n   t = new table for b  \n   link t above stack  \n   lvn(b,t) \n   for each s successor of b,\n     if s has one pred then evn(s, t)\n     else add s to worklist \n   dealocate t",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#safety",
    "href": "lectures/03b_local_value_numbering.html#safety",
    "title": "local value numbering",
    "section": "safety",
    "text": "safety\nif the result of evaluating E1 cannot be distinguished from evaluating E the compiler is free to replace E with E1\nSome compilers assume it is ok if E1 produces less errors than E\nsome compilers assume that safety is only required for “standard conforming” code and undefined behavior for other code.\nWhy is value numbering safe?\n\nif an expression is in the hash table, it must have occurred at least one in the block\nAlgorithm modified the code but does not invalidate the table",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#when-is-value-numbering-profitable",
    "href": "lectures/03b_local_value_numbering.html#when-is-value-numbering-profitable",
    "title": "local value numbering",
    "section": "when is value numbering profitable",
    "text": "when is value numbering profitable\nif reuse is cheaper then re-compute 1. does not cause a spill 1. if does not need a copy (does the copy take as long as the compute)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "local value numbering"
    ]
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "title": "local value numbering",
    "section": "local value numbering covers lot of optimizations that look different",
    "text": "local value numbering covers lot of optimizations that look different\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#variables-vis-values",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#variables-vis-values",
    "title": "local value numbering",
    "section": "variables vis values",
    "text": "variables vis values\nWe want to stop thinking about variables and think about values. Two instructions are redundant if they compute the same value."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#value-numbering-continued",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#value-numbering-continued",
    "title": "local value numbering",
    "section": "value numbering continued",
    "text": "value numbering continued"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#use-of-turnt",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#use-of-turnt",
    "title": "local value numbering",
    "section": "use of turnt ",
    "text": "use of turnt \nturnt\nthere is a directory   bril/examples/test/tdce   which has some test programs \nand a file turnt.toml  that contains  one line \ncommand = “bril2json &lt; {filename} | python3 ../../tdce.py {args} | bril2txt”\nto execute \n(.venv) (base) norm@norm-ubuntu:~/bril/examples/test/tdce$ turnt *.bril 1..8 ok 1 - combo.bril ok 2 - diamond.bril ok 3 - double.bril ok 4 - double-pass.bril ok 5 - reassign.bril ok 6 - reassign-dkp.bril ok 7 - simple.bril ok 8 - skipped.bril"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#redundancy-elimination",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#redundancy-elimination",
    "title": "local value numbering",
    "section": "redundancy elimination",
    "text": "redundancy elimination\nan expression x+y is redundant if and only if\n\nalong every path from the entry it has been evaluated and\nits subexpressions x and y have not been redefined\n\nif the compiler can prove an expression is redundant it can\n\npreserve the earlier evaluation\nreplace the redundant expression with a use of the preserved value"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#key-idea",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#key-idea",
    "title": "local value numbering",
    "section": "key idea",
    "text": "key idea\nassign a number (value number) to each expression\n\ntwo expressions have the same value number if they always have the same value\nuse hashing to make this efficient"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code",
    "title": "local value numbering",
    "section": "pseudo code",
    "text": "pseudo code\nwalk each block, assign a distinct value number to each value the block computes.\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code-vn-version-1",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code-vn-version-1",
    "title": "local value numbering",
    "section": "pseudo code vn version 1",
    "text": "pseudo code vn version 1\nwe have two tables - hash_table: expression to vn, variable holding the value variable to vn\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest \nAn example\na add b, c \nb sub a, d \nc add b, c\nd sub a, d  // d id b\nitem   vn       hash \nb      0/4\nc      1/5\n                add12  2    a \na      2 \nd      3\n\n                sub23 4     b\n                add41 5     c\n                \nPseudo code (similar to an interpreter)\n\nhash table constants and expressions of value numbers to value numbers and to a variable holding the value\nreverse map from variables to value numbers"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#extension",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#extension",
    "title": "local value numbering",
    "section": "extension",
    "text": "extension\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\nConstant folding If all the operands of an operation have known constant values, lvn can perform the operation and fold the answer directly into the code. lvn can store information about constants in the hash table, including their value. Before hash-key formation, it can test the operands and, if possible, evaluate them. If lvn discovers a constant expression, it can replace the operation with an immediate load of the result. Subsequent copy folding will clean up the code.\nAlgebraic identities: lvn can apply algebraic identities to simplify the code. For example, x + 0 and x should receive the same value number. Unfortunately, lvn needs special-case code for each identity. A series of tests, one per identity, can easily become long enough to produce an unacceptable slowdown in the algorithm. To ameliorate this problem, lvn should organize the tests into operator-specific decision trees.\na +0, a-0, a1 a0, a-a"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#vn-version-2",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#vn-version-2",
    "title": "local value numbering",
    "section": "vn version 2",
    "text": "vn version 2\nadd a bit indicating that a variable is a constant\nfor each instr in the block\n  v= [ value_number(a) for a in the args of the instr]\n  if all v's are constants, fold the operation \n  check for all the identities \n  build temp inst hash = instr.op + v\n  if hash in hash_table:\n     get from table vn, cann_variable \n     replace instr with instr.dest = cann_variable\n     instr.dest = vn\n  else: \n    generate a new value number, add new entry to hash_table, new vn, instr.dest"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#problem",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#problem",
    "title": "local value numbering",
    "section": "problem:",
    "text": "problem:\na = x +y \nb = x + y\na = 17\nc = x +y \nkeep track of all variables that contain the value and select one\none option is to save the value, if x will be overwritten add a temp\nt = a+b\nx = t \nx = \n  = t"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#another-option-is-renaming",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#another-option-is-renaming",
    "title": "local value numbering",
    "section": "another option is renaming",
    "text": "another option is renaming\n\n\na = x + y\nb = x + y\na = 17\nc = x +Y\n\na0 = x0 + y0\nb0 = x0+ y0\na1 = 17\nc0 = x0 +y0"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#indirect-assignments",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#indirect-assignments",
    "title": "local value numbering",
    "section": "indirect assignments",
    "text": "indirect assignments\nassignments via a pointer, or to an array element\na = b[i]\n...       no change to i \nc = b[i]\n\n\na = b[i]\ni=\nc = b[i]\n\n\na = b[i]\nb[k] =\n   =b[i]\n   =b[k]\nindexed stores\nwhen we see an assignment a[i] = exp\nwe have 3 value numbers a, i, exp\ngive the array a new value number give the array[i] operation the value number of the exp"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering.",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering.",
    "title": "local value numbering",
    "section": "Local value numbering.",
    "text": "Local value numbering.\nYou can see one implementation in lvn.py in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#testing-your-optimizations",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#testing-your-optimizations",
    "title": "local value numbering",
    "section": "Testing Your Optimizations",
    "text": "Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#homework-2",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#homework-2",
    "title": "local value numbering",
    "section": "homework 2",
    "text": "homework 2\npart 1: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned.\npart2: Implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\nremember that the result is a blog post"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#crossing-blocks",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#crossing-blocks",
    "title": "local value numbering",
    "section": "crossing blocks",
    "text": "crossing blocks\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA[\"m = a + b&lt;br&gt; n = a + b\"]\nB[\"p = c + d&lt;br&gt;r = c + d\"]\n\nC[\"q = a + b&lt;br&gt; r = c + d\"]\nD[\"e = b + 18&lt;br&gt; s = a + b &lt;br&gt; u = e + f\"]\nE[\"e = a + 17&lt;br&gt; t = c + d &lt;br&gt; u = e + f\"]\nF[\"v = a + b &lt;br&gt; w = c + d &lt;br&gt; x = e + f\"]\nG[\"y = a + b &lt;br&gt; z = c + d\"]\n\nstyle A fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle B fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle C fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle D fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle E fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle F fill:#ffffff,stroke:#000000,stroke-width:1px\nstyle G fill:#ffffff,stroke:#000000,stroke-width:1px\nA--&gt; B\nA--&gt; C\nC --&gt; D\nC --&gt; E\nD--&gt; F\nE --&gt; F\nF--&gt; G\nB--&gt; G"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#extended-basic-blocks",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#extended-basic-blocks",
    "title": "local value numbering",
    "section": "extended basic blocks",
    "text": "extended basic blocks\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;b\nA--&gt;c\nc--&gt;d\nc--&gt;e\n\n\n\n\n\n\nhow do we extend the hash tables over the boundary\nwe need to do value numbering over each path\nworklist = {entry block}\nstack = {}\nwhile worklist is not empty \n   remove a block b from the worklist \n   evn(b)\n\nevn(b, stack)\n   t = new table for b  \n   link t above stack  \n   lvn(b,t) \n   for each s successor of b,\n     if s has one pred then evn(s, t)\n     else add s to worklist \n   dealocate t"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#safety",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#safety",
    "title": "local value numbering",
    "section": "safety",
    "text": "safety\nif the result of evaluating E1 cannot be distinguished from evaluating E the compiler is free to replace E with E1\nSome compilers assume it is ok if E1 produces less errors than E\nsome compilers assume that safety is only required for “standard conforming” code and undefined behavior for other code.\nWhy is value numbering safe?\n\nif an expression is in the hash table, it must have occurred at least one in the block\nAlgorithm modified the code but does not invalidate the table"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#when-is-value-numbering-profitable",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#when-is-value-numbering-profitable",
    "title": "local value numbering",
    "section": "when is value numbering profitable",
    "text": "when is value numbering profitable\nif reuse is cheaper then re-compute 1. does not cause a spill 1. if does not need a copy (does the copy take as long as the compute)"
  },
  {
    "objectID": "lectures/09_poly.html",
    "href": "lectures/09_poly.html",
    "title": "Polyhedral Analysis",
    "section": "",
    "text": "There are two kinds of polyhedral problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid?\npolyhedral scheduling - find a transform that maximizes/minimizes some property",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#intro-to-polyhedral-techniques",
    "href": "lectures/09_poly.html#intro-to-polyhedral-techniques",
    "title": "Polyhedral Analysis",
    "section": "",
    "text": "There are two kinds of polyhedral problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid?\npolyhedral scheduling - find a transform that maximizes/minimizes some property",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#base-idea",
    "href": "lectures/09_poly.html#base-idea",
    "title": "Polyhedral Analysis",
    "section": "Base Idea",
    "text": "Base Idea\nThe base ideas -\n\nA statement in a loop might execute a lot of times. Each time it executes there is one instance of the statement. Polyhedral methods keep track of instances.\nWe can think of a program as having two parts: An algorithm, like \\[ a[i] = 3, i \\in \\{1,2,3\\}\\] and a schedule like: execute the instances in reverse order.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#poly-steps",
    "href": "lectures/09_poly.html#poly-steps",
    "title": "Polyhedral Analysis",
    "section": "poly steps",
    "text": "poly steps\n\nchange the program into a polyhedral notations (a set like notation)\nApply some kind of transformations to add a schedule\nGenerate code that lets the result execute on a computer",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#polyhedral-methods",
    "href": "lectures/09_poly.html#polyhedral-methods",
    "title": "Polyhedral Analysis",
    "section": "Polyhedral Methods",
    "text": "Polyhedral Methods\n\nUse equations as an intermediate representation (IR)\nAllow reasoning about each instance\nEnsure finiteness (even if the number of instances is not)\nReduce phase ordering issues by applying multiple transformations simultaneously\nIdeal for tiling, parallelism, and cache management",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#negatives-of-polyhedral-analysis",
    "href": "lectures/09_poly.html#negatives-of-polyhedral-analysis",
    "title": "Polyhedral Analysis",
    "section": "Negatives of Polyhedral Analysis",
    "text": "Negatives of Polyhedral Analysis\n\nOnly applies to loop nests, but we can wrap a for (i= 0; i &lt;1; i++) around a group of statements\nRequires affine array indexes, bounds, and statements\nNot applicable to loops hidden by recursion",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#an-example-changing-the-order-of-iterations",
    "href": "lectures/09_poly.html#an-example-changing-the-order-of-iterations",
    "title": "Polyhedral Analysis",
    "section": "an example changing the order of iterations",
    "text": "an example changing the order of iterations\ncan we reverse this loop: (change the schedule so that i takes values 4,3,2,1). Does it get the same answer\nfor i = [1,2,3,4]\ns:   a[i] = a[i-1]\n\nDo these loops do the same thing\nfor i = [1,2,3,4]               for i = [4,3,2,1]\ns:   a[i] = a[i-1]               s:   a[i] = a[i-1] \n. . .\nprogram trace (instances)\n   s(1)                               s(4)\n   s(2)                               s(3)\n   s(3)                               s(2)\n   s(4)                               s(1)\nand the data that is accessed\n          reads  writes                       reads writes\n   s(1)    a[0]   a[1]               s(4)     a[3]   a[4]\n   s(2)    a[1]   a[2]               s(3)     a[2]   a[3]\n   s(3)    a[2]   a[3]               s(2)     a[1]   a[2]\n   s(4)    a[3]   a[4]               s(1)     a[0]   a[1]\n\nA transformation is valid (legal) if it preserves the dependence relations: producers have to execute before consumers\nit is not valid if there is a pair s[i] and s[j], s[i] produces a value s[j] reads that value, s[j] is first in the new schedule",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#a-graphical-view",
    "href": "lectures/09_poly.html#a-graphical-view",
    "title": "Polyhedral Analysis",
    "section": "a graphical view",
    "text": "a graphical view\n(not legal if there is a pair where the arrows go in opposite directions)\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  i_values.append(i)\n  j_values.append(1)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 3))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n    plt.annotate('',\n      xy=(i,1), xytext=(i-1,1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\nplt.annotate(\"time left schedule\", xy=(n, 1.02), xytext=(1,1.02), arrowprops=dict(facecolor='green', shrink=0.05))\n\nplt.annotate(\"time right schedule\", xy=(1, 1.04), xytext=(n-1,1.04), arrowprops=dict(facecolor='red', shrink=0.05))\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nThere are 3 pairs that make this invalid",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#a-second-example",
    "href": "lectures/09_poly.html#a-second-example",
    "title": "Polyhedral Analysis",
    "section": "a second example",
    "text": "a second example\nfor i in [1,2,3,4]\n  for j in [1,2,3,4]\n    a[i,j] = a[i,j-1]+ a[i-1,j]\ncan we execute this is parallel\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  for j in range(1, n + 1):\n    i_values.append(i)\n    j_values.append(j)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 4))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.ylabel('j loop index')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n  for j in range(2, n +1):\n    plt.annotate('',\n       xy=(i,j), xytext=(i-1,j),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\n    plt.annotate('',\n       xy=(i,j), xytext=(i,j-1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\n# plt.annotate(\"time left schedule\", xy=(n, 1.02), xytext=(1,1.02), arrowprops=dict(facecolor='green', shrink=0.05))\n\n# plt.annotate(\"time right schedule\", xy=(1, 1.04), xytext=(n-1,1.04), arrowprops=dict(facecolor='red', shrink=0.05))\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\noriginal code: time goes down each column\n. . .\nrun diagonal order and could tile the loops",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#definitions",
    "href": "lectures/09_poly.html#definitions",
    "title": "Polyhedral Analysis",
    "section": "definitions",
    "text": "definitions\nan affine function\n\\[\n\\text { affine function } f(\\vec{v})=M_{f} \\vec{v}+\\vec{f}_{0}\n\\]\nwhere \\(\\vec{v}=\\left(\\begin{array}{c}v_{1} \\\\ \\vdots \\\\ v_{d}\\end{array}\\right)\\) and \\(M_{f} \\in \\mathbb{R}^{k \\times d}\\) is a matrix with \\(k\\) rows and \\(d\\) columns, \\(f_{0} \\in \\mathbb{R}^{k}\\) is a \\(k\\)-dimensional vector. In all cases, we deal with affine functions with \\(M_{f} \\in \\mathbb{Z}^{k \\times d}\\) and \\(f_{0} \\in \\mathbb{Z}^{k}\\). The domain is also a set of integers: \\(\\vec{v} \\in \\mathbb{Z}^{d}\\).\nPerfect loop nest, Imperfect loop nest. A set of nested loops is called a perfect loop nest iff all statements appearing in the nest appear inside the body of the innermost loop. Otherwise, the loop nest is called an imperfect loop nest.\nAffine loop nest. Affine loop nests are sequences of imperfectly nested loops with loop bounds and array accesses that are affine functions of outer loop variables and program parameters.\nProgram parameters or structure parameters are symbolic constants that appear in loop bounds or access functions. They very often represent the problem size. \\(N\\) and beta are the program parameters.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA portion of the GEMVER kernel\nAffine spaces. A set of vectors is an affine space iff it is closed under affine combination, i.e., if \\(\\vec{x}, \\vec{y}\\) are in the space, all points lying on the line joining \\(\\vec{x}\\) and \\(\\vec{y}\\) belong to the space.\nAffine hyperplane An affine hyperplane is an \\(n-1\\) dimensional affine sub-space of an \\(n\\) dimensional space.\nIn our context, the set of all vectors \\(v \\in \\mathbb{Z}^{n}\\) such that \\(\\mathbf{h} . \\vec{v}=k\\), for \\(k \\in \\mathbb{Z}\\), forms an affine hyperplane. The set of parallel hyperplane instances correspond to different values of \\(k\\) with the row vector \\(\\mathbf{h}\\) normal to the hyperplane. Two vectors \\(\\overrightarrow{v_{1}}\\) and \\(\\overrightarrow{v_{2}}\\) lie in the same hyperplane if \\(\\mathbf{h} \\cdot \\overrightarrow{v_{1}}=\\mathbf{h} \\cdot \\overrightarrow{v_{2}}\\).\n\nAn affine hyperplane\nPolyhedron, Polytope. A polyhedron is an intersection of a finite number of half-spaces. A polytope is a bounded polyhedron.\nEach of the half-spaces provides a face to the polyhedron. Hence, the set of affine inequalities, each representing a face, can be used to compactly represent the polyhedron. If there are \\(m\\) inequalities, then the polyhedron is\n\\[\n\\left\\{\\vec{x} \\in \\mathbb{R}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\]\nwhere \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{R}^{m}\\).\n\nIn our context, we are always interested in the integer points inside a polyhedron since loop iterators typically have integer data types and traverse an integer space. The matrix \\(A\\) and \\(\\vec{b}\\) for problems we will deal with also comprise only integers. So, we always have:\n\\[\n\\begin{equation*}\n\\left\\{\\vec{x} \\in \\mathbb{Z}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\end{equation*}\n\\]\nwhere \\(A \\in \\mathbb{Z}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{Z}^{m}\\).\nIteration vector. The iteration vector of a statement is the vector consisting of values of the indices of all loops surrounding the statement.\nLet \\(S\\) be a statement of a program. The iteration vector is denoted by \\(\\vec{i}_{S}\\). An iteration vector represents a dynamic instance of a statement appearing in a loop nest that may be nested perfectly or imperfectly.\nDomain, Index set. The set of all iteration vectors for a given statement is the domain or the index set of the statement.\nA program comprises a sequence of statements, each statement surrounded by loops in a given order. We denote the domain of a statement \\(S\\) by \\(\\mathcal{D}^{S}\\). When the loop bounds and data accesses are affine functions of outer loop indices and other program parameters, and all conditionals are statically predictable, the domain of every statement is a polyhedron as defined in (. Again, conditionals that are affine functions of outer loop indices and program parameters are statically predictable.\nEach dynamic instance of a statement \\(S\\), in a program, is identified by its iteration vector \\(\\vec{i}_{S}\\) which contains values for the indices of the loops surrounding \\(S\\), from outermost to innermost. A statement \\(S\\) is associated with a polytope \\(\\mathcal{D}^{S}\\) of dimensionality \\(m_{S}\\). Each point in the polytope is an \\(m_{S}\\)-dimensional iteration vector.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\n\\[\n\\begin{aligned}\ni & \\geq 0 \\\\\nj & \\geq 0 \\\\\n-i+N-1 & \\geq 0 \\\\\n-j+N-1 & \\geq 0\n\\end{aligned} \\quad \\quad \\mathcal{D}^{S_{1}}:\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n-1 & 0 & 1 & -1 \\\\\n0 & -1 & 1 & -1\n\\end{array}\\right)\\left(\\begin{array}{c}\ni \\\\\nj \\\\\nN \\\\\n1\n\\end{array}\\right) \\geq 0\n\\]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#iteration-space-as-a-set-in-matrix-multiplication",
    "href": "lectures/09_poly.html#iteration-space-as-a-set-in-matrix-multiplication",
    "title": "Polyhedral Analysis",
    "section": "Iteration space as a set in matrix multiplication",
    "text": "Iteration space as a set in matrix multiplication\nfor (i =0 ;i &lt; M ; i++)\n for (j =0l j &lt; N; j++)\n   for (k= 0; k &lt; K, k++)\n     c[i,j] = c[i,j] + a[i,k]* B[k,j]\nIteration domain as a set:\n\\[ [M, N, K] -&gt; \\{ S[i, j, k] : 0 &lt;= i &lt; M \\and  0 &lt;= j &lt; N \\and 0 &lt;= k &lt; K; \\}\\]\n\\[ writes -&gt;  \\{ S[i, j, k] -&gt; C[i, j] \\}\\]\n\\[ reads := \\{S[i, j, k] -&gt; B[k, j], S[i, j, k] -&gt; A[i, k], S[i, j, k] -&gt; C[i, j] \\}\\]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#dependence",
    "href": "lectures/09_poly.html#dependence",
    "title": "Polyhedral Analysis",
    "section": "Dependence",
    "text": "Dependence\nTwo instances are dependent if they access the same location and one of them is a write.\ntrue dependence producer is a write, consumer is a read. Also called read after write to RAW, also called a flow dependence\nanti dependence write after read. WAR\n*output dependence both writes WAW",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#dependence-in-example",
    "href": "lectures/09_poly.html#dependence-in-example",
    "title": "Polyhedral Analysis",
    "section": "dependence in example",
    "text": "dependence in example\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor (k=0 ;k&lt;N; k++ )\n    for (l=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA[i,j] same location as A[l,k]\ni between 0 and N\nj between 0 and N\nk between 0 and N\nl between 0 and N\ni - l == 0\nj - k == 0\nDomain for statement S1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#loop-interchange-example",
    "href": "lectures/09_poly.html#loop-interchange-example",
    "title": "Polyhedral Analysis",
    "section": "loop interchange example",
    "text": "loop interchange example\nfor (i = 0, i &lt; 9; i++)\n  for (j = i; j &lt; 7 && j &lt; i+4; j++)\n     a[i,j] = \n\nThere is no dependence so we can reorder the loops but what are the new bounds\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Initialize the coordinates for the domain\ndomain_i = []\ndomain_j = []\n\n# Loop through the values as described in the pseudocode\nfor i in range(9):  # i = 0 to 8\n    for j in range(i, min(7, i + 4)):  # j starts from i, and is less than both 7 and i+4\n        domain_i.append(i)\n        domain_j.append(j)\n\n# Plot the domain points\nplt.scatter(domain_i, domain_j, color='blue', label='Domain Points')\n\n# Define the range for i and j for the hyperplanes\ni_values = np.arange(0, 9)\nj_values_i = i_values  # j = i\nj_values_7 = np.full_like(i_values, 7)  # j = 7\nj_values_i_plus_4 = i_values + 4  # j = i + 4\n\n# Plot the hyperplanes\nplt.plot(i_values, j_values_i, label='j = i', color='red')\nplt.plot(i_values, j_values_7, label='j = 7', color='green')\nplt.plot(i_values, j_values_i_plus_4, label='j = i + 4', color='orange')\n\n# Set plot properties\nplt.title('Domain of (i, j) with Hyperplanes')\nplt.xlabel('i')\nplt.ylabel('j')\nplt.grid(True)\nplt.xticks(range(9))\nplt.yticks(range(7))\nplt.gca().invert_yaxis()  # Invert y-axis to match matrix notation\nplt.legend()\nplt.show()",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#reodered-loops",
    "href": "lectures/09_poly.html#reodered-loops",
    "title": "Polyhedral Analysis",
    "section": "reodered loops",
    "text": "reodered loops\nfor (j = 0; j &lt;=6; j++)\n for (i = max(j-3,0); i &lt;= j; i++)\n   a[i,j] = 0\noutloop bounds cannot depend on i\ninner loop bounds can depend on j\nWe can read off j as a proection, for each value of j, i is a convex polygon (if the bounds were not convex this would be false)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#fourier-motzkin-method",
    "href": "lectures/09_poly.html#fourier-motzkin-method",
    "title": "Polyhedral Analysis",
    "section": "fourier-motzkin method",
    "text": "fourier-motzkin method\ninput:\n\nA convex polygon S on \\(x_1, x_2, ... x_n\\)\nA variable \\(X_m\\) to be eliminated\n\noutput: \\(S^1\\) a projection of S with out dimiension \\(m\\)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#alogorithm",
    "href": "lectures/09_poly.html#alogorithm",
    "title": "Polyhedral Analysis",
    "section": "alogorithm",
    "text": "alogorithm\n\\[ S = \\{ vec(x) | B vec(x) + vec(f) \\ge 0 \\}\\] \\[C\\] = constraints in S that involve \\(S_m\\) (coef is not zero)\n-=======================",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#how-much-of-a-limitation-is-affine-only",
    "href": "lectures/09_poly.html#how-much-of-a-limitation-is-affine-only",
    "title": "Polyhedral Analysis",
    "section": "How much of a limitation is affine only",
    "text": "How much of a limitation is affine only\n99% of hpc loops are affine C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam. Putting polyhedral loop transformations to work. In LCPC, 2003.\nover 95% of loops in deep learning are affine Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, RaminderBajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA). IEEE, 1–12.\n\nOver the course of this, I’ll use 3 pieces of math\n\nILP integer linear programming find a set of integers that satisfies a set of inequalities and maximize something\nfourier-motzkin method\nThe affine form of Farkas Lemma (maybe)\n\n\nHere is a graph showing the data flow \n\n::: {#ddd6968a .cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  i_values.append(i)\n  j_values.append(1)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 3))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n    plt.annotate('',\n      xy=(i,1), xytext=(i-1,1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n:::\n\nWe need to preserve order where an instance produces a value, some other instance consumes the value\nmore formally:\nThe order that statements execute is called a *schedule\neach s(i) is an instance of a single statement\ndata dependence is a mapping: \\(s(i) =&gt; s(i+1)\\)\na valid schedule does not violate data dependence\n\nobservation 1- same set of instances\nif we track each instance, we have more info but could run out of space\nwe need a more compressed ir format, polyhedral methods use sets and math",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#some-notation",
    "href": "lectures/09_poly.html#some-notation",
    "title": "Polyhedral Analysis",
    "section": "some notation",
    "text": "some notation\n\\[\n\\begin{align*}\ndomain &= \\left\\{ i \\in \\mathbf{Z}^1  \\mid 1 &lt;= i &lt;= 4\\right\\} \\\\\ninstances\\  of   \\ s &= \\left\\{ s(i) \\mid 1 &lt;=i &lt;= 4\\right\\}\n\\end{align*}\n\\]\nThe domain is the set of integer values of the loop index. left and right have the same domain\nWe call the order that instances execute the schedule The schedule is the ordering of instances. this is a map of instance to time.\n\nobservation 2- different schedules. instance -&gt; time\n\\[\n\\begin{align*}\nleft \\ schedule &= \\left\\{ s[i] \\rightarrow i \\right\\} \\\\\nright \\ schedule &= \\left\\{ s[i] \\rightarrow 5-i \\right\\}\n\\end{align*}\n\\]\ndata dependences (just the same as before but with bounds) \\[\ndependence = \\left \\{(s(i), s(i+1)) \\mid 1&lt;= i &lt;= 3 \\right \\}\n\\]\nNew schedule is legal, if it respects all data dependences, or set of violated data dependences is empty",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#what-is-a-violated-data-dependence",
    "href": "lectures/09_poly.html#what-is-a-violated-data-dependence",
    "title": "Polyhedral Analysis",
    "section": "what is a violated data dependence",
    "text": "what is a violated data dependence\na pair (p, c) where p produces data that c consumes and c comes before p in the new schedule\ndata dependence \\[\n\\left \\{(s(i), s(i+1)) \\mid 1 \\le i \\le 3 \\right \\}\n\\]\nset of violated data dependences \\[\n\\left \\{(s(i), s(j)) \\mid \\ newSch(j) \\ge newSch(i) \\right \\}\n\\]\n\nDependence is \\(s[i] -&gt; s[i+1]\\)\nset of violated data dependences \\[\n\\left \\{(s(i), s(j)) \\mid \\ newSch(j) \\ge newSch(i) \\right \\}\n\\]\n\\[\n\\left \\{ (s(i), s(i+1)) \\mid 1 \\le i \\le 3 \\land 5-i+1 \\ge 5-i  \\right \\}\n\\]\nconstrants are : \\[\n\\begin{align*}\n1&lt;= i &lt;= 3 \\\\\n5-i +1  &gt;= 5-i\n\\end{align*}\n\\]\n\nUse an ilp solver to find a solution one solution is i = 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#ilp-solver-info",
    "href": "lectures/09_poly.html#ilp-solver-info",
    "title": "Polyhedral Analysis",
    "section": "ilp solver info",
    "text": "ilp solver info\ncan an ilp solver always work?\nHilbert’s tenth problem is the tenth on the list of mathematical problems that the German mathematician David Hilbert posed in 1900. It is the challenge to provide a general algorithm that, for any given Diophantine equation (a polynomial equation with integer coefficients and a finite number of unknowns), can decide whether the equation has a solution with all unknowns taking integer values.\nsadly answer is no (found in 1970)\nBut we can do this if we limit the kinds of inequalities",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#affine-limitations",
    "href": "lectures/09_poly.html#affine-limitations",
    "title": "Polyhedral Analysis",
    "section": "Affine limitations",
    "text": "Affine limitations\naffine functions, no multiplying unknowns, no quantifiers (for all, or exists) and is ok, or ok (if we change to two problems) just add/subtract/ multiply by a constant, can add minimize/maximize a function. division and remainder by a constant, max/min/ absolute\nMost scientific programs and ai programs fit, because array subscripts are often affine\nBut lots of other kinds of programs do not.\nThere is a lot of formal math background here, decidability in logic.\n\nilp is np-complete so it is slow, but often tractable for problems with up to several hundred variables.\nSome compiler writers feel that means can only do this for toy programs? What do you think?\n\n2 multiple dimensions\nfor (i=1; i&lt;=n; i++)\nfor (j=1; j&lt;=n; j++)\nS: A[i][j] = (A[i-1][j] + A[i][j-1]) * 0.5;\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # You can change n to any desired value\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n    for j in range(1, n + 1):\n        i_values.append(i)\n        j_values.append(j)\n\n# Plotting the iteration space\nplt.figure(figsize=(5, 5))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i (outer loop index)')\nplt.ylabel('j (inner loop index)')\nplt.title('Data Dependence for A[i][j] = (A[i-1][j] + A[i][j-1]) * 0.5')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\n# Annotate the iteration order and add arrows for data dependencies\nfor i in range(1, n + 1):\n    for j in range(1, n + 1):\n        if i &gt; 1:  # Dependency on A[i-1][j]\n            plt.annotate('',\n                         xy=(i, j), xytext=(i-1, j),\n                         arrowprops=dict(facecolor='black', shrink=0.05))\n        if j &gt; 1:  # Dependency on A[i][j-1]\n            plt.annotate('',\n                         xy=(i, j), xytext=(i, j-1),\n                         arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Force the x-axis to use integer labels and remove y-axis labels\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])  # Turn off y-axis labels\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nThe schedule actually goes up each column (the j values) going over the columns left to right (the i column)\nnotice that this does not execute in parallel, but it could if pick a different schedule\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.ticker as ticker\n\nplt.figure(figsize=(8, 8))\ntile_size = 1\n\n# # Define parameters\n# n = 12 # Size of the matrix\n# tile_size = 2  # Size of the tile\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Calculate iteration points for tiles\nfor t in range(8):\n  for p in range(8):\n    i = p + t\n    j = p\n    if i &gt;= 8:\n      continue\n    if (i &gt;= 0 and  j &gt;= 0) :\n      i_values.append(i)\n      j_values.append(j)\n      if i &lt;= j:\n        continue\n      if ((t % 2) == 0) and (p % 2 ) == 0:\n          plt.gca().add_patch(   \\\n          patches.Rectangle((t,p), tile_size, tile_size,  \\\n                              linewidth=1, edgecolor='red', facecolor='none'))\n#         for i in range(ti, min(ti + tile_size, n + 1)):\n#             for j in range(tj, min(tj + tile_size, n + 1)):\n#                 if (i &gt; 1 and  j &gt; 1) :\n#                   i_values.append(i)\n#                   j_values.append(j)\n\n# # Plotting the iteration space\n\nplt.scatter(i_values, j_values, c='blue', marker='o', label='Iterations')\nplt.xlabel('i')\nplt.ylabel('j')\nplt.title('Iteration Space with Tiling and Dependencies')\n# plt.grid(True)\n#lt.gca().invert_yaxis()\n\n# # Draw a box around each tile\n# for ti in range(1, n + 1, tile_size):\n#     for tj in range(1, n + 1, tile_size):\n#         plt.gca().add_patch(\n#             patches.Rectangle((ti, tj), tile_size, tile_size,\n#                                linewidth=1, edgecolor='red', facecolor='none')\n#         )\n\n# # Draw dependencies\n# for i in range(1, n + 1):\n#     for j in range(1, n + 1):\n#         if i &gt; 1:  # Dependency on A[i-1][j]\n#             plt.annotate('',\n#                          xy=(i, j), xytext=(i-1, j),\n#                          arrowprops=dict(facecolor='black', shrink=0.05))\n#         if j &gt; 1:  # Dependency on A[i][j-1]\n#             plt.annotate('',\n#                          xy=(i, j), xytext=(i, j-1),\n#                          arrowprops=dict(facecolor='red', shrink=0.05))\n\n# # Force the x-axis and y-axis to use integer labels\n# plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n# plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n\n# # Show the plot\n# plt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nt p i j 0 0 0 0 1 0 1 0 1 1 0 1 t-p p 2 1 1 1 2 2 0 2\n\n## formalizing the schedule, Lexicographic ordering\n\nschedule s(i,j) -&gt; (i,j)\nstatements -&gt; vector (should be a time)\n\nHow do we interpret a vector as a time, e.g. hours, min, seconds. \n\nUsually written  as $\\gg $ Generalization of alphabetical order\n\n$$\n(i,j) \\gg (m,n) \\iff i &gt;  m \\lor (i=m \\land j&gt; n)\n$$\n\nCompare left to right if terms are equal, go to next term, or different so compare the terms\n\nNotice the or we will need to call the ilp solver more than once \n\nChecking for loop interchange \n\nfor i in [1,2,3,4] for j in [1,2,3] for j in [1,2,3] for i in [1,2,3,4] s: a(i,j) = a(i-1,j+1) a(i,j) = a(i-1,j+1)\ns(i, j) -&gt; (i,j) s(i,j)=(j,i)\n\ndata flow \n\n\n        read write\ns(1,1)  a(0,2)  a(1,1)\ns(1,2)  a(0,3)  a(1,2)\ns(1,3)  a(0,4)  a(1,3)\ns(1,4)  a(0,5)  a(1,4)\ns(2,1)  a(1,2)  a(2,1)   s(1,2)-&gt; s(2,1)\ns(2,2)  a(1,3)  a(2,2)   s(1,3)-&gt; s(2.2)\n...\n\ns(i,j) writes a value that is consumed in s(i+1, j-1)\n\n\n$$\ns(i,j) \\rightarrow s(i+1, j-1)\n$$\nconstants:\n\nDoes there exist a statement s(i,j) and a statement $s(i',j')$\nwhere in the new schedule $s(i',j')$ executes first and  data flows backward in time \n$$\n\\begin{align*}\n(i', j') \\gg (j,i)   &\\text{ $i',j'$ is first} \\\\\ni' = 1+ i            &\\text{ data\\  from \\ i+1 to $i'$}\\\\\nj' = -1 +j           &\\text{ data\\  from \\ j-1 to $j'$}\\\\\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 3  \\\\\n1 \\le i' le 4 \\\\\n1 \\le j' \\leftrightarrows 3\n\\end{align*}\n$$\n\nbecause of the lexicographic order ( or) we have two ilp problems\none where $i'$ is greater then j, and one where $i'$ = j, and the other where $j'$ &gt; j\n\ni ran it through:\n\nhttps://online-optimizer.appspot.com\n\nwhich gave me a solution \n\ns(4,2) reads  s(3,3) but s(4,2) executes first \n\n## ir\n\nHow do we represent these sets in the  ir?\n\n~~~\nfor i in [0,1,2,3,4,5]\n  for j from  i to 7\n     a(i,j) = 0\n\n~~~\n\nchange the equations around so that they are ... $\\ge 0$\n\n$$\n\\begin{align*}\ni \\ge 0  &\\rightarrow  i \\ge 0 \\\\\ni \\le 5 &\\rightarrow -i + 5 \\ge 0 \\\\\nj \\ge i &\\rightarrow -i + j \\ge 0 \\\\\nj \\le 7 &\\rightarrow =j+7 \\ge 0\n\\end{align*}\n$$\n\n\nWe can split off the constraints:\n$$\nconstraints  = \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\} \n$$\n\nWhere:\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0 \\\\\n 5  \\\\\n 0   \\\\\n7\n\\end{bmatrix}\n\\vec{x} =\n\\begin{bmatrix}\ni \\\\\nj \n\\end{bmatrix}\n\\end{equation*}\n$$\n\nThis also works if the loop bounds are symbolic\nfor i in [L.. U] for j from i to 7 a(i,j) = 0\n\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n L \\\\\n U\\\\\n0\\\\\n7\n\\end{bmatrix}\n\\end{equation*}\n$$\n\n\n## suppose we have complex loop bounds?\n\nfor i=0; i &lt; 7, i++ for j =i, j &lt; min(7, i+4), j++ a(i,j) = 0\n![alt text](plot1-7.png)\n\nshaded area is the polygon\nwhat are the loop bounds if we interchange the loops?\n\nWhat are the upper and lower bounds if we interchange the loops?\n\ninequalities\n$$\n\\begin{align*}\ni \\ge 0   & \\rightarrow  i  \\ge 0 \\\\\ni \\le 6   & \\rightarrow  -i+6 \\ge 0 \\\\\nj \\ge i   & \\rightarrow j-i \\ge 0 \\\\\nj \\le 6    & \\rightarrow  6  -j  \\ge 0 \\\\\nj \\le i+3 & \\rightarrow -j+i+3 \\ge 0 \n\\end{align*}\n$$\n\nfor j (must be constants) for j (constants and j )\n\nwe can get the j bounds by projecting onto the j axis,  next we want to remove j from the inequalities \n\n\nir constants\n\n\n\n\n\n$$\n\\begin{align*}\n\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n 1 & 0 \\\\\n-1 & 0 \\\\\n-1 & 1 \\\\\n0 & -1 \\\\\n 1 & -1 \n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0\\\\\n 6 \\\\\n0\\\\\n6\\\\\n3\n\\end{bmatrix}\n\n\n\\end{align*}\n$$\n\n\nwritten for i\n$$\n\\begin{align}\n0  \\le  & i & \\\\\n        & i &\\le 6 \\\\\n        & i & \\le j \\\\\n        & &  6  -j  \\ge 0 \\\\\nj -3 \\le & i &\n\\end{align}\n$$\n\n$ i \\le max(0, j-3) \\land  i \\le min(6,j) $\n\nwritten for j\n$$\n\\begin{align}\n       & & i \\ge 0 \\\\\n       & & i \\le 6  \\\\\ni \\le  &j & \\\\\n    &  j  & \\le 6 \\\\\n&j& \\le i+3 \n\\end{align}\n$$\n\n\nbounds for j depend on i -  We need to remove i \n\n\nmath thing #2 fourier-motzkin method\n\nhttps://people.math.carleton.ca/~kcheung/math/notes/MATH5801/02/2_1_fourier_motzkin.html\n\nGiven a set of inequalities remove one variable, (for higher dim d, need to do this multiple times)\n\nin general \nSuppose we want to remove $x_m$ we find a pair $L \\le c_1 * x_m $  and  upper bound $x_2 * x_m \\ge U$ and both c's are &gt;= 0\n\nremove x_m and add $c_2* L \\ge c_1 *U $\n\nWe start with each pair of constants\n$$\nc_1 * i &lt; U \\land\nc_2 *i &gt; L\n$$\n\nthere are 4 pairs (1,2), (1,3) , (2,5),  (3,5) \nall the c's are 1 \nfrom the ir column 1 (i column) ignore zeros, pair up plus and minus values \n\n\nWe need to eliminate i (to get the bounds for the outer loop in j)\n\nwe have 4 inequalities where i is not multiplied by zero $ j \\le 6$ \n\nwe consider each pair\n\n$$\n\\begin{align*}\n(1,2) \\rightarrow  0 &\\le 6 \\ done \\\\\n(1,3) \\rightarrow  0 &\\le j\\\\\n(2,5) \\rightarrow j-3  &\\le 6\\\\\n(3,5) \\rightarrow j-3  &\\le j \\ done \n\\end{align*}\n$$\n\nbounds for j are 0 to 6\n\n\nfor j =0 ; j &lt;= 6 , j++ for i = max(j-3,6), i &lt; j; i++&gt;\na[i,j] = 0\n\n\n## suppose we want to run the an example  in parallel\n~~~\nfor i in [1,2,3,4]\n  for j in [1,2,3, 4]\n    s: a(i,j) = a(i-1, j+1) \n~~~\n\n\n\nreorder to run in parallel get new bounds, we want to run diagonally $k= i-j$, we know the transformation that we want \nWe replace $i = k+j $\n\nfor k = ??\n   for j = ?? \n     s: a(j-k,j) = a(j-k-1, j+1)\n\n\n$$\n\\begin{align*}\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 4 \\\\\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n1 \\le & k+j &\\le 4 \\\\\n1 \\le & j &\\le 4 \\\\\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n1-k \\le j \\le 4-k \\\\\n1 \\le j &lt;= 4\n\\end{align*}\n$$\n\nnow for mf\n$$\n\\begin{align*}\n1-k \\le  4-k \\\\\n1-k  \\le 4\\\\\n1 \\le 4-k \\\\\n1 \\le 4\n\\end{align*}\n$$\n\ngiving k bounds -3 to 3 \nj bound are max(1,1,k) yo min(4, 4-k)\n\n\n#  4 Scheduling \n\nUp till now we assumed we know the transformation but now we consider \ncan we find a schedule that is good in some way\n\nan example \nfor i in [0,1,2,3,4,5] P: a(i) = input(i) +1 for j in [0,12,3,4,5] c: b(j) = a(j) +2\n\nThis is not quite a loop nest - unless we picture an outer loop running one time.\n\n\n\nThe new schedule has to be affine (restriction)\nschedule is a map from instances to time \n$$\nP(i) = sp*i + dp \\\\ \nC(j) = sc*j + dc \n$$\n\noptimization pick sp, dp, sc, dc that optimizes the locality.\n\n\nconstraint is for all i,j, p(i) writes data that c(j) reads, and i,j are in bounds\n\n\nFor any legal schedule:\n\n\n$$\n\\forall i,j \\mid 0 \\le i \\le 5 \\land 0 \\le j \\le 5 \\land i = j \n\\land sp * i + dp  \\le sc * j + dc\n$$\n\n\ndifferent values of sp, dp, sc, and dc give different schedules.  \nSince all these schedules are affine - None on them is the \"best\".\nSome non-affine schedule might be better.\n\nThis is not suitable for ilp, because of the  $ sp * i $\n\nSuppose we want to select one of the schedules that minimizes a cost function:\n$$\nw(i,j)  = sc * j + dc - sp * i + dp \n$$\n\nw is the time the value is needed\n\nHow we select a legal schedule that has the smallest w?\n\n\n\nmath fact 3 \n\nThe affine form of Farkas Lemma\nAn affine function non-negative everywhere inside a polygon \niff its non-negative at all the vertices \n\n$$\ngiven: \n\\forall \\vec{x} \\mid \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\} \nS^T \\vec{x}+\\vec{d} \\ge 0\n$$\nif and only if \n$$\n\\exists p_0, \\vec{p} \\ge 0 \\mid \\forall \\vec{x}\\mid S^T \\vec{x} + \\vec{d} = (\\vec{p})^t(B\\vec{x}+\\vec{d}) + p_0\n$$\n\nWhat does this mean and how does it help?\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Arc\n\nfig, ax = plt.subplots(figsize=(5,5))\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n    i_values.append(i)\n    j_values.append(1)\n\n    arc = Arc(xy=(i+.5, 1), width=1, height=1, angle=0, theta1=0, theta2=180, color='red', lw=2)\n    ax.add_patch(arc)\n\nax.set_ylim(0,2)\n\n# Plotting the iteration space\n\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i (outer loop index)')\nplt.ylabel('j (inner loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\n# # Annotate the iteration order and add arrows for data flow\n# for i in range(1, n + 1):\n#     for j in range(2, m + 1):  # Start from j=2 since j-1 needs to exist\n#         plt.annotate('',\n#                      xy=(i, j), xytext=(i, j-1),\n#                      arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Analysis"
    ]
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#intro-to-polyhedral-techniques",
    "href": "lectures/revealjs_09_poly.qmd.html#intro-to-polyhedral-techniques",
    "title": "Polyhedral Analysis",
    "section": "intro to polyhedral techniques",
    "text": "intro to polyhedral techniques\nThere are two kinds of polyhedral problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid?\npolyhedral scheduling - find a transform that maximizes/minimizes some property"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#base-idea",
    "href": "lectures/revealjs_09_poly.qmd.html#base-idea",
    "title": "Polyhedral Analysis",
    "section": "Base Idea",
    "text": "Base Idea\nThe base ideas -\n\nA statement in a loop might execute a lot of times. Each time it executes there is one instance of the statement. Polyhedral methods keep track of instances.\nWe can think of a program as having two parts: An algorithm, like \\[ a[i] = 3, i \\in \\{1,2,3\\}\\] and a schedule like: execute the instances in reverse order."
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#poly-steps",
    "href": "lectures/revealjs_09_poly.qmd.html#poly-steps",
    "title": "Polyhedral Analysis",
    "section": "poly steps",
    "text": "poly steps\n\nchange the program into a polyhedral notations (a set like notation)\nApply some kind of transformations to add a schedule\nGenerate code that lets the result execute on a computer"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#polyhedral-methods",
    "href": "lectures/revealjs_09_poly.qmd.html#polyhedral-methods",
    "title": "Polyhedral Analysis",
    "section": "Polyhedral Methods",
    "text": "Polyhedral Methods\n\nUse equations as an intermediate representation (IR)\nAllow reasoning about each instance\nEnsure finiteness (even if the number of instances is not)\nReduce phase ordering issues by applying multiple transformations simultaneously\nIdeal for tiling, parallelism, and cache management"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#negatives-of-polyhedral-analysis",
    "href": "lectures/revealjs_09_poly.qmd.html#negatives-of-polyhedral-analysis",
    "title": "Polyhedral Analysis",
    "section": "Negatives of Polyhedral Analysis",
    "text": "Negatives of Polyhedral Analysis\n\nOnly applies to loop nests, but we can wrap a for (i= 0; i &lt;1; i++) around a group of statements\nRequires affine array indexes, bounds, and statements\nNot applicable to loops hidden by recursion"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#an-example-changing-the-order-of-iterations",
    "href": "lectures/revealjs_09_poly.qmd.html#an-example-changing-the-order-of-iterations",
    "title": "Polyhedral Analysis",
    "section": "an example changing the order of iterations",
    "text": "an example changing the order of iterations\ncan we reverse this loop: (change the schedule so that i takes values 4,3,2,1). Does it get the same answer\nfor i = [1,2,3,4]\ns:   a[i] = a[i-1]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#a-graphical-view",
    "href": "lectures/revealjs_09_poly.qmd.html#a-graphical-view",
    "title": "Polyhedral Analysis",
    "section": "a graphical view",
    "text": "a graphical view\n(not legal if there is a pair where the arrows go in opposite directions)\n\n\nCode\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Define the range of the loops\nn = 4  # Range for 'i' (1 to 4)\n\n# Create lists to hold the iteration points\ni_values = []\nj_values = []\n\n# Nested loops to generate iteration space\nfor i in range(1, n + 1):\n  i_values.append(i)\n  j_values.append(1)\n\n# Plotting the iteration space\nplt.figure(figsize=(6, 3))\nplt.scatter(i_values, j_values, c='blue', marker='o')\nplt.xlabel('i  loop index)')\nplt.title('Iteration Space with Data Flow')\nplt.grid(True)\nplt.gca().invert_yaxis()\n\nplt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n#plt.gca().yaxis.set_ticklabels([])\n\n# Annotate the iteration order and add arrows for data flow\nfor i in range(2, n + 1):\n    plt.annotate('',\n      xy=(i,1), xytext=(i-1,1),\n        arrowprops=dict(facecolor='black', shrink=0.05))\n\nplt.annotate(\"time left schedule\", xy=(n, 1.02), xytext=(1,1.02), arrowprops=dict(facecolor='green', shrink=0.05))\n\nplt.annotate(\"time right schedule\", xy=(1, 1.04), xytext=(n-1,1.04), arrowprops=dict(facecolor='red', shrink=0.05))\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nThere are 3 pairs that make this invalid"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#a-second-example",
    "href": "lectures/revealjs_09_poly.qmd.html#a-second-example",
    "title": "Polyhedral Analysis",
    "section": "a second example",
    "text": "a second example\nfor i in [1,2,3,4]\n  for j in [1,2,3,4]\n    a[i,j] = a[i,j-1]+ a[i-1,j]\ncan we execute this is parallel"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#definitions",
    "href": "lectures/revealjs_09_poly.qmd.html#definitions",
    "title": "Polyhedral Analysis",
    "section": "definitions",
    "text": "definitions\nan affine function\n\\[\n\\text { affine function } f(\\vec{v})=M_{f} \\vec{v}+\\vec{f}_{0}\n\\]\nwhere \\(\\vec{v}=\\left(\\begin{array}{c}v_{1} \\\\ \\vdots \\\\ v_{d}\\end{array}\\right)\\) and \\(M_{f} \\in \\mathbb{R}^{k \\times d}\\) is a matrix with \\(k\\) rows and \\(d\\) columns, \\(f_{0} \\in \\mathbb{R}^{k}\\) is a \\(k\\)-dimensional vector. In all cases, we deal with affine functions with \\(M_{f} \\in \\mathbb{Z}^{k \\times d}\\) and \\(f_{0} \\in \\mathbb{Z}^{k}\\). The domain is also a set of integers: \\(\\vec{v} \\in \\mathbb{Z}^{d}\\).\nPerfect loop nest, Imperfect loop nest. A set of nested loops is called a perfect loop nest iff all statements appearing in the nest appear inside the body of the innermost loop. Otherwise, the loop nest is called an imperfect loop nest.\nAffine loop nest. Affine loop nests are sequences of imperfectly nested loops with loop bounds and array accesses that are affine functions of outer loop variables and program parameters.\nProgram parameters or structure parameters are symbolic constants that appear in loop bounds or access functions. They very often represent the problem size. \\(N\\) and beta are the program parameters.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA portion of the GEMVER kernel\nAffine spaces. A set of vectors is an affine space iff it is closed under affine combination, i.e., if \\(\\vec{x}, \\vec{y}\\) are in the space, all points lying on the line joining \\(\\vec{x}\\) and \\(\\vec{y}\\) belong to the space.\nAffine hyperplane An affine hyperplane is an \\(n-1\\) dimensional affine sub-space of an \\(n\\) dimensional space.\nIn our context, the set of all vectors \\(v \\in \\mathbb{Z}^{n}\\) such that \\(\\mathbf{h} . \\vec{v}=k\\), for \\(k \\in \\mathbb{Z}\\), forms an affine hyperplane. The set of parallel hyperplane instances correspond to different values of \\(k\\) with the row vector \\(\\mathbf{h}\\) normal to the hyperplane. Two vectors \\(\\overrightarrow{v_{1}}\\) and \\(\\overrightarrow{v_{2}}\\) lie in the same hyperplane if \\(\\mathbf{h} \\cdot \\overrightarrow{v_{1}}=\\mathbf{h} \\cdot \\overrightarrow{v_{2}}\\).\n\nAn affine hyperplane\nPolyhedron, Polytope. A polyhedron is an intersection of a finite number of half-spaces. A polytope is a bounded polyhedron.\nEach of the half-spaces provides a face to the polyhedron. Hence, the set of affine inequalities, each representing a face, can be used to compactly represent the polyhedron. If there are \\(m\\) inequalities, then the polyhedron is\n\\[\n\\left\\{\\vec{x} \\in \\mathbb{R}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\]\nwhere \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{R}^{m}\\).\n\nIn our context, we are always interested in the integer points inside a polyhedron since loop iterators typically have integer data types and traverse an integer space. The matrix \\(A\\) and \\(\\vec{b}\\) for problems we will deal with also comprise only integers. So, we always have:\n\\[\n\\begin{equation*}\n\\left\\{\\vec{x} \\in \\mathbb{Z}^{n} \\mid A \\vec{x}+\\vec{b} \\geq \\overrightarrow{0}\\right\\}\n\\end{equation*}\n\\]\nwhere \\(A \\in \\mathbb{Z}^{m \\times n}\\) and \\(\\vec{b} \\in \\mathbb{Z}^{m}\\).\nIteration vector. The iteration vector of a statement is the vector consisting of values of the indices of all loops surrounding the statement.\nLet \\(S\\) be a statement of a program. The iteration vector is denoted by \\(\\vec{i}_{S}\\). An iteration vector represents a dynamic instance of a statement appearing in a loop nest that may be nested perfectly or imperfectly.\nDomain, Index set. The set of all iteration vectors for a given statement is the domain or the index set of the statement.\nA program comprises a sequence of statements, each statement surrounded by loops in a given order. We denote the domain of a statement \\(S\\) by \\(\\mathcal{D}^{S}\\). When the loop bounds and data accesses are affine functions of outer loop indices and other program parameters, and all conditionals are statically predictable, the domain of every statement is a polyhedron as defined in (. Again, conditionals that are affine functions of outer loop indices and program parameters are statically predictable.\nEach dynamic instance of a statement \\(S\\), in a program, is identified by its iteration vector \\(\\vec{i}_{S}\\) which contains values for the indices of the loops surrounding \\(S\\), from outermost to innermost. A statement \\(S\\) is associated with a polytope \\(\\mathcal{D}^{S}\\) of dimensionality \\(m_{S}\\). Each point in the polytope is an \\(m_{S}\\)-dimensional iteration vector.\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor $(k=0 ;k&lt;N; k++ )\n    for (l}=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\n\\[\n\\begin{aligned}\ni & \\geq 0 \\\\\nj & \\geq 0 \\\\\n-i+N-1 & \\geq 0 \\\\\n-j+N-1 & \\geq 0\n\\end{aligned} \\quad \\quad \\mathcal{D}^{S_{1}}:\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n-1 & 0 & 1 & -1 \\\\\n0 & -1 & 1 & -1\n\\end{array}\\right)\\left(\\begin{array}{c}\ni \\\\\nj \\\\\nN \\\\\n1\n\\end{array}\\right) \\geq 0\n\\]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#iteration-space-as-a-set-in-matrix-multiplication",
    "href": "lectures/revealjs_09_poly.qmd.html#iteration-space-as-a-set-in-matrix-multiplication",
    "title": "Polyhedral Analysis",
    "section": "Iteration space as a set in matrix multiplication",
    "text": "Iteration space as a set in matrix multiplication\nfor (i =0 ;i &lt; M ; i++)\n for (j =0l j &lt; N; j++)\n   for (k= 0; k &lt; K, k++)\n     c[i,j] = c[i,j] + a[i,k]* B[k,j]\nIteration domain as a set:\n\\[ [M, N, K] -&gt; \\{ S[i, j, k] : 0 &lt;= i &lt; M \\and  0 &lt;= j &lt; N \\and 0 &lt;= k &lt; K; \\}\\]\n\\[ writes -&gt;  \\{ S[i, j, k] -&gt; C[i, j] \\}\\]\n\\[ reads := \\{S[i, j, k] -&gt; B[k, j], S[i, j, k] -&gt; A[i, k], S[i, j, k] -&gt; C[i, j] \\}\\]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#dependence",
    "href": "lectures/revealjs_09_poly.qmd.html#dependence",
    "title": "Polyhedral Analysis",
    "section": "Dependence",
    "text": "Dependence\nTwo instances are dependent if they access the same location and one of them is a write.\ntrue dependence producer is a write, consumer is a read. Also called read after write to RAW, also called a flow dependence\nanti dependence write after read. WAR\n*output dependence both writes WAW"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#dependence-in-example",
    "href": "lectures/revealjs_09_poly.qmd.html#dependence-in-example",
    "title": "Polyhedral Analysis",
    "section": "dependence in example",
    "text": "dependence in example\nfor (i=0 ; i&lt;N ; i++)\n    for (j=0 ; j&lt;N ; j++) \n        S1: A[i,j]=A[i,j]+  u1[i] * v1[j]+u2[i] * v2[j] ;\n\nfor (k=0 ;k&lt;N; k++ )\n    for (l=0 ; l&lt;N ; l++)\n        S2: x[k]=x[k]+beta*A[l,k] *y[l] ;\nA[i,j] same location as A[l,k]\ni between 0 and N\nj between 0 and N\nk between 0 and N\nl between 0 and N\ni - l == 0\nj - k == 0\nDomain for statement S1"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#loop-interchange-example",
    "href": "lectures/revealjs_09_poly.qmd.html#loop-interchange-example",
    "title": "Polyhedral Analysis",
    "section": "loop interchange example",
    "text": "loop interchange example\nfor (i = 0, i &lt; 9; i++)\n  for (j = i; j &lt; 7 && j &lt; i+4; j++)\n     a[i,j] = \n\nThere is no dependence so we can reorder the loops but what are the new bounds\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Initialize the coordinates for the domain\ndomain_i = []\ndomain_j = []\n\n# Loop through the values as described in the pseudocode\nfor i in range(9):  # i = 0 to 8\n    for j in range(i, min(7, i + 4)):  # j starts from i, and is less than both 7 and i+4\n        domain_i.append(i)\n        domain_j.append(j)\n\n# Plot the domain points\nplt.scatter(domain_i, domain_j, color='blue', label='Domain Points')\n\n# Define the range for i and j for the hyperplanes\ni_values = np.arange(0, 9)\nj_values_i = i_values  # j = i\nj_values_7 = np.full_like(i_values, 7)  # j = 7\nj_values_i_plus_4 = i_values + 4  # j = i + 4\n\n# Plot the hyperplanes\nplt.plot(i_values, j_values_i, label='j = i', color='red')\nplt.plot(i_values, j_values_7, label='j = 7', color='green')\nplt.plot(i_values, j_values_i_plus_4, label='j = i + 4', color='orange')\n\n# Set plot properties\nplt.title('Domain of (i, j) with Hyperplanes')\nplt.xlabel('i')\nplt.ylabel('j')\nplt.grid(True)\nplt.xticks(range(9))\nplt.yticks(range(7))\nplt.gca().invert_yaxis()  # Invert y-axis to match matrix notation\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#reodered-loops",
    "href": "lectures/revealjs_09_poly.qmd.html#reodered-loops",
    "title": "Polyhedral Analysis",
    "section": "reodered loops",
    "text": "reodered loops\nfor (j = 0; j &lt;=6; j++)\n for (i = max(j-3,0); i &lt;= j; i++)\n   a[i,j] = 0\noutloop bounds cannot depend on i\ninner loop bounds can depend on j\nWe can read off j as a proection, for each value of j, i is a convex polygon (if the bounds were not convex this would be false)"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#fourier-motzkin-method",
    "href": "lectures/revealjs_09_poly.qmd.html#fourier-motzkin-method",
    "title": "Polyhedral Analysis",
    "section": "fourier-motzkin method",
    "text": "fourier-motzkin method\ninput:\n\nA convex polygon S on \\(x_1, x_2, ... x_n\\)\nA variable \\(X_m\\) to be eliminated\n\noutput: \\(S^1\\) a projection of S with out dimiension \\(m\\)"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#alogorithm",
    "href": "lectures/revealjs_09_poly.qmd.html#alogorithm",
    "title": "Polyhedral Analysis",
    "section": "alogorithm",
    "text": "alogorithm\n\\[ S = \\{ vec(x) | B vec(x) + vec(f) \\ge 0 \\}\\] \\[C\\] = constraints in S that involve \\(S_m\\) (coef is not zero)\n-======================="
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#how-much-of-a-limitation-is-affine-only",
    "href": "lectures/revealjs_09_poly.qmd.html#how-much-of-a-limitation-is-affine-only",
    "title": "Polyhedral Analysis",
    "section": "How much of a limitation is affine only",
    "text": "How much of a limitation is affine only\n99% of hpc loops are affine C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam. Putting polyhedral loop transformations to work. In LCPC, 2003.\nover 95% of loops in deep learning are affine Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, RaminderBajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA). IEEE, 1–12."
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#some-notation",
    "href": "lectures/revealjs_09_poly.qmd.html#some-notation",
    "title": "Polyhedral Analysis",
    "section": "some notation",
    "text": "some notation\n\\[\n\\begin{align*}\ndomain &= \\left\\{ i \\in \\mathbf{Z}^1  \\mid 1 &lt;= i &lt;= 4\\right\\} \\\\\ninstances\\  of   \\ s &= \\left\\{ s(i) \\mid 1 &lt;=i &lt;= 4\\right\\}\n\\end{align*}\n\\]\nThe domain is the set of integer values of the loop index. left and right have the same domain\nWe call the order that instances execute the schedule The schedule is the ordering of instances. this is a map of instance to time."
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#what-is-a-violated-data-dependence",
    "href": "lectures/revealjs_09_poly.qmd.html#what-is-a-violated-data-dependence",
    "title": "Polyhedral Analysis",
    "section": "what is a violated data dependence",
    "text": "what is a violated data dependence\na pair (p, c) where p produces data that c consumes and c comes before p in the new schedule\ndata dependence \\[\n\\left \\{(s(i), s(i+1)) \\mid 1 \\le i \\le 3 \\right \\}\n\\]\nset of violated data dependences \\[\n\\left \\{(s(i), s(j)) \\mid \\ newSch(j) \\ge newSch(i) \\right \\}\n\\]"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#ilp-solver-info",
    "href": "lectures/revealjs_09_poly.qmd.html#ilp-solver-info",
    "title": "Polyhedral Analysis",
    "section": "ilp solver info",
    "text": "ilp solver info\ncan an ilp solver always work?\nHilbert’s tenth problem is the tenth on the list of mathematical problems that the German mathematician David Hilbert posed in 1900. It is the challenge to provide a general algorithm that, for any given Diophantine equation (a polynomial equation with integer coefficients and a finite number of unknowns), can decide whether the equation has a solution with all unknowns taking integer values.\nsadly answer is no (found in 1970)\nBut we can do this if we limit the kinds of inequalities"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#affine-limitations",
    "href": "lectures/revealjs_09_poly.qmd.html#affine-limitations",
    "title": "Polyhedral Analysis",
    "section": "Affine limitations",
    "text": "Affine limitations\naffine functions, no multiplying unknowns, no quantifiers (for all, or exists) and is ok, or ok (if we change to two problems) just add/subtract/ multiply by a constant, can add minimize/maximize a function. division and remainder by a constant, max/min/ absolute\nMost scientific programs and ai programs fit, because array subscripts are often affine\nBut lots of other kinds of programs do not.\nThere is a lot of formal math background here, decidability in logic."
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html",
    "href": "lectures/01a1_performance_measurement.html",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\nA sample blog post about this paper blog\n\n\n\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.\n\n\n\n\n\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html#example-1",
    "href": "lectures/01a1_performance_measurement.html#example-1",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\nA sample blog post about this paper blog",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html#violin-plots",
    "href": "lectures/01a1_performance_measurement.html#violin-plots",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "data\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/01a1_performance_measurement.html#error-bars",
    "href": "lectures/01a1_performance_measurement.html#error-bars",
    "title": "Performance and Measurement part 1",
    "section": "",
    "text": "print(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 1"
    ]
  },
  {
    "objectID": "lectures/revealjs_01a1_performance_measurement.qmd.html#example-1",
    "href": "lectures/revealjs_01a1_performance_measurement.qmd.html#example-1",
    "title": "Performance and Measurement part 1",
    "section": "example 1",
    "text": "example 1\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references"
  },
  {
    "objectID": "lectures/revealjs_01a1_performance_measurement.qmd.html#violin-plots",
    "href": "lectures/revealjs_01a1_performance_measurement.qmd.html#violin-plots",
    "title": "Performance and Measurement part 1",
    "section": "violin plots",
    "text": "violin plots\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n\nCode\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots"
  },
  {
    "objectID": "lectures/revealjs_01a1_performance_measurement.qmd.html#error-bars",
    "href": "lectures/revealjs_01a1_performance_measurement.qmd.html#error-bars",
    "title": "Performance and Measurement part 1",
    "section": "error bars",
    "text": "error bars\n\n\nCode\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000"
  },
  {
    "objectID": "lectures/mem_consistancy.html",
    "href": "lectures/mem_consistancy.html",
    "title": "memory consistancy",
    "section": "",
    "text": "The C semantics assume that (within a single thread) all loads and stores stay in order. That is is not allowed to re-order a store past a load of the same address.\nin ssa each argument of an instruction is a pointer to the source instruction. These edges force serialization of the code.\nWe want to apply this to loads and stores this will make ordering explicit\nIn Static Single Assignment (SSA) form, memory tokens, representing stores or loads to memory, are typically handled by introducing memory state variables\n\nload: dest = load addrs, memory_token\nstore memory_token = store value, address, memory_token\ncalls to functions that might modify memory also need to read and write memory tokens\n\ntreat a store as though it created a new copy of memory\nwe can use phi functions on memory tokens\nMaintaining Correct Memory Order: By tracking memory states explicitly in SSA form (through these memory tokens and versioning), SSA ensures that memory operations respect the correct order, even if the control flow of the program is complex. This helps compilers optimize code by making memory dependencies explicit.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n\nOptimize loads/stores\nwalk backwards - load from store\n\nif we can prove the load address is the same as the store address- remove the load\nif we can prove the load address is different move the load up a store\notherwise go on",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#memory-operations",
    "href": "lectures/mem_consistancy.html#memory-operations",
    "title": "memory consistancy",
    "section": "",
    "text": "The C semantics assume that (within a single thread) all loads and stores stay in order. That is is not allowed to re-order a store past a load of the same address.\nin ssa each argument of an instruction is a pointer to the source instruction. These edges force serialization of the code.\nWe want to apply this to loads and stores this will make ordering explicit\nIn Static Single Assignment (SSA) form, memory tokens, representing stores or loads to memory, are typically handled by introducing memory state variables\n\nload: dest = load addrs, memory_token\nstore memory_token = store value, address, memory_token\ncalls to functions that might modify memory also need to read and write memory tokens\n\ntreat a store as though it created a new copy of memory\nwe can use phi functions on memory tokens\nMaintaining Correct Memory Order: By tracking memory states explicitly in SSA form (through these memory tokens and versioning), SSA ensures that memory operations respect the correct order, even if the control flow of the program is complex. This helps compilers optimize code by making memory dependencies explicit.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n\nOptimize loads/stores\nwalk backwards - load from store\n\nif we can prove the load address is the same as the store address- remove the load\nif we can prove the load address is different move the load up a store\notherwise go on",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#multi-threaded-programs",
    "href": "lectures/mem_consistancy.html#multi-threaded-programs",
    "title": "memory consistancy",
    "section": "multi-threaded programs",
    "text": "multi-threaded programs\nCompilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#shared-memory-multi-threading",
    "href": "lectures/mem_consistancy.html#shared-memory-multi-threading",
    "title": "memory consistancy",
    "section": "shared memory multi-threading",
    "text": "shared memory multi-threading\nThe most common parallel system is\n\nA single big memory\nmultiple threads address that memory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#what-is-sequential-consistency-sq",
    "href": "lectures/mem_consistancy.html#what-is-sequential-consistency-sq",
    "title": "memory consistancy",
    "section": "what is sequential consistency SQ",
    "text": "what is sequential consistency SQ\nProgram Order is Maintained Within Threads:\nOperations (reads and writes) appear to occur in the order they are issued by each individual thread. If a thread performs a write followed by a read, the read cannot appear to happen before the write in the execution.\nGlobal Order of Operations Across Threads:\nAll threads see the effects of memory operations in the same sequential order. Every thread agrees on the order of reads and writes, though the specific order is not predefined—it just needs to be consistent across all threads. Interleaving of Operations:\nThe execution can be viewed as an interleaving of instructions from all threads. However, the interleaving must follow the program order within each thread.\nno real machine/compiler implements this",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#compiler-effects",
    "href": "lectures/mem_consistancy.html#compiler-effects",
    "title": "memory consistancy",
    "section": "compiler effects",
    "text": "compiler effects\nCompiler transformations that break multi-thread sequential consistency (SC) often reorder or optimize instructions in ways that do not respect the original program order seen by other threads. These transformations can lead to subtle bugs in multithreaded programs where the expected interleaving of operations is violated.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#loadstore-reordering",
    "href": "lectures/mem_consistancy.html#loadstore-reordering",
    "title": "memory consistancy",
    "section": "Load/Store Reordering",
    "text": "Load/Store Reordering\nTransformation: Compilers might reorder loads and stores to improve performance. Violation: In a multi-threaded environment, this can lead to a situation where one thread sees stale or unexpected data. Example:\nCopy code\n// Thread 1\nx = 1;     // Store\nr1 = y;    // Load\n\n// Thread 2\ny = 1;     // Store\nr2 = x;    // Load\nUnder sequential consistency, if thread 1’s x = 1 happens before thread 2’s r2 = x, then thread 2 should observe r2 == 1. But reordering could result in thread 2 reading x as 0.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#common-subexpression-elimination-cse",
    "href": "lectures/mem_consistancy.html#common-subexpression-elimination-cse",
    "title": "memory consistancy",
    "section": "Common Subexpression Elimination (CSE)",
    "text": "Common Subexpression Elimination (CSE)\nTransformation: If a variable or expression is computed multiple times, the compiler may optimize by reusing the result of an earlier computation. Violation: This assumes that no other thread modifies shared variables between these uses. Example:\n// Original code\nr1 = x;\nr2 = x;\n\n// Transformed code (CSE applied)\ntemp = x;\nr1 = temp;\nr2 = temp;\nIf x is modified by another thread between the two reads, the transformed code will incorrectly assume the value of x hasn’t changed.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#dead-code-elimination-dce",
    "href": "lectures/mem_consistancy.html#dead-code-elimination-dce",
    "title": "memory consistancy",
    "section": "Dead Code Elimination (DCE)",
    "text": "Dead Code Elimination (DCE)\nTransformation: The compiler may remove stores to variables that are not subsequently read in the same thread. Violation: If the variable is shared and accessed by other threads, removing the store could lead to unexpected behavior. Example:\n// Original code\nx = 1;\n\n// Transformed code (DCE applied)\n// x = 1 is removed because x is not used locally If another thread reads x, it expects the store to have happened, but DCE breaks this assumption.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#speculative-execution-out-of-order-execution",
    "href": "lectures/mem_consistancy.html#speculative-execution-out-of-order-execution",
    "title": "memory consistancy",
    "section": "Speculative Execution (Out-of-Order Execution)",
    "text": "Speculative Execution (Out-of-Order Execution)\nTransformation: Compilers (or hardware) may execute instructions speculatively, assuming certain branches are likely to be taken. Violation: This can cause out-of-order writes or reads visible to other threads, breaking SC. Example:\nif (flag) {\n    r1 = x;\n}\nIf the compiler speculatively reads x before knowing the value of flag, another thread’s write to x might be missed or observed out-of-order.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#loop-invariant-code-motion",
    "href": "lectures/mem_consistancy.html#loop-invariant-code-motion",
    "title": "memory consistancy",
    "section": "Loop Invariant Code Motion",
    "text": "Loop Invariant Code Motion\nTransformation: The compiler moves computations that are invariant inside a loop to outside the loop. Violation: If these computations involve shared variables modified by other threads within the loop, moving them outside could make the code see stale values. Example:\n// Original code\nwhile (condition) {\n    r = shared_variable;\n}\n\n// Transformed code (Loop Invariant Code Motion)\ntemp = shared_variable;\nwhile (condition) {\n    r = temp;\n}\nIf shared_variable is updated by another thread, the transformed code might keep using the old value.\n\nRegister Allocation (Caching Shared Variables in Registers)\nTransformation: Compilers can keep a shared variable in a register for efficiency rather than repeatedly loading it from memory. Violation: If another thread modifies that shared variable in memory, the compiler’s register optimization would cause the thread to read stale data. Example:\nwhile (flag == 0) {\n    // busy-wait\n}\nIf flag is cached in a register, updates to flag by another thread in memory won’t be reflected, breaking SC.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#instruction-fusion-combining-loadsstores",
    "href": "lectures/mem_consistancy.html#instruction-fusion-combining-loadsstores",
    "title": "memory consistancy",
    "section": "Instruction Fusion (Combining Loads/Stores)",
    "text": "Instruction Fusion (Combining Loads/Stores)\nTransformation: The compiler may combine consecutive memory accesses into one, such as merging adjacent stores into a single store or combining two loads. Violation: If other threads expect these loads or stores to happen separately, they might see an inconsistent view of memory. Example:\n// Original code\nx = 1;\ny = 2;\n\n// Transformed code (store fusion)\n// x and y are stored together in a single transaction\nA thread expecting x and y to be updated separately might observe an inconsistent state if this transformation is applied.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#thread-libraries",
    "href": "lectures/mem_consistancy.html#thread-libraries",
    "title": "memory consistancy",
    "section": "thread libraries",
    "text": "thread libraries\nstart out assuming single threaded, add a threads library like pthreads\nmultiple threads could access shared memory simultaneously, leading to race conditions, inconsistent data, and undefined behavior.\nModern CPUs and compilers perform optimizations like instruction reordering, which can break assumptions about the order of memory operations in multithreaded programs.\nMultithreaded code is harder to test because race conditions and bugs might only manifest under certain timing conditions.\nDebugging multithreaded programs is more difficult due to the unpredictable nature of thread execution and interactions.\nSome optimizations might reorder instructions in a way that is incompatible with multithreading, introducing subtle bugs or performance regressions.\nCaching, prefetching, or other memory optimizations need to account for the fact that multiple threads may be accessing the same memory, which a simple thread library does not handle.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#using-libraries",
    "href": "lectures/mem_consistancy.html#using-libraries",
    "title": "memory consistancy",
    "section": "using libraries",
    "text": "using libraries\n\nFunctions such as pthread mutex lock() that are guaranteed by the standard to “synchronize memory” include hardware instructions (“memory barriers”) that prevent hardware reordering of memory operations around the call\nTo prevent the compiler from moving memory operations around calls to functions such as pthread mutex lock(), they are essentially treated as calls to opaque functions, about which the compiler has no information.\n\nThe compiler effectively assumes that pthread mutex lock() may read or write any global variable. Thus a memory reference cannot simply be moved across the call. This approach also ensures that transitive calls, e.g. a call to a function f() which then calls pthread mutex lock(), are handled in the same way more or less appropriately, i.e. memory operations are not moved across the call to f() either, whether or not the entire user program is being analyzed at once.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#adding-multi-threading-to-user-explaining-the-intent",
    "href": "lectures/mem_consistancy.html#adding-multi-threading-to-user-explaining-the-intent",
    "title": "memory consistancy",
    "section": "adding multi-threading to user explaining the intent",
    "text": "adding multi-threading to user explaining the intent\nc++/c added atomics\nAtomic operations are operations that are completed as a single, uninterruptible action. No other thread can observe a partial update or interfere with the operation.\nThese operations ensure that read-modify-write sequences are safe without needing explicit locks.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#an-example-1",
    "href": "lectures/mem_consistancy.html#an-example-1",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n// Global spinlock using atomic_flag\nstd::atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid enter_critical_section() {\n    // Busy-wait (spin) until the lock is acquired\n    while (lock.test_and_set(std::memory_order_acquire)) {\n        // Spin and wait for the lock to become available\n    }\n}\n\nvoid leave_critical_section() {\n    // Release the lock\n    lock.clear(std::memory_order_release);\n}\n\n// Shared resource\nint shared_counter = 0;\n\nvoid critical_section_task(int num_increments) {\n    for (int i = 0; i &lt; num_increments; ++i) {\n        enter_critical_section();\n        // Begin critical section\n        ++shared_counter;\n        // End critical section\n        leave_critical_section();\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#load-acquire-needs-special-hardware",
    "href": "lectures/mem_consistancy.html#load-acquire-needs-special-hardware",
    "title": "memory consistancy",
    "section": "load acquire (needs special hardware )",
    "text": "load acquire (needs special hardware )\nused by default with atomics not used for non-atomics\nall memory reads and writes after the load operation cannot be moved before the load. This ensures that after acquiring the value, any operations that depend on this value (like accessing shared data) will see consistent and up-to-date memory.\na one way fence - nothing can move up",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#write-release-needs-special-hardware",
    "href": "lectures/mem_consistancy.html#write-release-needs-special-hardware",
    "title": "memory consistancy",
    "section": "write release (needs special hardware )",
    "text": "write release (needs special hardware )\nprevents the compiler or processor from reordering any memory operations (reads or writes) that appear before the release store. This guarantees that all operations that modify shared data before the release are visible to other threads that subsequently perform an acquire operation.\nalso a one way fence - nothing can move down\nload.acquire - \nloads and stores on non-atomics  - compiler picks the order for these operations \nstore.release",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#using-atomics",
    "href": "lectures/mem_consistancy.html#using-atomics",
    "title": "memory consistancy",
    "section": "using atomics",
    "text": "using atomics\nAll operations appear to occur in a single total order that is consistent across all threads. This means that the results of operations are predictable and consistent as if all operations were executed in some sequential order.\nlimits the hardware and compiler because it prevents reordering",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#data-race-free",
    "href": "lectures/mem_consistancy.html#data-race-free",
    "title": "memory consistancy",
    "section": "Data Race Free",
    "text": "Data Race Free\nData Race Free (DRF) means that a program is free from data races, which occur when:\n\nTwo or more threads access the same variable concurrently.\nAt least one of the accesses is a write.\n\nThere is no synchronization mechanism (like mutexes or atomic operations) to control the access. In a data race-free program, every shared variable is accessed in a way that ensures predictable results. C++ provides various synchronization primitives (such as mutexes and atomic types) to help developers write DRF code.\nAll shared variables must be accessed using synchronization to prevent concurrent threads from modifying shared data simultaneously without coordination.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#an-example-2",
    "href": "lectures/mem_consistancy.html#an-example-2",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nint shared_counter1 = 0;                  // First non-atomic shared variable\nint shared_counter2 = 0;                  // Second non-atomic shared variable\nstd::atomic&lt;bool&gt; lock_flag(false);       // Atomic flag to control access\n\nvoid safe_increment() {\n    for (int i = 0; i &lt; 1000; ++i) {\n        // Spin until the lock is acquired\n        while (lock_flag.exchange(true)) {\n            // Busy-wait (spin) until the lock is free\n        }\n\n        // Critical section: update the non-atomic shared variables\n        ++shared_counter1;\n        ++shared_counter2;\n\n        // Release the lock\n        lock_flag.store(false);\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#language-rules",
    "href": "lectures/mem_consistancy.html#language-rules",
    "title": "memory consistancy",
    "section": "language rules",
    "text": "language rules\nC and C++\ndo not define what happens in the presence of data races. If a program has data races (e.g., multiple threads concurrently reading and writing to the same variable without synchronization), the behavior is considered undefined. This means that the program may produce unexpected results, crash, or behave inconsistently across different executions or platforms.\nJava\ntries to define what happens but definition is very complex and maybe inconsistent\nRust\nCompile-Time Guarantees: Rust’s ownership and borrowing system prevents data races at compile time. If a program is not DRF, the Rust compiler will typically refuse to compile it, enforcing memory safety guarantees.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#can-the-compiler-add-a-race-to-a-drf-program",
    "href": "lectures/mem_consistancy.html#can-the-compiler-add-a-race-to-a-drf-program",
    "title": "memory consistancy",
    "section": "can the compiler add a race to a drf program",
    "text": "can the compiler add a race to a drf program\nnew rule, compiler cannot add a write to a shared variable\nif (x ==1) y++\n\nto \ny++\nif (x!=1) y--",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/mem_consistancy.html#how-does-this-effect-hardware",
    "href": "lectures/mem_consistancy.html#how-does-this-effect-hardware",
    "title": "memory consistancy",
    "section": "how does this effect hardware?",
    "text": "how does this effect hardware?\nstruct { char a; char b; char c; char d;} s;\ns.a = 1\ns.c = 3\n\ncan a compiler do \nchar temp[4] = s // load 32 bits \ntemp[0] = 1\ntemp[2] = 3\ns = temp\nnot allowed - reads/writes b and d, so compiler incorrectly added writes\noptions are either have byte addressable hardware, or pad so that each char gets 32 bits\nVendors forced to add 8 byte loads/stores",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "memory consistancy"
    ]
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#memory-operations",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#memory-operations",
    "title": "memory consistancy",
    "section": "memory operations",
    "text": "memory operations\nThe C semantics assume that (within a single thread) all loads and stores stay in order. That is is not allowed to re-order a store past a load of the same address.\nin ssa each argument of an instruction is a pointer to the source instruction. These edges force serialization of the code.\nWe want to apply this to loads and stores this will make ordering explicit\nIn Static Single Assignment (SSA) form, memory tokens, representing stores or loads to memory, are typically handled by introducing memory state variables\n\nload: dest = load addrs, memory_token\nstore memory_token = store value, address, memory_token\ncalls to functions that might modify memory also need to read and write memory tokens\n\ntreat a store as though it created a new copy of memory\nwe can use phi functions on memory tokens\nMaintaining Correct Memory Order: By tracking memory states explicitly in SSA form (through these memory tokens and versioning), SSA ensures that memory operations respect the correct order, even if the control flow of the program is complex. This helps compilers optimize code by making memory dependencies explicit.\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstore1\nload1\nload2\nstore2\nload4\nload3\nstore1--&gt;load1\nstore1--&gt;load2\nstore1 --&gt; store2\nstore2 --&gt; load3\nstore2--&gt; load4\nstore2--&gt; exit\n\n\n\n\n\n\nOptimize loads/stores\nwalk backwards - load from store\n\nif we can prove the load address is the same as the store address- remove the load\nif we can prove the load address is different move the load up a store\notherwise go on"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#multi-threaded-programs",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#multi-threaded-programs",
    "title": "memory consistancy",
    "section": "multi-threaded programs",
    "text": "multi-threaded programs\nCompilers started out assuming targets are single threaded. What optimizations change for multi-threaded code? How do users tell compiler that the target is multi-threaded?"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#shared-memory-multi-threading",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#shared-memory-multi-threading",
    "title": "memory consistancy",
    "section": "shared memory multi-threading",
    "text": "shared memory multi-threading\nThe most common parallel system is\n\nA single big memory\nmultiple threads address that memory"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#what-is-sequential-consistency-sq",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#what-is-sequential-consistency-sq",
    "title": "memory consistancy",
    "section": "what is sequential consistency SQ",
    "text": "what is sequential consistency SQ\nProgram Order is Maintained Within Threads:\nOperations (reads and writes) appear to occur in the order they are issued by each individual thread. If a thread performs a write followed by a read, the read cannot appear to happen before the write in the execution.\nGlobal Order of Operations Across Threads:\nAll threads see the effects of memory operations in the same sequential order. Every thread agrees on the order of reads and writes, though the specific order is not predefined—it just needs to be consistent across all threads. Interleaving of Operations:\nThe execution can be viewed as an interleaving of instructions from all threads. However, the interleaving must follow the program order within each thread.\nno real machine/compiler implements this"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#compiler-effects",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#compiler-effects",
    "title": "memory consistancy",
    "section": "compiler effects",
    "text": "compiler effects\nCompiler transformations that break multi-thread sequential consistency (SC) often reorder or optimize instructions in ways that do not respect the original program order seen by other threads. These transformations can lead to subtle bugs in multithreaded programs where the expected interleaving of operations is violated."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#loadstore-reordering",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#loadstore-reordering",
    "title": "memory consistancy",
    "section": "Load/Store Reordering",
    "text": "Load/Store Reordering\nTransformation: Compilers might reorder loads and stores to improve performance. Violation: In a multi-threaded environment, this can lead to a situation where one thread sees stale or unexpected data. Example:\nCopy code\n// Thread 1\nx = 1;     // Store\nr1 = y;    // Load\n\n// Thread 2\ny = 1;     // Store\nr2 = x;    // Load\nUnder sequential consistency, if thread 1’s x = 1 happens before thread 2’s r2 = x, then thread 2 should observe r2 == 1. But reordering could result in thread 2 reading x as 0."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#common-subexpression-elimination-cse",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#common-subexpression-elimination-cse",
    "title": "memory consistancy",
    "section": "Common Subexpression Elimination (CSE)",
    "text": "Common Subexpression Elimination (CSE)\nTransformation: If a variable or expression is computed multiple times, the compiler may optimize by reusing the result of an earlier computation. Violation: This assumes that no other thread modifies shared variables between these uses. Example:\n// Original code\nr1 = x;\nr2 = x;\n\n// Transformed code (CSE applied)\ntemp = x;\nr1 = temp;\nr2 = temp;\nIf x is modified by another thread between the two reads, the transformed code will incorrectly assume the value of x hasn’t changed."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#dead-code-elimination-dce",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#dead-code-elimination-dce",
    "title": "memory consistancy",
    "section": "Dead Code Elimination (DCE)",
    "text": "Dead Code Elimination (DCE)\nTransformation: The compiler may remove stores to variables that are not subsequently read in the same thread. Violation: If the variable is shared and accessed by other threads, removing the store could lead to unexpected behavior. Example:\n// Original code\nx = 1;\n\n// Transformed code (DCE applied)\n// x = 1 is removed because x is not used locally If another thread reads x, it expects the store to have happened, but DCE breaks this assumption."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#speculative-execution-out-of-order-execution",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#speculative-execution-out-of-order-execution",
    "title": "memory consistancy",
    "section": "Speculative Execution (Out-of-Order Execution)",
    "text": "Speculative Execution (Out-of-Order Execution)\nTransformation: Compilers (or hardware) may execute instructions speculatively, assuming certain branches are likely to be taken. Violation: This can cause out-of-order writes or reads visible to other threads, breaking SC. Example:\nif (flag) {\n    r1 = x;\n}\nIf the compiler speculatively reads x before knowing the value of flag, another thread’s write to x might be missed or observed out-of-order."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#loop-invariant-code-motion",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#loop-invariant-code-motion",
    "title": "memory consistancy",
    "section": "Loop Invariant Code Motion",
    "text": "Loop Invariant Code Motion\nTransformation: The compiler moves computations that are invariant inside a loop to outside the loop. Violation: If these computations involve shared variables modified by other threads within the loop, moving them outside could make the code see stale values. Example:\n// Original code\nwhile (condition) {\n    r = shared_variable;\n}\n\n// Transformed code (Loop Invariant Code Motion)\ntemp = shared_variable;\nwhile (condition) {\n    r = temp;\n}\nIf shared_variable is updated by another thread, the transformed code might keep using the old value.\nRegister Allocation (Caching Shared Variables in Registers)\nTransformation: Compilers can keep a shared variable in a register for efficiency rather than repeatedly loading it from memory. Violation: If another thread modifies that shared variable in memory, the compiler’s register optimization would cause the thread to read stale data. Example:\nwhile (flag == 0) {\n    // busy-wait\n}\nIf flag is cached in a register, updates to flag by another thread in memory won’t be reflected, breaking SC."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#instruction-fusion-combining-loadsstores",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#instruction-fusion-combining-loadsstores",
    "title": "memory consistancy",
    "section": "Instruction Fusion (Combining Loads/Stores)",
    "text": "Instruction Fusion (Combining Loads/Stores)\nTransformation: The compiler may combine consecutive memory accesses into one, such as merging adjacent stores into a single store or combining two loads. Violation: If other threads expect these loads or stores to happen separately, they might see an inconsistent view of memory. Example:\n// Original code\nx = 1;\ny = 2;\n\n// Transformed code (store fusion)\n// x and y are stored together in a single transaction\nA thread expecting x and y to be updated separately might observe an inconsistent state if this transformation is applied."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#thread-libraries",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#thread-libraries",
    "title": "memory consistancy",
    "section": "thread libraries",
    "text": "thread libraries\nstart out assuming single threaded, add a threads library like pthreads\nmultiple threads could access shared memory simultaneously, leading to race conditions, inconsistent data, and undefined behavior.\nModern CPUs and compilers perform optimizations like instruction reordering, which can break assumptions about the order of memory operations in multithreaded programs.\nMultithreaded code is harder to test because race conditions and bugs might only manifest under certain timing conditions.\nDebugging multithreaded programs is more difficult due to the unpredictable nature of thread execution and interactions.\nSome optimizations might reorder instructions in a way that is incompatible with multithreading, introducing subtle bugs or performance regressions.\nCaching, prefetching, or other memory optimizations need to account for the fact that multiple threads may be accessing the same memory, which a simple thread library does not handle."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#using-libraries",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#using-libraries",
    "title": "memory consistancy",
    "section": "using libraries",
    "text": "using libraries\n\nFunctions such as pthread mutex lock() that are guaranteed by the standard to “synchronize memory” include hardware instructions (“memory barriers”) that prevent hardware reordering of memory operations around the call\nTo prevent the compiler from moving memory operations around calls to functions such as pthread mutex lock(), they are essentially treated as calls to opaque functions, about which the compiler has no information.\n\nThe compiler effectively assumes that pthread mutex lock() may read or write any global variable. Thus a memory reference cannot simply be moved across the call. This approach also ensures that transitive calls, e.g. a call to a function f() which then calls pthread mutex lock(), are handled in the same way more or less appropriately, i.e. memory operations are not moved across the call to f() either, whether or not the entire user program is being analyzed at once."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#adding-multi-threading-to-user-explaining-the-intent",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#adding-multi-threading-to-user-explaining-the-intent",
    "title": "memory consistancy",
    "section": "adding multi-threading to user explaining the intent",
    "text": "adding multi-threading to user explaining the intent\nc++/c added atomics\nAtomic operations are operations that are completed as a single, uninterruptible action. No other thread can observe a partial update or interfere with the operation.\nThese operations ensure that read-modify-write sequences are safe without needing explicit locks."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#an-example-1",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#an-example-1",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n// Global spinlock using atomic_flag\nstd::atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid enter_critical_section() {\n    // Busy-wait (spin) until the lock is acquired\n    while (lock.test_and_set(std::memory_order_acquire)) {\n        // Spin and wait for the lock to become available\n    }\n}\n\nvoid leave_critical_section() {\n    // Release the lock\n    lock.clear(std::memory_order_release);\n}\n\n// Shared resource\nint shared_counter = 0;\n\nvoid critical_section_task(int num_increments) {\n    for (int i = 0; i &lt; num_increments; ++i) {\n        enter_critical_section();\n        // Begin critical section\n        ++shared_counter;\n        // End critical section\n        leave_critical_section();\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#load-acquire-needs-special-hardware",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#load-acquire-needs-special-hardware",
    "title": "memory consistancy",
    "section": "load acquire (needs special hardware )",
    "text": "load acquire (needs special hardware )\nused by default with atomics not used for non-atomics\nall memory reads and writes after the load operation cannot be moved before the load. This ensures that after acquiring the value, any operations that depend on this value (like accessing shared data) will see consistent and up-to-date memory.\na one way fence - nothing can move up"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#write-release-needs-special-hardware",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#write-release-needs-special-hardware",
    "title": "memory consistancy",
    "section": "write release (needs special hardware )",
    "text": "write release (needs special hardware )\nprevents the compiler or processor from reordering any memory operations (reads or writes) that appear before the release store. This guarantees that all operations that modify shared data before the release are visible to other threads that subsequently perform an acquire operation.\nalso a one way fence - nothing can move down\nload.acquire - \nloads and stores on non-atomics  - compiler picks the order for these operations \nstore.release"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#using-atomics",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#using-atomics",
    "title": "memory consistancy",
    "section": "using atomics",
    "text": "using atomics\nAll operations appear to occur in a single total order that is consistent across all threads. This means that the results of operations are predictable and consistent as if all operations were executed in some sequential order.\nlimits the hardware and compiler because it prevents reordering"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#data-race-free",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#data-race-free",
    "title": "memory consistancy",
    "section": "Data Race Free",
    "text": "Data Race Free\nData Race Free (DRF) means that a program is free from data races, which occur when:\n\nTwo or more threads access the same variable concurrently.\nAt least one of the accesses is a write.\n\nThere is no synchronization mechanism (like mutexes or atomic operations) to control the access. In a data race-free program, every shared variable is accessed in a way that ensures predictable results. C++ provides various synchronization primitives (such as mutexes and atomic types) to help developers write DRF code.\nAll shared variables must be accessed using synchronization to prevent concurrent threads from modifying shared data simultaneously without coordination."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#an-example-2",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#an-example-2",
    "title": "memory consistancy",
    "section": "an example",
    "text": "an example\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nint shared_counter1 = 0;                  // First non-atomic shared variable\nint shared_counter2 = 0;                  // Second non-atomic shared variable\nstd::atomic&lt;bool&gt; lock_flag(false);       // Atomic flag to control access\n\nvoid safe_increment() {\n    for (int i = 0; i &lt; 1000; ++i) {\n        // Spin until the lock is acquired\n        while (lock_flag.exchange(true)) {\n            // Busy-wait (spin) until the lock is free\n        }\n\n        // Critical section: update the non-atomic shared variables\n        ++shared_counter1;\n        ++shared_counter2;\n\n        // Release the lock\n        lock_flag.store(false);\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#language-rules",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#language-rules",
    "title": "memory consistancy",
    "section": "language rules",
    "text": "language rules\nC and C++\ndo not define what happens in the presence of data races. If a program has data races (e.g., multiple threads concurrently reading and writing to the same variable without synchronization), the behavior is considered undefined. This means that the program may produce unexpected results, crash, or behave inconsistently across different executions or platforms.\nJava\ntries to define what happens but definition is very complex and maybe inconsistent\nRust\nCompile-Time Guarantees: Rust’s ownership and borrowing system prevents data races at compile time. If a program is not DRF, the Rust compiler will typically refuse to compile it, enforcing memory safety guarantees."
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#can-the-compiler-add-a-race-to-a-drf-program",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#can-the-compiler-add-a-race-to-a-drf-program",
    "title": "memory consistancy",
    "section": "can the compiler add a race to a drf program",
    "text": "can the compiler add a race to a drf program\nnew rule, compiler cannot add a write to a shared variable\nif (x ==1) y++\n\nto \ny++\nif (x!=1) y--"
  },
  {
    "objectID": "lectures/revealjs_mem_consistancy.qmd.html#how-does-this-effect-hardware",
    "href": "lectures/revealjs_mem_consistancy.qmd.html#how-does-this-effect-hardware",
    "title": "memory consistancy",
    "section": "how does this effect hardware?",
    "text": "how does this effect hardware?\nstruct { char a; char b; char c; char d;} s;\ns.a = 1\ns.c = 3\n\ncan a compiler do \nchar temp[4] = s // load 32 bits \ntemp[0] = 1\ntemp[2] = 3\ns = temp\nnot allowed - reads/writes b and d, so compiler incorrectly added writes\noptions are either have byte addressable hardware, or pad so that each char gets 32 bits\nVendors forced to add 8 byte loads/stores"
  },
  {
    "objectID": "lectures/02b_bril.html",
    "href": "lectures/02b_bril.html",
    "title": "Overview of Bril",
    "section": "",
    "text": "Bril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#how-to-use-bril-with-real-code",
    "href": "lectures/02b_bril.html#how-to-use-bril-with-real-code",
    "title": "Overview of Bril",
    "section": "",
    "text": "Bril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#lets-look-at-a-bril-program.",
    "href": "lectures/02b_bril.html#lets-look-at-a-bril-program.",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\nimport json\nimport subprocess\nimport os \nimport sys\n\n\n### temp \nout = subprocess.check_output('which python', shell=True)\nprint(out)\nprint('***********************')\n\n# read from a file \nwith open(\"images/add.json\",\"r\") as f:\n    bril_program = json.load(f)\n\n# read from a pipe\n# bril_program = json.load(sys.stdin)\n    \nprint(json.dumps(bril_program, \n    indent=2))\n\nb'/opt/hostedtoolcache/Python/3.10.15/x64/bin/python\\n'\n***********************\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#formatted",
    "href": "lectures/02b_bril.html#formatted",
    "title": "Overview of Bril",
    "section": "Formatted",
    "text": "Formatted\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\"dest\": \"v0\", \"op\": \"const\",\"type\": \"int\",\"value\": 1},\n        {\"dest\": \"v1\", \"op\": \"const\",\"type\": \"int\",\"value\": 2},\n        {\"dest\": \"v2\", \"op\": \"add\",  \"type\": \"int\",\"args\": [\"v0\",\"v1\"],},\n                       \"op\": \"print\",\"args\": [ \"v2\"],}],\n      \"name\": \"main\",\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#getting-started",
    "href": "lectures/02b_bril.html#getting-started",
    "title": "Overview of Bril",
    "section": "getting started",
    "text": "getting started\nlinks:\n\nLanguage specification\ngithub site",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "href": "lectures/02b_bril.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "title": "Overview of Bril",
    "section": "step 1 clone the bril repo on a linux or wsl machine",
    "text": "step 1 clone the bril repo on a linux or wsl machine\ngit clone https://github.com/sampsyo/bril.git",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-2-support-packages",
    "href": "lectures/02b_bril.html#step-2-support-packages",
    "title": "Overview of Bril",
    "section": "step 2 support packages",
    "text": "step 2 support packages\n\ndeno is the runtime for typescript/javascript\n\ncurl -fsSL https://deno.land/install.sh | sh\non my ubuntu machine ‘sudo snap install deno’ also worked\nyou may need to add $HOME/.deno/bin to your $PATH.\n\nflit a python package manager\n\npython3 -m pip install flit",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "href": "lectures/02b_bril.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "title": "Overview of Bril",
    "section": "step 3 install the bril interpreter, and the typescript to bril compiler",
    "text": "step 3 install the bril interpreter, and the typescript to bril compiler\ncd bril\ndeno install brili.ts \ndeno install --allow-env --allow-read ts2bril.ts",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#running-the-interpreter",
    "href": "lectures/02b_bril.html#running-the-interpreter",
    "title": "Overview of Bril",
    "section": "running the interpreter",
    "text": "running the interpreter\nbrili &lt;images/add.json\nbrili -p &lt;images/add.json\nthe -p flag turns on profiling",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#text-to-json-and-back",
    "href": "lectures/02b_bril.html#text-to-json-and-back",
    "title": "Overview of Bril",
    "section": "text to json and back",
    "text": "text to json and back\nThere are programs bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\ninstall text tools\ncd bril-txt\nflit install --symlink --user\nrun json to text\nbril2txt &lt; images/add.json",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#connect-tools-via-pipes",
    "href": "lectures/02b_bril.html#connect-tools-via-pipes",
    "title": "Overview of Bril",
    "section": "connect tools via pipes",
    "text": "connect tools via pipes\ncat images/add.json'\nbril2txt &lt; images/add.json | bril2json",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#other-tools",
    "href": "lectures/02b_bril.html#other-tools",
    "title": "Overview of Bril",
    "section": "Other tools",
    "text": "Other tools\nThere is also a fast interpreter written in Rust see docs for installation",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#turnt-tiny-unified-runner-and-tester",
    "href": "lectures/02b_bril.html#turnt-tiny-unified-runner-and-tester",
    "title": "Overview of Bril",
    "section": "turnt Tiny unified runner and tester",
    "text": "turnt Tiny unified runner and tester\nBril uses turnt as a test tool\nTurnt is a simple snapshot testing tool inspired by LLVM’s lit. It’s good for testing things that translate text files to other text files, like compilers. The idea is that each test is one input file, and you want to run a command and check that it still matches the saved output file.\npip install –user turnt\nAs you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (can be wsl) machine",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#gen-cfg",
    "href": "lectures/02b_bril.html#gen-cfg",
    "title": "Overview of Bril",
    "section": "Gen CFG",
    "text": "Gen CFG\nLets write a sample program - that generates the cfg\nHow would you do that?\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}\n\n. . .\nI’ll do this in two steps\n\nfind all the basic blocks\nadd all the cfg edges\n\nYou can also do this in a single step, adding cfg edges as soon as you reach the successor node.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#basic-blocks-from-a-list-of-instructions-",
    "href": "lectures/02b_bril.html#basic-blocks-from-a-list-of-instructions-",
    "title": "Overview of Bril",
    "section": "basic blocks from a list of instructions-",
    "text": "basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\n. . .\nin: list of instrs \nout: list of lists of instrs \n \nblocks = []\ncurr_block = []\nfor each instr in list \n    if the instruction is not a label put it on curr_block\n    if instr is a label or terminator \n       put curr_block on blocks\n       curr_block = []\n \n if curr_block is not empty add it to blocks\n return blocks \ntwo labels in a row do not need another block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#step-2-add-edges",
    "href": "lectures/02b_bril.html#step-2-add-edges",
    "title": "Overview of Bril",
    "section": "step 2 add edges",
    "text": "step 2 add edges\nfind cfg: in: is bril program in json \nfor each function find the list of basic blocks\nfor each basic block\n   get last_instr \n   if it is a terminator  br/jmp/ret \n     add edge from current block to successor  \n    --- what do we want to do with call? \n   else it is a fall through\n      add edge to next block\n. . .\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we handle fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case\nwhat happens if try to delete the terminator (because the block never executes)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#code",
    "href": "lectures/02b_bril.html#code",
    "title": "Overview of Bril",
    "section": "code",
    "text": "code\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed.\n\nGitHub Copilot says:\nOrderedDict in Python is a dictionary subclass that maintains the order in which keys are inserted. When iterating over an OrderedDict, the items are returned in the order they were added. This behavior contrasts with a standard dictionary in Python 3.6 and earlier, where the iteration order was not guaranteed. However, starting from Python 3.7, the built-in dict type also maintains insertion order by default, making OrderedDict less necessary for most applications. OrderedDict still provides additional functionality, such as the move_to_end method, which allows moving an existing key to either end of the dictionary.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#ill-use-a-generator",
    "href": "lectures/02b_bril.html#ill-use-a-generator",
    "title": "Overview of Bril",
    "section": "I’ll use a generator",
    "text": "I’ll use a generator\nIn Python, a generator is an iterator that is defined with a function using the yield statement.\n\nProduce items only once\nDo not store all the items in memory\nWhen items from the generator are requested, the function executes until it reaches a yield statement, which produces the next value. Execution then pauses, preserving the function’s state, until the next item is requested.\n\n\nGiven a list of Bril instructions, generate a sequence of instruction lists representing the basic blocks in the program.\nEvery instruction in instr will show up in exactly one block. Jump and branch instructions may only appear at the end of a block, and control can transfer only to the top of a basic block—so labels can only appear at the start of a basic block. Basic blocks may not be empty.\n\n\n    #Instructions that terminate a basic block.\n    TERMINATORS = 'br', 'jmp', 'ret'\n\n    def form_blocks(instrs):\n        # Start with an empty block.\n        cur_block = []\n\n        for instr in instrs:\n            if 'op' in instr:  # It's an instruction.\n                # Add the instruction to the currently-being-formed block.\n                cur_block.append(instr)\n\n                # If this is a terminator (branching instruction), it's the\n                # last instruction in the block. Finish this block and\n                # start a new one.\n                if instr['op'] in TERMINATORS:\n                    yield cur_block\n                    cur_block = []\n            \n            else:  # It's a label.\n                # End the block here (if it contains anything).\n                if cur_block:\n                    yield cur_block\n\n                # Start a new block with the label.\n                cur_block = [instr]\n\n        # Produce the final block, if any.\n        if cur_block:\n            yield cur_block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#as-a-test-lets-print-out-the-blocks",
    "href": "lectures/02b_bril.html#as-a-test-lets-print-out-the-blocks",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\ndef print_blocks(bril):\n    \"\"\"Given a Bril program, print out its basic blocks.\n    \"\"\"\n\n\n    func = bril['functions'][0]  # We only process one function.\n    for block in form_blocks(func['instrs']):\n        # Mark the block.\n        leader = block[0]\n        if 'label' in leader:\n            print( f\"block {leader['label']}\")\n            block = block[1:]  # Hide the label\n        else:\n            print('anonymous block:')\n\n        # Print the instructions.\n        for instr in block:\n            print(instr)\n\nprint_blocks(bril_program)\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}\n\n\nthis test program has one block so pretty easy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#lets-try-a-second-example-with-a-jmp",
    "href": "lectures/02b_bril.html#lets-try-a-second-example-with-a-jmp",
    "title": "Overview of Bril",
    "section": "lets try a second example with a jmp",
    "text": "lets try a second example with a jmp\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#running-commands-inside-python",
    "href": "lectures/02b_bril.html#running-commands-inside-python",
    "title": "Overview of Bril",
    "section": "running commands inside python",
    "text": "running commands inside python\nGitHub Copilot: subprocess.check_output is a function in Python’s subprocess module that runs a command with arguments and returns its output as a byte string. If the command exits with a non-zero exit status, it raises a CalledProcessError, which includes the exit status and output of the command. This function is useful for capturing the output of a command for further processing in Python.\n\n\nimport subprocess\n\n# Run a command and capture its output\noutput = subprocess.check_output(['ls', '-l'])\n\n# Convert the byte string to a regular string (assuming UTF-8 encoding)\noutput_str = output.decode('utf-8')\n\nprint(output_str)\n\ntotal 1556\n-rw-r--r-- 1 runner docker 40847 Nov  4 13:41 010_compiler_overview.html\n-rw-r--r-- 1 runner docker 11163 Nov  4 13:41 010_compiler_overview.qmd\n-rw-r--r-- 1 runner docker  3000 Nov  4 13:41 01a1_performance_measurement.qmd\ndrwxr-xr-x 3 runner docker  4096 Nov  4 13:40 01a1_performance_measurement_files\n-rw-r--r-- 1 runner docker  3000 Nov  4 13:41 01a2_performance_measurement.qmd\n-rw-r--r-- 1 runner docker 33799 Nov  4 13:41 01a_performance_measurement.html\n-rw-r--r-- 1 runner docker  4134 Nov  4 13:41 01a_performance_measurement.qmd\ndrwxr-xr-x 4 runner docker  4096 Nov  4 13:41 01a_performance_measurement_files\n-rw-r--r-- 1 runner docker  7413 Nov  4 13:41 02a_representation.qmd\n-rw-r--r-- 1 runner docker 13777 Nov  4 13:41 02b_bril.qmd\n-rw-r--r-- 1 runner docker 23601 Nov  4 13:41 02b_bril.quarto_ipynb\n-rw-r--r-- 1 runner docker 75099 Nov  4 13:41 03_local.html\n-rw-r--r-- 1 runner docker 12742 Nov  4 13:41 03_local.qmd\n-rw-r--r-- 1 runner docker 13267 Nov  4 13:41 03b_local_value_numbering.qmd\n-rw-r--r-- 1 runner docker 56836 Nov  4 13:41 04_data_flow.html\n-rw-r--r-- 1 runner docker  9438 Nov  4 13:41 04_data_flow.qmd\n-rw-r--r-- 1 runner docker  9974 Nov  4 13:41 05_global.qmd\n-rw-r--r-- 1 runner docker  4544 Nov  4 13:41 05b_licm.qmd\n-rw-r--r-- 1 runner docker  3148 Nov  4 13:41 05c_pre.qmd\n-rw-r--r-- 1 runner docker 20184 Nov  4 13:41 06_ssa.qmd\n-rwxr-xr-x 1 runner docker 25643 Nov  4 13:40 07_llvm.notebook\n-rw-r--r-- 1 runner docker 28320 Nov  4 13:41 08_classic_loop_ops.html\n-rw-r--r-- 1 runner docker  5691 Nov  4 13:41 08_classic_loop_ops.qmd\n-rwxr-xr-x 1 runner docker 32457 Nov  4 13:41 09_poly.qmd\ndrwxr-xr-x 3 runner docker  4096 Nov  4 13:40 09_poly_files\n-rw-r--r-- 1 runner docker   302 Nov  4 13:41 100_mlir.qmd\n-rw-r--r-- 1 runner docker 21170 Nov  4 13:41 110_whole_program.html\n-rw-r--r-- 1 runner docker   320 Nov  4 13:41 110_whole_program.qmd\n-rw-r--r-- 1 runner docker 21228 Nov  4 13:41 12_memory.html\n-rw-r--r-- 1 runner docker   316 Nov  4 13:41 12_memory.qmd\n-rw-r--r-- 1 runner docker 79398 Nov  4 13:41 13_dynamic_compilers.html\n-rw-r--r-- 1 runner docker 16077 Nov  4 13:41 13_dynamic_compilers.qmd\n-rw-r--r-- 1 runner docker 10117 Nov  4 13:41 14_gpu_compilers.qmd\n-rw-r--r-- 1 runner docker  4682 Nov  4 13:40 a.json\n-rw-r--r-- 1 runner docker   248 Nov  4 13:40 a.ts\ndrwxr-xr-x 2 runner docker  4096 Nov  4 13:40 df\n-rw-r--r-- 1 runner docker 27504 Nov  4 13:41 diverg.qmd\n-rw-r--r-- 1 runner docker  4983 Nov  4 13:41 diverg1.qmd\n-rw-r--r-- 1 runner docker  4595 Nov  4 13:40 errors\n-rw-r--r-- 1 runner docker  3623 Nov  4 13:40 foo.ll\n-rw-r--r-- 1 runner docker  2296 Nov  4 13:40 identity.bc\ndrwxr-xr-x 2 runner docker  4096 Nov  4 13:40 images\n-rw-r--r-- 1 runner docker 30815 Nov  4 13:41 junk.html\n-rw-r--r-- 1 runner docker  2134 Nov  4 13:41 junk.qmd\n-rw-r--r-- 1 runner docker   905 Nov  4 13:40 junk.txt\n-rw-r--r-- 1 runner docker 51734 Nov  4 13:41 llvm.html\n-rw-r--r-- 1 runner docker 20713 Nov  4 13:41 llvm.qmd\n-rw-r--r-- 1 runner docker  7641 Nov  4 13:40 llvm.qmd.next\n-rw-r--r-- 1 runner docker 14847 Nov  4 13:41 mem_consistancy.qmd\n-rw-r--r-- 1 runner docker  2260 Nov  4 13:41 mlir.qmd\ndrwxr-xr-x 2 runner docker  4096 Nov  4 13:40 papers\ndrwxr-xr-x 2 runner docker  4096 Nov  4 13:40 ra\n-rw-r--r-- 1 runner docker 39373 Nov  4 13:41 ra-checking.html\n-rw-r--r-- 1 runner docker  8226 Nov  4 13:41 ra-checking.qmd\n-rw-r--r-- 1 runner docker  8014 Nov  4 13:41 register_allocation.qmd\n-rw-r--r-- 1 runner docker 52254 Nov  4 13:41 revealjs_010_compiler_overview.qmd.html\n-rw-r--r-- 1 runner docker 46478 Nov  4 13:41 revealjs_01a_performance_measurement.qmd.html\n-rw-r--r-- 1 runner docker 85290 Nov  4 13:41 revealjs_03_local.qmd.html\n-rw-r--r-- 1 runner docker 62223 Nov  4 13:41 revealjs_04_data_flow.qmd.html\n-rw-r--r-- 1 runner docker 39234 Nov  4 13:41 revealjs_08_classic_loop_ops.qmd.html\n-rw-r--r-- 1 runner docker 33153 Nov  4 13:41 revealjs_110_whole_program.qmd.html\n-rw-r--r-- 1 runner docker 33176 Nov  4 13:41 revealjs_12_memory.qmd.html\n-rw-r--r-- 1 runner docker 77886 Nov  4 13:41 revealjs_13_dynamic_compilers.qmd.html\n-rw-r--r-- 1 runner docker 41999 Nov  4 13:41 revealjs_junk.qmd.html\n-rw-r--r-- 1 runner docker 63025 Nov  4 13:41 revealjs_llvm.qmd.html\n-rw-r--r-- 1 runner docker 49639 Nov  4 13:41 revealjs_ra-checking.qmd.html\n-rw-r--r-- 1 runner docker 22316 Nov  4 13:40 xx",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#print-the-blocks",
    "href": "lectures/02b_bril.html#print-the-blocks",
    "title": "Overview of Bril",
    "section": "print the blocks",
    "text": "print the blocks\n\nimport json \nimport os\nimport subprocess\n\nresult =  subprocess.check_output('bril2json &lt; images/jmp.bril', shell=True)\ntest2json = json.loads(result)\nprint_blocks(test2json)\n\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}\n{'labels': ['somewhere'], 'op': 'jmp'}\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}\nblock somewhere\n{'args': ['v'], 'op': 'print'}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#the-map-label-names-to-blocks",
    "href": "lectures/02b_bril.html#the-map-label-names-to-blocks",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\nfrom collections import OrderedDict\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n\n    The name of the block comes from the label it starts with, if any.\n    Anonymous blocks, which don't start with a label, get an\n    automatically generated name. Blocks in the mapping have their\n    labels removed.\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = f'gen_bk_{len(by_name)}'\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\nfor (name, instrs) in od.items():\n    print (name, instrs)\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#the-cfg-given-the-block-map-pseudo-code",
    "href": "lectures/02b_bril.html#the-cfg-given-the-block-map-pseudo-code",
    "title": "Overview of Bril",
    "section": "the cfg given the block map (pseudo code)",
    "text": "the cfg given the block map (pseudo code)\nout cfg = {} \n# map label -&gt; list of labels the successors of the block\n\nfor i,block in enumerate(blocks)  # blocks is a ordereddict \n    last = block[i]  # last instruction\n    if last is jmp:\n        cfg[block_name] = jmp.dest\n    elif last is br:\n        cfg[block.name] = [ last.if_label, last.else_label]\n    else\n        # fall through\n        cfg[block_name] = blocks[i+1].name  ## special case for last block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#cfg",
    "href": "lectures/02b_bril.html#cfg",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\ndef get_cfg(ordered_blocks):\n    cfg = {}\n\n    labels = list(ordered_blocks.keys())\n\n    for i, (block_name, block) in enumerate(ordered_blocks.items()):\n        last = block[-1]\n        op = last['op']\n\n        if op == 'jmp':\n            cfg[block_name] = last['labels']\n        elif op == 'br':\n            cfg[block_name] = last['labels']\n        else:\n            if i+1 &lt; len(labels):  # last block does not fall through\n                cfg[block_name] = [labels[i+1]]\n            else:\n                cfg[block_name] = []\n    return cfg\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\ncfg = get_cfg(od)\n\nprint(cfg)\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere'], 'somewhere': []}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#graph",
    "href": "lectures/02b_bril.html#graph",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html#homework",
    "href": "lectures/02b_bril.html#homework",
    "title": "Overview of Bril",
    "section": "homework",
    "text": "homework\nDue in 1 week\nYour goal is to get familiar with Bril.\n\nPart 1\nWrite a new benchmark.\nYou can write it by hand, use the TypeScript compiler, or generate it some other way. Try running it with brili.\nUse turnt –save yours.bril to create the test outputs for your new benchmark. (See the Turnt README for details.)\nStart your blog post, talking about your benchmark.\n\npart 2\nWrite a program to analyze or transform Bril programs in some small way. Pick your favorite programming language—there is no “starter code,” so you can start from scratch.\nLoad up a JSON file. You can start with the tiny ones in lectures/images! Read the docs.\nDo something unambitious with it: count the number of add instructions, or add a print instruction before every jump, or whatever. Pick something small and contrived! Use Turnt to test your new tool.\nAlong the way, you will run into problems! Ask questions on github discussions, use open issues and pull requests to describe or fix problems. For example, even super simple benchmarks you might imagine probably can’t be written easily because Bril is too simple. Mention this in discussions, and consider pitching in to help add features.\nThink about how to write a good test, and add to your post describing your work, submit the post on github, and finally add a link to the post in canvas, homework 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Overview of Bril"
    ]
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#how-to-use-bril-with-real-code",
    "href": "lectures/revealjs_02b_bril.qmd.html#how-to-use-bril-with-real-code",
    "title": "Overview of Bril",
    "section": "How to use Bril with real code",
    "text": "How to use Bril with real code\n\nBril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\n\nCode\nimport json\nimport subprocess\nimport os \nimport sys\n\n\n### temp \nout = subprocess.check_output('which python', shell=True)\nprint(out)\nprint('***********************')\n\n# read from a file \nwith open(\"images/add.json\",\"r\") as f:\n    bril_program = json.load(f)\n\n# read from a pipe\n# bril_program = json.load(sys.stdin)\n    \nprint(json.dumps(bril_program, \n    indent=2))"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.-output",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\n\nb'/opt/hostedtoolcache/Python/3.10.15/x64/bin/python\\n'\n***********************\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#formatted",
    "href": "lectures/revealjs_02b_bril.qmd.html#formatted",
    "title": "Overview of Bril",
    "section": "Formatted",
    "text": "Formatted\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\"dest\": \"v0\", \"op\": \"const\",\"type\": \"int\",\"value\": 1},\n        {\"dest\": \"v1\", \"op\": \"const\",\"type\": \"int\",\"value\": 2},\n        {\"dest\": \"v2\", \"op\": \"add\",  \"type\": \"int\",\"args\": [\"v0\",\"v1\"],},\n                       \"op\": \"print\",\"args\": [ \"v2\"],}],\n      \"name\": \"main\",\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#getting-started",
    "href": "lectures/revealjs_02b_bril.qmd.html#getting-started",
    "title": "Overview of Bril",
    "section": "getting started",
    "text": "getting started\nlinks:\n\nLanguage specification\ngithub site"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "title": "Overview of Bril",
    "section": "step 1 clone the bril repo on a linux or wsl machine",
    "text": "step 1 clone the bril repo on a linux or wsl machine\ngit clone https://github.com/sampsyo/bril.git"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-2-support-packages",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-2-support-packages",
    "title": "Overview of Bril",
    "section": "step 2 support packages",
    "text": "step 2 support packages\n\ndeno is the runtime for typescript/javascript\n\ncurl -fsSL https://deno.land/install.sh | sh\non my ubuntu machine ‘sudo snap install deno’ also worked\nyou may need to add $HOME/.deno/bin to your $PATH.\n\nflit a python package manager\n\npython3 -m pip install flit"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "title": "Overview of Bril",
    "section": "step 3 install the bril interpreter, and the typescript to bril compiler",
    "text": "step 3 install the bril interpreter, and the typescript to bril compiler\ncd bril\ndeno install brili.ts \ndeno install --allow-env --allow-read ts2bril.ts"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#running-the-interpreter",
    "href": "lectures/revealjs_02b_bril.qmd.html#running-the-interpreter",
    "title": "Overview of Bril",
    "section": "running the interpreter",
    "text": "running the interpreter\nbrili &lt;images/add.json\nbrili -p &lt;images/add.json\nthe -p flag turns on profiling"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#text-to-json-and-back",
    "href": "lectures/revealjs_02b_bril.qmd.html#text-to-json-and-back",
    "title": "Overview of Bril",
    "section": "text to json and back",
    "text": "text to json and back\nThere are programs bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\ninstall text tools\ncd bril-txt\nflit install --symlink --user\nrun json to text\nbril2txt &lt; images/add.json"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#connect-tools-via-pipes",
    "href": "lectures/revealjs_02b_bril.qmd.html#connect-tools-via-pipes",
    "title": "Overview of Bril",
    "section": "connect tools via pipes",
    "text": "connect tools via pipes\ncat images/add.json'\nbril2txt &lt; images/add.json | bril2json"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#other-tools",
    "href": "lectures/revealjs_02b_bril.qmd.html#other-tools",
    "title": "Overview of Bril",
    "section": "Other tools",
    "text": "Other tools\nThere is also a fast interpreter written in Rust see docs for installation"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#turnt-tiny-unified-runner-and-tester",
    "href": "lectures/revealjs_02b_bril.qmd.html#turnt-tiny-unified-runner-and-tester",
    "title": "Overview of Bril",
    "section": "turnt Tiny unified runner and tester",
    "text": "turnt Tiny unified runner and tester\nBril uses turnt as a test tool\nTurnt is a simple snapshot testing tool inspired by LLVM’s lit. It’s good for testing things that translate text files to other text files, like compilers. The idea is that each test is one input file, and you want to run a command and check that it still matches the saved output file.\npip install –user turnt\nAs you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (can be wsl) machine"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#gen-cfg",
    "href": "lectures/revealjs_02b_bril.qmd.html#gen-cfg",
    "title": "Overview of Bril",
    "section": "Gen CFG",
    "text": "Gen CFG\nLets write a sample program - that generates the cfg\nHow would you do that?\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}\n\nI’ll do this in two steps\n\nfind all the basic blocks\nadd all the cfg edges\n\nYou can also do this in a single step, adding cfg edges as soon as you reach the successor node."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#basic-blocks-from-a-list-of-instructions-",
    "href": "lectures/revealjs_02b_bril.qmd.html#basic-blocks-from-a-list-of-instructions-",
    "title": "Overview of Bril",
    "section": "basic blocks from a list of instructions-",
    "text": "basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\n\nin: list of instrs \nout: list of lists of instrs \n \nblocks = []\ncurr_block = []\nfor each instr in list \n    if the instruction is not a label put it on curr_block\n    if instr is a label or terminator \n       put curr_block on blocks\n       curr_block = []\n \n if curr_block is not empty add it to blocks\n return blocks \ntwo labels in a row do not need another block"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-2-add-edges",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-2-add-edges",
    "title": "Overview of Bril",
    "section": "step 2 add edges",
    "text": "step 2 add edges\nfind cfg: in: is bril program in json \nfor each function find the list of basic blocks\nfor each basic block\n   get last_instr \n   if it is a terminator  br/jmp/ret \n     add edge from current block to successor  \n    --- what do we want to do with call? \n   else it is a fall through\n      add edge to next block\n\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we handle fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case\nwhat happens if try to delete the terminator (because the block never executes)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#code",
    "href": "lectures/revealjs_02b_bril.qmd.html#code",
    "title": "Overview of Bril",
    "section": "code",
    "text": "code\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#ill-use-a-generator",
    "href": "lectures/revealjs_02b_bril.qmd.html#ill-use-a-generator",
    "title": "Overview of Bril",
    "section": "I’ll use a generator",
    "text": "I’ll use a generator\nIn Python, a generator is an iterator that is defined with a function using the yield statement.\n\nProduce items only once\nDo not store all the items in memory\nWhen items from the generator are requested, the function executes until it reaches a yield statement, which produces the next value. Execution then pauses, preserving the function’s state, until the next item is requested."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\n\nCode\ndef print_blocks(bril):\n    \"\"\"Given a Bril program, print out its basic blocks.\n    \"\"\"\n\n\n    func = bril['functions'][0]  # We only process one function.\n    for block in form_blocks(func['instrs']):\n        # Mark the block.\n        leader = block[0]\n        if 'label' in leader:\n            print( f\"block {leader['label']}\")\n            block = block[1:]  # Hide the label\n        else:\n            print('anonymous block:')\n\n        # Print the instructions.\n        for instr in block:\n            print(instr)\n\nprint_blocks(bril_program)\n\n\n\nthis test program has one block so pretty easy"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks-output",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-try-a-second-example-with-a-jmp",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-try-a-second-example-with-a-jmp",
    "title": "Overview of Bril",
    "section": "lets try a second example with a jmp",
    "text": "lets try a second example with a jmp\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#running-commands-inside-python",
    "href": "lectures/revealjs_02b_bril.qmd.html#running-commands-inside-python",
    "title": "Overview of Bril",
    "section": "running commands inside python",
    "text": "running commands inside python\nGitHub Copilot: subprocess.check_output is a function in Python’s subprocess module that runs a command with arguments and returns its output as a byte string. If the command exits with a non-zero exit status, it raises a CalledProcessError, which includes the exit status and output of the command. This function is useful for capturing the output of a command for further processing in Python."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#print-the-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#print-the-blocks",
    "title": "Overview of Bril",
    "section": "print the blocks",
    "text": "print the blocks\n\n\nCode\nimport json \nimport os\nimport subprocess\n\nresult =  subprocess.check_output('bril2json &lt; images/jmp.bril', shell=True)\ntest2json = json.loads(result)\nprint_blocks(test2json)\n\n\n\n\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}\n{'labels': ['somewhere'], 'op': 'jmp'}\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}\nblock somewhere\n{'args': ['v'], 'op': 'print'}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\n\nCode\nfrom collections import OrderedDict\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n\n    The name of the block comes from the label it starts with, if any.\n    Anonymous blocks, which don't start with a label, get an\n    automatically generated name. Blocks in the mapping have their\n    labels removed.\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = f'gen_bk_{len(by_name)}'\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\nfor (name, instrs) in od.items():\n    print (name, instrs)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks-output",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-cfg-given-the-block-map-pseudo-code",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-cfg-given-the-block-map-pseudo-code",
    "title": "Overview of Bril",
    "section": "the cfg given the block map (pseudo code)",
    "text": "the cfg given the block map (pseudo code)\nout cfg = {} \n# map label -&gt; list of labels the successors of the block\n\nfor i,block in enumerate(blocks)  # blocks is a ordereddict \n    last = block[i]  # last instruction\n    if last is jmp:\n        cfg[block_name] = jmp.dest\n    elif last is br:\n        cfg[block.name] = [ last.if_label, last.else_label]\n    else\n        # fall through\n        cfg[block_name] = blocks[i+1].name  ## special case for last block"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#cfg",
    "href": "lectures/revealjs_02b_bril.qmd.html#cfg",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\n\nCode\ndef get_cfg(ordered_blocks):\n    cfg = {}\n\n    labels = list(ordered_blocks.keys())\n\n    for i, (block_name, block) in enumerate(ordered_blocks.items()):\n        last = block[-1]\n        op = last['op']\n\n        if op == 'jmp':\n            cfg[block_name] = last['labels']\n        elif op == 'br':\n            cfg[block_name] = last['labels']\n        else:\n            if i+1 &lt; len(labels):  # last block does not fall through\n                cfg[block_name] = [labels[i+1]]\n            else:\n                cfg[block_name] = []\n    return cfg\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\ncfg = get_cfg(od)\n\nprint(cfg)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#cfg-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#cfg-output",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere'], 'somewhere': []}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#graph",
    "href": "lectures/revealjs_02b_bril.qmd.html#graph",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#graph-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#graph-output",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#homework",
    "href": "lectures/revealjs_02b_bril.qmd.html#homework",
    "title": "Overview of Bril",
    "section": "homework",
    "text": "homework\nDue in 1 week\nYour goal is to get familiar with Bril."
  },
  {
    "objectID": "lectures/04_data_flow.html",
    "href": "lectures/04_data_flow.html",
    "title": "Data Flow",
    "section": "",
    "text": "The material in these slides have been taken from Lecture Notes in Static Analysis” (Sec.6), by Michael I. Schwartzbach, “Principles of Program Analysis”, Chapter 6, by Niesen et al, and from Miachel Schwartzbach’s “Lecture notes in Static Analysis”, Chapter 6, First Section.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#in-and-out",
    "href": "lectures/04_data_flow.html#in-and-out",
    "title": "Data Flow",
    "section": "IN and OUT",
    "text": "IN and OUT",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#equations",
    "href": "lectures/04_data_flow.html#equations",
    "title": "Data Flow",
    "section": "EQUATIONS",
    "text": "EQUATIONS",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#liveness-example",
    "href": "lectures/04_data_flow.html#liveness-example",
    "title": "Data Flow",
    "section": "Liveness Example",
    "text": "Liveness Example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#summary-by-basic-blocks",
    "href": "lectures/04_data_flow.html#summary-by-basic-blocks",
    "title": "Data Flow",
    "section": "Summary by basic blocks",
    "text": "Summary by basic blocks\nThe dataflow equations used for a given basic block b and exiting block final in live variable analysis:\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b\nThe in-state of a block is the set of variables that are live at the start of the block. Its out-state is the set of variables that are live at the end of it. The out-state is the union of the in-states of the block’s successors. The transfer function of a statement is applied by making the variables that are written dead, then making the variables that are read live.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#equations-1",
    "href": "lectures/04_data_flow.html#equations-1",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n$\n\\[\\begin{aligned}\n  & \\operatorname{IN}[b]=\\operatorname{GEN}[b] \\cup\\left(\\operatorname{OUT}[b]-\\operatorname{KILL}[s]\\right) \\\\\n  & \\operatorname{OUT}[\\text { final }]=\\emptyset \\\\\n  & \\operatorname{OUT}[b]=\\bigcup_{p \\in s u c c[b]} \\operatorname{IN}[p] \\\\\n  & \\operatorname{GEN}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\left\\{x_1, \\ldots, x_n\\right\\} \\\\\n  & \\operatorname{KILL}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\{y\\}\n\n\\end{aligned}\\]\n$",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#an-example",
    "href": "lectures/04_data_flow.html#an-example",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nb1: \na = 3\nb = 5\nd = 4\nx = 100\nif a &gt; b then \n\n   b2: \n    c = a + b\n    d = 2 \n\nb3: \n   c = 4\n   return b*d +c\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b\n\nGEN[b1] = []         kill[b1] = [a,b,d,x]\nGEN[b2] = [a,b]      kill[b2] = [c,d]\nGEN[b3] = [b,d]      Kill[b3] = [c]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#processing",
    "href": "lectures/04_data_flow.html#processing",
    "title": "Data Flow",
    "section": "processing",
    "text": "processing\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\nGEN[b1] = []         kill[b1] = [a,b,d,x]\nGEN[b2] = [a,b]      kill[b2] = [c,d]\nGEN[b3] = [b,d]      Kill[b3] = [c]\nblock OUT       IN   Next IN        worklist  \nb3    []        []    [b,d]           b1,b2\nb1    [b,d]     []    []              b2\nb2    [b,d]     []    [a,b]           b1\nb1    [a,b,d]   []    []              empty",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#frameworks",
    "href": "lectures/04_data_flow.html#frameworks",
    "title": "Data Flow",
    "section": "frameworks",
    "text": "frameworks",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#common-properties-direction",
    "href": "lectures/04_data_flow.html#common-properties-direction",
    "title": "Data Flow",
    "section": "common properties Direction",
    "text": "common properties Direction\nDirection\n\n\nbackward\n\nliveness\nvery busy expressions\n\nOUT is a function of the IN of successors\n\nforward\n\nreaching Defs\nAvailable Expressions\n\nIN is a function of the OUT of Preds",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#common-properties-operation",
    "href": "lectures/04_data_flow.html#common-properties-operation",
    "title": "Data Flow",
    "section": "common properties Operation",
    "text": "common properties Operation\n\n\nMay union\n\nLiveness\nReaching defs\n\nmerge using intersection\n\nmust\n\nvery busy expressions\nAvailable Expressions\n\nmerge using union",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#transfer-functions-with-a-block-or-for-one-statement",
    "href": "lectures/04_data_flow.html#transfer-functions-with-a-block-or-for-one-statement",
    "title": "Data Flow",
    "section": "transfer functions with a block or for one statement",
    "text": "transfer functions with a block or for one statement\nForward\n\\[ \\text{OUT}_b = f_b(\\text{IN}_b) \\]\nBackward\n\\[ \\text{IN}_b = f_b(\\text{OUT}_b) \\]\nliveness IN = (OUT-def) union (args)\nVery busy expressions IN = (OUT - exprs(def)) union (this expr)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#an-example-1",
    "href": "lectures/04_data_flow.html#an-example-1",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nif b1 \n    while b2 { x = a1}\nelse \n    while b3 { x = a2}\nx = a3\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\nreaching defs - a definition of a variable v at pv reaches a point p if there is a path from pv tp p and v is not redefined along the path",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#equations-2",
    "href": "lectures/04_data_flow.html#equations-2",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\n\n\n\\[ \\small \\text{IN}_p = \\bigcup \\text{OUT}_{ps}, ps \\in pred(p)\\]\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\n\n\n\\[ \\small \\text{OUT}_p = (\\text{IN)}_p - defs(v)) \\cup \\{ (p,v) \\}  \\]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#complexity",
    "href": "lectures/04_data_flow.html#complexity",
    "title": "Data Flow",
    "section": "complexity",
    "text": "complexity",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#graph-of-equations",
    "href": "lectures/04_data_flow.html#graph-of-equations",
    "title": "Data Flow",
    "section": "graph of equations",
    "text": "graph of equations\n\n\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#reverse-postorder",
    "href": "lectures/04_data_flow.html#reverse-postorder",
    "title": "Data Flow",
    "section": "Reverse Postorder",
    "text": "Reverse Postorder\nvisit successors first (need an ordering)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#order",
    "href": "lectures/04_data_flow.html#order",
    "title": "Data Flow",
    "section": "order",
    "text": "order\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n\n\n\norder b5 b6 b3 b3 b2 b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#implement",
    "href": "lectures/04_data_flow.html#implement",
    "title": "Data Flow",
    "section": "implement",
    "text": "implement\nkeep two data structures\n\nC current list\nP set of pending lists\n\ninitially C is a reverse post order sort of the nodes\nprocess each element of C\nwhen we find a changed add it to P\nWhen C is empty, sort P in reverse post order and move to C",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#representing-sets",
    "href": "lectures/04_data_flow.html#representing-sets",
    "title": "Data Flow",
    "section": "representing sets",
    "text": "representing sets\nwe keep doing union and intersection for sets, which are sparse\ncompilers generally use bit vectors",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#pseudo-code",
    "href": "lectures/04_data_flow.html#pseudo-code",
    "title": "Data Flow",
    "section": "pseudo code",
    "text": "pseudo code\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#loops",
    "href": "lectures/04_data_flow.html#loops",
    "title": "Data Flow",
    "section": "loops",
    "text": "loops\nThis algorithm has no problems with loops!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#homework-3",
    "href": "lectures/04_data_flow.html#homework-3",
    "title": "Data Flow",
    "section": "homework 3",
    "text": "homework 3\nImplement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it. use a simple ordering- Not necessary to use reverse post order\nas always think about testing",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Data Flow"
    ]
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#in-and-out",
    "href": "lectures/revealjs_04_data_flow.qmd.html#in-and-out",
    "title": "Data Flow",
    "section": "IN and OUT",
    "text": "IN and OUT"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#equations",
    "href": "lectures/revealjs_04_data_flow.qmd.html#equations",
    "title": "Data Flow",
    "section": "EQUATIONS",
    "text": "EQUATIONS"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#liveness-example",
    "href": "lectures/revealjs_04_data_flow.qmd.html#liveness-example",
    "title": "Data Flow",
    "section": "Liveness Example",
    "text": "Liveness Example"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#summary-by-basic-blocks",
    "href": "lectures/revealjs_04_data_flow.qmd.html#summary-by-basic-blocks",
    "title": "Data Flow",
    "section": "Summary by basic blocks",
    "text": "Summary by basic blocks\nThe dataflow equations used for a given basic block b and exiting block final in live variable analysis:\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b\nThe in-state of a block is the set of variables that are live at the start of the block. Its out-state is the set of variables that are live at the end of it. The out-state is the union of the in-states of the block’s successors. The transfer function of a statement is applied by making the variables that are written dead, then making the variables that are read live."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#equations-1",
    "href": "lectures/revealjs_04_data_flow.qmd.html#equations-1",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n$\n\\[\\begin{aligned}\n  & \\operatorname{IN}[b]=\\operatorname{GEN}[b] \\cup\\left(\\operatorname{OUT}[b]-\\operatorname{KILL}[s]\\right) \\\\\n  & \\operatorname{OUT}[\\text { final }]=\\emptyset \\\\\n  & \\operatorname{OUT}[b]=\\bigcup_{p \\in s u c c[b]} \\operatorname{IN}[p] \\\\\n  & \\operatorname{GEN}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\left\\{x_1, \\ldots, x_n\\right\\} \\\\\n  & \\operatorname{KILL}\\left[b: y \\leftarrow f\\left(x_1, \\cdots, x_n\\right)\\right]=\\{y\\}\n\n\\end{aligned}\\]\n$"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#an-example",
    "href": "lectures/revealjs_04_data_flow.qmd.html#an-example",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nb1: \na = 3\nb = 5\nd = 4\nx = 100\nif a &gt; b then \n\n   b2: \n    c = a + b\n    d = 2 \n\nb3: \n   c = 4\n   return b*d +c\n\\(\\operatorname{GEN}[b]\\) - The set of variables that are used in b before any assignment in the same basic block.\n\\(\\operatorname{KILL}[b]\\) - The set of variables that are assigned a value in b"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#processing",
    "href": "lectures/revealjs_04_data_flow.qmd.html#processing",
    "title": "Data Flow",
    "section": "processing",
    "text": "processing\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nb1--&gt; b2\nb1 --&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\nGEN[b1] = []         kill[b1] = [a,b,d,x]\nGEN[b2] = [a,b]      kill[b2] = [c,d]\nGEN[b3] = [b,d]      Kill[b3] = [c]\nblock OUT       IN   Next IN        worklist  \nb3    []        []    [b,d]           b1,b2\nb1    [b,d]     []    []              b2\nb2    [b,d]     []    [a,b]           b1\nb1    [a,b,d]   []    []              empty"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#frameworks",
    "href": "lectures/revealjs_04_data_flow.qmd.html#frameworks",
    "title": "Data Flow",
    "section": "frameworks",
    "text": "frameworks"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#common-properties-direction",
    "href": "lectures/revealjs_04_data_flow.qmd.html#common-properties-direction",
    "title": "Data Flow",
    "section": "common properties Direction",
    "text": "common properties Direction\nDirection\n\n\nbackward\n\nliveness\nvery busy expressions\n\nOUT is a function of the IN of successors\n\nforward\n\nreaching Defs\nAvailable Expressions\n\nIN is a function of the OUT of Preds"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#common-properties-operation",
    "href": "lectures/revealjs_04_data_flow.qmd.html#common-properties-operation",
    "title": "Data Flow",
    "section": "common properties Operation",
    "text": "common properties Operation\n\n\nMay union\n\nLiveness\nReaching defs\n\nmerge using intersection\n\nmust\n\nvery busy expressions\nAvailable Expressions\n\nmerge using union"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#transfer-functions-with-a-block-or-for-one-statement",
    "href": "lectures/revealjs_04_data_flow.qmd.html#transfer-functions-with-a-block-or-for-one-statement",
    "title": "Data Flow",
    "section": "transfer functions with a block or for one statement",
    "text": "transfer functions with a block or for one statement\nForward\n\\[ \\text{OUT}_b = f_b(\\text{IN}_b) \\]\nBackward\n\\[ \\text{IN}_b = f_b(\\text{OUT}_b) \\]\nliveness IN = (OUT-def) union (args)\nVery busy expressions IN = (OUT - exprs(def)) union (this expr)"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#an-example-1",
    "href": "lectures/revealjs_04_data_flow.qmd.html#an-example-1",
    "title": "Data Flow",
    "section": "an example",
    "text": "an example\nif b1 \n    while b2 { x = a1}\nelse \n    while b3 { x = a2}\nx = a3\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\nreaching defs - a definition of a variable v at pv reaches a point p if there is a path from pv tp p and v is not redefined along the path"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#equations-2",
    "href": "lectures/revealjs_04_data_flow.qmd.html#equations-2",
    "title": "Data Flow",
    "section": "equations",
    "text": "equations\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD;\nb1[\"p1: if b1\"]\nb2[\"p2: use b3\"]\nb3[\"p3: x = a2\"]\nb4[\"p4: use b2\"]\nb5[\"p5: x = a1\"]\nb6[\"p6: x = a3\"]\nb1--&gt; b4\nb1 --&gt; b2\n\n\nb2--&gt; b6\nb2--&gt; b3\n\nb3--&gt; b2\nb5--&gt; b4\n\nb4--&gt; b5\nb4--&gt; b6\n\n\n\n\n\n\n\n\n\n\\[ \\small \\text{IN}_p = \\bigcup \\text{OUT}_{ps}, ps \\in pred(p)\\]\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\n\n\n\\[ \\small \\text{OUT}_p = (\\text{IN)}_p - defs(v)) \\cup \\{ (p,v) \\}  \\]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#complexity",
    "href": "lectures/revealjs_04_data_flow.qmd.html#complexity",
    "title": "Data Flow",
    "section": "complexity",
    "text": "complexity"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#graph-of-equations",
    "href": "lectures/revealjs_04_data_flow.qmd.html#graph-of-equations",
    "title": "Data Flow",
    "section": "graph of equations",
    "text": "graph of equations\n\n\nIN[1] = empty\nIN[2] = OUT[1] union OUT[3]\nIN[3] = OUT[2]\nIN[4] = OUT[1] union OUT[5]\nIN[5] = OUT[4]\nIN[6] = OUT[2] union OUT[4]\nOUT[1] = IN[1]\nOUT[2] = IN[2]\nOUT[3] = (IN[3] -{3,5,6}) union {3}\nOUT[4] = IN[4]\nOUT[5] = (IN[5] - {3,5,6}) union {5}\nOUT[6] = (IN[6] - {3,5,6}) union {6}\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#reverse-postorder",
    "href": "lectures/revealjs_04_data_flow.qmd.html#reverse-postorder",
    "title": "Data Flow",
    "section": "Reverse Postorder",
    "text": "Reverse Postorder\nvisit successors first (need an ordering)"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#order",
    "href": "lectures/revealjs_04_data_flow.qmd.html#order",
    "title": "Data Flow",
    "section": "order",
    "text": "order\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB;\nIN1--&gt;OUT1\nOUT1--&gt;IN2\nOUT1--&gt;IN4\nOUT3--&gt; IN2\nOUT2--&gt; IN3\nOUT5--&gt; IN4\nOUT4--&gt; IN5\nOUT2--&gt; IN6\nOUT4--&gt; IN6\nIN2--&gt; OUT2\nIN3--&gt; OUT3\nIN4--&gt; OUT4\nIN5--&gt; OUT5\nIN6--&gt; OUT6\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[b1-1]--&gt; b4[b4-4]\nb1--&gt; b2[b2-2]\nb4--&gt; b6[b6-5]\nb4--&gt; b5[b5-6]\nb2--&gt; b3[b3-3]\n\n\n\n\n\n\n\norder b5 b6 b3 b3 b2 b1"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#implement",
    "href": "lectures/revealjs_04_data_flow.qmd.html#implement",
    "title": "Data Flow",
    "section": "implement",
    "text": "implement\nkeep two data structures\n\nC current list\nP set of pending lists\n\ninitially C is a reverse post order sort of the nodes\nprocess each element of C\nwhen we find a changed add it to P\nWhen C is empty, sort P in reverse post order and move to C"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#representing-sets",
    "href": "lectures/revealjs_04_data_flow.qmd.html#representing-sets",
    "title": "Data Flow",
    "section": "representing sets",
    "text": "representing sets\nwe keep doing union and intersection for sets, which are sparse\ncompilers generally use bit vectors"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#pseudo-code",
    "href": "lectures/revealjs_04_data_flow.qmd.html#pseudo-code",
    "title": "Data Flow",
    "section": "pseudo code",
    "text": "pseudo code\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#loops",
    "href": "lectures/revealjs_04_data_flow.qmd.html#loops",
    "title": "Data Flow",
    "section": "loops",
    "text": "loops\nThis algorithm has no problems with loops!"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#homework-3",
    "href": "lectures/revealjs_04_data_flow.qmd.html#homework-3",
    "title": "Data Flow",
    "section": "homework 3",
    "text": "homework 3\nImplement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it. use a simple ordering- Not necessary to use reverse post order\nas always think about testing"
  },
  {
    "objectID": "lectures/03_local.html",
    "href": "lectures/03_local.html",
    "title": "Local Analysis & Optimization",
    "section": "",
    "text": "and anyone who forgot hw0, still needed!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "href": "lectures/03_local.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "title": "Local Analysis & Optimization",
    "section": "",
    "text": "and anyone who forgot hw0, still needed!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#llvm-control-flow-graph",
    "href": "lectures/03_local.html#llvm-control-flow-graph",
    "title": "Local Analysis & Optimization",
    "section": "llvm control flow graph",
    "text": "llvm control flow graph\ncommands to draw a dot list of a c file from llvm\n clang -S -emit-llvm images/identity.c -o foo.ll \n opt -dot-cfg foo.ll -disable-output -enable-new-pm=0\nvoid identity(int **a, int N)\n{\n    int i, j;\n    for (i = 0; i &lt; N; i++)\n    {\n        for (j = 0; j &lt; N; j++)\n        {\n            a[i][j] = 0;\n        }\n    }\n    for (i = 0; i &lt; N; i++)\n    {\n        a[i][i] = 1;\n    }\n}\n\ndigraph \"CFG for 'identity' function\" {\n    label=\"CFG for 'identity' function\";\n\n    Node0x12c5490 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%2:\\l  %3 = alloca i32**, align 8\\l  %4 = alloca i32, align 4\\l  %5 = alloca i32, align 4\\l  %6 = alloca i32, align 4\\l  store i32** %0, i32*** %3, align 8\\l  store i32 %1, i32* %4, align 4\\l  store i32 0, i32* %5, align 4\\l  br label %7\\l}\"];\n    Node0x12c5490 -&gt; Node0x12c5da0;\n    Node0x12c5da0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%7:\\l7:                                                \\l  %8 = load i32, i32* %5, align 4\\l  %9 = load i32, i32* %4, align 4\\l  %10 = icmp slt i32 %8, %9\\l  br i1 %10, label %11, label %32\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c5da0:s0 -&gt; Node0x12c5c70;\n    Node0x12c5da0:s1 -&gt; Node0x12c5f40;\n    Node0x12c5c70 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%11:\\l11:                                               \\l  store i32 0, i32* %6, align 4\\l  br label %12\\l}\"];\n    Node0x12c5c70 -&gt; Node0x12c6080;\n    Node0x12c6080 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%12:\\l12:                                               \\l  %13 = load i32, i32* %6, align 4\\l  %14 = load i32, i32* %4, align 4\\l  %15 = icmp slt i32 %13, %14\\l  br i1 %15, label %16, label %28\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c6080:s0 -&gt; Node0x12c62b0;\n    Node0x12c6080:s1 -&gt; Node0x12c6300;\n    Node0x12c62b0 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%16:\\l16:                                               \\l  %17 = load i32**, i32*** %3, align 8\\l  %18 = load i32, i32* %5, align 4\\l  %19 = sext i32 %18 to i64\\l  %20 = getelementptr inbounds i32*, i32** %17, i64 %19\\l  %21 = load i32*, i32** %20, align 8\\l  %22 = load i32, i32* %6, align 4\\l  %23 = sext i32 %22 to i64\\l  %24 = getelementptr inbounds i32, i32* %21, i64 %23\\l  store i32 0, i32* %24, align 4\\l  br label %25\\l}\"];\n    Node0x12c62b0 -&gt; Node0x12c6820;\n    Node0x12c6820 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%25:\\l25:                                               \\l  %26 = load i32, i32* %6, align 4\\l  %27 = add nsw i32 %26, 1\\l  store i32 %27, i32* %6, align 4\\l  br label %12, !llvm.loop !6\\l}\"];\n    Node0x12c6820 -&gt; Node0x12c6080;\n    Node0x12c6300 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%28:\\l28:                                               \\l  br label %29\\l}\"];\n    Node0x12c6300 -&gt; Node0x12c75b0;\n    Node0x12c75b0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%29:\\l29:                                               \\l  %30 = load i32, i32* %5, align 4\\l  %31 = add nsw i32 %30, 1\\l  store i32 %31, i32* %5, align 4\\l  br label %7, !llvm.loop !8\\l}\"];\n    Node0x12c75b0 -&gt; Node0x12c5da0;\n    Node0x12c5f40 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%32:\\l32:                                               \\l  store i32 0, i32* %5, align 4\\l  br label %33\\l}\"];\n    Node0x12c5f40 -&gt; Node0x12c7bd0;\n    Node0x12c7bd0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%33:\\l33:                                               \\l  %34 = load i32, i32* %5, align 4\\l  %35 = load i32, i32* %4, align 4\\l  %36 = icmp slt i32 %34, %35\\l  br i1 %36, label %37, label %49\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c7bd0:s0 -&gt; Node0x12c7e00;\n    Node0x12c7bd0:s1 -&gt; Node0x12c7e50;\n    Node0x12c7e00 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%37:\\l37:                                               \\l  %38 = load i32**, i32*** %3, align 8\\l  %39 = load i32, i32* %5, align 4\\l  %40 = sext i32 %39 to i64\\l  %41 = getelementptr inbounds i32*, i32** %38, i64 %40\\l  %42 = load i32*, i32** %41, align 8\\l  %43 = load i32, i32* %5, align 4\\l  %44 = sext i32 %43 to i64\\l  %45 = getelementptr inbounds i32, i32* %42, i64 %44\\l  store i32 1, i32* %45, align 4\\l  br label %46\\l}\"];\n    Node0x12c7e00 -&gt; Node0x12c8400;\n    Node0x12c8400 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%46:\\l46:                                               \\l  %47 = load i32, i32* %5, align 4\\l  %48 = add nsw i32 %47, 1\\l  store i32 %48, i32* %5, align 4\\l  br label %33, !llvm.loop !9\\l}\"];\n    Node0x12c8400 -&gt; Node0x12c7bd0;\n    Node0x12c7e50 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%49:\\l49:                                               \\l  ret void\\l}\"];\n}\n\n\n\n\n\n\nCFG for 'identity' function\n\nCFG for 'identity' function\n\n\nNode0x12c5490\n\n%2:\n %3 = alloca i32**, align 8\n %4 = alloca i32, align 4\n %5 = alloca i32, align 4\n %6 = alloca i32, align 4\n store i32** %0, i32*** %3, align 8\n store i32 %1, i32* %4, align 4\n store i32 0, i32* %5, align 4\n br label %7\n\n\n\nNode0x12c5da0\n\n%7:\n7: \n %8 = load i32, i32* %5, align 4\n %9 = load i32, i32* %4, align 4\n %10 = icmp slt i32 %8, %9\n br i1 %10, label %11, label %32\n\nT\n\nF\n\n\n\nNode0x12c5490-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c5c70\n\n%11:\n11: \n store i32 0, i32* %6, align 4\n br label %12\n\n\n\nNode0x12c5da0:s0-&gt;Node0x12c5c70\n\n\n\n\n\nNode0x12c5f40\n\n%32:\n32: \n store i32 0, i32* %5, align 4\n br label %33\n\n\n\nNode0x12c5da0:s1-&gt;Node0x12c5f40\n\n\n\n\n\nNode0x12c6080\n\n%12:\n12: \n %13 = load i32, i32* %6, align 4\n %14 = load i32, i32* %4, align 4\n %15 = icmp slt i32 %13, %14\n br i1 %15, label %16, label %28\n\nT\n\nF\n\n\n\nNode0x12c5c70-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c7bd0\n\n%33:\n33: \n %34 = load i32, i32* %5, align 4\n %35 = load i32, i32* %4, align 4\n %36 = icmp slt i32 %34, %35\n br i1 %36, label %37, label %49\n\nT\n\nF\n\n\n\nNode0x12c5f40-&gt;Node0x12c7bd0\n\n\n\n\n\nNode0x12c62b0\n\n%16:\n16: \n %17 = load i32**, i32*** %3, align 8\n %18 = load i32, i32* %5, align 4\n %19 = sext i32 %18 to i64\n %20 = getelementptr inbounds i32*, i32** %17, i64 %19\n %21 = load i32*, i32** %20, align 8\n %22 = load i32, i32* %6, align 4\n %23 = sext i32 %22 to i64\n %24 = getelementptr inbounds i32, i32* %21, i64 %23\n store i32 0, i32* %24, align 4\n br label %25\n\n\n\nNode0x12c6080:s0-&gt;Node0x12c62b0\n\n\n\n\n\nNode0x12c6300\n\n%28:\n28: \n br label %29\n\n\n\nNode0x12c6080:s1-&gt;Node0x12c6300\n\n\n\n\n\nNode0x12c6820\n\n%25:\n25: \n %26 = load i32, i32* %6, align 4\n %27 = add nsw i32 %26, 1\n store i32 %27, i32* %6, align 4\n br label %12, !llvm.loop !6\n\n\n\nNode0x12c62b0-&gt;Node0x12c6820\n\n\n\n\n\nNode0x12c75b0\n\n%29:\n29: \n %30 = load i32, i32* %5, align 4\n %31 = add nsw i32 %30, 1\n store i32 %31, i32* %5, align 4\n br label %7, !llvm.loop !8\n\n\n\nNode0x12c6300-&gt;Node0x12c75b0\n\n\n\n\n\nNode0x12c6820-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c75b0-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c7e00\n\n%37:\n37: \n %38 = load i32**, i32*** %3, align 8\n %39 = load i32, i32* %5, align 4\n %40 = sext i32 %39 to i64\n %41 = getelementptr inbounds i32*, i32** %38, i64 %40\n %42 = load i32*, i32** %41, align 8\n %43 = load i32, i32* %5, align 4\n %44 = sext i32 %43 to i64\n %45 = getelementptr inbounds i32, i32* %42, i64 %44\n store i32 1, i32* %45, align 4\n br label %46\n\n\n\nNode0x12c7bd0:s0-&gt;Node0x12c7e00\n\n\n\n\n\nNode0x12c7e50\n\n%49:\n49: \n ret void\n\n\n\nNode0x12c7bd0:s1-&gt;Node0x12c7e50\n\n\n\n\n\nNode0x12c8400\n\n%46:\n46: \n %47 = load i32, i32* %5, align 4\n %48 = add nsw i32 %47, 1\n store i32 %48, i32* %5, align 4\n br label %33, !llvm.loop !9\n\n\n\nNode0x12c7e00-&gt;Node0x12c8400\n\n\n\n\n\nNode0x12c8400-&gt;Node0x12c7bd0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#flavors-of-optimization",
    "href": "lectures/03_local.html#flavors-of-optimization",
    "title": "Local Analysis & Optimization",
    "section": "flavors of optimization",
    "text": "flavors of optimization\nI want to separate 3 flavors of optimization.\n\nlocal meaning within one basic block\nglobal meaning within one function (not really global)\ninter-procedural over the entire program\n\n\nUsually an optimization takes time that is more then linear in some property, For example a local optimization might take time \\(n^2\\) in the number of instructions in the block. a global optimization might take much longer, and an inter-procedural longer still. To keep compile time reasonable many compilers limit the number of global optimizations and skip inter-procedural optimizations. As a consequence many more optimizations get published but not used in production.\n\nWhen would running an optimization speedup compilation?\nFor a local optimization, instructions within a block are ordered, so it makes sense to talk about instructions coming before or after others.\nFor a global optimization, two instructions are ordered by a path from one block to another and different paths through the program give different orders.\n\nOne special case is JIT (just in time) compilers, where programs get compiled at the start of execution. GPU compilers (and java compilers) look like this. They may use run-time information to decide of recompiling a function is a good idea. This is called Hotspot compiling. Some JIT compilers use hot/cold compiling, where they only run the fancy compiler on basic blocks that are hot , i.e., execute a lot.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\n\n\n\n\n\n\n\n\nWe are going to consider several versions of trivial dead code elimination. Trivial because we are going to hold off on control flow related optimizations till later. Sometimes people call this DCE or trivial DCE.\n\nFor each case, we start by defining what we mean by dead code.\nexample 1\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;\n  d: int = add a b;\n  print d;\n}\nWhat instruction is dead? (meaning get the same answer if we delete the instruction) What is your definition? Is this meaning of dead code local or global?\n\nWhy would you ever have dead code in a program? One reason is that have DCE as a separate pass means other optimizations do not have to clean up.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels do not write a variable so they do not get deleted as well.\n\nWhat is the pseudo code to find dead instructions using this definition?\n. . .\nused = empty set \nfor instr in func \n   used += instr.args \nfor instd in func\n    if instr has a dest and dest in not in used \n       delete instr\n\nexample 2\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;  \n  d: int = add a b;\n  e: int = add c d; \n  print d;\n}\n. . .\nThe code so far only deletes one instruction, but we would like to get rid of two. Instruction c should also be dead. How do we change the definition",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#iterating-till-convergence",
    "href": "lectures/03_local.html#iterating-till-convergence",
    "title": "Local Analysis & Optimization",
    "section": "iterating till convergence",
    "text": "iterating till convergence\nwhile changes:\n       run one pass of tdce above",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "href": "lectures/03_local.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "title": "Local Analysis & Optimization",
    "section": "what would be faster? What is some pseudo code for the change",
    "text": "what would be faster? What is some pseudo code for the change\n. . .\n  find all the variables that are used in more then one block\n  for each block b \n     used = all variables used in more then one block\n     walk backwards over the instruction in the block\n     for each instruction is dest in used?\n        yes - remove dest from used, add arguments to used \n        no  - instruction is dead \n\nfinding all the variables used in more then one block might be expensive\n\nexample 3\n@main {\n  a: int = const 4;\n  a: int = const 200;\n  print a;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#for-now-we-want-to-skip-control-flow",
    "href": "lectures/03_local.html#for-now-we-want-to-skip-control-flow",
    "title": "Local Analysis & Optimization",
    "section": "for now we want to skip control flow",
    "text": "for now we want to skip control flow",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\ncands are the variables that are defined but not used \nlast_def = {}  variables -&gt; instructions \nthis is a mapping variables that have been defined but not used\n\n   for instr in block:\n      each arg (use) removes arg from last def \n      if the instr has a dest \n          if the dest is in last_def, \n      add dest-&gt;instr to last def\n  \nand as you might expect, we need to iterate this till convergence\n\nCompilers often run dce more then once- why?\n\ntesting out dce\n\nprogram should get the same answer\nprogram should run less instructions\n\n\nSome test cases:\n\nsimple.bril,\nreassign.bril,\nother examples in the DCE test directory",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#testing",
    "href": "lectures/03_local.html#testing",
    "title": "Local Analysis & Optimization",
    "section": "testing",
    "text": "testing\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamically executed instructions.\nHow good a measure is this for real programs?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#using-trunt-golden-images",
    "href": "lectures/03_local.html#using-trunt-golden-images",
    "title": "Local Analysis & Optimization",
    "section": "using trunt (golden images)",
    "text": "using trunt (golden images)\n\nConfigure. Decide what command you want to test. Make a turnt.toml config file and put command = “mycmd {filename}” in it to pass each test file as an argument to mycmd.\nTake a snapshot. Run turnt –save foo.bril. Execute mycmd foo.bril and save the standard output into foo.out.\n\nYou might want to take a look at this output to make sure it’s what you expect\n\nTest your work. Now that you have a test in place, keep working. Use turnt *.bril to run all your tests and confirm that the output still matches.\n\nIf there’s a mismatch, you can do turnt –diff to see the changes.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#peephole-optimizations",
    "href": "lectures/03_local.html#peephole-optimizations",
    "title": "Local Analysis & Optimization",
    "section": "peephole optimizations",
    "text": "peephole optimizations\n1.Peephole optimizations are a category of local code optimizations.\n1. The principle is very simple: a. the optimizer analyzes sequences of instructions. –  a. only code that is within a small window of instructions is analyzed each time.\na. this window slides over the code. a. once patterns are discovered inside this window, optimizations are applied.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#some-examples",
    "href": "lectures/03_local.html#some-examples",
    "title": "Local Analysis & Optimization",
    "section": "some examples",
    "text": "some examples\n\nredundant loads and stores\nm = load r0 store m in r0\n\n\nbranch transformations\n’’’ if debug ==1 go to l1 go to l2 l1: l2:\ntransforms to \nif debug !=1 goto l2 l1: l2: ```\n\n\nreduction in strength\n4*x =&gt; x &lt;&lt; 2\n\n\nspecial machine idioms",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "href": "lectures/revealjs_03_local.qmd.html#reminder-hw1-due-on-friday--i-expected-some-questions",
    "title": "Local Analysis & Optimization",
    "section": "reminder hw1 due on Friday- I expected some questions?",
    "text": "reminder hw1 due on Friday- I expected some questions?\nand anyone who forgot hw0, still needed!"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#llvm-control-flow-graph",
    "href": "lectures/revealjs_03_local.qmd.html#llvm-control-flow-graph",
    "title": "Local Analysis & Optimization",
    "section": "llvm control flow graph",
    "text": "llvm control flow graph\ncommands to draw a dot list of a c file from llvm\n clang -S -emit-llvm images/identity.c -o foo.ll \n opt -dot-cfg foo.ll -disable-output -enable-new-pm=0\nvoid identity(int **a, int N)\n{\n    int i, j;\n    for (i = 0; i &lt; N; i++)\n    {\n        for (j = 0; j &lt; N; j++)\n        {\n            a[i][j] = 0;\n        }\n    }\n    for (i = 0; i &lt; N; i++)\n    {\n        a[i][i] = 1;\n    }\n}\n\n\nCode\ndigraph \"CFG for 'identity' function\" {\n    label=\"CFG for 'identity' function\";\n\n    Node0x12c5490 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%2:\\l  %3 = alloca i32**, align 8\\l  %4 = alloca i32, align 4\\l  %5 = alloca i32, align 4\\l  %6 = alloca i32, align 4\\l  store i32** %0, i32*** %3, align 8\\l  store i32 %1, i32* %4, align 4\\l  store i32 0, i32* %5, align 4\\l  br label %7\\l}\"];\n    Node0x12c5490 -&gt; Node0x12c5da0;\n    Node0x12c5da0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%7:\\l7:                                                \\l  %8 = load i32, i32* %5, align 4\\l  %9 = load i32, i32* %4, align 4\\l  %10 = icmp slt i32 %8, %9\\l  br i1 %10, label %11, label %32\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c5da0:s0 -&gt; Node0x12c5c70;\n    Node0x12c5da0:s1 -&gt; Node0x12c5f40;\n    Node0x12c5c70 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%11:\\l11:                                               \\l  store i32 0, i32* %6, align 4\\l  br label %12\\l}\"];\n    Node0x12c5c70 -&gt; Node0x12c6080;\n    Node0x12c6080 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%12:\\l12:                                               \\l  %13 = load i32, i32* %6, align 4\\l  %14 = load i32, i32* %4, align 4\\l  %15 = icmp slt i32 %13, %14\\l  br i1 %15, label %16, label %28\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c6080:s0 -&gt; Node0x12c62b0;\n    Node0x12c6080:s1 -&gt; Node0x12c6300;\n    Node0x12c62b0 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%16:\\l16:                                               \\l  %17 = load i32**, i32*** %3, align 8\\l  %18 = load i32, i32* %5, align 4\\l  %19 = sext i32 %18 to i64\\l  %20 = getelementptr inbounds i32*, i32** %17, i64 %19\\l  %21 = load i32*, i32** %20, align 8\\l  %22 = load i32, i32* %6, align 4\\l  %23 = sext i32 %22 to i64\\l  %24 = getelementptr inbounds i32, i32* %21, i64 %23\\l  store i32 0, i32* %24, align 4\\l  br label %25\\l}\"];\n    Node0x12c62b0 -&gt; Node0x12c6820;\n    Node0x12c6820 [shape=record,color=\"#b70d28ff\", style=filled, fillcolor=\"#b70d2870\",label=\"{%25:\\l25:                                               \\l  %26 = load i32, i32* %6, align 4\\l  %27 = add nsw i32 %26, 1\\l  store i32 %27, i32* %6, align 4\\l  br label %12, !llvm.loop !6\\l}\"];\n    Node0x12c6820 -&gt; Node0x12c6080;\n    Node0x12c6300 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%28:\\l28:                                               \\l  br label %29\\l}\"];\n    Node0x12c6300 -&gt; Node0x12c75b0;\n    Node0x12c75b0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%29:\\l29:                                               \\l  %30 = load i32, i32* %5, align 4\\l  %31 = add nsw i32 %30, 1\\l  store i32 %31, i32* %5, align 4\\l  br label %7, !llvm.loop !8\\l}\"];\n    Node0x12c75b0 -&gt; Node0x12c5da0;\n    Node0x12c5f40 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%32:\\l32:                                               \\l  store i32 0, i32* %5, align 4\\l  br label %33\\l}\"];\n    Node0x12c5f40 -&gt; Node0x12c7bd0;\n    Node0x12c7bd0 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%33:\\l33:                                               \\l  %34 = load i32, i32* %5, align 4\\l  %35 = load i32, i32* %4, align 4\\l  %36 = icmp slt i32 %34, %35\\l  br i1 %36, label %37, label %49\\l|{&lt;s0&gt;T|&lt;s1&gt;F}}\"];\n    Node0x12c7bd0:s0 -&gt; Node0x12c7e00;\n    Node0x12c7bd0:s1 -&gt; Node0x12c7e50;\n    Node0x12c7e00 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%37:\\l37:                                               \\l  %38 = load i32**, i32*** %3, align 8\\l  %39 = load i32, i32* %5, align 4\\l  %40 = sext i32 %39 to i64\\l  %41 = getelementptr inbounds i32*, i32** %38, i64 %40\\l  %42 = load i32*, i32** %41, align 8\\l  %43 = load i32, i32* %5, align 4\\l  %44 = sext i32 %43 to i64\\l  %45 = getelementptr inbounds i32, i32* %42, i64 %44\\l  store i32 1, i32* %45, align 4\\l  br label %46\\l}\"];\n    Node0x12c7e00 -&gt; Node0x12c8400;\n    Node0x12c8400 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#f3c7b170\",label=\"{%46:\\l46:                                               \\l  %47 = load i32, i32* %5, align 4\\l  %48 = add nsw i32 %47, 1\\l  store i32 %48, i32* %5, align 4\\l  br label %33, !llvm.loop !9\\l}\"];\n    Node0x12c8400 -&gt; Node0x12c7bd0;\n    Node0x12c7e50 [shape=record,color=\"#3d50c3ff\", style=filled, fillcolor=\"#88abfd70\",label=\"{%49:\\l49:                                               \\l  ret void\\l}\"];\n}\n\n\n\n\n\n\n\nCFG for 'identity' function\n\nCFG for 'identity' function\n\n\nNode0x12c5490\n\n%2:\n %3 = alloca i32**, align 8\n %4 = alloca i32, align 4\n %5 = alloca i32, align 4\n %6 = alloca i32, align 4\n store i32** %0, i32*** %3, align 8\n store i32 %1, i32* %4, align 4\n store i32 0, i32* %5, align 4\n br label %7\n\n\n\nNode0x12c5da0\n\n%7:\n7: \n %8 = load i32, i32* %5, align 4\n %9 = load i32, i32* %4, align 4\n %10 = icmp slt i32 %8, %9\n br i1 %10, label %11, label %32\n\nT\n\nF\n\n\n\nNode0x12c5490-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c5c70\n\n%11:\n11: \n store i32 0, i32* %6, align 4\n br label %12\n\n\n\nNode0x12c5da0:s0-&gt;Node0x12c5c70\n\n\n\n\n\nNode0x12c5f40\n\n%32:\n32: \n store i32 0, i32* %5, align 4\n br label %33\n\n\n\nNode0x12c5da0:s1-&gt;Node0x12c5f40\n\n\n\n\n\nNode0x12c6080\n\n%12:\n12: \n %13 = load i32, i32* %6, align 4\n %14 = load i32, i32* %4, align 4\n %15 = icmp slt i32 %13, %14\n br i1 %15, label %16, label %28\n\nT\n\nF\n\n\n\nNode0x12c5c70-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c7bd0\n\n%33:\n33: \n %34 = load i32, i32* %5, align 4\n %35 = load i32, i32* %4, align 4\n %36 = icmp slt i32 %34, %35\n br i1 %36, label %37, label %49\n\nT\n\nF\n\n\n\nNode0x12c5f40-&gt;Node0x12c7bd0\n\n\n\n\n\nNode0x12c62b0\n\n%16:\n16: \n %17 = load i32**, i32*** %3, align 8\n %18 = load i32, i32* %5, align 4\n %19 = sext i32 %18 to i64\n %20 = getelementptr inbounds i32*, i32** %17, i64 %19\n %21 = load i32*, i32** %20, align 8\n %22 = load i32, i32* %6, align 4\n %23 = sext i32 %22 to i64\n %24 = getelementptr inbounds i32, i32* %21, i64 %23\n store i32 0, i32* %24, align 4\n br label %25\n\n\n\nNode0x12c6080:s0-&gt;Node0x12c62b0\n\n\n\n\n\nNode0x12c6300\n\n%28:\n28: \n br label %29\n\n\n\nNode0x12c6080:s1-&gt;Node0x12c6300\n\n\n\n\n\nNode0x12c6820\n\n%25:\n25: \n %26 = load i32, i32* %6, align 4\n %27 = add nsw i32 %26, 1\n store i32 %27, i32* %6, align 4\n br label %12, !llvm.loop !6\n\n\n\nNode0x12c62b0-&gt;Node0x12c6820\n\n\n\n\n\nNode0x12c75b0\n\n%29:\n29: \n %30 = load i32, i32* %5, align 4\n %31 = add nsw i32 %30, 1\n store i32 %31, i32* %5, align 4\n br label %7, !llvm.loop !8\n\n\n\nNode0x12c6300-&gt;Node0x12c75b0\n\n\n\n\n\nNode0x12c6820-&gt;Node0x12c6080\n\n\n\n\n\nNode0x12c75b0-&gt;Node0x12c5da0\n\n\n\n\n\nNode0x12c7e00\n\n%37:\n37: \n %38 = load i32**, i32*** %3, align 8\n %39 = load i32, i32* %5, align 4\n %40 = sext i32 %39 to i64\n %41 = getelementptr inbounds i32*, i32** %38, i64 %40\n %42 = load i32*, i32** %41, align 8\n %43 = load i32, i32* %5, align 4\n %44 = sext i32 %43 to i64\n %45 = getelementptr inbounds i32, i32* %42, i64 %44\n store i32 1, i32* %45, align 4\n br label %46\n\n\n\nNode0x12c7bd0:s0-&gt;Node0x12c7e00\n\n\n\n\n\nNode0x12c7e50\n\n%49:\n49: \n ret void\n\n\n\nNode0x12c7bd0:s1-&gt;Node0x12c7e50\n\n\n\n\n\nNode0x12c8400\n\n%46:\n46: \n %47 = load i32, i32* %5, align 4\n %48 = add nsw i32 %47, 1\n store i32 %48, i32* %5, align 4\n br label %33, !llvm.loop !9\n\n\n\nNode0x12c7e00-&gt;Node0x12c8400\n\n\n\n\n\nNode0x12c8400-&gt;Node0x12c7bd0"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#flavors-of-optimization",
    "href": "lectures/revealjs_03_local.qmd.html#flavors-of-optimization",
    "title": "Local Analysis & Optimization",
    "section": "flavors of optimization",
    "text": "flavors of optimization\nI want to separate 3 flavors of optimization.\n\nlocal meaning within one basic block\nglobal meaning within one function (not really global)\ninter-procedural over the entire program"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/revealjs_03_local.qmd.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels do not write a variable so they do not get deleted as well."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/revealjs_03_local.qmd.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#iterating-till-convergence",
    "href": "lectures/revealjs_03_local.qmd.html#iterating-till-convergence",
    "title": "Local Analysis & Optimization",
    "section": "iterating till convergence",
    "text": "iterating till convergence\nwhile changes:\n       run one pass of tdce above"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "href": "lectures/revealjs_03_local.qmd.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "title": "Local Analysis & Optimization",
    "section": "what would be faster? What is some pseudo code for the change",
    "text": "what would be faster? What is some pseudo code for the change\n\n  find all the variables that are used in more then one block\n  for each block b \n     used = all variables used in more then one block\n     walk backwards over the instruction in the block\n     for each instruction is dest in used?\n        yes - remove dest from used, add arguments to used \n        no  - instruction is dead \n\nfinding all the variables used in more then one block might be expensive"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#for-now-we-want-to-skip-control-flow",
    "href": "lectures/revealjs_03_local.qmd.html#for-now-we-want-to-skip-control-flow",
    "title": "Local Analysis & Optimization",
    "section": "for now we want to skip control flow",
    "text": "for now we want to skip control flow"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#testing",
    "href": "lectures/revealjs_03_local.qmd.html#testing",
    "title": "Local Analysis & Optimization",
    "section": "testing",
    "text": "testing\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamically executed instructions.\nHow good a measure is this for real programs?"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#using-trunt-golden-images",
    "href": "lectures/revealjs_03_local.qmd.html#using-trunt-golden-images",
    "title": "Local Analysis & Optimization",
    "section": "using trunt (golden images)",
    "text": "using trunt (golden images)\n\nConfigure. Decide what command you want to test. Make a turnt.toml config file and put command = “mycmd {filename}” in it to pass each test file as an argument to mycmd.\nTake a snapshot. Run turnt –save foo.bril. Execute mycmd foo.bril and save the standard output into foo.out.\n\nYou might want to take a look at this output to make sure it’s what you expect\n\nTest your work. Now that you have a test in place, keep working. Use turnt *.bril to run all your tests and confirm that the output still matches.\n\nIf there’s a mismatch, you can do turnt –diff to see the changes."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#peephole-optimizations",
    "href": "lectures/revealjs_03_local.qmd.html#peephole-optimizations",
    "title": "Local Analysis & Optimization",
    "section": "peephole optimizations",
    "text": "peephole optimizations\n1.Peephole optimizations are a category of local code optimizations.\n1. The principle is very simple: a. the optimizer analyzes sequences of instructions. –  a. only code that is within a small window of instructions is analyzed each time.\na. this window slides over the code. a. once patterns are discovered inside this window, optimizations are applied."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#some-examples",
    "href": "lectures/revealjs_03_local.qmd.html#some-examples",
    "title": "Local Analysis & Optimization",
    "section": "some examples",
    "text": "some examples\nredundant loads and stores\nm = load r0 store m in r0\nbranch transformations\n’’’ if debug ==1 go to l1 go to l2 l1: l2:\ntransforms to \nif debug !=1 goto l2 l1: l2: ```\nreduction in strength\n4*x =&gt; x &lt;&lt; 2\nspecial machine idioms"
  },
  {
    "objectID": "lectures/12_memory.html",
    "href": "lectures/12_memory.html",
    "title": "Dynamic Memory Management",
    "section": "",
    "text": "Warning\n\n\n\nnot done\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Memory Management"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html",
    "href": "lectures/010_compiler_overview.html",
    "title": "Compiler Overview",
    "section": "",
    "text": "A compiler writer builds bridges between people and machines, and every day this task becomes more challenging.\n\nSoftware engineers want abstractions\n\nHardware engineers want efficiency\n\n\n\n\nA compiler\n\n\n\n\nMost homework\n\nwe talk about some algorithm using pseudo\nYou implement that algorithm\nYou write up a blog post explaining what happened\nIf you like up to 3 people can submit a homework\n\nSince most programming languages have a json library, you can do homework in any language you like.\n\n\n\nwe are going to critically read current research papers\n\nEach person leads a paper discussion (up to two people can sign up as a team to present the same paper)\nEveryone reads the paper; the leader goes over the contents pros and cons\nThe leader writes a blog post, (possibly including discussion insights )\nblog is due one week after the presentation.\nI recommend that people pair up (two people going over a paper before hand is a lot easier)\nI listed a lot of papers, but if there is a different paper you want to present let me know\n\n\n\n\nEverybody gets to do a project, which is compiler related\n\nyou will need to get a proposal approved half way through the term\nyou submit a blog reporting on what happened\nIf you like up to 3 people can submit a project\n\n\n\n\nWrite a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website.\n\n\n\nOriginally, a compiler was a person doing calculations.\nhidden figures\n\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n\n\n\nGrace Hopper\n\n\n\n\n\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.\n\n\n\nIn these early years, the vendor development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on stage 2 (The middle end)\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy\n\n\n\n\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.\n\n\n\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.\n\n\n\n\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n\n\n\n\n\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nsource\n\nSome observations:\n\nProduction compilers are expensive.\nIR does not change easily.\nMuch of compiler technology is old.\nThere is a vast difference between production and student projects.\n\n\n\n\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Domain specific languages for AI)\nMore kinds of hardware\n\n\n\n\nAt the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\n\n\n\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt\n\n\n\nTalk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write.\n\n\n\nRemove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types\n\n\nOver time hardware has become more of a challenge for compilers, for example caches are not predictable at compile time. So compilers have to guess\nAnd hardware can ignore features of the compiler can deal with them - for example interlock",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#homework",
    "href": "lectures/010_compiler_overview.html#homework",
    "title": "Compiler Overview",
    "section": "",
    "text": "Most homework\n\nwe talk about some algorithm using pseudo\nYou implement that algorithm\nYou write up a blog post explaining what happened\nIf you like up to 3 people can submit a homework\n\nSince most programming languages have a json library, you can do homework in any language you like.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#readings",
    "href": "lectures/010_compiler_overview.html#readings",
    "title": "Compiler Overview",
    "section": "",
    "text": "we are going to critically read current research papers\n\nEach person leads a paper discussion (up to two people can sign up as a team to present the same paper)\nEveryone reads the paper; the leader goes over the contents pros and cons\nThe leader writes a blog post, (possibly including discussion insights )\nblog is due one week after the presentation.\nI recommend that people pair up (two people going over a paper before hand is a lot easier)\nI listed a lot of papers, but if there is a different paper you want to present let me know",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#project",
    "href": "lectures/010_compiler_overview.html#project",
    "title": "Compiler Overview",
    "section": "",
    "text": "Everybody gets to do a project, which is compiler related\n\nyou will need to get a proposal approved half way through the term\nyou submit a blog reporting on what happened\nIf you like up to 3 people can submit a project",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#homework-0",
    "href": "lectures/010_compiler_overview.html#homework-0",
    "title": "Compiler Overview",
    "section": "",
    "text": "Write a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#early-compilers",
    "href": "lectures/010_compiler_overview.html#early-compilers",
    "title": "Compiler Overview",
    "section": "",
    "text": "Originally, a compiler was a person doing calculations.\nhidden figures\n\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n\n\n\nGrace Hopper",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#fortran",
    "href": "lectures/010_compiler_overview.html#fortran",
    "title": "Compiler Overview",
    "section": "",
    "text": "In 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-development-model",
    "href": "lectures/010_compiler_overview.html#compiler-development-model",
    "title": "Compiler Overview",
    "section": "",
    "text": "In these early years, the vendor development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on stage 2 (The middle end)\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#gcc",
    "href": "lectures/010_compiler_overview.html#gcc",
    "title": "Compiler Overview",
    "section": "",
    "text": "In 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#llvm",
    "href": "lectures/010_compiler_overview.html#llvm",
    "title": "Compiler Overview",
    "section": "",
    "text": "in about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#bril",
    "href": "lectures/010_compiler_overview.html#bril",
    "title": "Compiler Overview",
    "section": "",
    "text": "In this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "href": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "title": "Compiler Overview",
    "section": "",
    "text": "Compilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nsource\n\nSome observations:\n\nProduction compilers are expensive.\nIR does not change easily.\nMuch of compiler technology is old.\nThere is a vast difference between production and student projects.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-assumptions-how-many-are-still-true",
    "href": "lectures/010_compiler_overview.html#compiler-assumptions-how-many-are-still-true",
    "title": "Compiler Overview",
    "section": "",
    "text": "The time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Domain specific languages for AI)\nMore kinds of hardware",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "href": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "title": "Compiler Overview",
    "section": "",
    "text": "At the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#proebstings-law",
    "href": "lectures/010_compiler_overview.html#proebstings-law",
    "title": "Compiler Overview",
    "section": "",
    "text": "proebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#why-compilers-are-not-better",
    "href": "lectures/010_compiler_overview.html#why-compilers-are-not-better",
    "title": "Compiler Overview",
    "section": "",
    "text": "Talk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#effects-of-optimization",
    "href": "lectures/010_compiler_overview.html#effects-of-optimization",
    "title": "Compiler Overview",
    "section": "",
    "text": "Remove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types\n\n\nOver time hardware has become more of a challenge for compilers, for example caches are not predictable at compile time. So compilers have to guess\nAnd hardware can ignore features of the compiler can deal with them - for example interlock",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#homework",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#homework",
    "title": "Compiler Overview",
    "section": "Homework",
    "text": "Homework\nMost homework\n\nwe talk about some algorithm using pseudo\nYou implement that algorithm\nYou write up a blog post explaining what happened\nIf you like up to 3 people can submit a homework\n\nSince most programming languages have a json library, you can do homework in any language you like."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#readings",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#readings",
    "title": "Compiler Overview",
    "section": "Readings",
    "text": "Readings\nwe are going to critically read current research papers\n\nEach person leads a paper discussion (up to two people can sign up as a team to present the same paper)\nEveryone reads the paper; the leader goes over the contents pros and cons\nThe leader writes a blog post, (possibly including discussion insights )\nblog is due one week after the presentation.\nI recommend that people pair up (two people going over a paper before hand is a lot easier)\nI listed a lot of papers, but if there is a different paper you want to present let me know"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#project",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#project",
    "title": "Compiler Overview",
    "section": "Project",
    "text": "Project\nEverybody gets to do a project, which is compiler related\n\nyou will need to get a proposal approved half way through the term\nyou submit a blog reporting on what happened\nIf you like up to 3 people can submit a project"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#homework-0",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#homework-0",
    "title": "Compiler Overview",
    "section": "homework 0",
    "text": "homework 0\nWrite a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#early-compilers",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#early-compilers",
    "title": "Compiler Overview",
    "section": "Early Compilers",
    "text": "Early Compilers\nOriginally, a compiler was a person doing calculations.\nhidden figures"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#fortran",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#fortran",
    "title": "Compiler Overview",
    "section": "FORTRAN",
    "text": "FORTRAN\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\n2/3 of the cost and 90% of the time for solving a problem was coding.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-development-model",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-development-model",
    "title": "Compiler Overview",
    "section": "Compiler Development Model",
    "text": "Compiler Development Model\nIn these early years, the vendor development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#gcc",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#gcc",
    "title": "Compiler Overview",
    "section": "gcc",
    "text": "gcc\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#llvm",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#llvm",
    "title": "Compiler Overview",
    "section": "LLVM",
    "text": "LLVM\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#bril",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#bril",
    "title": "Compiler Overview",
    "section": "bril",
    "text": "bril\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#cost-of-a-compiler.",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#cost-of-a-compiler.",
    "title": "Compiler Overview",
    "section": "Cost of a compiler.",
    "text": "Cost of a compiler.\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nsource"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-assumptions-how-many-are-still-true",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-assumptions-how-many-are-still-true",
    "title": "Compiler Overview",
    "section": "Compiler Assumptions (How many are still true?)",
    "text": "Compiler Assumptions (How many are still true?)\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#how-well-do-compilers-do",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#how-well-do-compilers-do",
    "title": "Compiler Overview",
    "section": "How well do compilers do",
    "text": "How well do compilers do\nAt the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#proebstings-law",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#proebstings-law",
    "title": "Compiler Overview",
    "section": "proebsting’s law",
    "text": "proebsting’s law\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#why-compilers-are-not-better",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#why-compilers-are-not-better",
    "title": "Compiler Overview",
    "section": "why compilers are not better",
    "text": "why compilers are not better\nTalk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#effects-of-optimization",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#effects-of-optimization",
    "title": "Compiler Overview",
    "section": "effects of optimization",
    "text": "effects of optimization\nRemove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types"
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html",
    "href": "lectures/08_classic_loop_ops.html",
    "title": "8 classic loop optimizations",
    "section": "",
    "text": "Loops optimizations are important because\nWhat are classic loop optimizations?\nLess classic loop optimizations\nFirst recall natural loops\ndef of loop invariant for an instruction d = op a,b\nin SSA form if we find a loop invariant instruction we can always move it into the pre-header, because the value it writes is never rewritten, and the values that it depends on come from outside the loop\nconditions when moving an instruction d = a op b is ok\ncan move d\nL0: d = 0 preheader L1: if (i&gt;=N) goto L2 i = i + 1 d = a ⊕ b = d goto L1 L2: x = d ```\nno good d used after the loop, would not be changed if the loop executes zero times\nno good d reassigned in the loop, do invar would be changed\nwhile (e) { j = loopinv // may never execute S }\nj = loopinv // always executes while (e) { S }\nif (e) { j = loopinv // may never execute while (e) { S }\n} ````",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "href": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "href": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/revealjs_08_classic_loop_ops.qmd.html#induction-variable-elimination",
    "href": "lectures/revealjs_08_classic_loop_ops.qmd.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l"
  },
  {
    "objectID": "lectures/revealjs_08_classic_loop_ops.qmd.html#loop-un-switching",
    "href": "lectures/revealjs_08_classic_loop_ops.qmd.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#example-1",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#example-1",
    "title": "Performance and Measurement",
    "section": "example 1",
    "text": "example 1\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#another-example",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#another-example",
    "title": "Performance and Measurement",
    "section": "another example",
    "text": "another example\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#violin-plots",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#violin-plots",
    "title": "Performance and Measurement",
    "section": "violin plots",
    "text": "violin plots\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n\nCode\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#error-bars",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#error-bars",
    "title": "Performance and Measurement",
    "section": "error bars",
    "text": "error bars\n\n\nCode\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000"
  },
  {
    "objectID": "lectures/01a_performance_measurement.html",
    "href": "lectures/01a_performance_measurement.html",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog\n\n\n\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\n\n\n\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.\n\n\n\n\n\nprint(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#example-1",
    "href": "lectures/01a_performance_measurement.html#example-1",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#another-example",
    "href": "lectures/01a_performance_measurement.html#another-example",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Strangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#violin-plots",
    "href": "lectures/01a_performance_measurement.html#violin-plots",
    "title": "Performance and Measurement",
    "section": "",
    "text": "data\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#error-bars",
    "href": "lectures/01a_performance_measurement.html#error-bars",
    "title": "Performance and Measurement",
    "section": "",
    "text": "print(df.describe())\n\nimport pandas as pd\n\n# Assuming df is your DataFrame and 'Release Date' is the column\ndf['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\ndf['Release Year'] = ((df['Release Date'].dt.year) // 5) * 5\n\n# Now df['Release Year'] contains the year extracted from 'Release Date'\n\n\n# plot a bar chart\nax = sns.barplot(x=df['Release Year'], y=df[\"TDP (W)\"], hue =df['Type'], estimator=np.mean, errorbar=(\"sd\"))\n\n        Unnamed: 0  Process Size (nm)      TDP (W)  Die Size (mm^2)  \\\ncount  4854.000000        4845.000000  4228.000000      4139.000000   \nmean   2426.500000          55.109598    81.359981       188.440445   \nstd    1401.373433          44.998676    76.807808       126.189383   \nmin       0.000000           0.000000     1.000000         1.000000   \n25%    1213.250000          22.000000    33.000000       104.000000   \n50%    2426.500000          40.000000    65.000000       148.000000   \n75%    3639.750000          90.000000   100.000000       239.000000   \nmax    4853.000000         250.000000   900.000000       826.000000   \n\n       Transistors (million)   Freq (MHz)    FP16 GFLOPS   FP32 GFLOPS  \\\ncount            4143.000000  4854.000000     536.000000   1948.000000   \nmean             1929.922279  1484.406057    8397.459851   2134.756653   \nstd              4044.891098  1066.701523   13799.551131   3898.431487   \nmin                 8.000000   100.000000      10.020000     12.800000   \n25%               154.000000   590.000000     768.800000    257.300000   \n50%               624.000000  1073.500000    2965.500000    696.000000   \n75%              1550.000000  2400.000000   10600.000000   2116.750000   \nmax             54200.000000  4700.000000  184600.000000  40000.000000   \n\n        FP64 GFLOPS  \ncount   1306.000000  \nmean     363.670511  \nstd     1145.931856  \nmin        3.600000  \n25%       38.295000  \n50%       89.280000  \n75%      220.000000  \nmax    11540.000000",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "title": "Dynamic Compilers",
    "section": "jit (just in time) compilers vs aot(ahead of time) compilers",
    "text": "jit (just in time) compilers vs aot(ahead of time) compilers\na jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#can-jit-compiled-code-run-faster-then-aot-code",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#can-jit-compiled-code-run-faster-then-aot-code",
    "title": "Dynamic Compilers",
    "section": "Can jit compiled code run faster then aot code?",
    "text": "Can jit compiled code run faster then aot code?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#comparison",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#comparison",
    "title": "Dynamic Compilers",
    "section": "Comparison",
    "text": "Comparison\n\n\n\naot\njit\n\n\n\n\ncannot inline libraries\ncan inline (even class methods)\n\n\nno runtime code gen\ncan use run time code gen\n\n\nno speculative opts\ncan use spec opts\n\n\nless information\nmore information\n\n\noverall performance lower\noverall performance often higher\n\n\nfull speed from the start\nrequires warmup\n\n\nno compile cost at run time\noverhead to run compiler"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs",
    "title": "Dynamic Compilers",
    "section": "Tradeoffs",
    "text": "Tradeoffs\n\nThe time to compile is part of the total execution time\nmight run less optimizations to speed up execution time\nmight look at run time info\nsame code might be compiled many times\n\nWt would the same code be compiled more than once?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tiered-compilers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tiered-compilers",
    "title": "Dynamic Compilers",
    "section": "tiered compilers",
    "text": "tiered compilers\nSince compilation is costly, do not compile functions that are only called once and do not contain a long running loop\nwe have a series of compilers, each with more aggressive optimization and each allowed to take longer\n\nthe lowest tier is the interpreter\nthe next is the base line compiler"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#magic-numbers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#magic-numbers",
    "title": "Dynamic Compilers",
    "section": "magic numbers",
    "text": "magic numbers\nassociate a counter with branches and functions if the counter reaches some magic number use one of the compilers\nif the counter for a backward branch, you recompile, but the code is executing in the middle of a loop, so how do you insert the newly compiled code?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#questions-when-building-a-jit",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#questions-when-building-a-jit",
    "title": "Dynamic Compilers",
    "section": "questions when building a JIT",
    "text": "questions when building a JIT\n\nwhat strategy do you use to invoke the jit\ndo you have to execute for a while before calling the jit\nhow much info do you need\nwhat is the price of wrong info\nare there easy and hard programs\ndo the easy programs match up with users common programs"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#speculation",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#speculation",
    "title": "Dynamic Compilers",
    "section": "Speculation",
    "text": "Speculation\n\nassume some property is true, compile using that info this is always a gamble, so you need to recover if the assumption was wrong\nassume a variable is an int, and does not overflow\nassume properties of an object is fixed\nassume the target of call is always the same\nassume past behavior predicts future behavior"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#flow",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#flow",
    "title": "Dynamic Compilers",
    "section": "flow",
    "text": "flow\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#boxed-values",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#boxed-values",
    "title": "Dynamic Compilers",
    "section": "boxed values",
    "text": "boxed values\nMany languages do not use strong static typeing\nfor example in python\nx = x + 1\nx could be an int/float/object\nthe value of x needs to carry a type. Represent x as a pair (type, pointer or bits) The pair is called a boxed value\nthen to generate code for the plus we have to figure out what kind of add, based on the type"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches",
    "title": "Dynamic Compilers",
    "section": "inline caches",
    "text": "inline caches\nin languages like python, calls to a method are more expensive then calls to a method in c++ why?\n\nPython objects are implemented as hash tables. While C++ uses virtual tables\nhow does that effect the cost?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#first-c-virtual-tables",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#first-c-virtual-tables",
    "title": "Dynamic Compilers",
    "section": "first C++ virtual tables",
    "text": "first C++ virtual tables\nin C++ a method call takes two dereferences\n\nfirst find the v-table\nsecond used a fixed offset from the table start to find the address"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-do-we-need-to-keep-the-offset-fixed",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-do-we-need-to-keep-the-offset-fixed",
    "title": "Dynamic Compilers",
    "section": "What do we need to keep the offset fixed?",
    "text": "What do we need to keep the offset fixed?\nif derived inherits from base, and both have a function f. the offset to f has to be the same.\nin languages where objects are hash tables, the c++ dereference becomes a hash table lookup, which is slower"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs-1",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs-1",
    "title": "Dynamic Compilers",
    "section": "tradeoffs",
    "text": "tradeoffs\nIn a dynamically typed language like python we can add or remove methods easily\nbut method calls are expensive\nwe want to make these calls cheaper"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-te-call-site",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-te-call-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at te call site",
    "text": "inline caches at te call site\nthe first time we call a method, we know the type (because we are generating code at runtime)\n\n\ndef func(a,b,c):\n  for i in range(10):\n     foo(a,b,c)\n\ndef func(a,b,c):\n  for i in range(1):\n    if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in the hash\n      call other(a,b,c\n      )"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-the-function-site",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-the-function-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at the function site",
    "text": "inline caches at the function site\n\n\ndef func(a,b,c):\n  for i in range(10):\n     _foo(a,b,c\n\ndef _foo(a,b,c)\n  if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in a\n      call other(a,b,c)\n\nis it better to do this at the call site or at the function site?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#polymorphic-calls",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#polymorphic-calls",
    "title": "Dynamic Compilers",
    "section": "polymorphic calls",
    "text": "polymorphic calls\nif the type changes at runtime (the call to other is taken) does the optimization help?\ncould invalidate the table and rebuild it with another case"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-are-the-costs",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-are-the-costs",
    "title": "Dynamic Compilers",
    "section": "what are the costs",
    "text": "what are the costs\nfor example v8 compiler\nmonomorphic inline hit - 10 instructions\npolymorphic hit - 35 instructions for 10 types, 60 instructions for 20 types\ncache miss 1000-4000 instructions"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#value-specialization",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#value-specialization",
    "title": "Dynamic Compilers",
    "section": "value specialization",
    "text": "value specialization\nOddly many functions are called with the same arguments"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example",
    "title": "Dynamic Compilers",
    "section": "an example",
    "text": "an example\ngiven a vector v of size n, and a parameter q find the element of v that is closest to q\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n        var i = 0;\n        var d = 0ffffffff;\n        while (i &lt; n) {\n           var nd = abs(v[i] - q);\n           if (nd &lt;= d) d = nd; \n           i++;\n        }    \n        return d;  \n      } \n}"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#the-cfg",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#the-cfg",
    "title": "Dynamic Compilers",
    "section": "the cfg",
    "text": "the cfg\nwe want to recompile this for specific v,q, and n, where we restart at the while test"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#two-entries",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#two-entries",
    "title": "Dynamic Compilers",
    "section": "two entries",
    "text": "two entries\nFirst entry is the regular starting point, second is the entry if we are currently running the loop in the interpreter\nSince we are compiling the function while in the loop we can ask the interpreter for values\n\nv == load[0]\nq = 42\nn = 100\ni = 40\nd = 0fffffff"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#dead-code-elimination",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#dead-code-elimination",
    "title": "Dynamic Compilers",
    "section": "dead code elimination",
    "text": "dead code elimination\nAfter this the all calls to the function assume these arguments so no need to keep the regular entry\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#array-in-bounds-check",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#array-in-bounds-check",
    "title": "Dynamic Compilers",
    "section": "array in bounds check",
    "text": "array in bounds check\nwe can pattern match loops with bounds checks if we know the limit"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#loop-inversion",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#loop-inversion",
    "title": "Dynamic Compilers",
    "section": "loop inversion",
    "text": "loop inversion\na general while loop\nwhile(cond){\n  ...\n}\ncan be changed into\nif (cond){\n  do {\n    ...\n  } while(cond)\n}\nfor this loop the first time around i = 40, n = 100 so the first condition is true"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#after-loop-inversion",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#after-loop-inversion",
    "title": "Dynamic Compilers",
    "section": "after loop inversion",
    "text": "after loop inversion\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#results",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#results",
    "title": "Dynamic Compilers",
    "section": "results",
    "text": "results\nspecialized code is shorter and compiles faster\nsince we know that the loop goes from 42 to 100, we could unroll the loop"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#trace-compilation",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#trace-compilation",
    "title": "Dynamic Compilers",
    "section": "trace compilation",
    "text": "trace compilation\ntracing jit: extract a hot path (not a function)\nHot paths are compiled as a single basic block, but the path might go through a call\ngamble: next execution starting at this point, go the same way, no branches leave the path\ngenerate machine code for hot paths interpret the rest of the program\nunlike specialization, tracing assumes the same path but not the same values"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example-x-42",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example-x-42",
    "title": "Dynamic Compilers",
    "section": "an example (x = 42)",
    "text": "an example (x = 42)\n\n\nfunction main(x){\n   y = x +1 \n   if x &lt;100 {\n      z = f(y)\n   } else {\n      z = g(y)\n   }\n   return z\n}\n\nfunction f(a){\n   return a -1 \n}\n\n\n\ny = x +1\nguard(x &lt; 100)\na = y\nz = a - 1\nreturn z\n\n\n\nguards at divergence, guards never return\noptimize assuming guards are true, ok to be slow if guard is false"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#move-guards-up",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#move-guards-up",
    "title": "Dynamic Compilers",
    "section": "move guards up",
    "text": "move guards up\nwhy is this a good idea?\n\n\nfail fast\nlonger region to optimize"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#use-local-value-numbering",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#use-local-value-numbering",
    "title": "Dynamic Compilers",
    "section": "use local value numbering",
    "text": "use local value numbering\n\n\n\nguard(x &lt; 100)\ny = x + 1\na = y\nz = a - 1\nreturn z\n\n\n\nguard(x &lt; 100)\nreturn x"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#how-do-this-in-bril",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#how-do-this-in-bril",
    "title": "Dynamic Compilers",
    "section": "how do this in Bril?",
    "text": "how do this in Bril?\n3 new operations (sort of like out-of-order instructions)\n\nspeculate\ncommit\nguard\n\nspeculative execution extension\nyou can nest speculate\nit does not role back stores\nwe can approximate trace compilation by running the program twice\nHow to modify the reference interpreter (warning typescript!)\nbrili\nthere are two functions to consider\n\nevalFunc interprets a function by calling evalInstr on each instruction\nevalInstr interprets one instruction, large case statement for each instruction\n\nyou will need to print instructions as they execute\n\nfigure out when to start and when to stop\nhow to print instructions (modify evalInstr by printing instructions) console.log(instr)\n\nyou have to optimize the trace and put it back"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html",
    "href": "lectures/13_dynamic_compilers.html",
    "title": "Dynamic Compilers",
    "section": "",
    "text": "a jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "href": "lectures/13_dynamic_compilers.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "title": "Dynamic Compilers",
    "section": "",
    "text": "a jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#can-jit-compiled-code-run-faster-then-aot-code",
    "href": "lectures/13_dynamic_compilers.html#can-jit-compiled-code-run-faster-then-aot-code",
    "title": "Dynamic Compilers",
    "section": "Can jit compiled code run faster then aot code?",
    "text": "Can jit compiled code run faster then aot code?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#comparison",
    "href": "lectures/13_dynamic_compilers.html#comparison",
    "title": "Dynamic Compilers",
    "section": "Comparison",
    "text": "Comparison\n\n\n\naot\njit\n\n\n\n\ncannot inline libraries\ncan inline (even class methods)\n\n\nno runtime code gen\ncan use run time code gen\n\n\nno speculative opts\ncan use spec opts\n\n\nless information\nmore information\n\n\noverall performance lower\noverall performance often higher\n\n\nfull speed from the start\nrequires warmup\n\n\nno compile cost at run time\noverhead to run compiler",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tradeoffs",
    "href": "lectures/13_dynamic_compilers.html#tradeoffs",
    "title": "Dynamic Compilers",
    "section": "Tradeoffs",
    "text": "Tradeoffs\n\nThe time to compile is part of the total execution time\nmight run less optimizations to speed up execution time\nmight look at run time info\nsame code might be compiled many times\n\nWt would the same code be compiled more than once?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tiered-compilers",
    "href": "lectures/13_dynamic_compilers.html#tiered-compilers",
    "title": "Dynamic Compilers",
    "section": "tiered compilers",
    "text": "tiered compilers\nSince compilation is costly, do not compile functions that are only called once and do not contain a long running loop\nwe have a series of compilers, each with more aggressive optimization and each allowed to take longer\n\nthe lowest tier is the interpreter\nthe next is the base line compiler\n\n\n\nstart interpreting the code\nif some part of the code takes a long time, compile it with the next higher tier\nis some runtime info changes, compile it again",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#magic-numbers",
    "href": "lectures/13_dynamic_compilers.html#magic-numbers",
    "title": "Dynamic Compilers",
    "section": "magic numbers",
    "text": "magic numbers\nassociate a counter with branches and functions if the counter reaches some magic number use one of the compilers\nif the counter for a backward branch, you recompile, but the code is executing in the middle of a loop, so how do you insert the newly compiled code?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#questions-when-building-a-jit",
    "href": "lectures/13_dynamic_compilers.html#questions-when-building-a-jit",
    "title": "Dynamic Compilers",
    "section": "questions when building a JIT",
    "text": "questions when building a JIT\n\nwhat strategy do you use to invoke the jit\ndo you have to execute for a while before calling the jit\nhow much info do you need\nwhat is the price of wrong info\nare there easy and hard programs\ndo the easy programs match up with users common programs",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#speculation",
    "href": "lectures/13_dynamic_compilers.html#speculation",
    "title": "Dynamic Compilers",
    "section": "Speculation",
    "text": "Speculation\n\nassume some property is true, compile using that info this is always a gamble, so you need to recover if the assumption was wrong\nassume a variable is an int, and does not overflow\nassume properties of an object is fixed\nassume the target of call is always the same\nassume past behavior predicts future behavior",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#flow",
    "href": "lectures/13_dynamic_compilers.html#flow",
    "title": "Dynamic Compilers",
    "section": "flow",
    "text": "flow\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#boxed-values",
    "href": "lectures/13_dynamic_compilers.html#boxed-values",
    "title": "Dynamic Compilers",
    "section": "boxed values",
    "text": "boxed values\nMany languages do not use strong static typeing\nfor example in python\nx = x + 1\nx could be an int/float/object\nthe value of x needs to carry a type. Represent x as a pair (type, pointer or bits) The pair is called a boxed value\nthen to generate code for the plus we have to figure out what kind of add, based on the type",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches",
    "href": "lectures/13_dynamic_compilers.html#inline-caches",
    "title": "Dynamic Compilers",
    "section": "inline caches",
    "text": "inline caches\nin languages like python, calls to a method are more expensive then calls to a method in c++ why?\n. . .\nPython objects are implemented as hash tables. While C++ uses virtual tables\nhow does that effect the cost?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#first-c-virtual-tables",
    "href": "lectures/13_dynamic_compilers.html#first-c-virtual-tables",
    "title": "Dynamic Compilers",
    "section": "first C++ virtual tables",
    "text": "first C++ virtual tables\nin C++ a method call takes two dereferences\n\nfirst find the v-table\nsecond used a fixed offset from the table start to find the address",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#what-do-we-need-to-keep-the-offset-fixed",
    "href": "lectures/13_dynamic_compilers.html#what-do-we-need-to-keep-the-offset-fixed",
    "title": "Dynamic Compilers",
    "section": "What do we need to keep the offset fixed?",
    "text": "What do we need to keep the offset fixed?\nif derived inherits from base, and both have a function f. the offset to f has to be the same.\nin languages where objects are hash tables, the c++ dereference becomes a hash table lookup, which is slower",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tradeoffs-1",
    "href": "lectures/13_dynamic_compilers.html#tradeoffs-1",
    "title": "Dynamic Compilers",
    "section": "tradeoffs",
    "text": "tradeoffs\nIn a dynamically typed language like python we can add or remove methods easily\nbut method calls are expensive\nwe want to make these calls cheaper",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches-at-te-call-site",
    "href": "lectures/13_dynamic_compilers.html#inline-caches-at-te-call-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at te call site",
    "text": "inline caches at te call site\nthe first time we call a method, we know the type (because we are generating code at runtime)\n\n\ndef func(a,b,c):\n  for i in range(10):\n     foo(a,b,c)\n\ndef func(a,b,c):\n  for i in range(1):\n    if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in the hash\n      call other(a,b,c\n      )",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches-at-the-function-site",
    "href": "lectures/13_dynamic_compilers.html#inline-caches-at-the-function-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at the function site",
    "text": "inline caches at the function site\n\n\ndef func(a,b,c):\n  for i in range(10):\n     _foo(a,b,c\n\ndef _foo(a,b,c)\n  if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in a\n      call other(a,b,c)\n\n\nis it better to do this at the call site or at the function site?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#polymorphic-calls",
    "href": "lectures/13_dynamic_compilers.html#polymorphic-calls",
    "title": "Dynamic Compilers",
    "section": "polymorphic calls",
    "text": "polymorphic calls\nif the type changes at runtime (the call to other is taken) does the optimization help?\ncould invalidate the table and rebuild it with another case",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#what-are-the-costs",
    "href": "lectures/13_dynamic_compilers.html#what-are-the-costs",
    "title": "Dynamic Compilers",
    "section": "what are the costs",
    "text": "what are the costs\nfor example v8 compiler\nmonomorphic inline hit - 10 instructions\npolymorphic hit - 35 instructions for 10 types, 60 instructions for 20 types\ncache miss 1000-4000 instructions",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#value-specialization",
    "href": "lectures/13_dynamic_compilers.html#value-specialization",
    "title": "Dynamic Compilers",
    "section": "value specialization",
    "text": "value specialization\nOddly many functions are called with the same arguments",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#an-example",
    "href": "lectures/13_dynamic_compilers.html#an-example",
    "title": "Dynamic Compilers",
    "section": "an example",
    "text": "an example\ngiven a vector v of size n, and a parameter q find the element of v that is closest to q\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n        var i = 0;\n        var d = 0ffffffff;\n        while (i &lt; n) {\n           var nd = abs(v[i] - q);\n           if (nd &lt;= d) d = nd; \n           i++;\n        }    \n        return d;  \n      } \n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#the-cfg",
    "href": "lectures/13_dynamic_compilers.html#the-cfg",
    "title": "Dynamic Compilers",
    "section": "the cfg",
    "text": "the cfg\nwe want to recompile this for specific v,q, and n, where we restart at the while test\n\n\n\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n      var i = 0;\n      var d = 0ffffffff;\n      while (i &lt; n) {\n         var nd = abs(v[i] - q);\n         if (nd &lt;= d) d = nd; \n         i++;\n        }    \n        return d;  \n      } \n}\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#two-entries",
    "href": "lectures/13_dynamic_compilers.html#two-entries",
    "title": "Dynamic Compilers",
    "section": "two entries",
    "text": "two entries\nFirst entry is the regular starting point, second is the entry if we are currently running the loop in the interpreter\nSince we are compiling the function while in the loop we can ask the interpreter for values\n\nv == load[0]\nq = 42\nn = 100\ni = 40\nd = 0fffffff\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#dead-code-elimination",
    "href": "lectures/13_dynamic_compilers.html#dead-code-elimination",
    "title": "Dynamic Compilers",
    "section": "dead code elimination",
    "text": "dead code elimination\nAfter this the all calls to the function assume these arguments so no need to keep the regular entry\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#array-in-bounds-check",
    "href": "lectures/13_dynamic_compilers.html#array-in-bounds-check",
    "title": "Dynamic Compilers",
    "section": "array in bounds check",
    "text": "array in bounds check\nwe can pattern match loops with bounds checks if we know the limit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     \"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     \"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#loop-inversion",
    "href": "lectures/13_dynamic_compilers.html#loop-inversion",
    "title": "Dynamic Compilers",
    "section": "loop inversion",
    "text": "loop inversion\na general while loop\nwhile(cond){\n  ...\n}\ncan be changed into\nif (cond){\n  do {\n    ...\n  } while(cond)\n}\nfor this loop the first time around i = 40, n = 100 so the first condition is true",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#after-loop-inversion",
    "href": "lectures/13_dynamic_compilers.html#after-loop-inversion",
    "title": "Dynamic Compilers",
    "section": "after loop inversion",
    "text": "after loop inversion\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#results",
    "href": "lectures/13_dynamic_compilers.html#results",
    "title": "Dynamic Compilers",
    "section": "results",
    "text": "results\nspecialized code is shorter and compiles faster\nsince we know that the loop goes from 42 to 100, we could unroll the loop",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#trace-compilation",
    "href": "lectures/13_dynamic_compilers.html#trace-compilation",
    "title": "Dynamic Compilers",
    "section": "trace compilation",
    "text": "trace compilation\ntracing jit: extract a hot path (not a function)\nHot paths are compiled as a single basic block, but the path might go through a call\ngamble: next execution starting at this point, go the same way, no branches leave the path\ngenerate machine code for hot paths interpret the rest of the program\nunlike specialization, tracing assumes the same path but not the same values",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#an-example-x-42",
    "href": "lectures/13_dynamic_compilers.html#an-example-x-42",
    "title": "Dynamic Compilers",
    "section": "an example (x = 42)",
    "text": "an example (x = 42)\n\n\nfunction main(x){\n   y = x +1 \n   if x &lt;100 {\n      z = f(y)\n   } else {\n      z = g(y)\n   }\n   return z\n}\n\nfunction f(a){\n   return a -1 \n}\n\n\n\ny = x +1\nguard(x &lt; 100)\na = y\nz = a - 1\nreturn z\n\n\n\n\nguards at divergence, guards never return\noptimize assuming guards are true, ok to be slow if guard is false",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#move-guards-up",
    "href": "lectures/13_dynamic_compilers.html#move-guards-up",
    "title": "Dynamic Compilers",
    "section": "move guards up",
    "text": "move guards up\nwhy is this a good idea?\n. . .\n\nfail fast\nlonger region to optimize",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#use-local-value-numbering",
    "href": "lectures/13_dynamic_compilers.html#use-local-value-numbering",
    "title": "Dynamic Compilers",
    "section": "use local value numbering",
    "text": "use local value numbering\n\n\n\nguard(x &lt; 100)\ny = x + 1\na = y\nz = a - 1\nreturn z\n\n\n\nguard(x &lt; 100)\nreturn x",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#how-do-this-in-bril",
    "href": "lectures/13_dynamic_compilers.html#how-do-this-in-bril",
    "title": "Dynamic Compilers",
    "section": "how do this in Bril?",
    "text": "how do this in Bril?\n3 new operations (sort of like out-of-order instructions)\n\nspeculate\ncommit\nguard\n\nspeculative execution extension\nyou can nest speculate\nit does not role back stores\nwe can approximate trace compilation by running the program twice\nHow to modify the reference interpreter (warning typescript!)\nbrili\nthere are two functions to consider\n\nevalFunc interprets a function by calling evalInstr on each instruction\nevalInstr interprets one instruction, large case statement for each instruction\n\nyou will need to print instructions as they execute\n\nfigure out when to start and when to stop\nhow to print instructions (modify evalInstr by printing instructions) console.log(instr)\n\nyou have to optimize the trace and put it back",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Dynamic Compilers"
    ]
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#this-is-based-on-the-cranelift-compiler-used-for-web-assembly-and-rust",
    "href": "lectures/revealjs_ra-checking.qmd.html#this-is-based-on-the-cranelift-compiler-used-for-web-assembly-and-rust",
    "title": "Testing Register allocators",
    "section": "this is based on the cranelift compiler used for web-assembly and rust",
    "text": "this is based on the cranelift compiler used for web-assembly and rust"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#what-is-register-allocation",
    "href": "lectures/revealjs_ra-checking.qmd.html#what-is-register-allocation",
    "title": "Testing Register allocators",
    "section": "what is register allocation",
    "text": "what is register allocation\nIn Bril and LLVM a program can use an arbitrary number of registers,\nvoid f() {\n    int x0 = compute(0);\n    int x1 = compute(1);\n    // ...\n    int x99 = compute(99);\n    \n    // --- 100 possibly different values were computed \n    // --- where are those values stored?\n    \n    consume(x0);\n    consume(x1);\n    // ...\n    consume(x99);\n}"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#storing-variables",
    "href": "lectures/revealjs_ra-checking.qmd.html#storing-variables",
    "title": "Testing Register allocators",
    "section": "storing variables",
    "text": "storing variables\none option\nAllocate a memory location for each local variable. All of the \\(x_N\\) variables above semantically live in memory. When the function is called, it allocates a nwe area on the stack called the stack frame and uses it to store local variables.\nThis means that adding two variables, takes two loads, one add, and one store so it is very slow\nCompiling code in this way is very fast because we need to make almost no decisions: a variable reference always becomes a memory load,\nOn computers we have a limited set of registers\nRegister allocation: is assigning a value in the program to a register for storage. The register allocator decides how to shuffle values between memory and registers, and between register.\nIn Bril and LLVM we have virtual registers - as many as you want. The register allocator has to rewrite the instructions to use physical registers. Since the number of physical registers is limited, The allocator might insert additional instructions:\n\nstores (called spills) to move a register to memory\nloads (called reloads) to move memory to a register\nmoves to copy from one register to another\n\nThe locations in memory are usually on the stack and are called spill-slots"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "href": "lectures/revealjs_ra-checking.qmd.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "title": "Testing Register allocators",
    "section": "example of register allocation on a machine with two physical registers",
    "text": "example of register allocation on a machine with two physical registers\nvirtual register code          physical register code \n                               {v0 -&gt; r0, v1 -&gt; r1}\n                               store r1, [sp+0]  a spill\nadd v2, v0, v1                 add r1, r0, r1 \n                               {v0 -&gt; r0, v1-&gt; [sp+-0], v2-&gt; r1}\nsub v3, v2, v0                 sub r1, r1, r0\n                               load r0, [sp+0]  a reload \nmul  v4, v3, v1                mul r0, r1, r0\n                               {v4-&gt; r0}\nstore v4, [sp+48]              store r0, [sp+48]"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#complexity",
    "href": "lectures/revealjs_ra-checking.qmd.html#complexity",
    "title": "Testing Register allocators",
    "section": "complexity",
    "text": "complexity\nif you do register allocation for code that is not in SSA, this is NP-complete But if you do it on code that is in SSA, the time complexity is polynomial.\nThere are lots of approximate algorithms- all complicated, lots of machines have extra constraints for instance there is a GPU load instruction that read 128 bits from memory and puts the value into 4 consecutive registers\nI’m not going to talk about these algorithms here"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-to-verify-correctness-of-an-allocator",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-to-verify-correctness-of-an-allocator",
    "title": "Testing Register allocators",
    "section": "How to Verify Correctness of an allocator?",
    "text": "How to Verify Correctness of an allocator?\nBefore and after the allocator, we have the same instructions (except for those added by the allocator)\nassume we have a machine with an infinite register set and a second machine with a finite register set.\nCorrect means both programs executed on these two machines get the same answer for all possible inputs"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-do-we-test-this",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-do-we-test-this",
    "title": "Testing Register allocators",
    "section": "how do we test this?",
    "text": "how do we test this?\nHow do we test this equivalence?\npick a random program and a random input. interpret and see if the result is the same.\ncould try more random inputs, could generate more random programs (fuzzer tools)\nCould reasonably confident but not 100% and very expensive"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "href": "lectures/revealjs_ra-checking.qmd.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "title": "Testing Register allocators",
    "section": "use value numbering check one program, one basic block, all possible inputs",
    "text": "use value numbering check one program, one basic block, all possible inputs\n// original               // allocated \nld v0, [A]                ld r0, [A]\nld v1, [B]                ld r1, [B]\nld v2, [C]                ld r2, [C]\nadd v3, v0, v1            add r0, r0, r1\nadd v4, v2, v3            add r0, r2, r0\nreturn v4                 return r0\n\nv0 -&gt; vn 1 ld [A]         r0 -&gt; vn 1 ld [A]\nv1 -&gt; vn 2 ld [B]         r1 -&gt; vn 2 ld [B]\nv2 -&gt; vn 3 ld [C]         r2 -&gt; vn 3 ld [C]\nv3 -&gt; vn 4 add 1,2        r0 -&gt; vn 4 add 1,2 \nv4 -&gt; vn 5 add 3,4        r0 -&gt; vn 5 add 3,4 \nreturn vn 5               return vn 5"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#check-more-then-one-program-all-programs-at-once",
    "href": "lectures/revealjs_ra-checking.qmd.html#check-more-then-one-program-all-programs-at-once",
    "title": "Testing Register allocators",
    "section": "check more then one program (all programs at once)",
    "text": "check more then one program (all programs at once)\nThis requires a proof that the two programs get the same result - this is an active research question -\nsome success but not easy\nnot used in production"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "href": "lectures/revealjs_ra-checking.qmd.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "title": "Testing Register allocators",
    "section": "best we can do is generate lots of programs check each one",
    "text": "best we can do is generate lots of programs check each one\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n\nWe could use the fuzzer to generate random programs or we could use a test set"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#algorithm-linear-in-number-of-instructions",
    "href": "lectures/revealjs_ra-checking.qmd.html#algorithm-linear-in-number-of-instructions",
    "title": "Testing Register allocators",
    "section": "algorithm (linear in number of instructions)",
    "text": "algorithm (linear in number of instructions)\nfor each instruction we need to form pairs - virtual and physical register that holds the same value\nfor instruction v and p, check that the arguments are equal, if not fail add the pair dest of v == dest of p\ndoes not matter what the original op code was, just need register names"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#more-general",
    "href": "lectures/revealjs_ra-checking.qmd.html#more-general",
    "title": "Testing Register allocators",
    "section": "more general",
    "text": "more general\nTreat the allocated program as containing:\n\nSpill , : copy data (symbol representing virtual register) from a register to a spill slot.\nReload , : copy data from a spill slot to a register.\ncopy , : move data from one CPU register to another (N.B.: only regalloc-inserted moves are recognized as a Move, not moves in the original input program.)\nOp read:, read_orig: write: write_orig:: some arbitrary operation that reads some registers and writes some other registers.\n\nRun the value number over this:\nstate: for each physical register, and spill slot\nwe need either:\n\nthe virtual register name\nunknown -\n\nconflicted if it has more then one virtual register"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#steps-still-no-control-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#steps-still-no-control-flow",
    "title": "Testing Register allocators",
    "section": "steps (still no control flow )",
    "text": "steps (still no control flow )\nWhen we see a Spill, Reload, or Move, we copy the symbolic state from the source location (register or spill slot) to the destination location.\nWhen we see an Op, we do some checks then some updates:\nFor each read (input) register, we examine the symbolic value stored in the given register.\nIf that symbol matches the virtual register that the original instruction used, then the allocator has properly conveyed the virtual register’s value to its use here, and thus the allocation is correct\nIf not, we can signal a checker error, and look for the bug in our register allocator. why are there no false positives?\nFor each write (output) register, we set the symbolic value stored in the given CPU register to be the given virtual register."
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#control-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#control-flow",
    "title": "Testing Register allocators",
    "section": "control flow",
    "text": "control flow\nWe can use data flow and a lattice\nhere is the lattice\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#now-for-the-data-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#now-for-the-data-flow",
    "title": "Testing Register allocators",
    "section": "now for the data flow",
    "text": "now for the data flow\nWe start out with all physical registers and spill slots as ‘unknown’ At each join point move down the lattice\nconflicted is ok, so long as it is not used\nSince the number of physical registers and spill slots is finite we can can merge all of them at the top of each basic block.\nlike usual we might pick a good order to process basic blocks"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-about-an-example",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-about-an-example",
    "title": "Testing Register allocators",
    "section": "How about an example:",
    "text": "How about an example:\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n\nat the top of C, we see that physical p0 is conflicted -\nbut that is not a error\nafter the reload we find it contains v2"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#tracing-pointers--",
    "href": "lectures/revealjs_ra-checking.qmd.html#tracing-pointers--",
    "title": "Testing Register allocators",
    "section": "tracing pointers -",
    "text": "tracing pointers -\nSince we know what virtual registers are in each spill-slot, and virtual registers have types we can tell which spill slots contain pointers\nsuppose we have a spot where we might call a gc, we could force spilling of all live vrs that contain a pointer and then tell the gc which spill locations to consider"
  },
  {
    "objectID": "lectures/ra-checking.html#what-is-register-allocation",
    "href": "lectures/ra-checking.html#what-is-register-allocation",
    "title": "Testing Register allocators",
    "section": "what is register allocation",
    "text": "what is register allocation\nIn Bril and LLVM a program can use an arbitrary number of registers,\nvoid f() {\n    int x0 = compute(0);\n    int x1 = compute(1);\n    // ...\n    int x99 = compute(99);\n    \n    // --- 100 possibly different values were computed \n    // --- where are those values stored?\n    \n    consume(x0);\n    consume(x1);\n    // ...\n    consume(x99);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#storing-variables",
    "href": "lectures/ra-checking.html#storing-variables",
    "title": "Testing Register allocators",
    "section": "storing variables",
    "text": "storing variables\none option\nAllocate a memory location for each local variable. All of the \\(x_N\\) variables above semantically live in memory. When the function is called, it allocates a nwe area on the stack called the stack frame and uses it to store local variables.\nThis means that adding two variables, takes two loads, one add, and one store so it is very slow\nCompiling code in this way is very fast because we need to make almost no decisions: a variable reference always becomes a memory load,\nOn computers we have a limited set of registers\nRegister allocation: is assigning a value in the program to a register for storage. The register allocator decides how to shuffle values between memory and registers, and between register.\nIn Bril and LLVM we have virtual registers - as many as you want. The register allocator has to rewrite the instructions to use physical registers. Since the number of physical registers is limited, The allocator might insert additional instructions:\n\nstores (called spills) to move a register to memory\nloads (called reloads) to move memory to a register\nmoves to copy from one register to another\n\nThe locations in memory are usually on the stack and are called spill-slots",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "href": "lectures/ra-checking.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "title": "Testing Register allocators",
    "section": "example of register allocation on a machine with two physical registers",
    "text": "example of register allocation on a machine with two physical registers\nvirtual register code          physical register code \n                               {v0 -&gt; r0, v1 -&gt; r1}\n                               store r1, [sp+0]  a spill\nadd v2, v0, v1                 add r1, r0, r1 \n                               {v0 -&gt; r0, v1-&gt; [sp+-0], v2-&gt; r1}\nsub v3, v2, v0                 sub r1, r1, r0\n                               load r0, [sp+0]  a reload \nmul  v4, v3, v1                mul r0, r1, r0\n                               {v4-&gt; r0}\nstore v4, [sp+48]              store r0, [sp+48]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#complexity",
    "href": "lectures/ra-checking.html#complexity",
    "title": "Testing Register allocators",
    "section": "complexity",
    "text": "complexity\nif you do register allocation for code that is not in SSA, this is NP-complete But if you do it on code that is in SSA, the time complexity is polynomial.\nThere are lots of approximate algorithms- all complicated, lots of machines have extra constraints for instance there is a GPU load instruction that read 128 bits from memory and puts the value into 4 consecutive registers\nI’m not going to talk about these algorithms here",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#how-to-verify-correctness-of-an-allocator",
    "href": "lectures/ra-checking.html#how-to-verify-correctness-of-an-allocator",
    "title": "Testing Register allocators",
    "section": "How to Verify Correctness of an allocator?",
    "text": "How to Verify Correctness of an allocator?\nBefore and after the allocator, we have the same instructions (except for those added by the allocator)\nassume we have a machine with an infinite register set and a second machine with a finite register set.\nCorrect means both programs executed on these two machines get the same answer for all possible inputs",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#how-do-we-test-this",
    "href": "lectures/ra-checking.html#how-do-we-test-this",
    "title": "Testing Register allocators",
    "section": "how do we test this?",
    "text": "how do we test this?\nHow do we test this equivalence?\npick a random program and a random input. interpret and see if the result is the same.\ncould try more random inputs, could generate more random programs (fuzzer tools)\nCould reasonably confident but not 100% and very expensive",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "href": "lectures/ra-checking.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "title": "Testing Register allocators",
    "section": "use value numbering check one program, one basic block, all possible inputs",
    "text": "use value numbering check one program, one basic block, all possible inputs\n// original               // allocated \nld v0, [A]                ld r0, [A]\nld v1, [B]                ld r1, [B]\nld v2, [C]                ld r2, [C]\nadd v3, v0, v1            add r0, r0, r1\nadd v4, v2, v3            add r0, r2, r0\nreturn v4                 return r0\n\nv0 -&gt; vn 1 ld [A]         r0 -&gt; vn 1 ld [A]\nv1 -&gt; vn 2 ld [B]         r1 -&gt; vn 2 ld [B]\nv2 -&gt; vn 3 ld [C]         r2 -&gt; vn 3 ld [C]\nv3 -&gt; vn 4 add 1,2        r0 -&gt; vn 4 add 1,2 \nv4 -&gt; vn 5 add 3,4        r0 -&gt; vn 5 add 3,4 \nreturn vn 5               return vn 5",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#check-more-then-one-program-all-programs-at-once",
    "href": "lectures/ra-checking.html#check-more-then-one-program-all-programs-at-once",
    "title": "Testing Register allocators",
    "section": "check more then one program (all programs at once)",
    "text": "check more then one program (all programs at once)\nThis requires a proof that the two programs get the same result - this is an active research question -\nsome success but not easy\nnot used in production",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "href": "lectures/ra-checking.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "title": "Testing Register allocators",
    "section": "best we can do is generate lots of programs check each one",
    "text": "best we can do is generate lots of programs check each one\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n\nWe could use the fuzzer to generate random programs or we could use a test set",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#algorithm-linear-in-number-of-instructions",
    "href": "lectures/ra-checking.html#algorithm-linear-in-number-of-instructions",
    "title": "Testing Register allocators",
    "section": "algorithm (linear in number of instructions)",
    "text": "algorithm (linear in number of instructions)\nfor each instruction we need to form pairs - virtual and physical register that holds the same value\nfor instruction v and p, check that the arguments are equal, if not fail add the pair dest of v == dest of p\ndoes not matter what the original op code was, just need register names",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#more-general",
    "href": "lectures/ra-checking.html#more-general",
    "title": "Testing Register allocators",
    "section": "more general",
    "text": "more general\nTreat the allocated program as containing:\n\nSpill , : copy data (symbol representing virtual register) from a register to a spill slot.\nReload , : copy data from a spill slot to a register.\ncopy , : move data from one CPU register to another (N.B.: only regalloc-inserted moves are recognized as a Move, not moves in the original input program.)\nOp read:, read_orig: write: write_orig:: some arbitrary operation that reads some registers and writes some other registers.\n\nRun the value number over this:\nstate: for each physical register, and spill slot\nwe need either:\n\nthe virtual register name\nunknown -\n\nconflicted if it has more then one virtual register",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#steps-still-no-control-flow",
    "href": "lectures/ra-checking.html#steps-still-no-control-flow",
    "title": "Testing Register allocators",
    "section": "steps (still no control flow )",
    "text": "steps (still no control flow )\nWhen we see a Spill, Reload, or Move, we copy the symbolic state from the source location (register or spill slot) to the destination location.\nWhen we see an Op, we do some checks then some updates:\nFor each read (input) register, we examine the symbolic value stored in the given register.\nIf that symbol matches the virtual register that the original instruction used, then the allocator has properly conveyed the virtual register’s value to its use here, and thus the allocation is correct\nIf not, we can signal a checker error, and look for the bug in our register allocator. why are there no false positives?\nFor each write (output) register, we set the symbolic value stored in the given CPU register to be the given virtual register.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#control-flow",
    "href": "lectures/ra-checking.html#control-flow",
    "title": "Testing Register allocators",
    "section": "control flow",
    "text": "control flow\nWe can use data flow and a lattice\nhere is the lattice\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#now-for-the-data-flow",
    "href": "lectures/ra-checking.html#now-for-the-data-flow",
    "title": "Testing Register allocators",
    "section": "now for the data flow",
    "text": "now for the data flow\nWe start out with all physical registers and spill slots as ‘unknown’ At each join point move down the lattice\nconflicted is ok, so long as it is not used\nSince the number of physical registers and spill slots is finite we can can merge all of them at the top of each basic block.\nlike usual we might pick a good order to process basic blocks",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#how-about-an-example",
    "href": "lectures/ra-checking.html#how-about-an-example",
    "title": "Testing Register allocators",
    "section": "How about an example:",
    "text": "How about an example:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n\nat the top of C, we see that physical p0 is conflicted -\nbut that is not a error\nafter the reload we find it contains v2",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/ra-checking.html#tracing-pointers--",
    "href": "lectures/ra-checking.html#tracing-pointers--",
    "title": "Testing Register allocators",
    "section": "tracing pointers -",
    "text": "tracing pointers -\nSince we know what virtual registers are in each spill-slot, and virtual registers have types we can tell which spill slots contain pointers\nsuppose we have a spot where we might call a gc, we could force spilling of all live vrs that contain a pointer and then tell the gc which spill locations to consider",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Testing Register allocators"
    ]
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#remember-that-project-proposals-are-due-oct-22",
    "href": "lectures/revealjs_llvm.qmd.html#remember-that-project-proposals-are-due-oct-22",
    "title": "using llvm",
    "section": "remember that project proposals are due oct 22!",
    "text": "remember that project proposals are due oct 22!\nAt the end of the course, you’ll do a language implementation research project. This is an open-ended and open-source project that can be on any topic that you can construe as being about compiler hacking. The final product is an experience report on the course blog where you rigorously evaluate the success of your implementation.\nYou can work individually or in groups of 2–3 people.\nProposal\nanswer these three questions\n\nWhat will you do?\nHow will you do it?\nHow will you empirically measure success?\n\nI will have feedback on how to approach your project.\nImplementation\nThe main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nEvaluation\nA major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\n\nWhere will you get the input code you’ll use in your evaluation?\nHow will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs.\nHow will you measure the benefit (in performance, energy, complexity, etc.) of your implementation?\nHow will you present the data you collect from your empirical evaluation?\n\nOther questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.\nExperience Report\nFor the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions:\n\nWhat was the goal?\nWhat did you do? (Include both the design and the implementation.)\nWhat were the hardest parts to get right?\nWere you successful? (Report rigorously on your empirical evaluation.)\n\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-llvm",
    "href": "lectures/revealjs_llvm.qmd.html#using-llvm",
    "title": "using llvm",
    "section": "Using LLVM",
    "text": "Using LLVM\nhandy links\nAdrians tutorial\nskeleton code\nllvm doc\nllvm programmers guide\ngoogle, github pilot and chatgpt are very useful."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#install-clang-and-cmake",
    "href": "lectures/revealjs_llvm.qmd.html#install-clang-and-cmake",
    "title": "using llvm",
    "section": "install clang and cmake",
    "text": "install clang and cmake\nhow to install clang and cmake\nsudo apt install clang cmake"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#llvm-ir",
    "href": "lectures/revealjs_llvm.qmd.html#llvm-ir",
    "title": "using llvm",
    "section": "llvm ir",
    "text": "llvm ir\nclang -emit-llvm -S -o - temp.c\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\ncompared to bril\nmore complex types, variables are %n, assumes a stack, must be in ssa"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-copilot",
    "href": "lectures/revealjs_llvm.qmd.html#using-copilot",
    "title": "using llvm",
    "section": "using copilot",
    "text": "using copilot\nwhat does the llvm alloca do\nIn LLVM, the alloca instruction is used to allocate memory on the stack. It stands for “allocate” and is similar to the alloca function in C. The memory allocated by alloca is automatically freed when the function returns, making it suitable for allocating temporary storage within a function."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#alloca",
    "href": "lectures/revealjs_llvm.qmd.html#alloca",
    "title": "using llvm",
    "section": "alloca",
    "text": "alloca\nExplanation of alloca Instruction\nSyntax: alloca &lt;type&gt;, &lt;num_elements&gt;, &lt;alignment&gt;\n&lt;type&gt;: The type of the elements to be allocated.\n&lt;num_elements&gt;: The number of elements to allocate (optional, defaults to 1).\n&lt;alignment&gt;: The alignment of the allocated memory (optional)."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#example",
    "href": "lectures/revealjs_llvm.qmd.html#example",
    "title": "using llvm",
    "section": "example",
    "text": "example\nExplanation:\n%3 = alloca i32, align 4:\n\nAllocates memory for a single i32 (32-bit integer) on the stack.\nThe allocated memory is aligned to a 4-byte boundary.\nThe result is a pointer to the allocated memory, stored in the variable %3."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#example-2",
    "href": "lectures/revealjs_llvm.qmd.html#example-2",
    "title": "using llvm",
    "section": "example 2",
    "text": "example 2\n%4 = alloca i32, align 4:\n\nSimilar to the first instruction, this allocates memory for another i32 on the stack with 4-byte alignment.\nThe result is stored in the variable %4.\n\n\n%5 = alloca i8**, align 8:\n\nAllocates memory for a single i8** (pointer to a pointer to an 8-bit integer) on the stack.\nThe allocated memory is aligned to an 8-byte boundary.\nThe result is stored in the variable %5."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#allocate-usage",
    "href": "lectures/revealjs_llvm.qmd.html#allocate-usage",
    "title": "using llvm",
    "section": "allocate usage",
    "text": "allocate usage\nUsage:\nTemporary Storage: alloca is typically used for temporary storage within a function, such as local variables.\nAutomatic Deallocation: The memory allocated by alloca is automatically deallocated when the function returns, so there is no need to manually free it.\nExample in Context:\nIn the provided LLVM IR code, the alloca instructions are used to allocate space for local variables %3, %4, and %5 on the stack. These variables are then used to store values and perform operations within the main function."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#allocate",
    "href": "lectures/revealjs_llvm.qmd.html#allocate",
    "title": "using llvm",
    "section": "allocate",
    "text": "allocate\nIn this function:\n\n%3 is allocated for an i32 and initialized to 0.\n%4 is allocated for an i32 and initialized with the value of the first argument %0.\n%5 is allocated for an i8** and initialized with the value of the second argument %1.\nThe value stored in %4 is loaded into %6 and returned.\nThis demonstrates how alloca is used to manage local variables within an LLVM function."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#llvm-classes",
    "href": "lectures/revealjs_llvm.qmd.html#llvm-classes",
    "title": "using llvm",
    "section": "llvm classes",
    "text": "llvm classes\nwhat is an llvm value\nIn LLVM, a Value is a fundamental class that represents a typed constant or variable. It is the base class for all values computed by a program that may be used as operands to other values. This includes constants, instructions, function arguments, and more."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#value-continued",
    "href": "lectures/revealjs_llvm.qmd.html#value-continued",
    "title": "using llvm",
    "section": "value continued",
    "text": "value continued\nKey Points about llvm::Value:\nBase Class: llvm::Value is the base class for many other classes in LLVM, such as llvm::Instruction, llvm::Constant, llvm::Argument, and llvm::GlobalVariable.\nTyped: Every Value has a type, represented by the llvm::Type class. This type information is crucial for type checking and code generation.\nUse-Def Chain: Value objects maintain a list of uses, which are the places where the value is used. This is part of the use-def (use-definition) chain, which is important for optimizations and transformations."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#value-continued-1",
    "href": "lectures/revealjs_llvm.qmd.html#value-continued-1",
    "title": "using llvm",
    "section": "value continued",
    "text": "value continued\nCommon Subclasses of llvm::Value:\nllvm::Instruction: Represents an individual instruction in the LLVM IR.\nllvm::Constant: Represents a constant value, such as an integer or floating-point constant.\nllvm::Argument: Represents an argument to a function.\nllvm::GlobalVariable: Represents a global variable."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "href": "lectures/revealjs_llvm.qmd.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "title": "using llvm",
    "section": "llvm classes (llvm is c++ but does not use standard library)",
    "text": "llvm classes (llvm is c++ but does not use standard library)\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#class-hierarchy",
    "href": "lectures/revealjs_llvm.qmd.html#class-hierarchy",
    "title": "using llvm",
    "section": "class hierarchy",
    "text": "class hierarchy\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, operands are pointers to instructions"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#plugins",
    "href": "lectures/revealjs_llvm.qmd.html#plugins",
    "title": "using llvm",
    "section": "plugins",
    "text": "plugins\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThe advantage for us is that using a plugin means you do not have to ever build llvm from source."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#pass-starter",
    "href": "lectures/revealjs_llvm.qmd.html#pass-starter",
    "title": "using llvm",
    "section": "pass starter",
    "text": "pass starter\nThere is a cs6120 package that makes setting up the build process for plugins simpler\npass starter\nThis has branches\nmaster - prints names of functions\ncontainers - prints everything\nmutate - changes the code\nrtlib - easier way to insert code with needing irbuilder"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-llvm-branches",
    "href": "lectures/revealjs_llvm.qmd.html#using-llvm-branches",
    "title": "using llvm",
    "section": "using llvm branches",
    "text": "using llvm branches\nTo clone a specific branch from a GitHub repository, you can use the git clone command with the -b option followed by the branch name and the repository URL. Here is the syntax:\ngit clone -b   \nto switch branches\ngit fetch –all\ngit checkout"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#using-the-master-branch",
    "href": "lectures/revealjs_llvm.qmd.html#using-the-master-branch",
    "title": "using llvm",
    "section": "using the master branch",
    "text": "using the master branch\ngit clone https://github.com/sampsyo/llvm-pass-skeleton\nls gives\nCMakeLists.txt LICENSE README.md skeleton\nls skeleton CMakeLists.txt Skeleton.cpp"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#skeleton.cpp",
    "href": "lectures/revealjs_llvm.qmd.html#skeleton.cpp",
    "title": "using llvm",
    "section": "Skeleton.cpp",
    "text": "Skeleton.cpp\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M) {\n            errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n        }\n        return PreservedAnalyses::all();\n    };\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#how-to-build-this",
    "href": "lectures/revealjs_llvm.qmd.html#how-to-build-this",
    "title": "using llvm",
    "section": "how to build this",
    "text": "how to build this\n~/llvm/llvm-pass-skeleton$ mkdir build\ncd build \ncmake ..\nThis generates build/skeleton/SkeletonPass.so"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#how-to-run-a-plugin",
    "href": "lectures/revealjs_llvm.qmd.html#how-to-run-a-plugin",
    "title": "using llvm",
    "section": "how to run a plugin",
    "text": "how to run a plugin\nto run this\nclang -fpass-plugin=llvm-pass-skeleton/build/skeleton/SkeletonPass.so a.cpp\ncreates a.out and prints out info from the pass\nto make this easier to use you might create a bash script or a makefile"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#look-at-the-post-on-containers",
    "href": "lectures/revealjs_llvm.qmd.html#look-at-the-post-on-containers",
    "title": "using llvm",
    "section": "look at the post on containers",
    "text": "look at the post on containers"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#getting-more-info",
    "href": "lectures/revealjs_llvm.qmd.html#getting-more-info",
    "title": "using llvm",
    "section": "getting more info",
    "text": "getting more info\nSome helpful llvm operations\nerrs() &lt;&lt; \"function Body:\\n\";\nerrs() &lt;&lt; F &lt;&lt; '\\n\"; '\noutput\nI saw a function called main!\nfunction Body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#entering-containers",
    "href": "lectures/revealjs_llvm.qmd.html#entering-containers",
    "title": "using llvm",
    "section": "entering containers",
    "text": "entering containers\nPreservedAnalyses run(Module &M, ModuleAnalysisManager &AM)\n        {\n            for (auto &F : M)\n            {\n                errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n                for (auto &B : F)\n                {\n                    errs() &lt;&lt; \"starting block\\n\";\n                    errs() &lt;&lt; B &lt;&lt; \"\\n\";\n                    for (auto &I : B)\n                    {\n                        errs() &lt;&lt; \"instr:\" &lt;&lt; I &lt;&lt; \"\\n\";\n                    }\n                };\n            };\n            return PreservedAnalyses::all();\n        };\n\nI saw a function called main!\nstarting block\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n\ninstr:  %3 = alloca i32, align 4\ninstr:  %4 = alloca i32, align 4\ninstr:  %5 = alloca i8**, align 8\ninstr:  store i32 0, i32* %3, align 4\ninstr:  store i32 %0, i32* %4, align 4\ninstr:  store i8** %1, i8*** %5, align 8\ninstr:  %6 = load i32, i32* %4, align 4\ninstr:  ret i32 %6"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#modify-the-program",
    "href": "lectures/revealjs_llvm.qmd.html#modify-the-program",
    "title": "using llvm",
    "section": "modify the program",
    "text": "modify the program\nfind the binary operators and change them to multiplies\n#// temp.c\nint main(int argc, char **argv)\n{\n       return argc + 5;\n}"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#find-all-the-binary-operators",
    "href": "lectures/revealjs_llvm.qmd.html#find-all-the-binary-operators",
    "title": "using llvm",
    "section": "find all the binary operators",
    "text": "find all the binary operators\nhow do i find all the binary operators in a llvm plugin\nto find all the binary operators in an LLVM plugin, you can iterate over all instructions in each function and use the isa&lt;BinaryOperator&gt; function to check if an instruction is a binary operator. If it is, you can then cast it to a BinaryOperator using dyn_cast&lt;BinaryOperator&gt; and process it as needed.\n\nHere is an example of how you can modify your LLVM plugin to find and print all binary operators:"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#plugin",
    "href": "lectures/revealjs_llvm.qmd.html#plugin",
    "title": "using llvm",
    "section": "plugin",
    "text": "plugin\nPreservedAnalyses run(Module &M, ModuleAnalysisManager &AM)\n    {\n        for (auto &F : M)\n        {\n            errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n            for (auto &B : F)\n            {\n                for (auto &I : B)\n                {\n                    if (isa&lt;BinaryOperator&gt;(&I))\n                    {\n                        errs() &lt;&lt; \"instr:\" &lt;&lt; I &lt;&lt; \"\\n\";\n                    }\n                    auto *op = dyn_cast&lt;BinaryOperator&gt;(&I);\n                    errs() &lt;&lt; \"from_op:\" &lt;&lt; op &lt;&lt; \"\\n\";\n                }\n            };\n        };\n        return PreservedAnalyses::all();\n    }\n\noutput\nI saw a function called main!\nI saw a function called main!\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\ninstr:  %7 = add nsw i32 %6, 5\nfrom_op:0xb58610\nfrom_op:0x0"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#getting-analysis-info",
    "href": "lectures/revealjs_llvm.qmd.html#getting-analysis-info",
    "title": "using llvm",
    "section": "getting analysis info",
    "text": "getting analysis info\n   PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Get the DominatorTree for the function.\n            DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Print the dominator tree.\n            errs() &lt;&lt; \"Dominator Tree for function: \" &lt;&lt; F.getName() &lt;&lt; \"\\n\";\n            DT.print(errs());\n        }"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#irbuilder",
    "href": "lectures/revealjs_llvm.qmd.html#irbuilder",
    "title": "using llvm",
    "section": "irbuilder",
    "text": "irbuilder\nerrs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\nfor (auto &B : F){\n    errs() &lt;&lt; B &lt;&lt; \"\\n\";\n    for (auto &I : B){\n        if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)){\n            errs() &lt;&lt; \"old inst \" &lt;&lt; *op &lt;&lt; \"\\n\";\n            IRBuilder&lt;&gt; builder(op);\n            Value *left = op-&gt;getOperand(0);  // first operand\n            Value *right = op-&gt;getOperand(1); // second operad\n            Value *mul = builder.CreateMul(left, right);\n\n            errs() &lt;&lt; \"new inst:\" &lt;&lt; *mul &lt;&lt; \"\\n\";\n\n            errs() &lt;&lt; B &lt;&lt; \"\\n\";\n\n            // replace uses of op with mul\n            for (auto &U : op-&gt;uses()){\n                int num = U.getOperandNo(); // which argument\n                User *user = U.getUser();   // the instruction with the use\n                errs() &lt;&lt; \" user:\" &lt;&lt; *user &lt;&lt; \"   \";\n                user-&gt;setOperand(num, mul);\n                errs() &lt;&lt; *user &lt;&lt; \"\\n\";\n                }\n            }\n        }\n    }\n};\nreturn PreservedAnalyses::none();"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#output",
    "href": "lectures/revealjs_llvm.qmd.html#output",
    "title": "using llvm",
    "section": "output",
    "text": "output\nI saw a function called main!\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = add nsw i32 %6, 5\n  ret i32 %7"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#output-2",
    "href": "lectures/revealjs_llvm.qmd.html#output-2",
    "title": "using llvm",
    "section": "output 2",
    "text": "output 2\n\nold inst   %7 = add nsw i32 %6, 5\nnew inst:  %7 = mul i32 %6, 5\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = mul i32 %6, 5\n  %8 = add nsw i32 %6, 5\n  ret i32 %8\n\n user:  ret i32 %8     ret i32 %7"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#more-complex-transforms---for-instrumentation",
    "href": "lectures/revealjs_llvm.qmd.html#more-complex-transforms---for-instrumentation",
    "title": "using llvm",
    "section": "more complex transforms - for instrumentation",
    "text": "more complex transforms - for instrumentation\ninstrumentation code in c not using builder\ninsert calls to functions and link them in\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#chat-gpt",
    "href": "lectures/revealjs_llvm.qmd.html#chat-gpt",
    "title": "using llvm",
    "section": "chat gpt",
    "text": "chat gpt\nhow do i write an instrumentation function in c for llvm, use a plugin pass to insert a call to the instrumentation routine\n\nWrite the Instrumentation Function in C: Create a C function that you want to call from your LLVM pass.\nCreate an LLVM Pass: Write an LLVM pass that inserts a call to the instrumentation function.\nBuild and Load the Pass: Compile the pass and load it using the opt tool or integrate it into your build system."
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#instrumentation-routine",
    "href": "lectures/revealjs_llvm.qmd.html#instrumentation-routine",
    "title": "using llvm",
    "section": "instrumentation routine",
    "text": "instrumentation routine\nvoid instrument_function(const char* bb_name) {\n    printf(\"Instrumentation function called for basic block: %s\\n\", bb_name);\n}"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#pass",
    "href": "lectures/revealjs_llvm.qmd.html#pass",
    "title": "using llvm",
    "section": "pass",
    "text": "pass\n   PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        LLVMContext &Ctx = M.getContext();\n        IRBuilder&lt;&gt; Builder(Ctx);\n\n        // Declare the instrumentation function as an external function\n        FunctionType *FuncType = FunctionType::get(Type::getVoidTy(Ctx), Type::getInt8PtrTy(Cctx), false);\n        FunctionCallee InstrumentFunc =\n                  M.getOrInsertFunction(\"instrument_function\", FuncType);\n\n        for (Function &F : M) {\n\n            // Insert the call at the beginning of each basic block\n            for (BasicBlock &BB : F) {\n                Builder.SetInsertPoint(&BB, BB.begin());\n\n                // Create a global string for the basic block name\n                Value *BBName = Builder.CreateGlobalStringPtr(BB.getName());\n\n                // Create the call to the instrumentation function\n                Builder.CreateCall(InstrumentFunc, BBName);\n            }\n        }\n\n        return PreservedAnalyses::none();"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#starter-code",
    "href": "lectures/revealjs_llvm.qmd.html#starter-code",
    "title": "using llvm",
    "section": "starter code",
    "text": "starter code\nrm -r llvm-pass-skeleton\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton\nmkdir -p build \ncd build \ncmake ..\nmake"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#adrians-skeleton",
    "href": "lectures/revealjs_llvm.qmd.html#adrians-skeleton",
    "title": "using llvm",
    "section": "Adrians skeleton",
    "text": "Adrians skeleton\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#adrians-instrumentation-code",
    "href": "lectures/revealjs_llvm.qmd.html#adrians-instrumentation-code",
    "title": "using llvm",
    "section": "Adrians instrumentation code",
    "text": "Adrians instrumentation code\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#link-together",
    "href": "lectures/revealjs_llvm.qmd.html#link-together",
    "title": "using llvm",
    "section": "link together",
    "text": "link together\ncd llvm-pass-skeleton\ncc -c rtlib.c --- generates rtlib.o \nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test.cpp   -- generates test.o\ncc test.o rtlib.o  -- links it together \n./a.out     --   runs it"
  },
  {
    "objectID": "lectures/revealjs_llvm.qmd.html#homework",
    "href": "lectures/revealjs_llvm.qmd.html#homework",
    "title": "using llvm",
    "section": "Homework",
    "text": "Homework\nFollow the LLVM tutorial blog post far enough to implement a pass that changes program execution.\nThis is intentionally open-ended. You can be as ambitious or as unambitious as you want. An example of an unambitious but acceptable task would be to print out a message every time the program uses floating-point division.\nAn example of an ambitious task would be to implement an optimization on LLVM IR and make sure it speeds things up in actual wall-clock time execution.\nFind a real-ish C/C++ program somewhere and run your pass on it to observe the results."
  },
  {
    "objectID": "lectures/llvm.html",
    "href": "lectures/llvm.html",
    "title": "using llvm",
    "section": "",
    "text": "At the end of the course, you’ll do a language implementation research project. This is an open-ended and open-source project that can be on any topic that you can construe as being about compiler hacking. The final product is an experience report on the course blog where you rigorously evaluate the success of your implementation.\nYou can work individually or in groups of 2–3 people.\nProposal\nanswer these three questions\n\nWhat will you do?\nHow will you do it?\nHow will you empirically measure success?\n\nI will have feedback on how to approach your project.\nImplementation\nThe main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nEvaluation\nA major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\n\nWhere will you get the input code you’ll use in your evaluation?\nHow will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs.\nHow will you measure the benefit (in performance, energy, complexity, etc.) of your implementation?\nHow will you present the data you collect from your empirical evaluation?\n\nOther questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.\nExperience Report\nFor the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions:\n\nWhat was the goal?\nWhat did you do? (Include both the design and the implementation.)\nWhat were the hardest parts to get right?\nWere you successful? (Report rigorously on your empirical evaluation.)\n\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#remember-that-project-proposals-are-due-oct-22",
    "href": "lectures/llvm.html#remember-that-project-proposals-are-due-oct-22",
    "title": "using llvm",
    "section": "",
    "text": "At the end of the course, you’ll do a language implementation research project. This is an open-ended and open-source project that can be on any topic that you can construe as being about compiler hacking. The final product is an experience report on the course blog where you rigorously evaluate the success of your implementation.\nYou can work individually or in groups of 2–3 people.\nProposal\nanswer these three questions\n\nWhat will you do?\nHow will you do it?\nHow will you empirically measure success?\n\nI will have feedback on how to approach your project.\nImplementation\nThe main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nEvaluation\nA major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\n\nWhere will you get the input code you’ll use in your evaluation?\nHow will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs.\nHow will you measure the benefit (in performance, energy, complexity, etc.) of your implementation?\nHow will you present the data you collect from your empirical evaluation?\n\nOther questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.\nExperience Report\nFor the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions:\n\nWhat was the goal?\nWhat did you do? (Include both the design and the implementation.)\nWhat were the hardest parts to get right?\nWere you successful? (Report rigorously on your empirical evaluation.)\n\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-llvm",
    "href": "lectures/llvm.html#using-llvm",
    "title": "using llvm",
    "section": "Using LLVM",
    "text": "Using LLVM\nhandy links\nAdrians tutorial\nskeleton code\nllvm doc\nllvm programmers guide\ngoogle, github pilot and chatgpt are very useful.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#install-clang-and-cmake",
    "href": "lectures/llvm.html#install-clang-and-cmake",
    "title": "using llvm",
    "section": "install clang and cmake",
    "text": "install clang and cmake\nhow to install clang and cmake\nsudo apt install clang cmake",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#llvm-ir",
    "href": "lectures/llvm.html#llvm-ir",
    "title": "using llvm",
    "section": "llvm ir",
    "text": "llvm ir\nclang -emit-llvm -S -o - temp.c\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\ncompared to bril\nmore complex types, variables are %n, assumes a stack, must be in ssa",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-copilot",
    "href": "lectures/llvm.html#using-copilot",
    "title": "using llvm",
    "section": "using copilot",
    "text": "using copilot\nwhat does the llvm alloca do\nIn LLVM, the alloca instruction is used to allocate memory on the stack. It stands for “allocate” and is similar to the alloca function in C. The memory allocated by alloca is automatically freed when the function returns, making it suitable for allocating temporary storage within a function.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#alloca",
    "href": "lectures/llvm.html#alloca",
    "title": "using llvm",
    "section": "alloca",
    "text": "alloca\nExplanation of alloca Instruction\nSyntax: alloca &lt;type&gt;, &lt;num_elements&gt;, &lt;alignment&gt;\n&lt;type&gt;: The type of the elements to be allocated.\n&lt;num_elements&gt;: The number of elements to allocate (optional, defaults to 1).\n&lt;alignment&gt;: The alignment of the allocated memory (optional).",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#example",
    "href": "lectures/llvm.html#example",
    "title": "using llvm",
    "section": "example",
    "text": "example\nExplanation:\n%3 = alloca i32, align 4:\n\nAllocates memory for a single i32 (32-bit integer) on the stack.\nThe allocated memory is aligned to a 4-byte boundary.\nThe result is a pointer to the allocated memory, stored in the variable %3.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#example-2",
    "href": "lectures/llvm.html#example-2",
    "title": "using llvm",
    "section": "example 2",
    "text": "example 2\n%4 = alloca i32, align 4:\n\nSimilar to the first instruction, this allocates memory for another i32 on the stack with 4-byte alignment.\nThe result is stored in the variable %4.\n\n\n%5 = alloca i8**, align 8:\n\nAllocates memory for a single i8** (pointer to a pointer to an 8-bit integer) on the stack.\nThe allocated memory is aligned to an 8-byte boundary.\nThe result is stored in the variable %5.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#allocate-usage",
    "href": "lectures/llvm.html#allocate-usage",
    "title": "using llvm",
    "section": "allocate usage",
    "text": "allocate usage\nUsage:\nTemporary Storage: alloca is typically used for temporary storage within a function, such as local variables.\nAutomatic Deallocation: The memory allocated by alloca is automatically deallocated when the function returns, so there is no need to manually free it.\nExample in Context:\nIn the provided LLVM IR code, the alloca instructions are used to allocate space for local variables %3, %4, and %5 on the stack. These variables are then used to store values and perform operations within the main function.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#allocate",
    "href": "lectures/llvm.html#allocate",
    "title": "using llvm",
    "section": "allocate",
    "text": "allocate\nIn this function:\n\n%3 is allocated for an i32 and initialized to 0.\n%4 is allocated for an i32 and initialized with the value of the first argument %0.\n%5 is allocated for an i8** and initialized with the value of the second argument %1.\nThe value stored in %4 is loaded into %6 and returned.\nThis demonstrates how alloca is used to manage local variables within an LLVM function.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#llvm-classes",
    "href": "lectures/llvm.html#llvm-classes",
    "title": "using llvm",
    "section": "llvm classes",
    "text": "llvm classes\nwhat is an llvm value\nIn LLVM, a Value is a fundamental class that represents a typed constant or variable. It is the base class for all values computed by a program that may be used as operands to other values. This includes constants, instructions, function arguments, and more.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#value-continued",
    "href": "lectures/llvm.html#value-continued",
    "title": "using llvm",
    "section": "value continued",
    "text": "value continued\nKey Points about llvm::Value:\nBase Class: llvm::Value is the base class for many other classes in LLVM, such as llvm::Instruction, llvm::Constant, llvm::Argument, and llvm::GlobalVariable.\nTyped: Every Value has a type, represented by the llvm::Type class. This type information is crucial for type checking and code generation.\nUse-Def Chain: Value objects maintain a list of uses, which are the places where the value is used. This is part of the use-def (use-definition) chain, which is important for optimizations and transformations.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#value-continued-1",
    "href": "lectures/llvm.html#value-continued-1",
    "title": "using llvm",
    "section": "value continued",
    "text": "value continued\nCommon Subclasses of llvm::Value:\nllvm::Instruction: Represents an individual instruction in the LLVM IR.\nllvm::Constant: Represents a constant value, such as an integer or floating-point constant.\nllvm::Argument: Represents an argument to a function.\nllvm::GlobalVariable: Represents a global variable.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "href": "lectures/llvm.html#llvm-classes-llvm-is-c-but-does-not-use-standard-library",
    "title": "using llvm",
    "section": "llvm classes (llvm is c++ but does not use standard library)",
    "text": "llvm classes (llvm is c++ but does not use standard library)\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#class-hierarchy",
    "href": "lectures/llvm.html#class-hierarchy",
    "title": "using llvm",
    "section": "class hierarchy",
    "text": "class hierarchy\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, operands are pointers to instructions",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#plugins",
    "href": "lectures/llvm.html#plugins",
    "title": "using llvm",
    "section": "plugins",
    "text": "plugins\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThe advantage for us is that using a plugin means you do not have to ever build llvm from source.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#pass-starter",
    "href": "lectures/llvm.html#pass-starter",
    "title": "using llvm",
    "section": "pass starter",
    "text": "pass starter\nThere is a cs6120 package that makes setting up the build process for plugins simpler\npass starter\nThis has branches\nmaster - prints names of functions\ncontainers - prints everything\nmutate - changes the code\nrtlib - easier way to insert code with needing irbuilder",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-llvm-branches",
    "href": "lectures/llvm.html#using-llvm-branches",
    "title": "using llvm",
    "section": "using llvm branches",
    "text": "using llvm branches\nTo clone a specific branch from a GitHub repository, you can use the git clone command with the -b option followed by the branch name and the repository URL. Here is the syntax:\ngit clone -b   \nto switch branches\ngit fetch –all\ngit checkout",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#using-the-master-branch",
    "href": "lectures/llvm.html#using-the-master-branch",
    "title": "using llvm",
    "section": "using the master branch",
    "text": "using the master branch\ngit clone https://github.com/sampsyo/llvm-pass-skeleton\nls gives\nCMakeLists.txt LICENSE README.md skeleton\nls skeleton CMakeLists.txt Skeleton.cpp",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#skeleton.cpp",
    "href": "lectures/llvm.html#skeleton.cpp",
    "title": "using llvm",
    "section": "Skeleton.cpp",
    "text": "Skeleton.cpp\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M) {\n            errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n        }\n        return PreservedAnalyses::all();\n    };\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#how-to-build-this",
    "href": "lectures/llvm.html#how-to-build-this",
    "title": "using llvm",
    "section": "how to build this",
    "text": "how to build this\n~/llvm/llvm-pass-skeleton$ mkdir build\ncd build \ncmake ..\nThis generates build/skeleton/SkeletonPass.so",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#how-to-run-a-plugin",
    "href": "lectures/llvm.html#how-to-run-a-plugin",
    "title": "using llvm",
    "section": "how to run a plugin",
    "text": "how to run a plugin\nto run this\nclang -fpass-plugin=llvm-pass-skeleton/build/skeleton/SkeletonPass.so a.cpp\ncreates a.out and prints out info from the pass\nto make this easier to use you might create a bash script or a makefile",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#look-at-the-post-on-containers",
    "href": "lectures/llvm.html#look-at-the-post-on-containers",
    "title": "using llvm",
    "section": "look at the post on containers",
    "text": "look at the post on containers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#getting-more-info",
    "href": "lectures/llvm.html#getting-more-info",
    "title": "using llvm",
    "section": "getting more info",
    "text": "getting more info\nSome helpful llvm operations\nerrs() &lt;&lt; \"function Body:\\n\";\nerrs() &lt;&lt; F &lt;&lt; '\\n\"; '\noutput\nI saw a function called main!\nfunction Body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#entering-containers",
    "href": "lectures/llvm.html#entering-containers",
    "title": "using llvm",
    "section": "entering containers",
    "text": "entering containers\nPreservedAnalyses run(Module &M, ModuleAnalysisManager &AM)\n        {\n            for (auto &F : M)\n            {\n                errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n                for (auto &B : F)\n                {\n                    errs() &lt;&lt; \"starting block\\n\";\n                    errs() &lt;&lt; B &lt;&lt; \"\\n\";\n                    for (auto &I : B)\n                    {\n                        errs() &lt;&lt; \"instr:\" &lt;&lt; I &lt;&lt; \"\\n\";\n                    }\n                };\n            };\n            return PreservedAnalyses::all();\n        };\n\nI saw a function called main!\nstarting block\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n\ninstr:  %3 = alloca i32, align 4\ninstr:  %4 = alloca i32, align 4\ninstr:  %5 = alloca i8**, align 8\ninstr:  store i32 0, i32* %3, align 4\ninstr:  store i32 %0, i32* %4, align 4\ninstr:  store i8** %1, i8*** %5, align 8\ninstr:  %6 = load i32, i32* %4, align 4\ninstr:  ret i32 %6",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#modify-the-program",
    "href": "lectures/llvm.html#modify-the-program",
    "title": "using llvm",
    "section": "modify the program",
    "text": "modify the program\nfind the binary operators and change them to multiplies\n#// temp.c\nint main(int argc, char **argv)\n{\n       return argc + 5;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#find-all-the-binary-operators",
    "href": "lectures/llvm.html#find-all-the-binary-operators",
    "title": "using llvm",
    "section": "find all the binary operators",
    "text": "find all the binary operators\nhow do i find all the binary operators in a llvm plugin\nto find all the binary operators in an LLVM plugin, you can iterate over all instructions in each function and use the isa&lt;BinaryOperator&gt; function to check if an instruction is a binary operator. If it is, you can then cast it to a BinaryOperator using dyn_cast&lt;BinaryOperator&gt; and process it as needed.\n\nHere is an example of how you can modify your LLVM plugin to find and print all binary operators:",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#plugin",
    "href": "lectures/llvm.html#plugin",
    "title": "using llvm",
    "section": "plugin",
    "text": "plugin\nPreservedAnalyses run(Module &M, ModuleAnalysisManager &AM)\n    {\n        for (auto &F : M)\n        {\n            errs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\n            for (auto &B : F)\n            {\n                for (auto &I : B)\n                {\n                    if (isa&lt;BinaryOperator&gt;(&I))\n                    {\n                        errs() &lt;&lt; \"instr:\" &lt;&lt; I &lt;&lt; \"\\n\";\n                    }\n                    auto *op = dyn_cast&lt;BinaryOperator&gt;(&I);\n                    errs() &lt;&lt; \"from_op:\" &lt;&lt; op &lt;&lt; \"\\n\";\n                }\n            };\n        };\n        return PreservedAnalyses::all();\n    }\n\noutput\nI saw a function called main!\nI saw a function called main!\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\nfrom_op:0x0\ninstr:  %7 = add nsw i32 %6, 5\nfrom_op:0xb58610\nfrom_op:0x0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#getting-analysis-info",
    "href": "lectures/llvm.html#getting-analysis-info",
    "title": "using llvm",
    "section": "getting analysis info",
    "text": "getting analysis info\n   PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Get the DominatorTree for the function.\n            DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Print the dominator tree.\n            errs() &lt;&lt; \"Dominator Tree for function: \" &lt;&lt; F.getName() &lt;&lt; \"\\n\";\n            DT.print(errs());\n        }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#irbuilder",
    "href": "lectures/llvm.html#irbuilder",
    "title": "using llvm",
    "section": "irbuilder",
    "text": "irbuilder\nerrs() &lt;&lt; \"I saw a function called \" &lt;&lt; F.getName() &lt;&lt; \"!\\n\";\nfor (auto &B : F){\n    errs() &lt;&lt; B &lt;&lt; \"\\n\";\n    for (auto &I : B){\n        if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)){\n            errs() &lt;&lt; \"old inst \" &lt;&lt; *op &lt;&lt; \"\\n\";\n            IRBuilder&lt;&gt; builder(op);\n            Value *left = op-&gt;getOperand(0);  // first operand\n            Value *right = op-&gt;getOperand(1); // second operad\n            Value *mul = builder.CreateMul(left, right);\n\n            errs() &lt;&lt; \"new inst:\" &lt;&lt; *mul &lt;&lt; \"\\n\";\n\n            errs() &lt;&lt; B &lt;&lt; \"\\n\";\n\n            // replace uses of op with mul\n            for (auto &U : op-&gt;uses()){\n                int num = U.getOperandNo(); // which argument\n                User *user = U.getUser();   // the instruction with the use\n                errs() &lt;&lt; \" user:\" &lt;&lt; *user &lt;&lt; \"   \";\n                user-&gt;setOperand(num, mul);\n                errs() &lt;&lt; *user &lt;&lt; \"\\n\";\n                }\n            }\n        }\n    }\n};\nreturn PreservedAnalyses::none();",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#output",
    "href": "lectures/llvm.html#output",
    "title": "using llvm",
    "section": "output",
    "text": "output\nI saw a function called main!\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = add nsw i32 %6, 5\n  ret i32 %7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#output-2",
    "href": "lectures/llvm.html#output-2",
    "title": "using llvm",
    "section": "output 2",
    "text": "output 2\n\nold inst   %7 = add nsw i32 %6, 5\nnew inst:  %7 = mul i32 %6, 5\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = mul i32 %6, 5\n  %8 = add nsw i32 %6, 5\n  ret i32 %8\n\n user:  ret i32 %8     ret i32 %7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#more-complex-transforms---for-instrumentation",
    "href": "lectures/llvm.html#more-complex-transforms---for-instrumentation",
    "title": "using llvm",
    "section": "more complex transforms - for instrumentation",
    "text": "more complex transforms - for instrumentation\ninstrumentation code in c not using builder\ninsert calls to functions and link them in\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#chat-gpt",
    "href": "lectures/llvm.html#chat-gpt",
    "title": "using llvm",
    "section": "chat gpt",
    "text": "chat gpt\nhow do i write an instrumentation function in c for llvm, use a plugin pass to insert a call to the instrumentation routine\n\nWrite the Instrumentation Function in C: Create a C function that you want to call from your LLVM pass.\nCreate an LLVM Pass: Write an LLVM pass that inserts a call to the instrumentation function.\nBuild and Load the Pass: Compile the pass and load it using the opt tool or integrate it into your build system.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#instrumentation-routine",
    "href": "lectures/llvm.html#instrumentation-routine",
    "title": "using llvm",
    "section": "instrumentation routine",
    "text": "instrumentation routine\nvoid instrument_function(const char* bb_name) {\n    printf(\"Instrumentation function called for basic block: %s\\n\", bb_name);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#pass",
    "href": "lectures/llvm.html#pass",
    "title": "using llvm",
    "section": "pass",
    "text": "pass\n   PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        LLVMContext &Ctx = M.getContext();\n        IRBuilder&lt;&gt; Builder(Ctx);\n\n        // Declare the instrumentation function as an external function\n        FunctionType *FuncType = FunctionType::get(Type::getVoidTy(Ctx), Type::getInt8PtrTy(Cctx), false);\n        FunctionCallee InstrumentFunc =\n                  M.getOrInsertFunction(\"instrument_function\", FuncType);\n\n        for (Function &F : M) {\n\n            // Insert the call at the beginning of each basic block\n            for (BasicBlock &BB : F) {\n                Builder.SetInsertPoint(&BB, BB.begin());\n\n                // Create a global string for the basic block name\n                Value *BBName = Builder.CreateGlobalStringPtr(BB.getName());\n\n                // Create the call to the instrumentation function\n                Builder.CreateCall(InstrumentFunc, BBName);\n            }\n        }\n\n        return PreservedAnalyses::none();",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#starter-code",
    "href": "lectures/llvm.html#starter-code",
    "title": "using llvm",
    "section": "starter code",
    "text": "starter code\nrm -r llvm-pass-skeleton\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton\nmkdir -p build \ncd build \ncmake ..\nmake",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#adrians-skeleton",
    "href": "lectures/llvm.html#adrians-skeleton",
    "title": "using llvm",
    "section": "Adrians skeleton",
    "text": "Adrians skeleton\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#adrians-instrumentation-code",
    "href": "lectures/llvm.html#adrians-instrumentation-code",
    "title": "using llvm",
    "section": "Adrians instrumentation code",
    "text": "Adrians instrumentation code\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#link-together",
    "href": "lectures/llvm.html#link-together",
    "title": "using llvm",
    "section": "link together",
    "text": "link together\ncd llvm-pass-skeleton\ncc -c rtlib.c --- generates rtlib.o \nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test.cpp   -- generates test.o\ncc test.o rtlib.o  -- links it together \n./a.out     --   runs it",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/llvm.html#homework",
    "href": "lectures/llvm.html#homework",
    "title": "using llvm",
    "section": "Homework",
    "text": "Homework\nFollow the LLVM tutorial blog post far enough to implement a pass that changes program execution.\nThis is intentionally open-ended. You can be as ambitious or as unambitious as you want. An example of an unambitious but acceptable task would be to print out a message every time the program uses floating-point division.\nAn example of an ambitious task would be to implement an optimization on LLVM IR and make sure it speeds things up in actual wall-clock time execution.\nFind a real-ish C/C++ program somewhere and run your pass on it to observe the results.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "using llvm"
    ]
  },
  {
    "objectID": "lectures/revealjs_junk.qmd.html#other",
    "href": "lectures/revealjs_junk.qmd.html#other",
    "title": "test",
    "section": "other",
    "text": "other\nentry – a b –&gt; b1 b1 –v1_0 v0_0 v0_1 + c m–&gt; comp_val comp_val – v1_1 v0_1 + c m –&gt; if_1\ncomp_val – v0_1 v1_1 c m –&gt; else_1 if_1 – v3_2 v1_1 c m –&gt; loop_bound else_1 – v3_1 v1_1 c m –&gt; loop_bound loop_bound – m –&gt; pend loop_bound –c –&gt; update_val update_val – v3_3 v0_2 c v0_1 g –&gt; if_2 update_val – v3_3 v0_2 c v0_1 g –&gt; else_2 if_2 – v4_1 v3_3 c v1_3 v0_1–&gt; back else_2 – v3_3 v9_2 c v1_1 v0_3–&gt; back back– v3_3 v1_2 c p1 –&gt; comp_val\n```"
  },
  {
    "objectID": "lectures/junk.html",
    "href": "lectures/junk.html",
    "title": "test",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry[\"op1=\n       op2=\"]\nb1[\"  vc0.0: int = const 0;\n  v0.0: int = id op1;\n  v1.0: int = id op2;\n  v1.1 = v1.0 \nv0.1 = v0.0 \n  jmp .cmp.val;\"]\n\ncomp_val[\"comp_val:\n  v1.1 = v1.1\n  v0.1: = v0.1\n  v2.1: bool = lt v0.1 v1.1;\n  br v2.1 .if.1 .else.1;\"]\nif_1[\"if1:  v3.2: int = sub v1.1 v0.1;\n v3.3: = v3.2 \n  jmp .loop.bound;\"]\nelse_1[\" v3.1: int = sub v0.1 v1.1;\n v3.3 = v3.1 \n  jmp .loop.bound;\"]\nloop_bound[\"loop_bound   v3.3 = v3.3\n  v4.1: bool = eq v3.3 vc0.0;\n  br v4.1 .program.end .update.val;\"]\nupdate_val[\"br v2.1 .if.2 .else.2;\"]\nif_2[\"  v1.3: int = id v3.3;\nv1.2 = v1.3\n  v0.2 = v0.1\n  jmp .back;\"]\nelse_2[\"  v0.3: int = id v3.3;\nv1.2 = v1.1 v1.3 \n  v0.2 = v0.3 v0.1\n  jmp .back;\"]\nback[\"  v1.2= v1.2\n  v0.2: = v0.2\n   v3.0 =  v3.3 \n    v2.0 = v2.1\n    v1.1 = v1.2\n    v0.1 = v0.2\n  jmp .cmp.val;\"]\npend[\"= v1.1\"]\n\nentry -- op1 op2 --&gt; b1\nb1 -- Xv1.1 Xv0.1 --&gt; comp_val\ncomp_val -- v1_1 xv0_1 --&gt; if_1\ncomp_val -- Xv_1 Xv0_1  --&gt; else_1\nif_1 --   Xv1_1 Xv3_3 --&gt; loop_bound\nelse_1 -- Xv1_1 Xv3_3--&gt; loop_bound\nloop_bound -- Xv1_1 --&gt; pend\nloop_bound --&gt; update_val\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1--&gt; if_2\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1 --&gt; else_2\nif_2 -- v4_1 v3_3  vc0_0 v1_3 v0_1--&gt; back\nelse_2  -- v4_1 v3_3  v9_2 vc0_0 v1_1 v0_3--&gt; back\nback-- xv1.1 Xv0.0--&gt; comp_val\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nentry[\"op1=\n       op2=\"]\nb1[\"  vc0.0: int = const 0;\n  v0.0: int = id op1;\n  v1.0: int = id op2;\n  v1.1 = v1.0 \nv0.1 = v0.0 \n  jmp .cmp.val;\"]\n\ncomp_val[\"comp_val:\n  v1.1 = v1.1\n  v0.1: = v0.1\n  v2.1: bool = lt v0.1 v1.1;\n  br v2.1 .if.1 .else.1;\"]\nif_1[\"if1:  v3.2: int = sub v1.1 v0.1;\n v3.3: = v3.2 \n  jmp .loop.bound;\"]\nelse_1[\" v3.1: int = sub v0.1 v1.1;\n v3.3 = v3.1 \n  jmp .loop.bound;\"]\nloop_bound[\"loop_bound   v3.3 = v3.3\n  v4.1: bool = eq v3.3 vc0.0;\n  br v4.1 .program.end .update.val;\"]\nupdate_val[\"br v2.1 .if.2 .else.2;\"]\nif_2[\"  v1.3: int = id v3.3;\nv1.2 = v1.3\n  v0.2 = v0.1\n  jmp .back;\"]\nelse_2[\"  v0.3: int = id v3.3;\nv1.2 = v1.1 v1.3 \n  v0.2 = v0.3 v0.1\n  jmp .back;\"]\nback[\"  v1.2= v1.2\n  v0.2: = v0.2\n   v3.0 =  v3.3 \n    v2.0 = v2.1\n    v1.1 = v1.2\n    v0.1 = v0.2\n  jmp .cmp.val;\"]\npend[\"= v1.1\"]\n\nentry -- op1 op2 --&gt; b1\nb1 -- Xv1.1 Xv0.1 --&gt; comp_val\ncomp_val -- v1_1 xv0_1 --&gt; if_1\ncomp_val -- Xv_1 Xv0_1  --&gt; else_1\nif_1 --   Xv1_1 Xv3_3 --&gt; loop_bound\nelse_1 -- Xv1_1 Xv3_3--&gt; loop_bound\nloop_bound -- Xv1_1 --&gt; pend\nloop_bound --&gt; update_val\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1--&gt; if_2\nupdate_val -- v4_1 v3_3  v0_2 vc0_0  v0_1 --&gt; else_2\nif_2 -- v4_1 v3_3  vc0_0 v1_3 v0_1--&gt; back\nelse_2  -- v4_1 v3_3  v9_2 vc0_0 v1_1 v0_3--&gt; back\nback-- xv1.1 Xv0.0--&gt; comp_val",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "test"
    ]
  },
  {
    "objectID": "lectures/junk.html#other",
    "href": "lectures/junk.html#other",
    "title": "test",
    "section": "other",
    "text": "other\nentry – a b –&gt; b1 b1 –v1_0 v0_0 v0_1 + c m–&gt; comp_val comp_val – v1_1 v0_1 + c m –&gt; if_1\ncomp_val – v0_1 v1_1 c m –&gt; else_1 if_1 – v3_2 v1_1 c m –&gt; loop_bound else_1 – v3_1 v1_1 c m –&gt; loop_bound loop_bound – m –&gt; pend loop_bound –c –&gt; update_val update_val – v3_3 v0_2 c v0_1 g –&gt; if_2 update_val – v3_3 v0_2 c v0_1 g –&gt; else_2 if_2 – v4_1 v3_3 c v1_3 v0_1–&gt; back else_2 – v3_3 v9_2 c v1_1 v0_3–&gt; back back– v3_3 v1_2 c p1 –&gt; comp_val\n```",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "test"
    ]
  },
  {
    "objectID": "lectures/110_whole_program.html",
    "href": "lectures/110_whole_program.html",
    "title": "11 Whole program",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "11 Whole program"
    ]
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#continuing-on-branch-divergence",
    "href": "lectures/revealjs_diverg1.qmd.html#continuing-on-branch-divergence",
    "title": "divergent flow PART TWO",
    "section": "continuing on branch divergence",
    "text": "continuing on branch divergence\nAt a branch- we turn off some threads, when do we go to the other threads, when do we reconverge?\nReconverge at the post-dominator of the branch. Closest point that must be reached by all paths from the branch.\nSome numbers from Fung micro 2007\n\nreconverge at post dominator vs never reconverge 93% speedup\nreconverge dynamically at best place 140% speedup\nestimate 5% chip area for simt-stack"
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#latency-hiding",
    "href": "lectures/revealjs_diverg1.qmd.html#latency-hiding",
    "title": "divergent flow PART TWO",
    "section": "latency hiding",
    "text": "latency hiding\nExecute lots of warps, cache hit rates are low, do not stall the pipeline on a miss.\nWhen a load misses, remove warp from an active list, in the next cycle run another warp from the active list.\nTo make the switch fast, and hide the latency, start each warp with all the resources it needs, (registers/shared mem etc) switching a warp, is just changed the pointers to the active resources."
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#stack-reconvergence-an-example",
    "href": "lectures/revealjs_diverg1.qmd.html#stack-reconvergence-an-example",
    "title": "divergent flow PART TWO",
    "section": "stack reconvergence an example",
    "text": "stack reconvergence an example\n\n\n__managed__ int *a, *b, *c;\n\n__global__ void kern() {\n  int t = threadIdx.x;\n\n\n\n  if (t &lt; 5) {\n\n\n    a[t] = 1;\n    b[t] = 2;\n    c[t] = 3;\n\n\n  } else {\n    a[t + 6] = 5;\n    b[t + 6] = 7;\n    c[t + 6] = 9;\n  }\n  a[6] = 99;\n}\n\n\n\n\n  SSY `(.L_x_0)\n\n\n    @!P0 BRA `(.L_x_1) ToTarget \n    // fallthrough\n\n    SYNC  &lt;  finish one side-\n  \n    .L_x_1:   &lt; branch target \n  \n    SYNC   &lt; finish one side \n\n\n  .L_x_0: &lt;  post dominator"
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#stack-control",
    "href": "lectures/revealjs_diverg1.qmd.html#stack-control",
    "title": "divergent flow PART TWO",
    "section": "stack control",
    "text": "stack control\nWhen a kernel is launched, a stack is allocated for each corresponding warp.\nstack entry:\n\na 32-bit mask is stored\nthe address of the next instruction to execute (next program counter or npc) and\naddress of the instruction at which the threads must wait for reconvergence (reconvergence program counter or rpc).\n\nThe next pc to execute is the address on the stack, as each instruction executes this address advances\nEach stack is initialized with an entry composed of:\na mask in which all the threads in the warp are active, the start address of the program as npc and the last address in memory as rpc (note that it does not need to be a valid instruction address)."
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#ssy-instruction",
    "href": "lectures/revealjs_diverg1.qmd.html#ssy-instruction",
    "title": "divergent flow PART TWO",
    "section": "ssy instruction",
    "text": "ssy instruction\nThe SSY instruction prepare the stack for a possible divergence\nadds two entries- what to do after the if-then-else, what to do on a branch\nWhen SSY @addr is executed, the top entry of the stack is popped. A new entry is pushed to handle the execution after reconvergence:\nThe npc is the reconvergence address (@addr), and the rpc and the mask are copied from the popped entry.\nA second new entry is then pushed to handle the potentially diverging portion of code: the npc is the actual next instruction (the npc of the popped entry + 8, since instructions are encoded in 64 bits), the rpc is the reconvergence address (@addr) and the mask is the same as in the popped entry.\nThe top entry is used to let all active threads execute the next instruction. Note that these instructions do not create divergence but instead prepare the stack for a possible upcoming divergence, which is why the mask remains unchanged at this point.\nreference"
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#actual-divergence",
    "href": "lectures/revealjs_diverg1.qmd.html#actual-divergence",
    "title": "divergent flow PART TWO",
    "section": "Actual Divergence",
    "text": "Actual Divergence\nActual divergence happens when a branch (BRA @addr) instruction is executed conditionally by only a subset of the threads of a warp. When this happens, the top entry of the corresponding stack is popped. Two new entries are then pushed:\n\nThe first pushed entry concerns the threads which do not take the branch:\n\nThe rpc is the same as in the popped entry.\nThe npc corresponds to the next instruction in the code (i.e., the current npc + 8).\nThe mask activates only the threads that do not take the branch (the ones for which the condition is false).\n\nThe second entry has the target address of the branch as npc and the same rpc as the popped entry:\n\nIts mask activates only the threads that take the branch (the ones for which the condition is true).\n\n\nAs a consequence, the GPU first executes the threads that take the branch until they reach a reconvergence instruction added by the compiler: SYNC or BRK (depending on whether an SSY or a PBK was executed before)."
  },
  {
    "objectID": "lectures/revealjs_diverg1.qmd.html#sync",
    "href": "lectures/revealjs_diverg1.qmd.html#sync",
    "title": "divergent flow PART TWO",
    "section": "sync",
    "text": "sync\nThe reconvergence instruction sync pops the top entry from the stack.\nThe GPU then resumes execution with the group of threads active in the mask of the new entry at the top of the stack: the threads that do not take the branch. When they reach a SYNC instruction, their corresponding entry is popped from the stack: the reconvergence is done and the execution flow resumes at the reconvergence address (which is the npc of the entry at the top of the stack at this point)."
  },
  {
    "objectID": "lectures/diverg1.html",
    "href": "lectures/diverg1.html",
    "title": "divergent flow PART TWO",
    "section": "",
    "text": "At a branch- we turn off some threads, when do we go to the other threads, when do we reconverge?\nReconverge at the post-dominator of the branch. Closest point that must be reached by all paths from the branch.\nSome numbers from Fung micro 2007\n\nreconverge at post dominator vs never reconverge 93% speedup\nreconverge dynamically at best place 140% speedup\nestimate 5% chip area for simt-stack",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#continuing-on-branch-divergence",
    "href": "lectures/diverg1.html#continuing-on-branch-divergence",
    "title": "divergent flow PART TWO",
    "section": "",
    "text": "At a branch- we turn off some threads, when do we go to the other threads, when do we reconverge?\nReconverge at the post-dominator of the branch. Closest point that must be reached by all paths from the branch.\nSome numbers from Fung micro 2007\n\nreconverge at post dominator vs never reconverge 93% speedup\nreconverge dynamically at best place 140% speedup\nestimate 5% chip area for simt-stack",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#latency-hiding",
    "href": "lectures/diverg1.html#latency-hiding",
    "title": "divergent flow PART TWO",
    "section": "latency hiding",
    "text": "latency hiding\nExecute lots of warps, cache hit rates are low, do not stall the pipeline on a miss.\nWhen a load misses, remove warp from an active list, in the next cycle run another warp from the active list.\nTo make the switch fast, and hide the latency, start each warp with all the resources it needs, (registers/shared mem etc) switching a warp, is just changed the pointers to the active resources.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#stack-reconvergence-an-example",
    "href": "lectures/diverg1.html#stack-reconvergence-an-example",
    "title": "divergent flow PART TWO",
    "section": "stack reconvergence an example",
    "text": "stack reconvergence an example\n\n\n__managed__ int *a, *b, *c;\n\n__global__ void kern() {\n  int t = threadIdx.x;\n\n\n\n  if (t &lt; 5) {\n\n\n    a[t] = 1;\n    b[t] = 2;\n    c[t] = 3;\n\n\n  } else {\n    a[t + 6] = 5;\n    b[t + 6] = 7;\n    c[t + 6] = 9;\n  }\n  a[6] = 99;\n}\n\n\n\n\n  SSY `(.L_x_0)\n\n\n    @!P0 BRA `(.L_x_1) ToTarget \n    // fallthrough\n\n    SYNC  &lt;  finish one side-\n  \n    .L_x_1:   &lt; branch target \n  \n    SYNC   &lt; finish one side \n\n\n  .L_x_0: &lt;  post dominator",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#stack-control",
    "href": "lectures/diverg1.html#stack-control",
    "title": "divergent flow PART TWO",
    "section": "stack control",
    "text": "stack control\nWhen a kernel is launched, a stack is allocated for each corresponding warp.\nstack entry:\n\na 32-bit mask is stored\nthe address of the next instruction to execute (next program counter or npc) and\naddress of the instruction at which the threads must wait for reconvergence (reconvergence program counter or rpc).\n\nThe next pc to execute is the address on the stack, as each instruction executes this address advances\nEach stack is initialized with an entry composed of:\na mask in which all the threads in the warp are active, the start address of the program as npc and the last address in memory as rpc (note that it does not need to be a valid instruction address).",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#ssy-instruction",
    "href": "lectures/diverg1.html#ssy-instruction",
    "title": "divergent flow PART TWO",
    "section": "ssy instruction",
    "text": "ssy instruction\nThe SSY instruction prepare the stack for a possible divergence\nadds two entries- what to do after the if-then-else, what to do on a branch\nWhen SSY @addr is executed, the top entry of the stack is popped. A new entry is pushed to handle the execution after reconvergence:\nThe npc is the reconvergence address (@addr), and the rpc and the mask are copied from the popped entry.\nA second new entry is then pushed to handle the potentially diverging portion of code: the npc is the actual next instruction (the npc of the popped entry + 8, since instructions are encoded in 64 bits), the rpc is the reconvergence address (@addr) and the mask is the same as in the popped entry.\nThe top entry is used to let all active threads execute the next instruction. Note that these instructions do not create divergence but instead prepare the stack for a possible upcoming divergence, which is why the mask remains unchanged at this point.\nreference",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#actual-divergence",
    "href": "lectures/diverg1.html#actual-divergence",
    "title": "divergent flow PART TWO",
    "section": "Actual Divergence",
    "text": "Actual Divergence\nActual divergence happens when a branch (BRA @addr) instruction is executed conditionally by only a subset of the threads of a warp. When this happens, the top entry of the corresponding stack is popped. Two new entries are then pushed:\n\nThe first pushed entry concerns the threads which do not take the branch:\n\nThe rpc is the same as in the popped entry.\nThe npc corresponds to the next instruction in the code (i.e., the current npc + 8).\nThe mask activates only the threads that do not take the branch (the ones for which the condition is false).\n\nThe second entry has the target address of the branch as npc and the same rpc as the popped entry:\n\nIts mask activates only the threads that take the branch (the ones for which the condition is true).\n\n\nAs a consequence, the GPU first executes the threads that take the branch until they reach a reconvergence instruction added by the compiler: SYNC or BRK (depending on whether an SSY or a PBK was executed before).",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/diverg1.html#sync",
    "href": "lectures/diverg1.html#sync",
    "title": "divergent flow PART TWO",
    "section": "sync",
    "text": "sync\nThe reconvergence instruction sync pops the top entry from the stack.\nThe GPU then resumes execution with the group of threads active in the mask of the new entry at the top of the stack: the threads that do not take the branch. When they reach a SYNC instruction, their corresponding entry is popped from the stack: the reconvergence is done and the execution flow resumes at the reconvergence address (which is the npc of the entry at the top of the stack at this point).",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "divergent flow PART TWO"
    ]
  },
  {
    "objectID": "lectures/revealjs_01a2_performance_measurement.qmd.html#another-example",
    "href": "lectures/revealjs_01a2_performance_measurement.qmd.html#another-example",
    "title": "Performance and Measurement part 2",
    "section": "another example",
    "text": "another example\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\nchecklist\nHere are the criteria by Berger, Blackburn, Hauswirth, and Hicks (2018):\n\nClearly stated claims\n\nExplicit Claims\nAppropriately-Scoped Claims\nAcknowledges Limitations\n\nSuitable Comparison\n\nAppropriate Baseline for Comparison\nFair Comparison\n\nPrincipled Benchmark Choice\n\nAppropriate Suite\nNon-Standard Suite(s) Justified\nApplications, Not (Just) Kernels\n\nAdequate Data Analysis\n\nSufficient Number of Trials\nAppropriate Summary Statistics\nReport Data Distribution\n\nRelevant Metrics\n\nDirect or Appropriate Proxy Metric\nMeasures All Important Effects\n\nAppropriate and Clear Experimental Design\n\nSufficient Information to Repeat\nReasonable Platform\nExplores Key Design Parameters\nOpen Loop in Workload Generator\nCross-Validation Where Needed\n\nPresentation of Results\n\nComprehensive Summary Results\nAxes Include Zero\nRatios Plotted Correctly\nAppropriate Level of Precision"
  },
  {
    "objectID": "lectures/01a2_performance_measurement.html",
    "href": "lectures/01a2_performance_measurement.html",
    "title": "Performance and Measurement part 2",
    "section": "",
    "text": "last time we looked at\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog\n\n\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\nchecklist\nHere are the criteria by Berger, Blackburn, Hauswirth, and Hicks (2018):\n\nClearly stated claims\n\nExplicit Claims\nAppropriately-Scoped Claims\nAcknowledges Limitations\n\nSuitable Comparison\n\nAppropriate Baseline for Comparison\nFair Comparison\n\nPrincipled Benchmark Choice\n\nAppropriate Suite\nNon-Standard Suite(s) Justified\nApplications, Not (Just) Kernels\n\nAdequate Data Analysis\n\nSufficient Number of Trials\nAppropriate Summary Statistics\nReport Data Distribution\n\nRelevant Metrics\n\nDirect or Appropriate Proxy Metric\nMeasures All Important Effects\n\nAppropriate and Clear Experimental Design\n\nSufficient Information to Repeat\nReasonable Platform\nExplores Key Design Parameters\nOpen Loop in Workload Generator\nCross-Validation Where Needed\n\nPresentation of Results\n\nComprehensive Summary Results\nAxes Include Zero\nRatios Plotted Correctly\nAppropriate Level of Precision",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 2"
    ]
  },
  {
    "objectID": "lectures/01a2_performance_measurement.html#another-example",
    "href": "lectures/01a2_performance_measurement.html#another-example",
    "title": "Performance and Measurement part 2",
    "section": "",
    "text": "Strangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\nchecklist\nHere are the criteria by Berger, Blackburn, Hauswirth, and Hicks (2018):\n\nClearly stated claims\n\nExplicit Claims\nAppropriately-Scoped Claims\nAcknowledges Limitations\n\nSuitable Comparison\n\nAppropriate Baseline for Comparison\nFair Comparison\n\nPrincipled Benchmark Choice\n\nAppropriate Suite\nNon-Standard Suite(s) Justified\nApplications, Not (Just) Kernels\n\nAdequate Data Analysis\n\nSufficient Number of Trials\nAppropriate Summary Statistics\nReport Data Distribution\n\nRelevant Metrics\n\nDirect or Appropriate Proxy Metric\nMeasures All Important Effects\n\nAppropriate and Clear Experimental Design\n\nSufficient Information to Repeat\nReasonable Platform\nExplores Key Design Parameters\nOpen Loop in Workload Generator\nCross-Validation Where Needed\n\nPresentation of Results\n\nComprehensive Summary Results\nAxes Include Zero\nRatios Plotted Correctly\nAppropriate Level of Precision",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Performance and Measurement part 2"
    ]
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#partial-redundancy-elimination",
    "href": "lectures/revealjs_05c_pre.qmd.html#partial-redundancy-elimination",
    "title": "_ partial_redundancy elimination",
    "section": "partial redundancy elimination",
    "text": "partial redundancy elimination\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#simplifications",
    "href": "lectures/revealjs_05c_pre.qmd.html#simplifications",
    "title": "_ partial_redundancy elimination",
    "section": "simplifications",
    "text": "simplifications\n\nonly going to look at one expression \\(b + c\\)\ninitially all nodes in the cfg contain at most one assignment statement\nif there is a node that has multiple successors (a branch node) and one of the successors has multiple predecessors (a join) node we have added a extra node between them"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#down-safe",
    "href": "lectures/revealjs_05c_pre.qmd.html#down-safe",
    "title": "_ partial_redundancy elimination",
    "section": "down safe",
    "text": "down safe\nwe are moving computations earlier in the cfg\ndon’t move so far that it might not be used, or that an argument gets changed\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n\n\n\ncannot move b +c to top, because b changes"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#up-safe",
    "href": "lectures/revealjs_05c_pre.qmd.html#up-safe",
    "title": "_ partial_redundancy elimination",
    "section": "up-safe",
    "text": "up-safe\nWe can add a computation of \\(b+c\\) in any down-safe node. We want to pick a good one.\ndefine up-safe(block) (also called available) if \\(b+c\\) will be definitely used without being killed, computed on every path from entry to the block and not killed\nDo not add \\(b+c\\) to a block if the expression is available at that block\nup-safe is a second data flow problem\n\\[\nU_{\\text{safe}}(\\text{entry}) = \\text{false}\n\\]\n\\[\nU_{\\text{safe}}(n)=  \\text{trans}(n) \\cap_{p \\in \\text{preds}(n)} \\text{used}(p) \\cup \\text{U}_{\\text{safwe}}(p)\n\\]"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#placement",
    "href": "lectures/revealjs_05c_pre.qmd.html#placement",
    "title": "_ partial_redundancy elimination",
    "section": "placement",
    "text": "placement\nwant a down-safe node, that is not up-safe\n\npick the closest to the entry (min number of computations)\npick a later node to lower register pressure\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\nWe could move b+c in nodes a,c or e, but e does not help"
  },
  {
    "objectID": "lectures/05c_pre.html",
    "href": "lectures/05c_pre.html",
    "title": "_ partial_redundancy elimination",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#partial-redundancy-elimination",
    "href": "lectures/05c_pre.html#partial-redundancy-elimination",
    "title": "_ partial_redundancy elimination",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#simplifications",
    "href": "lectures/05c_pre.html#simplifications",
    "title": "_ partial_redundancy elimination",
    "section": "simplifications",
    "text": "simplifications\n\nonly going to look at one expression \\(b + c\\)\ninitially all nodes in the cfg contain at most one assignment statement\nif there is a node that has multiple successors (a branch node) and one of the successors has multiple predecessors (a join) node we have added a extra node between them",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#down-safe",
    "href": "lectures/05c_pre.html#down-safe",
    "title": "_ partial_redundancy elimination",
    "section": "down safe",
    "text": "down safe\nwe are moving computations earlier in the cfg\ndon’t move so far that it might not be used, or that an argument gets changed\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n\n\n\ncannot move b +c to top, because b changes",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#up-safe",
    "href": "lectures/05c_pre.html#up-safe",
    "title": "_ partial_redundancy elimination",
    "section": "up-safe",
    "text": "up-safe\nWe can add a computation of \\(b+c\\) in any down-safe node. We want to pick a good one.\ndefine up-safe(block) (also called available) if \\(b+c\\) will be definitely used without being killed, computed on every path from entry to the block and not killed\nDo not add \\(b+c\\) to a block if the expression is available at that block\nup-safe is a second data flow problem\n\\[\nU_{\\text{safe}}(\\text{entry}) = \\text{false}\n\\]\n\\[\nU_{\\text{safe}}(n)=  \\text{trans}(n) \\cap_{p \\in \\text{preds}(n)} \\text{used}(p) \\cup \\text{U}_{\\text{safwe}}(p)\n\\]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/05c_pre.html#placement",
    "href": "lectures/05c_pre.html#placement",
    "title": "_ partial_redundancy elimination",
    "section": "placement",
    "text": "placement\nwant a down-safe node, that is not up-safe\n\npick the closest to the entry (min number of computations)\npick a later node to lower register pressure\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\nWe could move b+c in nodes a,c or e, but e does not help",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ partial_redundancy elimination"
    ]
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#mlir-multi-level-intermediate-representation",
    "href": "lectures/revealjs_mlir.qmd.html#mlir-multi-level-intermediate-representation",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "MLIR: Multi-Level Intermediate Representation",
    "text": "MLIR: Multi-Level Intermediate Representation\nMLIR (Multi-Level Intermediate Representation) was introduced by Google in April 2019 and is designed to serve as an IR from the outset. It provides various forms:"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#high-level-form",
    "href": "lectures/revealjs_mlir.qmd.html#high-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "High-level form",
    "text": "High-level form\nOps (general purpose to domain speciﬁc) on tensor types / memref types\n%patches = \"tf.reshape\"(%patches, %minus_one, %minor_dim_size)\n: (tensor&lt;? x ? x ? x ? x f32&gt;, index, index) −&gt; tensor&lt;? x ? x f32&gt;\n%mat_out = \"tf.matmul\"(%patches_ﬂat, %patches_ﬂat){transpose_a : true}\n: (tensor&lt;? x ? x f32&gt;, tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x ?\nx f32&gt;\n%vec_out = \"tf.reduce_sum\"(%patches_ﬂat) {axis: 0}\n: (tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x f32&gt;"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#loop-level-mid-level-form",
    "href": "lectures/revealjs_mlir.qmd.html#loop-level-mid-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Loop-level / mid-level form",
    "text": "Loop-level / mid-level form\naffine.for %i = 0 to 8 step 4 {\n  affine.for %j = 0 to 8 step 4 {\n    %5 = affine.load %arg0[%ii, %kk] : memref&lt;8x8xvector&lt;64xf32&gt;&gt;\n  }\n}"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#low-level-form-closer-to-hardware",
    "href": "lectures/revealjs_mlir.qmd.html#low-level-form-closer-to-hardware",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Low-level form: closer to hardware",
    "text": "Low-level form: closer to hardware\n%v1 = load %a[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;\n%v3 = addf %v1, %v2 : vector&lt;16xf32&gt;\nstore %v3, %d[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#design-principles",
    "href": "lectures/revealjs_mlir.qmd.html#design-principles",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Design principles",
    "text": "Design principles\n\nTextual format\nAbility to represent code at multiple levels\nUniﬁed representation for all the levels\nFirst class abstractions for multi-dimensional arrays (tensors), loop nests, and more\nVery ﬂexible, extensible"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#concepts",
    "href": "lectures/revealjs_mlir.qmd.html#concepts",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "concepts",
    "text": "concepts\n\nSSA, typed\nModule/Function/Block/Operation structure\nOperations can hold a “region” (a list of blocks)\n\nno phi nodes, basic blocks take arguments\n~~~{plaintext} func @condbr_simple() -&gt; (i32) { %cond = “foo”() : () -&gt; i1 %a = “bar”() : () -&gt; i32 %b = “bar”() : () -&gt; i64\n^bb1(%x : i32): %w = “foo_bar”(%x) : (i32) -&gt; i64 br ^bb2(%w: i64)\n^bb2(%y : i64): %z = “abc”(%y) : (i64) -&gt; i32 return %z : i32\n} ~~~"
  },
  {
    "objectID": "lectures/revealjs_mlir.qmd.html#operations",
    "href": "lectures/revealjs_mlir.qmd.html#operations",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "operations",
    "text": "operations\n\nalways have a name and source location\narbitrary number of ssa operands and results\nattributes - constant values\nregions"
  },
  {
    "objectID": "lectures/mlir.html",
    "href": "lectures/mlir.html",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "",
    "text": "#html: default",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#mlir-multi-level-intermediate-representation",
    "href": "lectures/mlir.html#mlir-multi-level-intermediate-representation",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "MLIR: Multi-Level Intermediate Representation",
    "text": "MLIR: Multi-Level Intermediate Representation\nMLIR (Multi-Level Intermediate Representation) was introduced by Google in April 2019 and is designed to serve as an IR from the outset. It provides various forms:",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#high-level-form",
    "href": "lectures/mlir.html#high-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "High-level form",
    "text": "High-level form\nOps (general purpose to domain speciﬁc) on tensor types / memref types\n%patches = \"tf.reshape\"(%patches, %minus_one, %minor_dim_size)\n: (tensor&lt;? x ? x ? x ? x f32&gt;, index, index) −&gt; tensor&lt;? x ? x f32&gt;\n%mat_out = \"tf.matmul\"(%patches_ﬂat, %patches_ﬂat){transpose_a : true}\n: (tensor&lt;? x ? x f32&gt;, tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x ?\nx f32&gt;\n%vec_out = \"tf.reduce_sum\"(%patches_ﬂat) {axis: 0}\n: (tensor&lt;? x ? x f32&gt;) −&gt; tensor&lt;? x f32&gt;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#loop-level-mid-level-form",
    "href": "lectures/mlir.html#loop-level-mid-level-form",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Loop-level / mid-level form",
    "text": "Loop-level / mid-level form\naffine.for %i = 0 to 8 step 4 {\n  affine.for %j = 0 to 8 step 4 {\n    %5 = affine.load %arg0[%ii, %kk] : memref&lt;8x8xvector&lt;64xf32&gt;&gt;\n  }\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#low-level-form-closer-to-hardware",
    "href": "lectures/mlir.html#low-level-form-closer-to-hardware",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Low-level form: closer to hardware",
    "text": "Low-level form: closer to hardware\n%v1 = load %a[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;\n%v3 = addf %v1, %v2 : vector&lt;16xf32&gt;\nstore %v3, %d[%i2, %i3] : memref&lt;256x64xvector&lt;16xf32&gt;&gt;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#design-principles",
    "href": "lectures/mlir.html#design-principles",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "Design principles",
    "text": "Design principles\n\nTextual format\nAbility to represent code at multiple levels\nUniﬁed representation for all the levels\nFirst class abstractions for multi-dimensional arrays (tensors), loop nests, and more\nVery ﬂexible, extensible",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#concepts",
    "href": "lectures/mlir.html#concepts",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "concepts",
    "text": "concepts\n\nSSA, typed\nModule/Function/Block/Operation structure\nOperations can hold a “region” (a list of blocks)\n\nno phi nodes, basic blocks take arguments\n~~~{plaintext} func @condbr_simple() -&gt; (i32) { %cond = “foo”() : () -&gt; i1 %a = “bar”() : () -&gt; i32 %b = “bar”() : () -&gt; i64\n^bb1(%x : i32): %w = “foo_bar”(%x) : (i32) -&gt; i64 br ^bb2(%w: i64)\n^bb2(%y : i64): %z = “abc”(%y) : (i64) -&gt; i32 return %z : i32\n} ~~~",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/mlir.html#operations",
    "href": "lectures/mlir.html#operations",
    "title": "Polyhedral Compilation Opportunities in MLIR",
    "section": "operations",
    "text": "operations\n\nalways have a name and source location\narbitrary number of ssa operands and results\nattributes - constant values\nregions",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Polyhedral Compilation Opportunities in MLIR"
    ]
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#static-single-assignment-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#static-single-assignment-ssa",
    "title": "Static Single Assignment",
    "section": "Static single assignment (SSA)",
    "text": "Static single assignment (SSA)\nA variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#ssa",
    "title": "Static Single Assignment",
    "section": "ssa",
    "text": "ssa\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA means statically there is only a single assignment per variable."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#the-ssa-philosophy",
    "href": "lectures/revealjs_06_ssa.qmd.html#the-ssa-philosophy",
    "title": "Static Single Assignment",
    "section": "The SSA Philosophy",
    "text": "The SSA Philosophy\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 0 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#straight-line-code",
    "href": "lectures/revealjs_06_ssa.qmd.html#straight-line-code",
    "title": "Static Single Assignment",
    "section": "straight line code",
    "text": "straight line code\nWe call a program without branches a piece of straight line code.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\n\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#pseudo-code-for-one-basic-block",
    "href": "lectures/revealjs_06_ssa.qmd.html#pseudo-code-for-one-basic-block",
    "title": "Static Single Assignment",
    "section": "pseudo code for one basic block",
    "text": "pseudo code for one basic block\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B:\n        for each use of a argument x in S: \n            i = top(Stack[x]) \n            replace the use of x with x_i\n            \n        for each variable a that S defines (a dest)\n            count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with a_i\nWe don’t need the stack here but we will need it later."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes",
    "title": "Static Single Assignment",
    "section": "phi-Nodes",
    "text": "phi-Nodes\nJust renaming assignments will quickly run into problems. Consider this program:\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nWhich “version” of a should we use in the print statement?"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-1",
    "title": "Static Single Assignment",
    "section": "phi nodes",
    "text": "phi nodes\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a phi-node.\nphi-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-in-bril",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-in-bril",
    "title": "Static Single Assignment",
    "section": "phi nodes in Bril",
    "text": "phi nodes in Bril\nIn Bril, a phi-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#back-to-the-example",
    "href": "lectures/revealjs_06_ssa.qmd.html#back-to-the-example",
    "title": "Static Single Assignment",
    "section": "back to the example",
    "text": "back to the example\nYou can write the above program in SSA like this:\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\n\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#bril-in-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#bril-in-ssa",
    "title": "Static Single Assignment",
    "section": "Bril in SSA",
    "text": "Bril in SSA\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#converting-to-ssa---very-simple-scheme",
    "href": "lectures/revealjs_06_ssa.qmd.html#converting-to-ssa---very-simple-scheme",
    "title": "Static Single Assignment",
    "section": "Converting to SSA - Very simple scheme",
    "text": "Converting to SSA - Very simple scheme\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nWhere do we need phi-functions?\nWhich variables\n\nphi At the merge (join) node\nvariable b"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#conditions",
    "href": "lectures/revealjs_06_ssa.qmd.html#conditions",
    "title": "Static Single Assignment",
    "section": "conditions",
    "text": "conditions\nconditions: phi-function for variable b at node z\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#scheme-part-2",
    "href": "lectures/revealjs_06_ssa.qmd.html#scheme-part-2",
    "title": "Static Single Assignment",
    "section": "scheme part 2",
    "text": "scheme part 2\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#diagram",
    "href": "lectures/revealjs_06_ssa.qmd.html#diagram",
    "title": "Static Single Assignment",
    "section": "diagram",
    "text": "diagram\nusing dash for path\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d \n\n\n\n\n\n\nWe could have complex flow - including loops on the paths"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#reminder-dominators",
    "href": "lectures/revealjs_06_ssa.qmd.html#reminder-dominators",
    "title": "Static Single Assignment",
    "section": "reminder dominators",
    "text": "reminder dominators\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] ="
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#fast-methods-for-inserting-phis",
    "href": "lectures/revealjs_06_ssa.qmd.html#fast-methods-for-inserting-phis",
    "title": "Static Single Assignment",
    "section": "fast methods for inserting phi’s",
    "text": "fast methods for inserting phi’s\nThe method for this has two steps\n\ninsert phi instructions where needed (do not add subscripts yet)\nin a second pass insert all the numbers"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#to-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#to-ssa",
    "title": "Static Single Assignment",
    "section": "to ssa",
    "text": "to ssa\nTo convert to SSA, we want to insert phi-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need phi-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition?\nThe dominance frontier!"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#recall-the-dominance-frontier",
    "href": "lectures/revealjs_06_ssa.qmd.html#recall-the-dominance-frontier",
    "title": "Static Single Assignment",
    "section": "recall the dominance frontier",
    "text": "recall the dominance frontier\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n\n\n\n\n\n\nblock\nA\nB\nC\nD\nE\n\n\nfrontier\nempty\nF\nE\nE\nF"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#a-block-can-be-in-its-own-dom-frontier",
    "href": "lectures/revealjs_06_ssa.qmd.html#a-block-can-be-in-its-own-dom-frontier",
    "title": "Static Single Assignment",
    "section": "a block can be in its own dom frontier",
    "text": "a block can be in its own dom frontier\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n\n\nwhy: A dom B, but B does not dom A. so A is in the dom frontier of A"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-almost-linear-method",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-almost-linear-method",
    "title": "Static Single Assignment",
    "section": "an almost linear method",
    "text": "an almost linear method\nWe do it in two steps.\n\ninsert phi-nodes:\nrename variables:"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#placing-phi-functions",
    "href": "lectures/revealjs_06_ssa.qmd.html#placing-phi-functions",
    "title": "Static Single Assignment",
    "section": "placing Phi functions",
    "text": "placing Phi functions\nlet b be a block with a def of a variable v, if b has multiple defs of v, use the last one\nWhat is the first block following v that can be reached by a different def of v\nin blocks dominated by b, b’s def must have been executed, (other defs of v in a dominated block may overwrite it)\nwe need to place a phi function for b at the start of all blocks in the dom frontier of b.\nafter we add phi functions to S where S = df(b) we have more defs, so we need to add phi’s in the dom frontier of all the blocks in S"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#example-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#example-1",
    "title": "Static Single Assignment",
    "section": "example 1",
    "text": "example 1\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#a-loop",
    "href": "lectures/revealjs_06_ssa.qmd.html#a-loop",
    "title": "Static Single Assignment",
    "section": "a loop",
    "text": "a loop\n::: {.columns}\n::: {.column}\n\n\nCode\ngraph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n graph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n::: {.column}\n\n\nCode\ngraph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n graph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n:::"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#iterative-placement",
    "href": "lectures/revealjs_06_ssa.qmd.html#iterative-placement",
    "title": "Static Single Assignment",
    "section": "iterative placement",
    "text": "iterative placement\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-placement",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-placement",
    "title": "Static Single Assignment",
    "section": "phi placement",
    "text": "phi placement\nfor each block b in the cfg \n  for each var v defined in b\n    add block to the set defs(v)  ## blocks that contain an assignment to v \n\n  W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[n]:  # Dominance frontier.\n           Add a phi-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v),\n             unless it's already in there."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-1",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n\n\n\n\ninitially w = {1,3,5,6}\nprocess DF(1) = empty\nprocess DF(3) = 4, add 4 to w and add a phi function for x to 4\nprocess DF(5) = 4,5 no need to add 5 to w, add phi for x to 5\nprocess DF(6) = 5\nprocess DF(4) = 4\n\n\nadd phi’s to blocks 4 and 5"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#rename-variables",
    "href": "lectures/revealjs_06_ssa.qmd.html#rename-variables",
    "title": "Static Single Assignment",
    "section": "rename variables:",
    "text": "rename variables:\n# allocate a stack and a counter for each variable\nfor each V a variable \n  c[v] = 0\n  s[v] = empty stack\n  search(entry)\n\nsearch(n):\n  for each instr i in n:\n     if instr is not a phi\n         replace every variable in the rhs of instr by vi where i = top(s[v])\n         if instr has a dest v\n           i = C(v)\n            replace v by new vi, push i onto s[v]\n            increment c[v]\n\n  for each y a successor of n\n     j = which pred (y,n)\n     for each phi function pinstr in Y replace the jth opernmad of pinstr by vi where \n        i = top(s(v)\n  \n  for each Y a child of n in the dominator tree \n      call search(Y)"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-2",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-2",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#what-is-the-dominator-tree",
    "href": "lectures/revealjs_06_ssa.qmd.html#what-is-the-dominator-tree",
    "title": "Static Single Assignment",
    "section": "What is the dominator tree?",
    "text": "What is the dominator tree?\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#dominance-frontiers",
    "href": "lectures/revealjs_06_ssa.qmd.html#dominance-frontiers",
    "title": "Static Single Assignment",
    "section": "dominance frontiers",
    "text": "dominance frontiers\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#add-phi-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#add-phi-nodes",
    "title": "Static Single Assignment",
    "section": "add phi nodes",
    "text": "add phi nodes\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#the-arity-of-phi-functions",
    "href": "lectures/revealjs_06_ssa.qmd.html#the-arity-of-phi-functions",
    "title": "Static Single Assignment",
    "section": "The arity of phi-functions",
    "text": "The arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\ndoing dead code elimination pruned ssa form"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#getting-out-of-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#getting-out-of-ssa",
    "title": "Static Single Assignment",
    "section": "Getting out of ssa",
    "text": "Getting out of ssa\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-3",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-3",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n\n\nwe cannot put instructions on edges, but we can add to prev block"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#critical-edges",
    "href": "lectures/revealjs_06_ssa.qmd.html#critical-edges",
    "title": "Static Single Assignment",
    "section": "critical edges",
    "text": "critical edges\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\n\nb2 = b0?\n\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors. This should remind you of adding a preheader to a loop"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#critical-edge-splitting",
    "href": "lectures/revealjs_06_ssa.qmd.html#critical-edge-splitting",
    "title": "Static Single Assignment",
    "section": "critical edge splitting",
    "text": "critical edge splitting\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#making-use-of-ssa-form",
    "href": "lectures/revealjs_06_ssa.qmd.html#making-use-of-ssa-form",
    "title": "Static Single Assignment",
    "section": "making use of ssa form",
    "text": "making use of ssa form\nOur previous analyses always used a (variable, program point), but in ssa these are the same"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#dead-code-elimination-in-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#dead-code-elimination-in-ssa",
    "title": "Static Single Assignment",
    "section": "dead code elimination in ssa",
    "text": "dead code elimination in ssa\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#sparse-constant-prop",
    "href": "lectures/revealjs_06_ssa.qmd.html#sparse-constant-prop",
    "title": "Static Single Assignment",
    "section": "sparse constant prop",
    "text": "sparse constant prop\nwe define a partial order on constats, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is any\n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#what-order-do-we-process-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#what-order-do-we-process-nodes",
    "title": "Static Single Assignment",
    "section": "What order do we process nodes?",
    "text": "What order do we process nodes?\nbecause the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#walking-the-dominator-tree-b0---b1",
    "href": "lectures/revealjs_06_ssa.qmd.html#walking-the-dominator-tree-b0---b1",
    "title": "Static Single Assignment",
    "section": "walking the dominator tree b0 -> b1",
    "text": "walking the dominator tree b0 -&gt; b1\n\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a0,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 -  1 (only one input defined)\nb0  - any\na2 -  2\nupdate the uses of a2 - the phi\na1 -  any \n\nupdate the uses of a1 \nno change"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#converting-from-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#converting-from-ssa",
    "title": "Static Single Assignment",
    "section": "Converting from SSA",
    "text": "Converting from SSA\nEventually, we need to convert out of SSA form to generate efficient code for real machines that don’t have phi-nodes and do have finite space for variable storage."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#basic-algorithm",
    "href": "lectures/revealjs_06_ssa.qmd.html#basic-algorithm",
    "title": "Static Single Assignment",
    "section": "basic algorithm",
    "text": "basic algorithm\nThe basic algorithm is pretty straightforward. If you have a phi-node:\nv = phi .l1 x .l2 y;\nThen there must be assignments to x and y (recursively) preceding this statement in the CFG.\nThe paths from x to the phi-containing block and from y to the same block must “converge” at that block. So insert code into the phi-containing block’s immediate predecessors along each of those two paths: one that does v = id x and one that does v = id y. Then you can delete the phi instruction."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#extra-copies",
    "href": "lectures/revealjs_06_ssa.qmd.html#extra-copies",
    "title": "Static Single Assignment",
    "section": "extra copies",
    "text": "extra copies\nThis basic approach can introduce some redundant copying. (Take a look at the code it generates after you implement it!) Non-SSA copy propagation optimization can work well as a post-processing step. For a more extensive take on how to translate out of SSA efficiently, see “Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#overlap",
    "href": "lectures/revealjs_06_ssa.qmd.html#overlap",
    "title": "Static Single Assignment",
    "section": "overlap",
    "text": "overlap\nits possible that an optimization can give overlapping phi-functions\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1,x3)\ny2 = phi(y1, y3)\n  z = x2\n  x3 = y2\n  y3= z\n  if() go to b1"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#optimize-it",
    "href": "lectures/revealjs_06_ssa.qmd.html#optimize-it",
    "title": "Static Single Assignment",
    "section": "optimize it",
    "text": "optimize it\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1, y2)\ny2 = phi(y1, x2)\n  if() go to b1"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#lost-the-temp-this-is-called-the-swap-problem",
    "href": "lectures/revealjs_06_ssa.qmd.html#lost-the-temp-this-is-called-the-swap-problem",
    "title": "Static Single Assignment",
    "section": "lost the temp (this is called the swap problem)",
    "text": "lost the temp (this is called the swap problem)\nif we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nphi nodes execute all at once - not one at a time\nSome SSA slides from Todd Mowry at CMU"
  },
  {
    "objectID": "lectures/06_ssa.html",
    "href": "lectures/06_ssa.html",
    "title": "Static Single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#static-single-assignment-ssa",
    "href": "lectures/06_ssa.html#static-single-assignment-ssa",
    "title": "Static Single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#ssa",
    "href": "lectures/06_ssa.html#ssa",
    "title": "Static Single Assignment",
    "section": "ssa",
    "text": "ssa\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA means statically there is only a single assignment per variable.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#the-ssa-philosophy",
    "href": "lectures/06_ssa.html#the-ssa-philosophy",
    "title": "Static Single Assignment",
    "section": "The SSA Philosophy",
    "text": "The SSA Philosophy\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges\n\n\nIn LLVM, for example, instructions do not refer to argument variables by name—an argument is a pointer to defining instruction.\nStatic means in the text, not in the execution.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example",
    "href": "lectures/06_ssa.html#an-example",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 0 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#straight-line-code",
    "href": "lectures/06_ssa.html#straight-line-code",
    "title": "Static Single Assignment",
    "section": "straight line code",
    "text": "straight line code\nWe call a program without branches a piece of straight line code.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\n. . .\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#pseudo-code-for-one-basic-block",
    "href": "lectures/06_ssa.html#pseudo-code-for-one-basic-block",
    "title": "Static Single Assignment",
    "section": "pseudo code for one basic block",
    "text": "pseudo code for one basic block\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B:\n        for each use of a argument x in S: \n            i = top(Stack[x]) \n            replace the use of x with x_i\n            \n        for each variable a that S defines (a dest)\n            count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with a_i\nWe don’t need the stack here but we will need it later.\n\nOf course, things will get a little more complicated when there is control flow. And because real machines are not SSA, using separate variables (i.e., memory locations and registers) for everything is bound to be inefficient.\nThe idea in SSA is to convert general programs into SSA form, do all our optimization there, and then convert back to a standard mutating form before we generate backend code.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes",
    "href": "lectures/06_ssa.html#phi-nodes",
    "title": "Static Single Assignment",
    "section": "phi-Nodes",
    "text": "phi-Nodes\nJust renaming assignments will quickly run into problems. Consider this program:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nWhich “version” of a should we use in the print statement?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes-1",
    "href": "lectures/06_ssa.html#phi-nodes-1",
    "title": "Static Single Assignment",
    "section": "phi nodes",
    "text": "phi nodes\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a phi-node.\nphi-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes-in-bril",
    "href": "lectures/06_ssa.html#phi-nodes-in-bril",
    "title": "Static Single Assignment",
    "section": "phi nodes in Bril",
    "text": "phi nodes in Bril\nIn Bril, a phi-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#back-to-the-example",
    "href": "lectures/06_ssa.html#back-to-the-example",
    "title": "Static Single Assignment",
    "section": "back to the example",
    "text": "back to the example\nYou can write the above program in SSA like this:\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\n\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#bril-in-ssa",
    "href": "lectures/06_ssa.html#bril-in-ssa",
    "title": "Static Single Assignment",
    "section": "Bril in SSA",
    "text": "Bril in SSA\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#converting-to-ssa---very-simple-scheme",
    "href": "lectures/06_ssa.html#converting-to-ssa---very-simple-scheme",
    "title": "Static Single Assignment",
    "section": "Converting to SSA - Very simple scheme",
    "text": "Converting to SSA - Very simple scheme\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nWhere do we need phi-functions?\nWhich variables\n. . .\nphi At the merge (join) node\nvariable b",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#conditions",
    "href": "lectures/06_ssa.html#conditions",
    "title": "Static Single Assignment",
    "section": "conditions",
    "text": "conditions\nconditions: phi-function for variable b at node z\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#scheme-part-2",
    "href": "lectures/06_ssa.html#scheme-part-2",
    "title": "Static Single Assignment",
    "section": "scheme part 2",
    "text": "scheme part 2\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#diagram",
    "href": "lectures/06_ssa.html#diagram",
    "title": "Static Single Assignment",
    "section": "diagram",
    "text": "diagram\nusing dash for path\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\na[\"x:x=\"]\nb[\"y:x=\"]\nc[join]\nd\na-.-&gt; c\nb-.-&gt; c\nc-.-&gt;d \n\n\n\n\n\n\nWe could have complex flow - including loops on the paths",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#reminder-dominators",
    "href": "lectures/06_ssa.html#reminder-dominators",
    "title": "Static Single Assignment",
    "section": "reminder dominators",
    "text": "reminder dominators\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] =\n\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] =  {vertex} + ...\n\nif b has multiple preds, and a dominates all of them, a dom b\nwhile dom is changing \nfor vertex in cfg \n   dom[vertex] =  {vertex} + Intersection( dom(p) for p a pred of vertex)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#fast-methods-for-inserting-phis",
    "href": "lectures/06_ssa.html#fast-methods-for-inserting-phis",
    "title": "Static Single Assignment",
    "section": "fast methods for inserting phi’s",
    "text": "fast methods for inserting phi’s\nThe method for this has two steps\n\ninsert phi instructions where needed (do not add subscripts yet)\nin a second pass insert all the numbers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#to-ssa",
    "href": "lectures/06_ssa.html#to-ssa",
    "title": "Static Single Assignment",
    "section": "to ssa",
    "text": "to ssa\nTo convert to SSA, we want to insert phi-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need phi-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition?\nThe dominance frontier!",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#recall-the-dominance-frontier",
    "href": "lectures/06_ssa.html#recall-the-dominance-frontier",
    "title": "Static Single Assignment",
    "section": "recall the dominance frontier",
    "text": "recall the dominance frontier\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt;B \nA--&gt; F\nB--&gt;C\nB--&gt; D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA--&gt; B\nA--&gt; F\nB--&gt; C\nB--&gt;D\nB--&gt; E\n\n\n\n\n\n\n\n\n\n\n\nblock\nA\nB\nC\nD\nE\n\n\nfrontier\nempty\nF\nE\nE\nF",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#a-block-can-be-in-its-own-dom-frontier",
    "href": "lectures/06_ssa.html#a-block-can-be-in-its-own-dom-frontier",
    "title": "Static Single Assignment",
    "section": "a block can be in its own dom frontier",
    "text": "a block can be in its own dom frontier\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nA--&gt; B\nB--&gt; A\nB--&gt; C\n\n\n\n\n\n\nwhy: A dom B, but B does not dom A. so A is in the dom frontier of A",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-almost-linear-method",
    "href": "lectures/06_ssa.html#an-almost-linear-method",
    "title": "Static Single Assignment",
    "section": "an almost linear method",
    "text": "an almost linear method\nWe do it in two steps.\n\ninsert phi-nodes:\nrename variables:",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#placing-phi-functions",
    "href": "lectures/06_ssa.html#placing-phi-functions",
    "title": "Static Single Assignment",
    "section": "placing Phi functions",
    "text": "placing Phi functions\nlet b be a block with a def of a variable v, if b has multiple defs of v, use the last one\nWhat is the first block following v that can be reached by a different def of v\nin blocks dominated by b, b’s def must have been executed, (other defs of v in a dominated block may overwrite it)\nwe need to place a phi function for b at the start of all blocks in the dom frontier of b.\nafter we add phi functions to S where S = df(b) we have more defs, so we need to add phi’s in the dom frontier of all the blocks in S",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#example-1",
    "href": "lectures/06_ssa.html#example-1",
    "title": "Static Single Assignment",
    "section": "example 1",
    "text": "example 1\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v=1\"]\nM\nM2[\"v=2\"]\nZ[\"M\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN[\"v1=1\"]\nM\nM2[\"v2=2\"]\nZ[\"M:v3= phi(v1,v2)\"]\nN--&gt; M\nM--&gt;Z\nM2--&gt; Z",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#a-loop",
    "href": "lectures/06_ssa.html#a-loop",
    "title": "Static Single Assignment",
    "section": "a loop",
    "text": "a loop\n::: {.columns}\n::: {.column}\n\ngraph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n graph TD\n V[\"v=init\"]\n Z{\"z:v = v+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n::: {.column}\n\ngraph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n graph TD\n V[\"v1=init\"]\n Z{\"z:v2 = phi(v1,v3)\\nv3 = v2+1\"}\n V --&gt; Z\n Z --&gt;Z\n\n\n\n\n\n\n:::\n:::",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#iterative-placement",
    "href": "lectures/06_ssa.html#iterative-placement",
    "title": "Static Single Assignment",
    "section": "iterative placement",
    "text": "iterative placement\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v=1]\nB2[v=2]\nB3\nB4[v=3]\nB5\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nB1[v1=1]\nB2[v2=2]\nB3[\"v3=phi(v1,v2)\"]\nB4[v4=3]\nB5[\"v5=phi(v3,v4)\"]\nB1--&gt; B3\nB2--&gt; B3\nB3--&gt; B5\nB4--&gt; B5",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#phi-placement",
    "href": "lectures/06_ssa.html#phi-placement",
    "title": "Static Single Assignment",
    "section": "phi placement",
    "text": "phi placement\nfor each block b in the cfg \n  for each var v defined in b\n    add block to the set defs(v)  ## blocks that contain an assignment to v \n\n  W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[n]:  # Dominance frontier.\n           Add a phi-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v),\n             unless it's already in there.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-1",
    "href": "lectures/06_ssa.html#an-example-1",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB\nN1[\"1:x = 1\"]\nN2[\"2:\"]\nN3[\"3:x= 2\"]\nN4[\"4:\"]\nN5[\"5:x=3\"]\nN6[6:x=4]\nN7[7:]\nN1--&gt; N2\nN1--&gt; N3\nN2--&gt; N4\nN3--&gt; N4\nN4--&gt; N5\nN5--&gt;  N4\nN5--&gt; N6\nN6--&gt; N7\nN6--&gt; N5\n\n\n\n\n\n\n\n\ninitially w = {1,3,5,6}\nprocess DF(1) = empty\nprocess DF(3) = 4, add 4 to w and add a phi function for x to 4\nprocess DF(5) = 4,5 no need to add 5 to w, add phi for x to 5\nprocess DF(6) = 5\nprocess DF(4) = 4\n\n\n\nadd phi’s to blocks 4 and 5",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#rename-variables",
    "href": "lectures/06_ssa.html#rename-variables",
    "title": "Static Single Assignment",
    "section": "rename variables:",
    "text": "rename variables:\n# allocate a stack and a counter for each variable\nfor each V a variable \n  c[v] = 0\n  s[v] = empty stack\n  search(entry)\n\nsearch(n):\n  for each instr i in n:\n     if instr is not a phi\n         replace every variable in the rhs of instr by vi where i = top(s[v])\n         if instr has a dest v\n           i = C(v)\n            replace v by new vi, push i onto s[v]\n            increment c[v]\n\n  for each y a successor of n\n     j = which pred (y,n)\n     for each phi function pinstr in Y replace the jth opernmad of pinstr by vi where \n        i = top(s(v)\n  \n  for each Y a child of n in the dominator tree \n      call search(Y)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-2",
    "href": "lectures/06_ssa.html#an-example-2",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#what-is-the-dominator-tree",
    "href": "lectures/06_ssa.html#what-is-the-dominator-tree",
    "title": "Static Single Assignment",
    "section": "What is the dominator tree?",
    "text": "What is the dominator tree?\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#dominance-frontiers",
    "href": "lectures/06_ssa.html#dominance-frontiers",
    "title": "Static Single Assignment",
    "section": "dominance frontiers",
    "text": "dominance frontiers\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#add-phi-nodes",
    "href": "lectures/06_ssa.html#add-phi-nodes",
    "title": "Static Single Assignment",
    "section": "add phi nodes",
    "text": "add phi nodes\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#the-arity-of-phi-functions",
    "href": "lectures/06_ssa.html#the-arity-of-phi-functions",
    "title": "Static Single Assignment",
    "section": "The arity of phi-functions",
    "text": "The arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\ndoing dead code elimination pruned ssa form",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#getting-out-of-ssa",
    "href": "lectures/06_ssa.html#getting-out-of-ssa",
    "title": "Static Single Assignment",
    "section": "Getting out of ssa",
    "text": "Getting out of ssa\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-3",
    "href": "lectures/06_ssa.html#an-example-3",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n\n\n\nwe cannot put instructions on edges, but we can add to prev block",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#critical-edges",
    "href": "lectures/06_ssa.html#critical-edges",
    "title": "Static Single Assignment",
    "section": "critical edges",
    "text": "critical edges\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\n\nb2 = b0?\n\n\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors. This should remind you of adding a preheader to a loop",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#critical-edge-splitting",
    "href": "lectures/06_ssa.html#critical-edge-splitting",
    "title": "Static Single Assignment",
    "section": "critical edge splitting",
    "text": "critical edge splitting\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#making-use-of-ssa-form",
    "href": "lectures/06_ssa.html#making-use-of-ssa-form",
    "title": "Static Single Assignment",
    "section": "making use of ssa form",
    "text": "making use of ssa form\nOur previous analyses always used a (variable, program point), but in ssa these are the same",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "href": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "title": "Static Single Assignment",
    "section": "dead code elimination in ssa",
    "text": "dead code elimination in ssa\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#sparse-constant-prop",
    "href": "lectures/06_ssa.html#sparse-constant-prop",
    "title": "Static Single Assignment",
    "section": "sparse constant prop",
    "text": "sparse constant prop\nwe define a partial order on constats, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is any\n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#what-order-do-we-process-nodes",
    "href": "lectures/06_ssa.html#what-order-do-we-process-nodes",
    "title": "Static Single Assignment",
    "section": "What order do we process nodes?",
    "text": "What order do we process nodes?\nbecause the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a1,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#walking-the-dominator-tree-b0---b1",
    "href": "lectures/06_ssa.html#walking-the-dominator-tree-b0---b1",
    "title": "Static Single Assignment",
    "section": "walking the dominator tree b0 -> b1",
    "text": "walking the dominator tree b0 -&gt; b1\n\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a0,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 -  1 (only one input defined)\nb0  - any\na2 -  2\nupdate the uses of a2 - the phi\na1 -  any \n\nupdate the uses of a1 \nno change",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#converting-from-ssa",
    "href": "lectures/06_ssa.html#converting-from-ssa",
    "title": "Static Single Assignment",
    "section": "Converting from SSA",
    "text": "Converting from SSA\nEventually, we need to convert out of SSA form to generate efficient code for real machines that don’t have phi-nodes and do have finite space for variable storage.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#basic-algorithm",
    "href": "lectures/06_ssa.html#basic-algorithm",
    "title": "Static Single Assignment",
    "section": "basic algorithm",
    "text": "basic algorithm\nThe basic algorithm is pretty straightforward. If you have a phi-node:\nv = phi .l1 x .l2 y;\nThen there must be assignments to x and y (recursively) preceding this statement in the CFG.\nThe paths from x to the phi-containing block and from y to the same block must “converge” at that block. So insert code into the phi-containing block’s immediate predecessors along each of those two paths: one that does v = id x and one that does v = id y. Then you can delete the phi instruction.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#extra-copies",
    "href": "lectures/06_ssa.html#extra-copies",
    "title": "Static Single Assignment",
    "section": "extra copies",
    "text": "extra copies\nThis basic approach can introduce some redundant copying. (Take a look at the code it generates after you implement it!) Non-SSA copy propagation optimization can work well as a post-processing step. For a more extensive take on how to translate out of SSA efficiently, see “Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#overlap",
    "href": "lectures/06_ssa.html#overlap",
    "title": "Static Single Assignment",
    "section": "overlap",
    "text": "overlap\nits possible that an optimization can give overlapping phi-functions\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1,x3)\ny2 = phi(y1, y3)\n  z = x2\n  x3 = y2\n  y3= z\n  if() go to b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#optimize-it",
    "href": "lectures/06_ssa.html#optimize-it",
    "title": "Static Single Assignment",
    "section": "optimize it",
    "text": "optimize it\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1, y2)\ny2 = phi(y1, x2)\n  if() go to b1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#lost-the-temp-this-is-called-the-swap-problem",
    "href": "lectures/06_ssa.html#lost-the-temp-this-is-called-the-swap-problem",
    "title": "Static Single Assignment",
    "section": "lost the temp (this is called the swap problem)",
    "text": "lost the temp (this is called the swap problem)\nif we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nphi nodes execute all at once - not one at a time\nSome SSA slides from Todd Mowry at CMU",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Static Single Assignment"
    ]
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#terms",
    "href": "lectures/revealjs_register_allocation.qmd.html#terms",
    "title": "Register Allocation",
    "section": "terms",
    "text": "terms\n\nThe task of determining the register in which each variable will be stored is known as register assignment.\nIf a variable must be stored in memory, it is referred to as a spill. Spilling involves identifying which variables need to be mapped to memory.\nIf the same register can be assigned to two variables related by a move instruction, the move can be eliminated. This optimization is called coalescing."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#more-terms",
    "href": "lectures/revealjs_register_allocation.qmd.html#more-terms",
    "title": "Register Allocation",
    "section": "more terms",
    "text": "more terms\n\nGPU performance often improves when fewer registers are used.\nVariables in Bril are virtual registers. After assignment, they become physical registers.\n\nRegister allocators often have to manage constraints. For example, a function argument may need to be placed in a specific physical register."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#formal-limits",
    "href": "lectures/revealjs_register_allocation.qmd.html#formal-limits",
    "title": "Register Allocation",
    "section": "Formal Limits",
    "text": "Formal Limits\nRegister allocation is NP complete. Given a program P and K registers, is there an assignment where each variable gets a register and all simultaneously live variables get different registers\nGregory Chaitin showed that if we have a graph that we want to paint with K colors, such that adjacent vertices get different colors we can construct a program where the program can be allocated with K registers iff the graph can be colored with K colors"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#interference-graph",
    "href": "lectures/revealjs_register_allocation.qmd.html#interference-graph",
    "title": "Register Allocation",
    "section": "Interference Graph",
    "text": "Interference Graph\nChaitin used the interference graph. One vertex for each variable, and edge between variables that are simultaneously live.\nTwo variables that interfere cannot be in the same register"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#allocation-and-liveness",
    "href": "lectures/revealjs_register_allocation.qmd.html#allocation-and-liveness",
    "title": "Register Allocation",
    "section": "Allocation and Liveness",
    "text": "Allocation and Liveness\nIf two variables are alive at the same point, and they have different values, they have to be assigned different registers\nApproximate this by ignoring “have different values” - Different registers if alive at the same point. (id is special)\nMaxLive is the max number of values live at the same point\nMinReg is the min number of registers we need\nminReg &gt;= MaxLive"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#an-example",
    "href": "lectures/revealjs_register_allocation.qmd.html#an-example",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\nWhat is the maximum number of variables alive at any program point?\nWhat is the interference graph of this program?\n\ndraw it?"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#interference-graph-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#interference-graph-1",
    "title": "Register Allocation",
    "section": "interference graph",
    "text": "interference graph\n\nMaxLive = 2 Can we compile this with 2 registers? - Need 3\ndraw it?\nThe interference graph is a pentagon, needed 3 registers.\nA pentagon is the smallest graph whose chromatic number (number of colors needed 3 ) is less the maximum clique (2)"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#ssa-form",
    "href": "lectures/revealjs_register_allocation.qmd.html#ssa-form",
    "title": "Register Allocation",
    "section": "SSA Form",
    "text": "SSA Form"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#with-liveness",
    "href": "lectures/revealjs_register_allocation.qmd.html#with-liveness",
    "title": "Register Allocation",
    "section": "with liveness",
    "text": "with liveness"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#ssa-with-interference-graph",
    "href": "lectures/revealjs_register_allocation.qmd.html#ssa-with-interference-graph",
    "title": "Register Allocation",
    "section": "ssa with interference graph",
    "text": "ssa with interference graph"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#register-allocation",
    "href": "lectures/revealjs_register_allocation.qmd.html#register-allocation",
    "title": "Register Allocation",
    "section": "register allocation",
    "text": "register allocation"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#swaps-via-xor",
    "href": "lectures/revealjs_register_allocation.qmd.html#swaps-via-xor",
    "title": "Register Allocation",
    "section": "swaps via xor",
    "text": "swaps via xor"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#final-code",
    "href": "lectures/revealjs_register_allocation.qmd.html#final-code",
    "title": "Register Allocation",
    "section": "final code",
    "text": "final code"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#ssa-based-register-allocation",
    "href": "lectures/revealjs_register_allocation.qmd.html#ssa-based-register-allocation",
    "title": "Register Allocation",
    "section": "ssa based register allocation",
    "text": "ssa based register allocation\nWe have been able to compile the SSA-form program with less registers than the minimum that the original program requires.\nTwo claims\n\nThe SSA-form program will never require more registers than the original program.\nAnd we can find the minimum number of registers that the SSA-form program needs in polynomial time."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#setting-up-the-colors",
    "href": "lectures/revealjs_register_allocation.qmd.html#setting-up-the-colors",
    "title": "Register Allocation",
    "section": "setting up the colors",
    "text": "setting up the colors\nsuppose we have an ordering of the vertices, where the neighbors of a node to the left of the node in the ordering from a clique. If there are K such neighbors we need K+1 colors"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#an-example-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#an-example-1",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n\n\ndraw it\ngiven this order - it is simple to pick the colors\nonce we have an order , we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored, so just pick one\nmaybe try not to clobber a copy\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#how-do-we-get-the-order",
    "href": "lectures/revealjs_register_allocation.qmd.html#how-do-we-get-the-order",
    "title": "Register Allocation",
    "section": "how do we get the order",
    "text": "how do we get the order\n\ngive each node number\ninitially each node gets count of zero 1 pick an unordered node with max count\nput that node in the front of the list, mark that node ordered\nincrement each neighbor by 1"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dominance-trees",
    "href": "lectures/revealjs_register_allocation.qmd.html#dominance-trees",
    "title": "Register Allocation",
    "section": "dominance trees",
    "text": "dominance trees\nWhat is the dominance tree of this program?"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dominance-tree",
    "href": "lectures/revealjs_register_allocation.qmd.html#dominance-tree",
    "title": "Register Allocation",
    "section": "dominance tree",
    "text": "dominance tree"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dom-sub-trees",
    "href": "lectures/revealjs_register_allocation.qmd.html#dom-sub-trees",
    "title": "Register Allocation",
    "section": "dom sub trees",
    "text": "dom sub trees"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#chordal-graphs-triangular-graphs",
    "href": "lectures/revealjs_register_allocation.qmd.html#chordal-graphs-triangular-graphs",
    "title": "Register Allocation",
    "section": "Chordal Graphs (triangular graphs)",
    "text": "Chordal Graphs (triangular graphs)\n\nintersection graph of subtrees\nA graph is chordal if each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle.\nif each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle. An equivalent definition is that any chord free cycles have at most three nodes."
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#examples-of-chordal-graphs",
    "href": "lectures/revealjs_register_allocation.qmd.html#examples-of-chordal-graphs",
    "title": "Register Allocation",
    "section": "examples of chordal graphs",
    "text": "examples of chordal graphs\ndraw am example of a cord graph"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#orderings",
    "href": "lectures/revealjs_register_allocation.qmd.html#orderings",
    "title": "Register Allocation",
    "section": "orderings",
    "text": "orderings\nwe number the vertices of G\nv0,v1,v2,…., vi, …\nconsider vi all the neighbors to the left are a clique (all connected )"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-1",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-2",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-2",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-3",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-3",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-4",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-4",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-5",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-5",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-6",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-6",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#running-example-7",
    "href": "lectures/revealjs_register_allocation.qmd.html#running-example-7",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#coloring",
    "href": "lectures/revealjs_register_allocation.qmd.html#coloring",
    "title": "Register Allocation",
    "section": "coloring",
    "text": "coloring\nonce we have an order (the reverse order above), we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#spilling",
    "href": "lectures/revealjs_register_allocation.qmd.html#spilling",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling\nif we ever have a program point where the number of live variables is &gt; MaxRegs we will have to spill - so do it here"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#spilling-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#spilling-1",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#coalescing",
    "href": "lectures/revealjs_register_allocation.qmd.html#coalescing",
    "title": "Register Allocation",
    "section": "coalescing",
    "text": "coalescing\nif we assign both sides of a copy to the same register, we can eliminate the copy.\ninput: L list of copy instructions, G=(V,E), K\noutput: updated graph G'\n\nG' = G\nfor all x=y in L\n   sx is the set of colors in the neighborhood of x\n   sy is the set of colors in the neighborood of y\n   let c be a color &lt; K that not in either set \n   add xy a new node xy is ajacent to all node in the union of neighborhoods \n   remove x and y from G'\nxy is a merge of x and y"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "href": "lectures/revealjs_register_allocation.qmd.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "title": "Register Allocation",
    "section": "how do we know that ssa graphs are chordal",
    "text": "how do we know that ssa graphs are chordal"
  },
  {
    "objectID": "lectures/revealjs_register_allocation.qmd.html#dominance-and-interference-thm-1",
    "href": "lectures/revealjs_register_allocation.qmd.html#dominance-and-interference-thm-1",
    "title": "Register Allocation",
    "section": "dominance and interference Thm 1",
    "text": "dominance and interference Thm 1\nIn a strict ssa form the definition of a variable dominates all the uses\nlemma1 : if two variables interfere then the def of one dominates the def of the other\nlemma2 if two variables a and b interfere and Da &lt; Db, then a is live at Db\nlemma3 if u,v,w are variables u-v interfere and v-w interfere and u-w do not if Du &lt; Dv then Dv &lt; Dw\nthm: the interference graph of an ssa form program is chordal"
  },
  {
    "objectID": "lectures/register_allocation.html",
    "href": "lectures/register_allocation.html",
    "title": "Register Allocation",
    "section": "",
    "text": "Register allocation is the process of determining storage locations to the values used in a program.\nThese values can either be stored in registers or in memory.\nRegisters provide fast access but are limited in number.\nMemory has much higher latency and slower access speeds.\nA good register allocation strategy keeps frequently accessed variables in registers to maximize performance.\nmuch of the material for these slides comes from fernando",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#terms",
    "href": "lectures/register_allocation.html#terms",
    "title": "Register Allocation",
    "section": "terms",
    "text": "terms\n\nThe task of determining the register in which each variable will be stored is known as register assignment.\nIf a variable must be stored in memory, it is referred to as a spill. Spilling involves identifying which variables need to be mapped to memory.\nIf the same register can be assigned to two variables related by a move instruction, the move can be eliminated. This optimization is called coalescing.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#more-terms",
    "href": "lectures/register_allocation.html#more-terms",
    "title": "Register Allocation",
    "section": "more terms",
    "text": "more terms\n\nGPU performance often improves when fewer registers are used.\nVariables in Bril are virtual registers. After assignment, they become physical registers.\n\nRegister allocators often have to manage constraints. For example, a function argument may need to be placed in a specific physical register.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#formal-limits",
    "href": "lectures/register_allocation.html#formal-limits",
    "title": "Register Allocation",
    "section": "Formal Limits",
    "text": "Formal Limits\nRegister allocation is NP complete. Given a program P and K registers, is there an assignment where each variable gets a register and all simultaneously live variables get different registers\nGregory Chaitin showed that if we have a graph that we want to paint with K colors, such that adjacent vertices get different colors we can construct a program where the program can be allocated with K registers iff the graph can be colored with K colors",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#interference-graph",
    "href": "lectures/register_allocation.html#interference-graph",
    "title": "Register Allocation",
    "section": "Interference Graph",
    "text": "Interference Graph\nChaitin used the interference graph. One vertex for each variable, and edge between variables that are simultaneously live.\nTwo variables that interfere cannot be in the same register",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#allocation-and-liveness",
    "href": "lectures/register_allocation.html#allocation-and-liveness",
    "title": "Register Allocation",
    "section": "Allocation and Liveness",
    "text": "Allocation and Liveness\nIf two variables are alive at the same point, and they have different values, they have to be assigned different registers\nApproximate this by ignoring “have different values” - Different registers if alive at the same point. (id is special)\nMaxLive is the max number of values live at the same point\nMinReg is the min number of registers we need\nminReg &gt;= MaxLive",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#an-example",
    "href": "lectures/register_allocation.html#an-example",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\nWhat is the maximum number of variables alive at any program point?\nWhat is the interference graph of this program?\n\ndraw it?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#interference-graph-1",
    "href": "lectures/register_allocation.html#interference-graph-1",
    "title": "Register Allocation",
    "section": "interference graph",
    "text": "interference graph\n\nMaxLive = 2 Can we compile this with 2 registers? - Need 3\ndraw it?\nThe interference graph is a pentagon, needed 3 registers.\nA pentagon is the smallest graph whose chromatic number (number of colors needed 3 ) is less the maximum clique (2)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#ssa-form",
    "href": "lectures/register_allocation.html#ssa-form",
    "title": "Register Allocation",
    "section": "SSA Form",
    "text": "SSA Form",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#with-liveness",
    "href": "lectures/register_allocation.html#with-liveness",
    "title": "Register Allocation",
    "section": "with liveness",
    "text": "with liveness",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#ssa-with-interference-graph",
    "href": "lectures/register_allocation.html#ssa-with-interference-graph",
    "title": "Register Allocation",
    "section": "ssa with interference graph",
    "text": "ssa with interference graph",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#register-allocation",
    "href": "lectures/register_allocation.html#register-allocation",
    "title": "Register Allocation",
    "section": "register allocation",
    "text": "register allocation",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#swaps-via-xor",
    "href": "lectures/register_allocation.html#swaps-via-xor",
    "title": "Register Allocation",
    "section": "swaps via xor",
    "text": "swaps via xor",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#final-code",
    "href": "lectures/register_allocation.html#final-code",
    "title": "Register Allocation",
    "section": "final code",
    "text": "final code",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#ssa-based-register-allocation",
    "href": "lectures/register_allocation.html#ssa-based-register-allocation",
    "title": "Register Allocation",
    "section": "ssa based register allocation",
    "text": "ssa based register allocation\nWe have been able to compile the SSA-form program with less registers than the minimum that the original program requires.\nTwo claims\n\nThe SSA-form program will never require more registers than the original program.\nAnd we can find the minimum number of registers that the SSA-form program needs in polynomial time.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#setting-up-the-colors",
    "href": "lectures/register_allocation.html#setting-up-the-colors",
    "title": "Register Allocation",
    "section": "setting up the colors",
    "text": "setting up the colors\nsuppose we have an ordering of the vertices, where the neighbors of a node to the left of the node in the ordering from a clique. If there are K such neighbors we need K+1 colors",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#an-example-1",
    "href": "lectures/register_allocation.html#an-example-1",
    "title": "Register Allocation",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn1--&gt; n2 --&gt; n3 --&gt;  n4 --&gt; n5 --&gt; n6--&gt; n1\n\n\n\n\n\n\ndraw it\ngiven this order - it is simple to pick the colors\nonce we have an order , we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored, so just pick one\nmaybe try not to clobber a copy\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#how-do-we-get-the-order",
    "href": "lectures/register_allocation.html#how-do-we-get-the-order",
    "title": "Register Allocation",
    "section": "how do we get the order",
    "text": "how do we get the order\n\ngive each node number\ninitially each node gets count of zero 1 pick an unordered node with max count\nput that node in the front of the list, mark that node ordered\nincrement each neighbor by 1",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dominance-trees",
    "href": "lectures/register_allocation.html#dominance-trees",
    "title": "Register Allocation",
    "section": "dominance trees",
    "text": "dominance trees\nWhat is the dominance tree of this program?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dominance-tree",
    "href": "lectures/register_allocation.html#dominance-tree",
    "title": "Register Allocation",
    "section": "dominance tree",
    "text": "dominance tree",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dom-sub-trees",
    "href": "lectures/register_allocation.html#dom-sub-trees",
    "title": "Register Allocation",
    "section": "dom sub trees",
    "text": "dom sub trees",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#chordal-graphs-triangular-graphs",
    "href": "lectures/register_allocation.html#chordal-graphs-triangular-graphs",
    "title": "Register Allocation",
    "section": "Chordal Graphs (triangular graphs)",
    "text": "Chordal Graphs (triangular graphs)\n\nintersection graph of subtrees\nA graph is chordal if each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle.\nif each of its cycles of four or more nodes has a chord, which is an edge joining two nodes that are not adjacent in the cycle. An equivalent definition is that any chord free cycles have at most three nodes.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#examples-of-chordal-graphs",
    "href": "lectures/register_allocation.html#examples-of-chordal-graphs",
    "title": "Register Allocation",
    "section": "examples of chordal graphs",
    "text": "examples of chordal graphs\ndraw am example of a cord graph",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#orderings",
    "href": "lectures/register_allocation.html#orderings",
    "title": "Register Allocation",
    "section": "orderings",
    "text": "orderings\nwe number the vertices of G\nv0,v1,v2,…., vi, …\nconsider vi all the neighbors to the left are a clique (all connected )",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example",
    "href": "lectures/register_allocation.html#running-example",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-1",
    "href": "lectures/register_allocation.html#running-example-1",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-2",
    "href": "lectures/register_allocation.html#running-example-2",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-3",
    "href": "lectures/register_allocation.html#running-example-3",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-4",
    "href": "lectures/register_allocation.html#running-example-4",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-5",
    "href": "lectures/register_allocation.html#running-example-5",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-6",
    "href": "lectures/register_allocation.html#running-example-6",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#running-example-7",
    "href": "lectures/register_allocation.html#running-example-7",
    "title": "Register Allocation",
    "section": "running example",
    "text": "running example",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#coloring",
    "href": "lectures/register_allocation.html#coloring",
    "title": "Register Allocation",
    "section": "coloring",
    "text": "coloring\nonce we have an order (the reverse order above), we can greedy color the nodes. When we get to the n’th node, all the neighbors are in a clique and are colored\nall nodes in the clique need different colors\nIn a chordal graph the size of the largest clique equals the chromatic number\nif we find the point in the program with max live variables, we know the chromatic number",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#spilling",
    "href": "lectures/register_allocation.html#spilling",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling\nif we ever have a program point where the number of live variables is &gt; MaxRegs we will have to spill - so do it here",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#spilling-1",
    "href": "lectures/register_allocation.html#spilling-1",
    "title": "Register Allocation",
    "section": "spilling",
    "text": "spilling",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#coalescing",
    "href": "lectures/register_allocation.html#coalescing",
    "title": "Register Allocation",
    "section": "coalescing",
    "text": "coalescing\nif we assign both sides of a copy to the same register, we can eliminate the copy.\ninput: L list of copy instructions, G=(V,E), K\noutput: updated graph G'\n\nG' = G\nfor all x=y in L\n   sx is the set of colors in the neighborhood of x\n   sy is the set of colors in the neighborood of y\n   let c be a color &lt; K that not in either set \n   add xy a new node xy is ajacent to all node in the union of neighborhoods \n   remove x and y from G'\nxy is a merge of x and y",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "href": "lectures/register_allocation.html#how-do-we-know-that-ssa-graphs-are-chordal",
    "title": "Register Allocation",
    "section": "how do we know that ssa graphs are chordal",
    "text": "how do we know that ssa graphs are chordal",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/register_allocation.html#dominance-and-interference-thm-1",
    "href": "lectures/register_allocation.html#dominance-and-interference-thm-1",
    "title": "Register Allocation",
    "section": "dominance and interference Thm 1",
    "text": "dominance and interference Thm 1\nIn a strict ssa form the definition of a variable dominates all the uses\nlemma1 : if two variables interfere then the def of one dominates the def of the other\nlemma2 if two variables a and b interfere and Da &lt; Db, then a is live at Db\nlemma3 if u,v,w are variables u-v interfere and v-w interfere and u-w do not if Du &lt; Dv then Dv &lt; Dw\nthm: the interference graph of an ssa form program is chordal",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Register Allocation"
    ]
  },
  {
    "objectID": "lectures/100_mlir.html",
    "href": "lectures/100_mlir.html",
    "title": "10 MLIR",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "10 MLIR"
    ]
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#graph-properties",
    "href": "lectures/revealjs_05_global.qmd.html#graph-properties",
    "title": "5 Global Analysis",
    "section": "Graph Properties",
    "text": "Graph Properties\nWe are going to define assorted graph properties, that can be calculated on cfgs."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominators",
    "href": "lectures/revealjs_05_global.qmd.html#dominators",
    "title": "5 Global Analysis",
    "section": "dominators",
    "text": "dominators\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominator-trees",
    "href": "lectures/revealjs_05_global.qmd.html#dominator-trees",
    "title": "5 Global Analysis",
    "section": "dominator trees",
    "text": "dominator trees\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#an-example",
    "href": "lectures/revealjs_05_global.qmd.html#an-example",
    "title": "5 Global Analysis",
    "section": "an example",
    "text": "an example\n\n\nA control flow graph\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\n\nThe dominator tree\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#simple-implementation-dominators",
    "href": "lectures/revealjs_05_global.qmd.html#simple-implementation-dominators",
    "title": "5 Global Analysis",
    "section": "simple implementation dominators",
    "text": "simple implementation dominators\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#pseudo-code",
    "href": "lectures/revealjs_05_global.qmd.html#pseudo-code",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nassume nodes start at 0,\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#how-do-we-implement-this",
    "href": "lectures/revealjs_05_global.qmd.html#how-do-we-implement-this",
    "title": "5 Global Analysis",
    "section": "How do we implement this",
    "text": "How do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#a-faster-way",
    "href": "lectures/revealjs_05_global.qmd.html#a-faster-way",
    "title": "5 Global Analysis",
    "section": "a faster way",
    "text": "a faster way\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, (the dominator)"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#a-more-complex-example",
    "href": "lectures/revealjs_05_global.qmd.html#a-more-complex-example",
    "title": "5 Global Analysis",
    "section": "a more complex example",
    "text": "a more complex example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n\nneed n4 and n8\n\nboth are dominated by n0"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "href": "lectures/revealjs_05_global.qmd.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "title": "5 Global Analysis",
    "section": "subproblem: find lowest common ancestor in dt of two nodes a and b",
    "text": "subproblem: find lowest common ancestor in dt of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower keep the nodes in post order, nodes at the top of the cfg have higher numbers"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#part1",
    "href": "lectures/revealjs_05_global.qmd.html#part1",
    "title": "5 Global Analysis",
    "section": "part1",
    "text": "part1\nintersect(b1, b2, idoms,postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#pseudo-code-1",
    "href": "lectures/revealjs_05_global.qmd.html#pseudo-code-1",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse i in postorder) {\n      bb = cffg block i \n      new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n\n      for pred in preds (bb)) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominator-frontiers",
    "href": "lectures/revealjs_05_global.qmd.html#dominator-frontiers",
    "title": "5 Global Analysis",
    "section": "dominator frontiers",
    "text": "dominator frontiers\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5 dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#natural-loops",
    "href": "lectures/revealjs_05_global.qmd.html#natural-loops",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\n\n\nCode\ngraph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#cycle-but-not-header",
    "href": "lectures/revealjs_05_global.qmd.html#cycle-but-not-header",
    "title": "5 Global Analysis",
    "section": "cycle but not header",
    "text": "cycle but not header\nHow about an example that has a cycle and no header\n\n\nCode\ngraph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#natural-loops-1",
    "href": "lectures/revealjs_05_global.qmd.html#natural-loops-1",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\nA back-edge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a back-edge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#example",
    "href": "lectures/revealjs_05_global.qmd.html#example",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\n\n\nBackedges B -&gt; H2,\nB-&gt; H1\n\nfor B-&gt; H2, loop is H2,\nfor B-&gt; H1, loop is H1, A, H2, B"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#reducible-control-flow",
    "href": "lectures/revealjs_05_global.qmd.html#reducible-control-flow",
    "title": "5 Global Analysis",
    "section": "reducible control flow",
    "text": "reducible control flow\nin a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#what-is-the-surface-version",
    "href": "lectures/revealjs_05_global.qmd.html#what-is-the-surface-version",
    "title": "5 Global Analysis",
    "section": "what is the surface version",
    "text": "what is the surface version\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#t1-and-t2-transforms",
    "href": "lectures/revealjs_05_global.qmd.html#t1-and-t2-transforms",
    "title": "5 Global Analysis",
    "section": "t1 and t2 transforms",
    "text": "t1 and t2 transforms\nLet G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1: on node n is removal of this self-loop.\nLet n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node.\ntransformation T2: on node pair (n1,n2) is merging nodes n1 and n2 into one node,"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#t1-t2",
    "href": "lectures/revealjs_05_global.qmd.html#t1-t2",
    "title": "5 Global Analysis",
    "section": "t1 / t2",
    "text": "t1 / t2\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#example-1",
    "href": "lectures/revealjs_05_global.qmd.html#example-1",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#simplified-control-flow",
    "href": "lectures/revealjs_05_global.qmd.html#simplified-control-flow",
    "title": "5 Global Analysis",
    "section": "simplified control flow",
    "text": "simplified control flow\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\nnot reducible"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#other-optimizations-interactions",
    "href": "lectures/revealjs_05_global.qmd.html#other-optimizations-interactions",
    "title": "5 Global Analysis",
    "section": "other optimizations interactions",
    "text": "other optimizations interactions\nloop: if (cond) goto past_loop\n    s1\n    call bar()\n    goto loop\npastloop:\n\nfunction bar()\n    b1 \n    if () return\n    b2"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#inline-the-function-combine-jmps-to-jmps",
    "href": "lectures/revealjs_05_global.qmd.html#inline-the-function-combine-jmps-to-jmps",
    "title": "5 Global Analysis",
    "section": "inline the function, combine jmps to jmps",
    "text": "inline the function, combine jmps to jmps\n\n\nloop: if (cond) goto past_loop\n    s1\n    b1\n    if () go to next\n    b2\n    next:\ngoto loop\n\n\n\nCode\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n\n\nNow we have two back edges so two loops"
  },
  {
    "objectID": "lectures/05_global.html",
    "href": "lectures/05_global.html",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#graph-properties",
    "href": "lectures/05_global.html#graph-properties",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#dominators",
    "href": "lectures/05_global.html#dominators",
    "title": "5 Global Analysis",
    "section": "dominators",
    "text": "dominators\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#dominator-trees",
    "href": "lectures/05_global.html#dominator-trees",
    "title": "5 Global Analysis",
    "section": "dominator trees",
    "text": "dominator trees\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#an-example",
    "href": "lectures/05_global.html#an-example",
    "title": "5 Global Analysis",
    "section": "an example",
    "text": "an example\n\n\nA control flow graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\n\nThe dominator tree\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#simple-implementation-dominators",
    "href": "lectures/05_global.html#simple-implementation-dominators",
    "title": "5 Global Analysis",
    "section": "simple implementation dominators",
    "text": "simple implementation dominators\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]\n\nTo find the dominators of a node, first put the node itself in the dominators set. Then, take all the common (i.e. intersection) dominators of its predecessors and put them in the set.\nWhat order do we want to process the nodes?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#pseudo-code",
    "href": "lectures/05_global.html#pseudo-code",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nassume nodes start at 0,\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#how-do-we-implement-this",
    "href": "lectures/05_global.html#how-do-we-implement-this",
    "title": "5 Global Analysis",
    "section": "How do we implement this",
    "text": "How do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#a-faster-way",
    "href": "lectures/05_global.html#a-faster-way",
    "title": "5 Global Analysis",
    "section": "a faster way",
    "text": "a faster way\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, (the dominator)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#a-more-complex-example",
    "href": "lectures/05_global.html#a-more-complex-example",
    "title": "5 Global Analysis",
    "section": "a more complex example",
    "text": "a more complex example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n\nneed n4 and n8\n\nboth are dominated by n0",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "href": "lectures/05_global.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "title": "5 Global Analysis",
    "section": "subproblem: find lowest common ancestor in dt of two nodes a and b",
    "text": "subproblem: find lowest common ancestor in dt of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower keep the nodes in post order, nodes at the top of the cfg have higher numbers",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#part1",
    "href": "lectures/05_global.html#part1",
    "title": "5 Global Analysis",
    "section": "part1",
    "text": "part1\nintersect(b1, b2, idoms,postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#pseudo-code-1",
    "href": "lectures/05_global.html#pseudo-code-1",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse i in postorder) {\n      bb = cffg block i \n      new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n\n      for pred in preds (bb)) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#dominator-frontiers",
    "href": "lectures/05_global.html#dominator-frontiers",
    "title": "5 Global Analysis",
    "section": "dominator frontiers",
    "text": "dominator frontiers\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5 dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#natural-loops",
    "href": "lectures/05_global.html#natural-loops",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\n\ngraph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#cycle-but-not-header",
    "href": "lectures/05_global.html#cycle-but-not-header",
    "title": "5 Global Analysis",
    "section": "cycle but not header",
    "text": "cycle but not header\nHow about an example that has a cycle and no header\n\ngraph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#natural-loops-1",
    "href": "lectures/05_global.html#natural-loops-1",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\nA back-edge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a back-edge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#example",
    "href": "lectures/05_global.html#example",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\n\n\nBackedges B -&gt; H2,\nB-&gt; H1\n\nfor B-&gt; H2, loop is H2,\nfor B-&gt; H1, loop is H1, A, H2, B",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#reducible-control-flow",
    "href": "lectures/05_global.html#reducible-control-flow",
    "title": "5 Global Analysis",
    "section": "reducible control flow",
    "text": "reducible control flow\nin a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#what-is-the-surface-version",
    "href": "lectures/05_global.html#what-is-the-surface-version",
    "title": "5 Global Analysis",
    "section": "what is the surface version",
    "text": "what is the surface version\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#t1-and-t2-transforms",
    "href": "lectures/05_global.html#t1-and-t2-transforms",
    "title": "5 Global Analysis",
    "section": "t1 and t2 transforms",
    "text": "t1 and t2 transforms\nLet G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1: on node n is removal of this self-loop.\nLet n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node.\ntransformation T2: on node pair (n1,n2) is merging nodes n1 and n2 into one node,",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#t1-t2",
    "href": "lectures/05_global.html#t1-t2",
    "title": "5 Global Analysis",
    "section": "t1 / t2",
    "text": "t1 / t2\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#example-1",
    "href": "lectures/05_global.html#example-1",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#simplified-control-flow",
    "href": "lectures/05_global.html#simplified-control-flow",
    "title": "5 Global Analysis",
    "section": "simplified control flow",
    "text": "simplified control flow\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\nnot reducible",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#other-optimizations-interactions",
    "href": "lectures/05_global.html#other-optimizations-interactions",
    "title": "5 Global Analysis",
    "section": "other optimizations interactions",
    "text": "other optimizations interactions\nloop: if (cond) goto past_loop\n    s1\n    call bar()\n    goto loop\npastloop:\n\nfunction bar()\n    b1 \n    if () return\n    b2",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#inline-the-function-combine-jmps-to-jmps",
    "href": "lectures/05_global.html#inline-the-function-combine-jmps-to-jmps",
    "title": "5 Global Analysis",
    "section": "inline the function, combine jmps to jmps",
    "text": "inline the function, combine jmps to jmps\n\n\nloop: if (cond) goto past_loop\n    s1\n    b1\n    if () go to next\n    b2\n    next:\ngoto loop\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n\n\n\nNow we have two back edges so two loops",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "homework/project.html",
    "href": "homework/project.html",
    "title": "project",
    "section": "",
    "text": "Half way through the course, you should submit a project proposal, I’ll review it to make sure you are not tackling too big a challenge or going to far afield.\nAt the end of the course, you will complete a compiler research project. This is an open- ended project that can be on any topic in the field of compilers.\nThe final product is an experience report where you rigorously evaluate the success of your implementation. You can work individually or in groups of 2–3 students. When you finish an implementation, write it up. Your writeup should answer these questions in a good degree of detail: ● What was the goal? ● What did you do? (include both the design and the implementation) ● What were the hardest parts to get right? ● Were you successful? (report rigorously on your empirical evaluation)\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "project"
    ]
  },
  {
    "objectID": "homework/hw5_llvm.html",
    "href": "homework/hw5_llvm.html",
    "title": "hw 5 llvm",
    "section": "",
    "text": "Follow the LLVM tutorial blog post far enough to implement a pass that changes program execution.\nThis is intentionally open-ended. You can be as ambitious or as unambitious as you want. An example of an unambitious but acceptable task would be to print out a message every time the program uses floating-point division.\nAn example of an ambitious task would be to implement an optimization on LLVM IR and make sure it speeds things up in actual wall-clock time execution.\nFind a real-ish C/C++ program somewhere and run your pass on it to observe the results.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "hw 5 llvm"
    ]
  },
  {
    "objectID": "homework/4_hw.html",
    "href": "homework/4_hw.html",
    "title": "homework - dominance",
    "section": "",
    "text": "Implement the dominance utilities-\n\nFind dominators for a function,\nconstruct the dominance tree,\ncompute the dominance frontier.\n\nDevise a way to test your implementations. Can you find a way to confirm that block A dominates blockB. When you code this,\nremember that checking their output could use slow naive algorithms.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "homework -  dominance"
    ]
  },
  {
    "objectID": "homework/hw0.html",
    "href": "homework/hw0.html",
    "title": "homework 0",
    "section": "",
    "text": "Write a paragraph to introduce yourself in a reply to the canvas introductions topic. Add a picture of you can. Mention a compilers topic you’d like to learn about someday, either in this class or beyond. Add your info to the canvas introductions discussion topic.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request (at the class github) for the weekly.qmd file, fill in your name in the LEADER: line. (I encurage teams of two to sign up for the same paper)\nOnce everyone has signed up, and I see which papers are covered, I’ll finalize the dates and times.\nAdd a text file containing done to Canvas assignment 0 to indicate you have done the introduction and claimed a paper\n\nFor this assignment you just need to submit a response to the canvas assignment to indicate that you are done after you write your introduction into canvas\nFor other assignments you should:\n\nWrite a blog post describing your work, and submit it via a pull request to the github page\nAdd a response to the the canvas assignment giving the name of your blog post\n\n\nMy plan is that grades, personal details and the like stay in canvas and everything else becomes public and goes on the github website.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "homework 0"
    ]
  },
  {
    "objectID": "homework/2_hw.html",
    "href": "homework/2_hw.html",
    "title": "Homework 2 local optimizations",
    "section": "",
    "text": "part 1: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned.\npart2: Implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Homework",
      "Homework 2 local optimizations"
    ]
  },
  {
    "objectID": "notebooks/possible_papers.html",
    "href": "notebooks/possible_papers.html",
    "title": "possible papers",
    "section": "",
    "text": "Glow: Graph Lowering Compiler Techniques for Neural Networks Nadav Rotem, Jordan Fix, Saleem Abdulrasool, Garret Catron, Summer Deng, Roman Dzhabarov, Nick Gibson, James Hegeman, Meghan Lele, Roman Levenstein, Jack Montgomery, Bert Maher, Satish Nadathur, Jakob Olesen, Jongsoo Park, Artem Rakhov, Misha Smelyanski chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/1805.00907\nA Deep Learning Based Cost Model for Automatic Code Optimization. Riyadh Baghdadi, Massinissa Merouani, Mohamed-Hicham Leghettas, Kamel Abdous, Taha Arbaoui, Karima Benatchba, Saman Amarasinghe. Proceedings of the Fourth Conference on Machine Learning and Systems (MLSys).\nhttps://dl.acm.org/doi/abs/10.1145/3213846.3213848?casa_token=cbgdY_Wgz9kAAAAA:IMKfnKAYKl3t9wXFen_yauFHY__vyUHcqSgjENz7RB2QEGeTC1L70FEC5vM9FnKBWdAiL6tw1uC4 Compiler fuzzing through deep learning\n“Effective Superword Level Parallelism for Multimedia Extension Architectures” by Samuel Larsen and Saman Amarasinghe (2000)\nEnergy-Aware Tile Size Selection for Affine Programs on GPUs, M. Jayaweera, M. Kong, Y. Wang, D. Kaeli, Pre-print, Artifact\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/llvm.html",
    "href": "notebooks/llvm.html",
    "title": "intro to llvm",
    "section": "",
    "text": "difference between bril and llvm\nlinks\nllvm page\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n[sudo] password for norm: The following packages were automatically installed and are no longer required:\n  cmake-data dh-elpa-helper emacsen-common libarchive13 libjsoncpp25 librhash0\nUse 'sudo apt autoremove' to remove them.\nThe following packages will be REMOVED:\n  clang* cmake*\n0 upgraded, 0 newly installed, 2 to remove and 48 not upgraded.\nAfter this operation, 21.3 MB disk space will be freed.\n\n(Reading database ... 40226 files and directories currently installed.)\nRemoving clang (1:14.0-55~exp2) ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Progress: [ 22%] [############..............................................] Progress: [ 33%] [###################.......................................] Progress: [ 44%] [#########################.................................] emoving cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] Progress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n[sudo] password for norm: Suggested packages:\n  cmake-doc ninja-build cmake-format\nThe following NEW packages will be installed:\n  clang cmake\n0 upgraded, 2 newly installed, 0 to remove and 48 not upgraded.\nNeed to get 0 B/5014 kB of archives.\nAfter this operation, 21.3 MB of additional disk space will be used.\n\nSelecting previously unselected package clang.\n(Reading database ... 40203 files and directories currently installed.)\nPreparing to unpack .../clang_1%3a14.0-55~exp2_amd64.deb ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Unpacking clang (1:14.0-55~exp2) ...\nProgress: [ 22%] [############..............................................] electing previously unselected package cmake.\nPreparing to unpack .../cmake_3.22.1-1ubuntu1.22.04.2_amd64.deb ...\nProgress: [ 33%] [###################.......................................] Unpacking cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 44%] [#########################.................................] etting up clang (1:14.0-55~exp2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] etting up cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/representation.html",
    "href": "notebooks/representation.html",
    "title": "Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/representation.html#a-more-regular-representation",
    "href": "notebooks/representation.html#a-more-regular-representation",
    "title": "Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "href": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "title": "Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "weekly.html",
    "href": "weekly.html",
    "title": "EECS7398 Weekly Schedule fa 2024",
    "section": "",
    "text": "Since the is the first time this course is offered.\nThis is a tentative schedule.\nThe papers listed here are suggestions, if there is a different paper you would like to present, send me a link so that I can approve it.\nEither 1 or 2 people can sign up for a paper. Once everyone has done so, I’ll schedule which paper gets which date.\n\n\n\n\n\n\n\n\n\n\nsession\nDate\ntopic\ndue\ndiscussions\n\n\n\n\n1\nFriday Sept 6\nCompiler Overview\n\ndiscussion\n\n\n\n\nPerformance Measurement-1\n\n\n\n\n2\nTuesday Sept 10\nPerformance Measurement-2\n\ndiscussion\n\n\n3\nFriday Sept 13\nRepresenting programs\nhw0\ndiscussion\n\n\n\n\nBril\n\ndiscussion\n\n\n4\nTuesday Sept 17\nLocal analysis and optimization\n\ndiscussion\n\n\n5\nFriday Sept 20\nLocal Value Numbering\nhw1\n\n\n\n6\nTuesday Sept 24\nlvn + data flow\n\n\n\n\n7\nFriday Sept 27\nData flow continued\n\n\n\n\n8\nTuesday Oct 1\nData flow + graphs\n\n\n\n\n9\nFriday Oct 4\nStatic single assignment\n\n\n\n\n10\nTuesday Oct 8\nregister allocation\n\n\n\n\n11\nFriday Oct 11\nNorm unavailable - guest lecture over zoom\nhw3\n\n\n\n\nguest lecture\n\n\n\n\n\n\n\n\n\n\n12\nTuesday Oct 15\nreading\n\n\n\n\n\nLeader: Aymane Jerari The MLIR Transform Dialect\n\n\n\n\n\n\n\n\n\n\n13\nFriday Oct 18\nGPU Compilers\nhw4\n\n\n\n14\nTuesday Oct 22\nLLVM\n\n\n\n\n\nproject proposal due\n\n\n\n\n\n\n\n\n\n\n15\nFriday Oct 25\nreading\n\n\n\n\n\nLeader: Oscar Kellner Retargeting and Respecializing GPU Workloads for Performance Portability\n\n\n\n\n\n\n\n\n\n\n16\nTuesday Oct 29\nreading\n\n\n\n\n\nLeader: Sana Anvari Large Language Models for Compiler Optimization\n\n\n\n\n\n\n\n\n\n\n17\nFriday Nov 1\ninstruction scheduling\nhw5\n\n\n\n18\nTuesday Nov 5\nreading\n\n\n\n\n\nLeader: Qucheng Jiang An MLIR-based Compiler Flow for System-Level Design and Hardware Acceleration\n\n\n\n\n\n\n\n\n\n\n19\nFriday Nov 8\ndivergence\n\n\n\n\n20\nTuesday Nov 12\nreading\n\n\n\n\n\nLeader: Yashaswini Makaram ProGraML: Graph-based Deep Learning for Program Optimization and Analysis\n\n\n\n\n\n\n\n\n\n\n21\nFriday Nov 15\nDynamic compilers 1\n\n\n\n\n22\nTuesday Nov 19\nreading\n\n\n\n\n\nLeaders: Rohit Anandakumar and Sharmila Sivalingam Generating GPU Compiler Heuristics using Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n23\nFriday Nov 22\nDynamic compilers\n\n\n\n\n24\nTuesday Nov 26\nreading\n\n\n\n\n\nLeader: Michael Maurer Energy-Aware Tile Size Selection for Affine Programs on GPUs\n\n\n\n\n\n\n\n\n\n\nNov 29\nThanksgiving\n\n\n\n\n\n26\nTuesday Dec 3\nreading\n\n\n\n\n\nLeader: Matin Raayai: Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\n\n\n\n\n\n\n\n\n\n\n27\nFriday Dec 6\nai in compilers\n\n\n\n\n\nPapers\nextra topics\nra checking, add more about ai\n\nextra papers\nTVM: An Automated End-to-End Optimizing Compiler for Deep Learning](https://www.usenix.org/conference/osdi18/presentation/chen) paper\nleader: SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly\nLeader:ACPO: AI-Enabled Compiler-Driven Program Optimization\nleader: Adaptive Online Context-Sensitive Inlining\nleader: Threaded Code Variations and Optimizations\nleader:Learning Compiler Pass Orders using Coreset and Normalized Value Prediction\nleader: Learning to Optimize Tensor Programs\nleader: End-to-end Deep Learning of Optimization Heuristics\nleader: Compiler Fuzzing through Deep Learning\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Weekly Schedule"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "EECS 7398 Fall 2024\nInstructor: Dr. Norman Rubin\nemail: n.rubin@northeastern.edu\nOffice hours by appointment\nThis course draws heavily from the CS6120 Advanced Compilers course at Cornell University. Special thanks to Adrian Sampson for granting permission to use his course materials.\nYou can find videos of Adrian Sampson’s lectures on the CS6120 self-guided page. These videos provide an in-depth explanation of many topics we’ll cover in this course.\nI want to take a moment to address an important aspect of this course: its evolving nature. Since this is the first time this course is being offered, please be aware that both the schedule and assignments may change as we progress.\n\n\n\n Back to top"
  },
  {
    "objectID": "check_meta.html",
    "href": "check_meta.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "# gather all the meta info from all  the files -  check for errors \nimport yaml\nfrom pathlib import Path\n\n\ndef extract_meta_from_qmd(file_path):\n    \"\"\"\n    Extracts and returns the YAML front matter (meta information) from a QMD file.\n    \n    Parameters:\n    - file_path: Path to the QMD file.\n    \n    Returns:\n    - A dictionary containing the parsed YAML front matter, or None if not found.\n    \"\"\"\n    # Initialize an empty string to hold the YAML content\n    yaml_content = ''\n    # Flag to indicate if we are within the YAML front matter\n    in_yaml = False\n    \n    with open(file_path, 'r') as f:\n        for line in f:\n            # Check for the start/end of the YAML front matter\n            if line.strip() == '---':\n                if in_yaml:\n                    # We found the second ---, stop reading further\n                    break\n                else:\n                    # We found the first ---, start collecting lines\n                    in_yaml = True\n            elif in_yaml:\n                # Add the current line to the YAML content\n                yaml_content += line\n    \n    # Parse the YAML content if any was found\n    if yaml_content:\n        return yaml.safe_load(yaml_content)\n    else:\n        return None\n\n\n\nimport os\n\ndef list_all_files(root_dir):\n    \"\"\"List all files in a directory and its subdirectories.\"\"\"\n    all_files = []\n    for root, dirs, files in os.walk(root_dir):\n        for file in files:\n            all_files.append(os.path.join(root, file))\n    return all_files\n\n\nbase = Path(\"/home/norm/compiler_course_2024fa/\")\n\n\nfrom numpy import isin\n\n\nmeta_union = {}\nfor file in list_all_files(base):\n    file_path = Path(file)\n    if file_path.suffix in [\".pdf\", \".jpg\", \".png\", \".woff\", \".eot\", \".woff2\", \".ttf\", \".so\", \".pyc\"]:\n        continue\n    if file_path.parent.name == \"bin\":\n        continue \n    if any(parent.name == \".venv\" for parent in file_path.parents):\n        continue\n    if any(parent.name == \".git\" for parent in file_path.parents):\n        continue\n    meta_info = extract_meta_from_qmd(file)\n    if meta_info:\n        for key, value in meta_info.items():\n    \n            if isinstance(value, list):\n                value = ', '.join(map(str, value))\n            elif isinstance(value,dict):\n                for sub_key, sub_value in value.items():\n                    combined_key = f\"{key}.{sub_key}\"  # Combine the parent key and sub-key\n                    sub_value = str(sub_value)  # Convert sub-value to string\n                    if combined_key not in meta_union:\n                        meta_union[combined_key] = {sub_value}\n                    else:\n                        meta_union[combined_key].add(sub_value)\n                continue\n            \n            if key not in meta_union:\n                meta_union[key] = {value}\n            else:\n                meta_union[key].add(value)\n\nfor (k,v) in meta_union.items():\n    print (k, v )\n\n    \n\ntitle {'Representation of programs', 'Performance and Measurement', '14_gpu_compilers', '5_hw', 'project', 'EECE7398 Fall 2024', '10 MLIR', '3_hw ', 'Untitled', '_ loop invariant code motion', '9 polyhedral analysis', '11 Whole program', 'EECS7398 Weekly Schedule', 'How to do assignments', 'homework 0', '8 classic loop optimizations', 'Overview of Bril', '_ partial_redundancy elimination', '4_hw', 'EECS7398 Weekly Schedule fa 2024', '_ local value numbering', '4. Data Flow', 'About', 'Schedule', '3 Local Analysis & Optimization', '2.hw', '12_memory.qmd', 'Testing Register allocators', '6- extra credit hw ', '1 Compiler Overview', '1-Homework', 'Static Single Assignment', '13_dynamic_compielrs', '5 Global Analysis'}\nformat {'html'}\ntbl-colwidths {'10, 20, 20, 20, 15, 15'}\nformat.html {'default'}\nformat.revealjs {\"{'chalkboard': True, 'output-file': 'revealjs-licm', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-rep'}\", \"{'chalkboard': True, 'output-file': 'revealjs-partial-redun', 'scrollable': True}\", \"{'chalkboard': True, 'scrollable': True, 'output-location': 'slide', 'code-line-numbers': True, 'output-file': 'revealjs-bril'}\", \"{'chalkboard': True, 'output-file': 'revealjs-local', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-ssa', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-lvn', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-compiler_overview.html', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-data-flow', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-global-anal', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-performance.html', 'scrollable': True}\"}\nkeep-ipynb {True}\npython {'kaggle_comp'}\nsidebar {False}\nexecute.echo {'True'}\n\n\n\nimport os\nimport yaml\n\nbase = Path(\"/home/norm/compiler_course_2024fa/\")\n\n# Step 1: List all .qmd files\nqmd_files = []\nslide_qmd_files = []\n\nfor root, dirs, files in os.walk(base):  # Adjust '.' to your project directory if necessary\n    revealjs_\n    if \"_site\" in Path(root).parts:\n        continue\n    for file in files:\n        if file.endswith('.qmd'):\n            qmd_files.append(os.path.join(root, file))\n\n# Step 2: Read and parse each .qmd file\nfor qmd_file in qmd_files:\n\n    with open(qmd_file, 'r') as file:\n        content = file.read()\n        # Assuming the YAML metadata is at the top of the file, delimited by ---\n        if content.startswith('---'):\n            end_of_yaml = content.find('---', 3)\n            if end_of_yaml != -1:\n                yaml_content = content[3:end_of_yaml]\n                metadata = yaml.safe_load(yaml_content)  # Parse YAML\n\n                format_data = metadata.get('format')\n                if not format_data:\n                    print(qmd_file, \"no format field\")\n                    continue\n                try:\n                    html_meta_data = format_data.get(\"html\")\n                except Exception as e:\n                    print(qmd_file, e, 'format does not have html')\n                    continue\n\n                if html_meta_data != 'default':\n                    print(qmd_file, \"not html default\")\n                    continue \n                try:\n                    revealjs_meta_data = format_data.get('revealjs')\n                except:\n                    print(\"qmd_file\", \"no revealjs\")\n                    continue\n                if revealjs_meta_data:\n                    chalk = revealjs_meta_data.get(\"chalkboard'\")\n                    if chalk != 'true':\n                        print(qmd_file, \"missing chalkboard\")\n    \n                # get the format\n                # see if it has a subkey, revealjs\n                # if it does check for an deeper subkey of output-file\n\n                # Step 3: Check for format: reveljs\n                if metadata.get('format') == 'revealjs':\n                    # Step 4: Verify the output file name\n                    expected_output = 'reveljs-' + os.path.basename(qmd_file).replace('.qmd', '')\n                    if metadata.get('output-file') == expected_output:\n                        print(f\"{qmd_file}: Success, output file name is correct.\")\n                    else:\n                        print(f\"{qmd_file}: Failure, output file name does not match the expected '{expected_output}'.\")\n\n/home/norm/compiler_course_2024fa/lectures/02a_representation.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/010_compiler_overview.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/02b_bril.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/05_global.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/01a_performance_measurement.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/06_ssa.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/05b_licm.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/04_data_flow.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/03b_local_value_numbering.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/03_local.qmd missing chalkboard\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "",
    "text": "This assignment is designed to allow us to get comfortable with Bril, an intermediate representation designed for learning. In this assignment, we add a benchmark program to the suite, and write a tool for analyzing JSON formatted Bril.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#introduction",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "",
    "text": "This assignment is designed to allow us to get comfortable with Bril, an intermediate representation designed for learning. In this assignment, we add a benchmark program to the suite, and write a tool for analyzing JSON formatted Bril.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-1-bril-benchmark-program",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-1-bril-benchmark-program",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Part 1: Bril Benchmark Program",
    "text": "Part 1: Bril Benchmark Program\nA good benchmark for this assignment is one which is new to the repository, but is fairly simple. As such, a benchmark which fits into the benchmark/core suite is likely a good choice.\nMy first idea was to implement a benchmark which computes the Hamming distance between two integers. In a high level language with a shift operator, this is a fairly easy program to write. However, Bril does not have a built-in shift operator. I spent some time writing a function to compute the Hamming distance without shifting, but it quickly became cumbersome and I searched for other ideas to not overcomplicate this work.\nMy next idea was to write a benchmark which computes the \\(nth\\) value in the Fibonacci sequence recursively. This is a sensible benchmark, as it may test a system’s ability to handle recursive programs, and further tests whether a compiler preserves this relationship.\nTo create this, only about 11 lines of TypeScript were required (when paired with the TypeScript compiler).\nAt the end, I created a program to compute the \\(nth\\) value in the Fibonacci sequence recursively, which can be found at benchmarks/core/fibonacci.bril, and can be tested with turnt.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#problems-faced",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#problems-faced",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Problems Faced",
    "text": "Problems Faced\nOne challenge as I learned was that the TS compiler does not recognize many types, and further regards many types as Any when they cannot be easily predicted. This was not much of a challenge to handle, however I am not much of a TS programmer so learning enough of the language was a step in the process.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Testing",
    "text": "Testing\nTo verify functionality, I first by hand compared the results of execution with different input values of \\(n\\), and additionally developed a turnt test. Results of testing can be observed below:\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 1\n1\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 5\n5\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 10\n55\n$ bril2json &lt; benchmarks/core/fibonacci.bril | brili 30\n832040\n\n# Including timing results as evidence that recursion is happening \n$ time bril2json &lt; benchmarks/core/fibonacci.bril | brili 30\n832040\n\nreal    0m1.836s\nuser    0m1.817s\nsys 0m0.052s\n[15:02:36] michaelmaurer:~/Documents/NEU/EECE7309-compilers/bril$ time bril2json &lt; benchmarks/core/fibonacci.bril | brili 10\n55\n\nreal    0m0.102s\nuser    0m0.096s\nsys 0m0.031s",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-2-bril-tooling",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#part-2-bril-tooling",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Part 2: Bril Tooling",
    "text": "Part 2: Bril Tooling\nFor the second part of this assignment, we were asked to design a tool which either analyzed or modified Bril code stored in JSON format. I chose to make a simple program, which for a given file, computes how many of each “type” of instruction the program contains. The three types of instructions are “Constants”, “Value Operations”, and “Effect Operations” as outlined in the docs.\nTo do this, I wrote a Python script which consumed the input JSON, parsed it to get the available instructions, and iterated through the map. Each instruction type has a unique construction, which I used to determine how many of each type of isntruction was contained. This tool only requires one pass through the program JSON to determine the count of each instruction type.\nThis tool could readily be extended to gather information about the types of instructions in a program.\nThe code for this tool is shared below:\n\n#!/usr/bin/env python3\n\nimport json\nimport sys\n\n# Read the input as json\n# Proc Exit: If valid input rec'd\ndef read_json_file(input):\n    try:\n        data = json.load(input)\n        return data\n    except json.JSONDecodeError:\n        print(f\"Error: The input does not contain valid JSON.\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        sys.exit(1)\n\n# Count the instruction types as specified by Bril syntax\ndef count_instr_types(data: dict):\n    db = {'constant': 0, 'value': 0, 'effect': 0}\n    for func in data['functions']:\n        for instr in func['instrs']:\n            # If instr op is const, it must be a constant instruction\n            if 'op' in instr and instr['op'] == 'const':\n                db['constant'] += 1\n            # If instr has a dest and is not a const, it must be a value instruction\n            elif 'dest' in instr:\n                db['value'] += 1\n            # Continue if this is a label\n            elif 'label' in instr:\n                continue\n            # Otherwise this must be an effect instruction\n            else:\n                db['effect'] += 1\n            # Note: this assumes the json is well-formed Bril.\n    return db\n\n# Main\ndef main():\n    data = read_json_file(sys.stdin)\n    print(count_instr_types(data))\n\nif __name__ == \"__main__\":\n    main()",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing-1",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#testing-1",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Testing",
    "text": "Testing\nI tested this program on a handful of the provided benchmarks, and verified the results by hand. Some results are shared below:\n$ bril2json &lt; ../benchmarks/core/hanoi.bril | python tool.py \n{'constant': 5, 'value': 2, 'effect': 6}\n[15:10:42] michaelmaurer:~/Documents/NEU/EECE7309-compilers/bril/mytools$ bril2json &lt; ../benchmarks/core/birthday.bril | python tool.py \n{'constant': 9, 'value': 26, 'effect': 4}\n[15:11:04] michaelmaurer:~/Documents/NEU/EECE7309-compilers/bril/mytools$ bril2json &lt; ../benchmarks/core/collatz.bril | python tool.py \n{'constant': 3, 'value': 7, 'effect': 7}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Challenges faced",
    "text": "Challenges faced\nOriginally, I had planned to construct a program which identified all control flow instructions, and further identified how many basic blocks the program contained. I moved away from this because I was not sure how exactly to handle call and ret instructions at this time, and it seems likely this work is coming in a future assignment.\nAnother challenge was that I had at first not realized that labels are contained within the instructions in the json files. This was causing my program to crash, and required some (brief) debugging.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#code",
    "href": "blogs/michael/09-20-2024-HW1-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 1 – Trying Out Bril",
    "section": "Code",
    "text": "Code\nThe code for this assignment is contained in the latest commit in my fork of Bril.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 1 -- Trying Out Bril"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "",
    "text": "This assignment asks us to investigate data flow analysis algorithms. Here, we discuss the algorithm implemented, and describe the process of developing this code. We primarily investigate “reaching definitions” here. Further, this code defines an Analysis class which allows the user to decelare a merge and transfer function for data flow analysis, and further allows them to indicate whether the analysis is forward or reverse. This was considered extra credit for this assignment.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#introduction",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#introduction",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "",
    "text": "This assignment asks us to investigate data flow analysis algorithms. Here, we discuss the algorithm implemented, and describe the process of developing this code. We primarily investigate “reaching definitions” here. Further, this code defines an Analysis class which allows the user to decelare a merge and transfer function for data flow analysis, and further allows them to indicate whether the analysis is forward or reverse. This was considered extra credit for this assignment.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#reaching-definitions",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#reaching-definitions",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "Reaching Definitions",
    "text": "Reaching Definitions\nWe wish to analyze whether a definition “reaches” a particular part of the program. This allows us to determine what definitions have a valid path to arrive at a specific block in the program. This can be very helpful for other optimizations such as dead code elimination. Reaching definition data flow analysis is a forward DFA algorithm, and employs a “may” merger strategy (i.e. a union). At a high level, this algorithm determines what definitions may reach the start of a basic block, and determines which definitions may leave the block, which can be deduced to the definitions at the start of the block minus those definitions which were killed (generally by reassignments).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#challenges-faced",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#challenges-faced",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nThere were a couple of challenges which I faced developing this code. The first was in determining how to represent the CFG of a given program. The previous assignments did leverage basic blocks, but only limited interconnection of them. As such, I was able to get by without defining more formal structures. In this assignment, I formalized this structure as one typically does with a graph. This is not inherently a difficult task, however this is the first time I have done so in Python and as such neglected how some common types are passed around, namely whether they are copies or references. I wrote the code under the assumption that they were copies initially, but this introduced a handful of bugs into my code which were not immediately clear. I also learned this the hard way when defining the data flow analysis algorithm itself. This proved particularly confusing when analyzing code with loops.\nAnother challenge I incurred was perhaps one of mistaken thought, where I had convinced myself that calls and returns would need to be handled for this analysis. What I neglected to realize is that at a call or return, the scope changes, and therefore this DFA does not really need to work across functions. The only scenario where this would be necessary is with some kind of global variable, which appears to be out of scope of this type of analysis. So, this was a bit of a tangent I sent myself on.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#implementation",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#implementation",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "Implementation",
    "text": "Implementation\nAs mentioned above, this implementation analyzes whether a definiton reaches a particular part of the program. To do this, we define an algorithm which inspects every basic block in each function in the program. We determine, based on the definitions which enter the block, the definitions that exit the block.\nIn more detail, we determine the definitions which enter the block as the union of all definitions exiting predecessor blocks to the given block (this is the merge step). Then, we determine what the outputs of the basic block are by overwriting any definitions found in b_in (the definitions which reach the block) of variables defined in the current block, which is to say that we overwrite the definitions killed by the current block. This is the transfer step. We iterate through all the basic blocks in the program, moving “forward” through the basic blocks, where forward is moving essentially forward through time in the program. At the end of each block’s analysis, if the outputs of the block have changed, we enqueue the successor blocks of the current block into our worklist. Once the outputs of the block cease to change, this analysis is complete and has converged (it is further provable that this algorithm always converges).\nThe data structure in this analysis is a CFG, containing “Blocks” which are defined as follows:\n\nclass Block:\n    def __init__(self, instrs: list, id, preds: set, succs: set):\n        self.instrs = instrs\n        self.id = id\n        self.preds = preds\n        self.succs = succs\n\nFurther, this code was designed to be compatible with other analyses. It does so by definining the following class:\n\nclass Analysis():\n    def __init__(self, forward: bool, merge: Callable[list, list], transfer: Callable[[dict, blocks.Block], dict]):\n        self.forward = forward\n        self.init = init\n        self.merge = merge\n        self.transfer = transfer\n    \n    def merge(self, b_ins: list):\n        return self.merge(b_ins)\n    \n    def transfer(self, b_in: dict, block: blocks.Block):\n        return self.transfer(b_in, block)\n\n    def data_flow(self, blocks):\n        ... # See linked code",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#testing",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#testing",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "Testing",
    "text": "Testing\nI tested this program on four programs, two of my own, and two found in Bril’s benchmark suite. One of the programs I experimented with was quadratic.bril, which is rather long, and as such I have put those results in the appendix of this blog.\nThe most basic test case was the following code:\n# sample.bril\n@main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    prod2: int = mul sum1 sum2;\n    print prod;\n}\nThis code only contains one basic block, and produces fairly trivial results, shown below.\nprinting blocks\n.start \n Instructions: [{'dest': 'a', 'op': 'const', 'type': 'int', 'value': 4}, {'dest': 'b', 'op': 'const', 'type': 'int', 'value': 2}, {'args': ['a', 'b'], 'dest': 'sum1', 'op': 'add', 'type': 'int'}, {'args': ['a', 'b'], 'dest': 'sum2', 'op': 'add', 'type': 'int'}, {'args': ['sum1', 'sum2'], 'dest': 'prod', 'op': 'mul', 'type': 'int'}, {'args': ['sum1', 'sum2'], 'dest': 'prod2', 'op': 'mul', 'type': 'int'}, {'args': ['prod'], 'op': 'print'}]\n ID: .start\n Predecessors: set()\n Successors: set()\n\n\nblock_id:  .start\nin_edges:  {}\nout_edges:  {'a': ['.start_0'], 'b': ['.start_1'], 'sum1': ['.start_2'], 'sum2': ['.start_3'], 'prod': ['.start_4'], 'prod2': ['.start_5']}\nThe next program introduced branching control flow:\n# test\n@main(a: int) {\n  v1: int = const 1;\n  cond: bool = lt v1 x;\n  br cond .then.0 .else.0;\n.then.0:\n  v2: int = id x;\n  jmp .print;\n.else.0:\n  v3: int = id x;\n  v4: int = const 1;\n  v2: int = sub v3 v4;\n.print:\n  print v2;\n}\nThis correctly produced the following result:\nprinting blocks\nthen.0 \n Instructions: [{'args': ['cond'], 'labels': ['then.0', 'else.0'], 'op': 'br'}, {'args': ['x'], 'dest': 'v2', 'op': 'id', 'type': 'int'}, {'labels': ['print'], 'op': 'jmp'}]\n ID: then.0\n Predecessors: {'.start'}\n Successors: {'print'}\n\nprinting blocks\nelse.0 \n Instructions: [{'args': ['cond'], 'labels': ['then.0', 'else.0'], 'op': 'br'}, {'args': ['x'], 'dest': 'v3', 'op': 'id', 'type': 'int'}, {'dest': 'v4', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v3', 'v4'], 'dest': 'v2', 'op': 'sub', 'type': 'int'}]\n ID: else.0\n Predecessors: {'.start'}\n Successors: {'print'}\n\nprinting blocks\n.start \n Instructions: [{'dest': 'v1', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v1', 'x'], 'dest': 'cond', 'op': 'lt', 'type': 'bool'}, {'args': ['cond'], 'labels': ['then.0', 'else.0'], 'op': 'br'}]\n ID: .start\n Predecessors: set()\n Successors: {'else.0', 'then.0'}\n\nprinting blocks\nprint \n Instructions: [{'labels': ['print'], 'op': 'jmp'}, {'args': ['v2'], 'op': 'print'}]\n ID: print\n Predecessors: {'else.0', 'then.0'}\n Successors: set()\n\n\nblock_id:  then.0\nin_edges:  {'v1': ['.start_0'], 'cond': ['.start_1']}\nout_edges:  {'v1': ['.start_0'], 'cond': ['.start_1'], 'v2': ['then.0_1']}\n\nblock_id:  else.0\nin_edges:  {'v1': ['.start_0'], 'cond': ['.start_1']}\nout_edges:  {'v1': ['.start_0'], 'cond': ['.start_1'], 'v3': ['else.0_1'], 'v4': ['else.0_2'], 'v2': ['else.0_3']}\n\nblock_id:  .start\nin_edges:  {}\nout_edges:  {'v1': ['.start_0'], 'cond': ['.start_1']}\n\nblock_id:  print\nin_edges:  {'v1': ['.start_0'], 'cond': ['.start_1'], 'v3': ['else.0_1'], 'v4': ['else.0_2'], 'v2': ['else.0_3', 'then.0_1']}\nout_edges:  {'v3': ['else.0_1'], 'v4': ['else.0_2'], 'v2': ['else.0_3', 'then.0_1'], 'v1': ['.start_0'], 'cond': ['.start_1']}\nAs we can see, the in and out edges for each block are what we expect. The key observation is in the final print block, definitions from both branches are “reaching”.\nFor a more complex example, we examined the loopfact.bril benchmark from the bril repository.\n# ARGS: 8\n@main(input: int) {\n  value: int = id input;\n  v1: int = const 1;\n  result: int = id v1;\n  v3: int = id value;\n  i: int = id v3;\n.for.cond.2:\n  v4: int = id i;\n  v5: int = const 0;\n  v6: bool = gt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: int = id result;\n  v8: int = id i;\n  v9: int = mul v7 v8;\n  result: int = id v9;\n  v10: int = id i;\n  v11: int = const 1;\n  v12: int = sub v10 v11;\n  i: int = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: int = id result;\n  print v13;\n  v14: int = const 0;\n}\nThis code contains a loop, which is a good test for our analysis. What we expect is all definitions reach the final .for.end.2 block, all definitions except for those in .for.end.2 reach the blocks .for.cond.2 and .for.body.2, and no definitions reach the start of .start. Further, we expect for .for.body.2 to kill the definitions of i and result which will enter the block. No other blocks should kill instructions.\nWe show that the expected results are generated by our program:\nprinting blocks\n.start \n Instructions: [{'args': ['input'], 'dest': 'value', 'op': 'id', 'type': 'int'}, {'dest': 'v1', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v1'], 'dest': 'result', 'op': 'id', 'type': 'int'}, {'args': ['value'], 'dest': 'v3', 'op': 'id', 'type': 'int'}, {'args': ['v3'], 'dest': 'i', 'op': 'id', 'type': 'int'}]\n ID: .start\n Predecessors: set()\n Successors: {'for.cond.2'}\n\nprinting blocks\nfor.cond.2 \n Instructions: [{'args': ['i'], 'dest': 'v4', 'op': 'id', 'type': 'int'}, {'dest': 'v5', 'op': 'const', 'type': 'int', 'value': 0}, {'args': ['v4', 'v5'], 'dest': 'v6', 'op': 'gt', 'type': 'bool'}, {'args': ['v6'], 'labels': ['for.body.2', 'for.end.2'], 'op': 'br'}]\n ID: for.cond.2\n Predecessors: {'for.body.2', '.start'}\n Successors: {'for.end.2', 'for.body.2'}\n\nprinting blocks\nfor.body.2 \n Instructions: [{'args': ['v6'], 'labels': ['for.body.2', 'for.end.2'], 'op': 'br'}, {'args': ['result'], 'dest': 'v7', 'op': 'id', 'type': 'int'}, {'args': ['i'], 'dest': 'v8', 'op': 'id', 'type': 'int'}, {'args': ['v7', 'v8'], 'dest': 'v9', 'op': 'mul', 'type': 'int'}, {'args': ['v9'], 'dest': 'result', 'op': 'id', 'type': 'int'}, {'args': ['i'], 'dest': 'v10', 'op': 'id', 'type': 'int'}, {'dest': 'v11', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v10', 'v11'], 'dest': 'v12', 'op': 'sub', 'type': 'int'}, {'args': ['v12'], 'dest': 'i', 'op': 'id', 'type': 'int'}, {'labels': ['for.cond.2'], 'op': 'jmp'}]\n ID: for.body.2\n Predecessors: {'for.cond.2'}\n Successors: {'for.cond.2'}\n\nprinting blocks\nfor.end.2 \n Instructions: [{'args': ['v6'], 'labels': ['for.body.2', 'for.end.2'], 'op': 'br'}, {'args': ['result'], 'dest': 'v13', 'op': 'id', 'type': 'int'}, {'args': ['v13'], 'op': 'print'}, {'dest': 'v14', 'op': 'const', 'type': 'int', 'value': 0}]\n ID: for.end.2\n Predecessors: {'for.cond.2'}\n Successors: set()\n\n\nblock_id:  .start\nin_edges:  {}\nout_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'result': ['.start_2'], 'v3': ['.start_3'], 'i': ['.start_4']}\n\nblock_id:  for.cond.2\nin_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'result': ['.start_2', 'for.body.2_4'], 'v3': ['.start_3'], 'i': ['.start_4', 'for.body.2_8'], 'v4': ['for.cond.2_0'], 'v5': ['for.cond.2_1'], 'v6': ['for.cond.2_2'], 'v7': ['for.body.2_1'], 'v8': ['for.body.2_2'], 'v9': ['for.body.2_3'], 'v10': ['for.body.2_5'], 'v11': ['for.body.2_6'], 'v12': ['for.body.2_7']}\nout_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'result': ['.start_2', 'for.body.2_4'], 'v3': ['.start_3'], 'i': ['.start_4', 'for.body.2_8'], 'v7': ['for.body.2_1'], 'v8': ['for.body.2_2'], 'v9': ['for.body.2_3'], 'v10': ['for.body.2_5'], 'v11': ['for.body.2_6'], 'v12': ['for.body.2_7'], 'v4': ['for.cond.2_0'], 'v5': ['for.cond.2_1'], 'v6': ['for.cond.2_2']}\n\nblock_id:  for.body.2\nin_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'result': ['.start_2', 'for.body.2_4'], 'v3': ['.start_3'], 'i': ['.start_4', 'for.body.2_8'], 'v7': ['for.body.2_1'], 'v8': ['for.body.2_2'], 'v9': ['for.body.2_3'], 'v10': ['for.body.2_5'], 'v11': ['for.body.2_6'], 'v12': ['for.body.2_7'], 'v4': ['for.cond.2_0'], 'v5': ['for.cond.2_1'], 'v6': ['for.cond.2_2']}\nout_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'v3': ['.start_3'], 'v4': ['for.cond.2_0'], 'v5': ['for.cond.2_1'], 'v6': ['for.cond.2_2'], 'v7': ['for.body.2_1'], 'v8': ['for.body.2_2'], 'v9': ['for.body.2_3'], 'result': ['for.body.2_4'], 'v10': ['for.body.2_5'], 'v11': ['for.body.2_6'], 'v12': ['for.body.2_7'], 'i': ['for.body.2_8']}\n\nblock_id:  for.end.2\nin_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'result': ['.start_2', 'for.body.2_4'], 'v3': ['.start_3'], 'i': ['.start_4', 'for.body.2_8'], 'v7': ['for.body.2_1'], 'v8': ['for.body.2_2'], 'v9': ['for.body.2_3'], 'v10': ['for.body.2_5'], 'v11': ['for.body.2_6'], 'v12': ['for.body.2_7'], 'v4': ['for.cond.2_0'], 'v5': ['for.cond.2_1'], 'v6': ['for.cond.2_2']}\nout_edges:  {'value': ['.start_0'], 'v1': ['.start_1'], 'result': ['.start_2', 'for.body.2_4'], 'v3': ['.start_3'], 'i': ['.start_4', 'for.body.2_8'], 'v7': ['for.body.2_1'], 'v8': ['for.body.2_2'], 'v9': ['for.body.2_3'], 'v10': ['for.body.2_5'], 'v11': ['for.body.2_6'], 'v12': ['for.body.2_7'], 'v4': ['for.cond.2_0'], 'v5': ['for.cond.2_1'], 'v6': ['for.cond.2_2'], 'v13': ['for.end.2_1'], 'v14': ['for.end.2_3']}\nWe further tested with the quadratic.bril program, and results for that test may be found in the appendix. This program contains multiple functions, loops, and branches, however is not especially interesting for this analysis as there is only one instance of a definition being killed (in the .endif.7 block).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#code",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#code",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "Code",
    "text": "Code\nThe code for this assignment is contained in a public GitHub repository. The code and testing code + results can be found in this repository.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#appendix",
    "href": "blogs/michael/10-11-2024-HW3-MichaelMaurer.html#appendix",
    "title": "EECE7309 Homework 3 – Data Flow",
    "section": "Appendix",
    "text": "Appendix\n# quadratic.bril\n# ARGS: -5 8 21\n@main(a: int, b: int, c: int) {\n  call @quadratic a b c;\n}\n\n@sqrt(x: int): int {\n  v1: int = const 1;\n  i: int = id v1;\n.for.cond.0:\n  v2: int = id i;\n  v3: int = id x;\n  v4: int = const 1;\n  v5: int = sub v3 v4;\n  v6: bool = lt v2 v5;\n  br v6 .for.body.0 .for.end.0;\n.for.body.0:\n  v8: int = id i;\n  v9: int = id i;\n  v10: int = mul v8 v9;\n  v11: int = id x;\n  v12: bool = ge v10 v11;\n  br v12 .then.7 .else.7;\n.then.7:\n  v13: int = id i;\n  ret v13;\n.else.7:\n.endif.7:\n  v14: int = id i;\n  v15: int = const 1;\n  v16: int = add v14 v15;\n  i: int = id v16;\n  jmp .for.cond.0;\n.for.end.0:\n  v17: int = const 0;\n  ret v17;\n}\n\n@quadratic(a: int, b: int, c: int) {\n  v0: int = id b;\n  v1: int = id b;\n  v2: int = mul v0 v1;\n  v3: int = const 4;\n  v4: int = id a;\n  v5: int = mul v3 v4;\n  v6: int = id c;\n  v7: int = mul v5 v6;\n  v8: int = sub v2 v7;\n  s: int = id v8;\n  v9: int = const 2;\n  v10: int = id a;\n  v11: int = mul v9 v10;\n  d: int = id v11;\n  v12: int = const 0;\n  v13: int = id b;\n  v14: int = sub v12 v13;\n  v15: int = id s;\n  v16: int = call @sqrt v15;\n  v17: int = add v14 v16;\n  r1: int = id v17;\n  v18: int = const 0;\n  v19: int = id b;\n  v20: int = sub v18 v19;\n  v21: int = id s;\n  v22: int = call @sqrt v21;\n  v23: int = sub v20 v22;\n  r2: int = id v23;\n  v24: int = id r1;\n  v25: int = id d;\n  v26: int = div v24 v25;\n  print v26;\n  v27: int = const 0;\n  v28: int = id r2;\n  v29: int = id d;\n  v30: int = div v28 v29;\n  print v30;\n  v31: int = const 0;\n}\nResults:\nprinting blocks\n.start \n Instructions: [{'args': ['a', 'b', 'c'], 'funcs': ['quadratic'], 'op': 'call'}]\n ID: .start\n Predecessors: set()\n Successors: set()\n\n\nblock_id:  .start\nin_edges:  {}\nout_edges:  {}\n\nprinting blocks\n.start \n Instructions: [{'dest': 'v1', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v1'], 'dest': 'i', 'op': 'id', 'type': 'int'}]\n ID: .start\n Predecessors: set()\n Successors: {'for.cond.0'}\n\nprinting blocks\nfor.cond.0 \n Instructions: [{'args': ['i'], 'dest': 'v2', 'op': 'id', 'type': 'int'}, {'args': ['x'], 'dest': 'v3', 'op': 'id', 'type': 'int'}, {'dest': 'v4', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v3', 'v4'], 'dest': 'v5', 'op': 'sub', 'type': 'int'}, {'args': ['v2', 'v5'], 'dest': 'v6', 'op': 'lt', 'type': 'bool'}, {'args': ['v6'], 'labels': ['for.body.0', 'for.end.0'], 'op': 'br'}]\n ID: for.cond.0\n Predecessors: {'.start', 'endif.7'}\n Successors: {'for.body.0', 'for.end.0'}\n\nprinting blocks\nfor.body.0 \n Instructions: [{'args': ['v6'], 'labels': ['for.body.0', 'for.end.0'], 'op': 'br'}, {'args': ['i'], 'dest': 'v8', 'op': 'id', 'type': 'int'}, {'args': ['i'], 'dest': 'v9', 'op': 'id', 'type': 'int'}, {'args': ['v8', 'v9'], 'dest': 'v10', 'op': 'mul', 'type': 'int'}, {'args': ['x'], 'dest': 'v11', 'op': 'id', 'type': 'int'}, {'args': ['v10', 'v11'], 'dest': 'v12', 'op': 'ge', 'type': 'bool'}, {'args': ['v12'], 'labels': ['then.7', 'else.7'], 'op': 'br'}]\n ID: for.body.0\n Predecessors: {'for.cond.0'}\n Successors: {'then.7', 'else.7'}\n\nprinting blocks\nfor.end.0 \n Instructions: [{'args': ['v6'], 'labels': ['for.body.0', 'for.end.0'], 'op': 'br'}, {'dest': 'v17', 'op': 'const', 'type': 'int', 'value': 0}, {'args': ['v17'], 'op': 'ret'}]\n ID: for.end.0\n Predecessors: {'for.cond.0'}\n Successors: set()\n\nprinting blocks\nthen.7 \n Instructions: [{'args': ['v12'], 'labels': ['then.7', 'else.7'], 'op': 'br'}, {'args': ['i'], 'dest': 'v13', 'op': 'id', 'type': 'int'}, {'args': ['v13'], 'op': 'ret'}]\n ID: then.7\n Predecessors: {'for.body.0'}\n Successors: set()\n\nprinting blocks\nelse.7 \n Instructions: [{'args': ['v12'], 'labels': ['then.7', 'else.7'], 'op': 'br'}]\n ID: else.7\n Predecessors: {'for.body.0'}\n Successors: {'endif.7'}\n\nprinting blocks\nendif.7 \n Instructions: [{'args': ['i'], 'dest': 'v14', 'op': 'id', 'type': 'int'}, {'dest': 'v15', 'op': 'const', 'type': 'int', 'value': 1}, {'args': ['v14', 'v15'], 'dest': 'v16', 'op': 'add', 'type': 'int'}, {'args': ['v16'], 'dest': 'i', 'op': 'id', 'type': 'int'}, {'labels': ['for.cond.0'], 'op': 'jmp'}]\n ID: endif.7\n Predecessors: {'else.7'}\n Successors: {'for.cond.0'}\n\n\nblock_id:  .start\nin_edges:  {}\nout_edges:  {'v1': ['.start_0'], 'i': ['.start_1']}\n\nblock_id:  for.cond.0\nin_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2']}\nout_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4']}\n\nblock_id:  for.body.0\nin_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4']}\nout_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5']}\n\nblock_id:  for.end.0\nin_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4']}\nout_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v17': ['for.end.0_1']}\n\nblock_id:  then.7\nin_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5']}\nout_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v13': ['then.7_1']}\n\nblock_id:  else.7\nin_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5']}\nout_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5']}\n\nblock_id:  endif.7\nin_edges:  {'v1': ['.start_0'], 'i': ['.start_1', 'endif.7_3'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5']}\nout_edges:  {'v1': ['.start_0'], 'v2': ['for.cond.0_0'], 'v3': ['for.cond.0_1'], 'v4': ['for.cond.0_2'], 'v5': ['for.cond.0_3'], 'v6': ['for.cond.0_4'], 'v8': ['for.body.0_1'], 'v9': ['for.body.0_2'], 'v10': ['for.body.0_3'], 'v11': ['for.body.0_4'], 'v12': ['for.body.0_5'], 'v14': ['endif.7_0'], 'v15': ['endif.7_1'], 'v16': ['endif.7_2'], 'i': ['endif.7_3']}\n\nprinting blocks\n.start \n Instructions: [{'args': ['b'], 'dest': 'v0', 'op': 'id', 'type': 'int'}, {'args': ['b'], 'dest': 'v1', 'op': 'id', 'type': 'int'}, {'args': ['v0', 'v1'], 'dest': 'v2', 'op': 'mul', 'type': 'int'}, {'dest': 'v3', 'op': 'const', 'type': 'int', 'value': 4}, {'args': ['a'], 'dest': 'v4', 'op': 'id', 'type': 'int'}, {'args': ['v3', 'v4'], 'dest': 'v5', 'op': 'mul', 'type': 'int'}, {'args': ['c'], 'dest': 'v6', 'op': 'id', 'type': 'int'}, {'args': ['v5', 'v6'], 'dest': 'v7', 'op': 'mul', 'type': 'int'}, {'args': ['v2', 'v7'], 'dest': 'v8', 'op': 'sub', 'type': 'int'}, {'args': ['v8'], 'dest': 's', 'op': 'id', 'type': 'int'}, {'dest': 'v9', 'op': 'const', 'type': 'int', 'value': 2}, {'args': ['a'], 'dest': 'v10', 'op': 'id', 'type': 'int'}, {'args': ['v9', 'v10'], 'dest': 'v11', 'op': 'mul', 'type': 'int'}, {'args': ['v11'], 'dest': 'd', 'op': 'id', 'type': 'int'}, {'dest': 'v12', 'op': 'const', 'type': 'int', 'value': 0}, {'args': ['b'], 'dest': 'v13', 'op': 'id', 'type': 'int'}, {'args': ['v12', 'v13'], 'dest': 'v14', 'op': 'sub', 'type': 'int'}, {'args': ['s'], 'dest': 'v15', 'op': 'id', 'type': 'int'}, {'args': ['v15'], 'dest': 'v16', 'funcs': ['sqrt'], 'op': 'call', 'type': 'int'}, {'args': ['v14', 'v16'], 'dest': 'v17', 'op': 'add', 'type': 'int'}, {'args': ['v17'], 'dest': 'r1', 'op': 'id', 'type': 'int'}, {'dest': 'v18', 'op': 'const', 'type': 'int', 'value': 0}, {'args': ['b'], 'dest': 'v19', 'op': 'id', 'type': 'int'}, {'args': ['v18', 'v19'], 'dest': 'v20', 'op': 'sub', 'type': 'int'}, {'args': ['s'], 'dest': 'v21', 'op': 'id', 'type': 'int'}, {'args': ['v21'], 'dest': 'v22', 'funcs': ['sqrt'], 'op': 'call', 'type': 'int'}, {'args': ['v20', 'v22'], 'dest': 'v23', 'op': 'sub', 'type': 'int'}, {'args': ['v23'], 'dest': 'r2', 'op': 'id', 'type': 'int'}, {'args': ['r1'], 'dest': 'v24', 'op': 'id', 'type': 'int'}, {'args': ['d'], 'dest': 'v25', 'op': 'id', 'type': 'int'}, {'args': ['v24', 'v25'], 'dest': 'v26', 'op': 'div', 'type': 'int'}, {'args': ['v26'], 'op': 'print'}, {'dest': 'v27', 'op': 'const', 'type': 'int', 'value': 0}, {'args': ['r2'], 'dest': 'v28', 'op': 'id', 'type': 'int'}, {'args': ['d'], 'dest': 'v29', 'op': 'id', 'type': 'int'}, {'args': ['v28', 'v29'], 'dest': 'v30', 'op': 'div', 'type': 'int'}, {'args': ['v30'], 'op': 'print'}, {'dest': 'v31', 'op': 'const', 'type': 'int', 'value': 0}]\n ID: .start\n Predecessors: set()\n Successors: set()\n\n\nblock_id:  .start\nin_edges:  {}\nout_edges:  {'v0': ['.start_0'], 'v1': ['.start_1'], 'v2': ['.start_2'], 'v3': ['.start_3'], 'v4': ['.start_4'], 'v5': ['.start_5'], 'v6': ['.start_6'], 'v7': ['.start_7'], 'v8': ['.start_8'], 's': ['.start_9'], 'v9': ['.start_10'], 'v10': ['.start_11'], 'v11': ['.start_12'], 'd': ['.start_13'], 'v12': ['.start_14'], 'v13': ['.start_15'], 'v14': ['.start_16'], 'v15': ['.start_17'], 'v16': ['.start_18'], 'v17': ['.start_19'], 'r1': ['.start_20'], 'v18': ['.start_21'], 'v19': ['.start_22'], 'v20': ['.start_23'], 'v21': ['.start_24'], 'v22': ['.start_25'], 'v23': ['.start_26'], 'r2': ['.start_27'], 'v24': ['.start_28'], 'v25': ['.start_29'], 'v26': ['.start_30'], 'v27': ['.start_32'], 'v28': ['.start_33'], 'v29': ['.start_34'], 'v30': ['.start_35'], 'v31': ['.start_37']}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Michael",
      "EECE7309 Homework 3 -- Data Flow"
    ]
  },
  {
    "objectID": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html",
    "href": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html",
    "title": "Homework5 - LLVM",
    "section": "",
    "text": "link for the implementation: llvm-pass-allocsize",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework5 - LLVM"
    ]
  },
  {
    "objectID": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework5 - LLVM",
    "section": "Explanation of the code",
    "text": "Explanation of the code\nFor this homework, I tried to implement AllocSizePass which is an LLVM pass that identifies alloca instructions within a function (representing stack allocations) and inserts a runtime printf statement after each allocation. This printf call outputs the size of each allocation in bytes, allowing users to observe the memory usage of each stack allocation during program execution. The pass traverses each function in the LLVM module, calculating the size of each allocation based on the data layout, then injects instrumentation code to print these sizes.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework5 - LLVM"
    ]
  },
  {
    "objectID": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html#how-it-is-tested",
    "href": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html#how-it-is-tested",
    "title": "Homework5 - LLVM",
    "section": "How It Is Tested",
    "text": "How It Is Tested\nThe pass was tested by:\n\nCompiling a C Program: A C program with multiple allocations was compiled with the pass plugin enabled, which allowed the pass to analyze and instrument the code.\nRuntime Execution: After compilation, the generated binary was executed. The output was inspected for runtime printf statements that reported the size of each allocation. This confirmed that the pass inserted the necessary instrumentation and altered the program’s runtime behavior as expected. The expected output included Allocation size: X bytes statements printed for each allocation, verifying that the pass correctly identified and instrumented allocations.\n\n#include &lt;stdio.h&gt;\n\nint calculate(int a, int b) {\n    int result;\n    if (a &gt; b) {\n        result = a - b;\n    } else {\n        result = a + b;\n    }\n    return result;\n}\n\nint main() {\n    int x[10];\n    int sum = 0;\n\n    for (int i = 0; i &lt; 10; i++) {\n        x[i] = i * 2;\n        sum += x[i];\n    }\n\n    int result1 = calculate(sum, 15);\n    int result2 = calculate(sum, 25);\n\n    printf(\"Result 1: %d\\n\", result1);\n    printf(\"Result 2: %d\\n\", result2);\n\n    return 0;\n}\nOutput:\nclang -fpass-plugin=build/alloc_size_pass.dylib test.c -o test_alloc_out \nFunction: calculate\n  Basic Block: %2\n    Allocation of type i32 with size: 4 bytes\n    Allocation of type i32 with size: 4 bytes\n    Allocation of type i32 with size: 4 bytes\n  Basic Block: %9\n  Basic Block: %13\n  Basic Block: %17\nFunction: main\n  Basic Block: %0\n    Allocation of type i32 with size: 4 bytes\n    Allocation of type [10 x i32] with size: 40 bytes\n    Allocation of type i32 with size: 4 bytes\n    Allocation of type i32 with size: 4 bytes\n    Allocation of type i32 with size: 4 bytes\n    Allocation of type i32 with size: 4 bytes\n  Basic Block: %7\n  Basic Block: %10\n  Basic Block: %22\n  Basic Block: %25\nFunction: printf\n./test_alloc_out \nAllocation size: 4 bytes\nAllocation size: 40 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nAllocation size: 4 bytes\nResult 1: 75\nResult 2: 65",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework5 - LLVM"
    ]
  },
  {
    "objectID": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html#what-was-challenging-during-implementation",
    "href": "blogs/Sana/11-1-2024-HW5-SanaTaghipourAnvari.html#what-was-challenging-during-implementation",
    "title": "Homework5 - LLVM",
    "section": "What Was Challenging During Implementation",
    "text": "What Was Challenging During Implementation\nAdding a printf call required defining printf in the LLVM IR, creating or referencing a global format string, and ensuring correct argument types. Missteps in the function type, format string handling, or argument casting could lead to compilation or runtime errors. Solution: I used getOrInsertFunction to declare printf, which ensured that the function was only added if it didn’t already exist. To handle arguments, I used IRBuilder for consistent type casting and format string handling, carefully matching printf’s arguments in LLVM IR.\nThis project specifically targets alloca instructions, if we want the pass to also detect other types of allocations, we should probably identify calls to other available allocation instructions as well for this to become a comprehensive project.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework5 - LLVM"
    ]
  },
  {
    "objectID": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html",
    "href": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html",
    "title": "Homework4 - dominance",
    "section": "",
    "text": "Link for the code: cfgdominance",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework4 - dominance"
    ]
  },
  {
    "objectID": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework4 - dominance",
    "section": "Explanation of the code",
    "text": "Explanation of the code\nThis implementation performs dominator analysis on a control flow graph (CFG). It includes several key functions:\n\nbuild_cfg: Constructs a Control Flow Graph from a given function’s instructions.\ncompute_dominators: Calculates the set of dominators for each node in the CFG.\nbuild_dominator_tree: Constructs the dominator tree by finding the immediate dominator for each node.\ncompute_dominance_frontier: Computes the dominance frontier for each node in the CFG.\ntest_dominance: Verifies the correctness of the computed dominators.\n\nThe main function reads a JSON input file containing function definitions, applies these analyses to each function, and outputs the results. Input:\nmain {\n  entry:\n    x: int = const 0;\n    jmp L1;\n\n  L1:\n    y: int = const 1;\n    br y L2 L3;\n\n  L2:\n    z: int = add x y;\n    jmp L4;\n\n  L3:\n    w: int = sub x y;\n    jmp L4;\n\n  L4:\n    ret z;\n}\nControl Flow Graph:\n          [ Block 0 (Entry) ]\n                   |\n                   v\n             [ Block 1 (L1) ]\n              /             \\\n             v               v\n    [ Block 2 (L2) ]     [ Block 3 (L3) ]\n             \\               /\n              \\             /\n               v           v\n             [ Block 4 (L4) ]\n                   |\n                [ Exit ]\n\nimport json\nfrom collections import defaultdict\n\ndef build_cfg(func):\n    cfg = defaultdict(list)\n    blocks = []\n    current_block = []\n    label_to_block = {}\n\n    for instr in func['instrs']:\n        if isinstance(instr, dict) and 'label' in instr:\n            if current_block:\n                blocks.append(current_block)\n            current_block = [instr]\n            label_to_block[instr['label']] = len(blocks)\n        else:\n            current_block.append(instr)\n\n        if isinstance(instr, dict) and instr.get('op') in ['jmp', 'br']:\n            blocks.append(current_block)\n            current_block = []\n\n    if current_block:\n        blocks.append(current_block)\n\n    for i, block in enumerate(blocks):\n        last_instr = block[-1]\n        if isinstance(last_instr, dict):\n            if last_instr.get('op') in ['jmp', 'br']:\n                for label in last_instr['labels']:\n                    if label in label_to_block:\n                        cfg[i].append(label_to_block[label])\n            elif last_instr.get('op') != 'ret' and i + 1 &lt; len(blocks):\n                cfg[i].append(i + 1)\n        cfg[i] \n\n    return cfg\n\ndef compute_dominators(cfg):\n    entry = 0\n    all_nodes = set(cfg.keys())\n    dom = {node: all_nodes.copy() for node in all_nodes}\n    dom[entry] = {entry}\n\n    changed = True\n    while changed:\n        changed = False\n        for node in cfg:\n            predecessors = get_predecessors(cfg, node)\n            if predecessors:\n                new_dom = set.intersection(*(dom[pred] for pred in predecessors))\n                new_dom.add(node)\n            else:\n                new_dom = {node}\n            if new_dom != dom[node]:\n                dom[node] = new_dom\n                changed = True\n\n    return dom\n\ndef get_predecessors(cfg, node):\n    return [pred for pred, succs in cfg.items() if node in succs]\n\ndef build_dominator_tree(dom):\n    idom = {}\n    for node in dom:\n        if node == 0:  \n            idom[node] = None\n        else:\n            # Sort dominators by the size of their dominator sets in descending order\n            sorted_doms = sorted(dom[node] - {node}, key=lambda x: len(dom[x]), reverse=True)\n            idom[node] = next(d for d in sorted_doms if d != node)\n    return idom\n\ndef compute_dominance_frontier(cfg, dom):\n    df = defaultdict(set)\n    for node in cfg:\n        for succ in cfg[node]:\n            runner = node\n            while runner not in dom[succ]:\n                df[runner].add(succ)\n                runner = next(d for d in sorted(dom[runner] - {runner}) if d != runner)\n    return df\n\ndef test_dominance(cfg, dom):\n    entry = 0\n    for node in cfg:\n        if node == entry:\n            continue\n        for d in dom[node] - {node}:\n            if d == entry:\n                continue\n            #Temporarily remove dominator d from the CFG\n            modified_cfg = remove_node_from_cfg(cfg, d)\n            # Check if node is still reachable from entry\n            if is_reachable(modified_cfg, entry, node):\n                #if node is still reachable without d, then d does not dominate node\n                return False\n    return True\n\n\ndef remove_node_from_cfg(cfg, node_to_remove):\n    modified_cfg = {node: succs.copy() for node, succs in cfg.items() if node != node_to_remove}\n    for succs in modified_cfg.values():\n        if node_to_remove in succs:\n            succs.remove(node_to_remove)\n    return modified_cfg\n\ndef is_reachable(cfg, start, target):\n    visited = set()\n    stack = [start]\n    while stack:\n        node = stack.pop()\n        if node == target:\n            return True\n        if node not in visited:\n            visited.add(node)\n            successors = cfg.get(node, [])\n            stack.extend(successors)\n    return False\n\n\ndef main(json_input):\n    data = json.loads(json_input)\n\n    for func in data['functions']:\n        print(f\"Function: {func['name']}\")\n\n        cfg = build_cfg(func)\n        print(\"\\nControl Flow Graph:\")\n        print(json.dumps(cfg, indent=2))\n\n        dom = compute_dominators(cfg)\n        print(\"\\nDominators:\")\n        print(json.dumps({k: sorted(list(v)) for k, v in dom.items()}, indent=2))\n\n        idom = build_dominator_tree(dom)\n        print(\"\\nImmediate Dominators (Dominator Tree):\")\n        print(json.dumps(idom, indent=2))\n\n        df = compute_dominance_frontier(cfg, dom)\n        print(\"\\nDominance Frontier:\")\n        print(json.dumps({k: sorted(list(v)) for k, v in df.items()}, indent=2))\n\n        test_result = test_dominance(cfg, dom)\n        print(\"\\nDominance Test Result:\")\n        print(test_result)\n\nif __name__ == \"__main__\":\n    input_json = '''\n    {\n      \"functions\": [\n        {\n          \"name\": \"main\",\n          \"instrs\": [\n            { \"label\": \"entry\" },\n            { \"op\": \"const\", \"dest\": \"x\", \"type\": \"int\", \"value\": 0 },\n            { \"op\": \"jmp\", \"labels\": [\"L1\"] },\n            \n            { \"label\": \"L1\" },\n            { \"op\": \"const\", \"dest\": \"y\", \"type\": \"int\", \"value\": 1 },\n            { \"op\": \"br\", \"args\": [\"y\"], \"labels\": [\"L2\", \"L3\"] },\n\n            { \"label\": \"L2\" },\n            { \"op\": \"add\", \"args\": [\"x\", \"y\"], \"dest\": \"z\", \"type\": \"int\" },\n            { \"op\": \"jmp\", \"labels\": [\"L4\"] },\n\n            { \"label\": \"L3\" },\n            { \"op\": \"sub\", \"args\": [\"x\", \"y\"], \"dest\": \"w\", \"type\": \"int\" },\n            { \"op\": \"jmp\", \"labels\": [\"L4\"] },\n\n            { \"label\": \"L4\" },\n            { \"op\": \"ret\", \"args\": [\"z\"] }\n          ]\n        }\n      ]\n    }\n    '''\n    main(input_json)\n\nFunction: main\n\nControl Flow Graph:\n{\n  \"0\": [\n    1\n  ],\n  \"1\": [\n    2,\n    3\n  ],\n  \"2\": [\n    4\n  ],\n  \"3\": [\n    4\n  ],\n  \"4\": []\n}\n\nDominators:\n{\n  \"0\": [\n    0\n  ],\n  \"1\": [\n    0,\n    1\n  ],\n  \"2\": [\n    0,\n    1,\n    2\n  ],\n  \"3\": [\n    0,\n    1,\n    3\n  ],\n  \"4\": [\n    0,\n    1,\n    4\n  ]\n}\n\nImmediate Dominators (Dominator Tree):\n{\n  \"0\": null,\n  \"1\": 0,\n  \"2\": 1,\n  \"3\": 1,\n  \"4\": 1\n}\n\nDominance Frontier:\n{\n  \"2\": [\n    4\n  ],\n  \"3\": [\n    4\n  ]\n}\n\nDominance Test Result:\nTrue",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework4 - dominance"
    ]
  },
  {
    "objectID": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html#how-we-testing-our-implementation",
    "href": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html#how-we-testing-our-implementation",
    "title": "Homework4 - dominance",
    "section": "How we testing our implementation",
    "text": "How we testing our implementation\nThe test_dominance function verifies the correctness of the computed dominators. It does this by:\n\nIt iterates through all nodes in the CFG except the entry node.\nFor each node, it considers all of its computed dominators (excluding the node itself and the entry node).\nFor each dominator, it temporarily removes that node from the CFG using the remove_node_from_cfg function.\nIt then checks if the original node is still reachable from the entry node in this modified CFG using the is_reachable function.\nIf the node is still reachable after removing a supposed dominator, it means that dominator wasn’t actually necessary to reach the node, so the test fails.\nIf all nodes pass this test for all their dominators, the function returns True. Also, in the code directory I tested this code with two different inputs and both passed the test function.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework4 - dominance"
    ]
  },
  {
    "objectID": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html#hardest-part-of-the-task-and-how-we-addressed-it",
    "href": "blogs/Sana/10-18-2024-HW4-SanaTaghipourAnvari.html#hardest-part-of-the-task-and-how-we-addressed-it",
    "title": "Homework4 - dominance",
    "section": "Hardest Part of the Task and How We Addressed It",
    "text": "Hardest Part of the Task and How We Addressed It\nThe hardest part of this task was likely the correct implementation of the dominator tree construction, specifically in the build_dominator_tree function. This is challenging because:\n\nIt requires finding the immediate dominator for each node, which is the closest strict dominator in the dominator graph.\nThe naive approach of simply choosing any dominator can lead to incorrect results in complex control flow structures.\n\nWe addressed this challenge by:\n\nSorting the dominators of each node based on the size of their own dominator sets, in descending order.\nThis sorting ensures that we consider closer dominators first, as nodes closer in the dominator tree will have larger dominator sets.\nWe then select the first dominator from this sorted list (excluding the node itself) as the immediate dominator.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sana",
      "Homework4 - dominance"
    ]
  },
  {
    "objectID": "blogs/aymane/readme5.html",
    "href": "blogs/aymane/readme5.html",
    "title": "Homework 5 – Implementing a simple LLVM pass",
    "section": "",
    "text": "For this assignment, I implemented an LLVM pass to count the number of instructions in each basic block of all functions in a module.\nstruct InstrCountPass : public PassInfoMixin&lt;InstrCountPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n            // print the name of each function it the module\n            errs() &lt;&lt; \"Function: \" &lt;&lt; F.getName() &lt;&lt; \"\\n\";\n            for (auto &BB : F) {\n                // print the name of the basic block\n                errs() &lt;&lt; \"  Basic Block: \";\n                BB.printAsOperand(errs(), false);\n\n\n                // Count and print the number of instructions in the basic block\n                int InstrCount = 0;\n                for (auto &I : BB) {\n                    InstrCount++;\n                }\n                errs() &lt;&lt; \"    Number of instructions: \" &lt;&lt; InstrCount &lt;&lt; \"\\n\";\n            }\n        }\n        return PreservedAnalyses::all();\n    }\n};\nAfter compiling the pass and running it, we can see all function names in the module, as well as all the blocks along with the number of instructions per block.\n$ clang -fpass-plugin=/home/eljeraria/compilers/instr_count_pass/build/instr_pass/InstrCountPass.so vec_add.c\nFunction: vec_add\n  Basic Block: %0    Number of instructions: 24\n  Basic Block: %18    Number of instructions: 4\n  Basic Block: %22    Number of instructions: 9\n  Basic Block: %29    Number of instructions: 4\n  Basic Block: %32    Number of instructions: 2\n  Basic Block: %33    Number of instructions: 4\n  Basic Block: %37    Number of instructions: 14\n  Basic Block: %50    Number of instructions: 4\n  Basic Block: %53    Number of instructions: 3\nFunction: llvm.stacksave.p0\nFunction: llvm.stackrestore.p0\nFunction: main\n  Basic Block: %0    Number of instructions: 4\nMy first attempt was to write a loop unrolling pass and compare the performance improvement of different unrolling factors. Unfortunately, I was not able to implement the pass successfully.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 5 -- Implementing a simple LLVM pass"
    ]
  },
  {
    "objectID": "blogs/aymane/readme3.html",
    "href": "blogs/aymane/readme3.html",
    "title": "Homework 3 – Implementing Liveness Dataflow Analysis",
    "section": "",
    "text": "In order to perform data flow analysis on a bril program, we need to perform certain preprocessing operations to create a control flow graph. Once the control flow graph is built, we need to run the iterative worklist algorithm to solve the dataflow analysis. For this assignment, I used certain functions from the bril repository to faciliate the generation of the block mapping. I focused on implementing the Liveness data flow analysis.\nKey Components of the DFA Program for this assignment are:\n\nGetting the successors of each block\n    def get_successors(self, block):\n        # last instr in block\n        instr = block[-1]\n        # get successors\n        if instr['op'] in ['jmp', 'br']:\n            return instr['labels']\n        # no successor\n        elif instr['op'] == 'ret':\n            return []\n        else: \n            return\nThis function determines the successors of a block (basic block of instructions). It does so based on the last instruction in a block, if it’s a jmp or br (branch) operation, the function returns the successors (.ie next block in the control flow graph (cfg)). If it’s a ret (return), there are no successors.\n\n\nGenerating the graph\n    def generate_graph(self, blocks):\n        # init all to empty lists\n        self.predecessors = {blk_id: [] for blk_id in blocks}\n        self.successors = {blk_id: [] for blk_id in blocks}\n        for name, block in blocks.items():\n            # get all succcessors\n            successors = self.get_successors(block)\n            self.successors[name].extend(successors) \n            \n            # make current block predecessors to all its successors\n            for s in successors:\n                self.predecessors[s].append(name)\nThis function builds the cfg for the program. It initializes empty lists for the predecessors and successors of each block. For each block, it determines the block’s successors and makes the current block a predecessor to all of its successors. This forms the graph that the DFA algorithm will traverse.\n    def analyze_dataflow(self, blocks):\n        # generate successors and predecessors for every block\n        self.generate_graph(blocks)\n\n        # start from the last block\n        blk_start = list(blocks.keys())[-1]\n        in_set = self.successors\n        out_set = self.predecessors\n\n        # init first block\n        self.in_set = {blk_start: set()}\n        self.out_set = {blk: set() for blk in blocks}\n\n        # iterative worklist dataflow algorithm\n        worklist = list(blocks.keys())\n        while worklist:\n            blk = worklist.pop(0)\n\n            # in values = merge all previous value \n            in_val = self.union_op(self.out_set[n] for n in in_set[blk])\n            self.in_set[blk] = in_val\n            \n            # out values generated using the transfer function\n            out_val = self.transfer_func(blocks[blk], in_val)\n\n            # if there was a change\n            if out_val != self.out_set[blk]:\n                # update\n                self.out_set[blk] = out_val\n                # add item to the workloist\n                worklist += out_set[blk]\n\n        return self.out_set, self.in_set\nThis is the function that conducts the data flow analysis by iterating over the control flow graph. Since liveness is a backwards algorithm, we start from the last block. The function uses the worklist algorithm to iteratively merge information using the transfer function.\nThe transfer function for liveness is\n\\[IN = GEN \\space \\cup \\space (OUT - KILL)\\]\nThe bril repository contains programs on which to perform data flow analysis. Let’s look at the cond.bril program:\n@main {\n  a: int = const 47;\n  b: int = const 42;\n  cond: bool = const true;\n  br cond .left .right;\n.left:\n  b: int = const 1;\n  c: int = const 5;\n  jmp .end;\n.right:\n  a: int = const 2;\n  c: int = const 10;\n  jmp .end;\n.end:\n  d: int = sub a c;\n  print d;\n}\nWithout performing any data flow analysis, we can, just by looking at this program, know that the only variables that reach a use are a and c when executing this instruction: d: int = sub a c. On the other hand, we expect not to see b in the liveness data flow analysis, since not instruction uses b as an argument. Below is the output for the livenes pass:\n$ bril2json &lt; cond.bril | python3 dfa.py\nb1:\n  in:  ∅\n  out: a\nleft:\n  in:  a\n  out: a, c\nright:\n  in:  ∅\n  out: a, c\nend:\n  in:  a, c\n  out: ∅\nI started the assignment by attempting to implement a generic approach, but it turned out to be more challenging than I expected. Eventually, I focused on implementing dataflow analysis specifically for liveness. The complexity mainly came from trying to create a modular worklist algorithm that could be parametrized with different inputs, such as the merge operation, transfer function, and whether the analysis is forward or backward.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 3 -- Implementing Liveness Dataflow Analysis"
    ]
  },
  {
    "objectID": "blogs/aymane/readme2.html",
    "href": "blogs/aymane/readme2.html",
    "title": "Homework 2 – Implementing DCE and LVN",
    "section": "",
    "text": "This assignment assumes that the input program is a single block. Multi block programs might not work as intended. Parsing the program into multiple blocks is handled by the helper functions inside cfg.py.\n\nPart 1: implementing trivial deadcode elimination\nI begin by setting up a class to perform dead code elimination, the class takes as input the program, and parses it before begining to perform the dce optimization. The block_dce() function performs the heavy lifting. Despite the fact that my implementation only works for a single block, I’ve tried to modularize the code such that a multi block implementation is easier.\n# perform deadcode elimination on a single block\ndef block_dce(self, block):\n    for instr in block:\n        if \"args\" not in instr.keys():\n            continue\n        self.used.update(instr[\"args\"])\n    \n    for i in range(len(block)-1, -1, -1):\n        if \"dest\" in block[i].keys() and block[i][\"dest\"] not in self.used:\n            rm_instr = block.pop(i)\n            # print(f\"Instruction removed:\\n {rm_instr}. Destination {rm_instr[\"dest\"]} was not used\")   \n    return block\nThe function loops over all instructions in the block adding only the instructions that have arguments to a set. This is done to keep track of all arguments that are used in the block. The second pass, loops over all instrucitons backwards.\nIf an instruction has a destination variable that doesn’t exists in the set of used variables we know that it is a dead instruction, therefore we can delete it.\nLet’s look at an example typescript program:\nlet x = 5n;  \nlet y = 13n;\n\nlet a = x + y;\nlet b = x + y;\nlet c = a * 2n;     # c is not used\nlet d = b * 2n;     \n\nlet e = a + 15n;    # e is not used\nlet f = d - b;\nlet g = f + 1n;     # g is not used\n\nconsole.log(f);\nWe should be able to eliminate 3 instructions.\nprogram.bril: text representation. program_j.bril: json representation. program.bril_dce: json representation with the dce pass.\nWe want to compare the number of instructions between program_j.bril and program.bril_dce and make sure the outputs are the same.\n$ wc program_j.bril && brili &lt; program_j.bril\n     280     421    4942 program_j.bril\n18\n$ wc program.bril_dce && brili &lt; program.bril_dce\n     249     375    6781 program.bril_dce\n18\nWe notice a reduction in the number of lines from 280, down to 249. Most of this reduction is a direct result of the json format returning to a new line after every entry. So most lines only contain a bracket, or a comma. The output (18) is the same for both programs.\n\n\nPart 2: implementing local value numbering\nMy lvn implementation involves two main functions: vn_gen() to generate the value number, and lvn() which performs the lvn pass.\nThe vn_gen() function returns the value number of a variable. If the variable doesn’t exist, we add it to the table, and increment the value number for the next variable.\n    def vn_gen(self, var):\n        if var not in self.vn2var.keys():\n            self.vn2var[var] = self.vn\n            self.vn += 1\n        return self.vn2var[var] \n    \n    def lvn(self, block):\n        for instr in block:\n            if \"dest\" in instr.keys():\n                if \"args\" in instr.keys():\n                    values = [self.vn_gen(arg) for arg in instr[\"args\"]]\n                    hash_entry = (instr[\"op\"], *values)\n                    canonical_var = instr[\"dest\"]\n                else:   \n                    val = instr[\"value\"]\n                    values = [self.vn_gen(instr[\"dest\"])]\n                    hash_entry = (instr[\"op\"], val)\n                    canonical_var = instr[\"dest\"]\n                \n                if hash_entry in self.hash_table.keys():\n                    vn = self.hash_table[hash_entry][\"vn\"]\n                    canonical_var = self.hash_table[hash_entry][\"canncl_var\"]\n                    self.vn2var[instr[\"dest\"]] = vn\n                    instr[\"dest\"] = canonical_var\n                \n                else:\n                    new_vn = self.vn_gen(instr[\"dest\"])\n                    self.hash_table[hash_entry] = {\"vn\": new_vn, \"canncl_var\": canonical_var}\n            else:\n                continue\n        return block\nThe lvn() function loops over all instructions in a block. If an instruction doesn’t contain a destination, we skip it. Otherwise, we check if the instruction contains arguments, if so, we calculate the value numebers of all arguments, and create the hash entry using those value numbers. If the instruction doesn’t contain arguments, then we only need to compute the value number of the destination variable, and use it to generate a hash entry.\nFinally, we need to check if the hash entry already exists in the table. If so, we update the structs to avoid recomputing the same value.\nIn the program below, the sum2 operation is redundant. Let’s see how the lvn algorithm modifices the code:\n@main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}\nRuning the lvn pass we notice that the sum2 instruction was rewritten in terms of sum1\npython3 lvn.py test.bril && bril2txt &lt; test.bril_lvn\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  sum1: int = add a b;\n  sum2: int = const sum1;\n  prod: int = mul sum1 sum2;\n  print prod;\n}\n\nValue Number Table\n{'a': 1, 'b': 2, 'sum1': 3, 'sum2': 3, 'prod': 4}\nHash Table:\n{('const', 4): {'vn': 1, 'canncl_var': 'a'}, ('const', 2): {'vn': 2, 'canncl_var': 'b'}, ('add', 1, 2): {'vn': 3, 'canncl_var': 'sum1'}, ('mul', 3, 3): {'vn': 4, 'canncl_var': 'prod'}}\n\n\nThings I found challenging\nHandling the formatting of the input and output to each command was a little tricky. It’s sometimes confusing trying to keep track of which format is being used at a specific instance when piping different commands into each other.\nFor example, it seems like the brili interpreter can not read a program from stdin, instead the filename has to be provided as input brili &lt; {filename}. This makes it difficult to pipe programs into brili, which requires running bril2txt and bril2json commands manually to guarantee correct execution.\nTo make things simple for next time, I will make sure that all programs I write accept input from stdin, and output to stdout.\nCode can be found here\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Aymane",
      "Homework 2 -- Implementing DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/junk.html",
    "href": "blogs/junk.html",
    "title": "sample blog",
    "section": "",
    "text": "this is a sample blog!\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "sample blog"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-10-11-HW3-Kellner.html",
    "href": "blogs/oscar/2024-10-11-HW3-Kellner.html",
    "title": "HW3 - Data Flow Analysis",
    "section": "",
    "text": "In this assignment, we model a dataflow framework to allow analysus for Bril programs in Lua through utilization of a control flow graph (CFG), which we also write a program to construct for us. A control flow graph represents all the possible paths that a program may take during execution in graph notation, delimited in blocks. Thus, we also use the gen_blocks program we had rewritten in the previous assignment.\nUsing the provided examples for direction, we first verify the correctness of the generated CFG by generating a GraphViz file and comparing with the same output that the example provides. Then, we attempt to implement a framework for dataflow analysis, allowing a user-defined analysis to work with the CFG we generated.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW3 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-10-11-HW3-Kellner.html#overview",
    "href": "blogs/oscar/2024-10-11-HW3-Kellner.html#overview",
    "title": "HW3 - Data Flow Analysis",
    "section": "",
    "text": "In this assignment, we model a dataflow framework to allow analysus for Bril programs in Lua through utilization of a control flow graph (CFG), which we also write a program to construct for us. A control flow graph represents all the possible paths that a program may take during execution in graph notation, delimited in blocks. Thus, we also use the gen_blocks program we had rewritten in the previous assignment.\nUsing the provided examples for direction, we first verify the correctness of the generated CFG by generating a GraphViz file and comparing with the same output that the example provides. Then, we attempt to implement a framework for dataflow analysis, allowing a user-defined analysis to work with the CFG we generated.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW3 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-10-11-HW3-Kellner.html#part-1-control-flow-graph",
    "href": "blogs/oscar/2024-10-11-HW3-Kellner.html#part-1-control-flow-graph",
    "title": "HW3 - Data Flow Analysis",
    "section": "Part 1: Control Flow Graph",
    "text": "Part 1: Control Flow Graph\nOne challenge of working with Lua is that, as powerful and versatile tables are (essentially being an analogue of Python’s dictionaries, or hash tables), are that there appears to be no standard implementation for other common data types such as sets, arrays, and so on. A lot of boilerplate must be written to emulate the same functionality that Python allows natively or within their standard library. One of these data structures is the OrderedDict, which keeps the order of key-value pairs stored in the order in which they were added. Lua does not keep a consistent order in its key-value pairs, so without any kind of ordering, the CFG will not maintain its order as its being created and it causes the graph to be formed incorrectly. We fix this by keeping an extra table specifically to keep track of the order in which blocks are added, which must be passed around alongside the block list across functions.\nWe write cfg_dot.lua to generate GraphViz files to represent bril programs in CFG form to test our implementation. A small shell script generates an PNG of the CFG for all functions that was stored in the GraphViz file. The CFG for the merge sort program is included, which includes a decent amount of control flow to demonstrate the CFG program.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW3 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/oscar/2024-10-11-HW3-Kellner.html#part-2-analysis-tool",
    "href": "blogs/oscar/2024-10-11-HW3-Kellner.html#part-2-analysis-tool",
    "title": "HW3 - Data Flow Analysis",
    "section": "Part 2: Analysis Tool",
    "text": "Part 2: Analysis Tool\nThe analysis tool, dataflow.lua and dataflow_run.lua, provides a small framework in which a user defined analysis can be run on an existing CFG for a bril program that is generated through use of the cfg.lua module created in part 1. A couple of boilerplate utility functions were implemented to allow for set operations. To allow for easier testing against the existing implementation, the output was carefully formatted to recreate that which the .out test files appear.\nOne of the issues encountered when debugging is that the program would loop indefinitely within the df_worklist function. It was resolved when a list of visited blocks was kept up to date, however it was remained to be seen whether it ended up affecting the correctness of the program.\nUnfortunately the output does not exactly match that of the provided example. Small errors appear in mismatching between the liveness of variables, particularly at the starts and ends of programs or functions. A small modification of the example turnt file allowed for comparison between the given and expected output.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Oscar",
      "HW3 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-10-17-Rohit-HW3.html",
    "href": "blogs/rohit/2024-10-17-Rohit-HW3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Definition: Data Flow Analysis (DFA) is a technique used in compiler optimization to analyze how values flow through program variables during execution.\n\nThe code should remove the instructions that are reassigned without being used.\nIf the value in being used in between the reassigning, then the instruction should be retained.\n\n\n\n\n\n\nFlows in direction of program execution\nPropagates information about variable definitions forward\nInitial state flows from start to end\n\n\n\n\n\nInformation flows from top to bottom\nComputes expressions already evaluated at each point\nPropagates forward through control flow graph\n\n\n\n\n\n\n\n\nInformation flows opposite to program execution\nStarts from variable uses and works backwards\nDetermines if variable value will be needed later\n\n\n\n\n\nFlows from bottom to top\nWorks backwards from expression uses\nDetermines what will definitely be computed later\n\n\n\n\n\n\nForward analyses use information from predecessor nodes\nBackward analyses use information from successor nodes\nDirection affects how we iterate through the control flow graph\nInitialization points differ (entry vs exit nodes)\n\n\n\n\n\n\n\n\nImport necessary modules (sys, json, etc.)\nDefine Analysis named tuple with attributes: forward, init, merge, transfer\n\n\n\n\n\nDefine union function: Merge multiple sets into one\nDefine intersection function: Find common elements among sets\n\n\n\n\n\nDetermine edges based on analysis direction (forward/backward)\nInitialize in_ and out sets for each block\nAdd all blocks to worklist\nWhile worklist is not empty:\n\nPop a block, calculate in_ value by merging predecessor/successor out values\nUpdate out value using transfer function\nIf out value changes, re-add successors/predecessors to worklist\n\n\n\n\n\n\nFormat sets and dictionaries into readable strings\n\n\n\n\n\nFor each function in the BRIL program:\n\nConvert instructions into blocks\nAdd terminators to blocks\nExecute worklist algorithm\nPrint in_ and out values for each block\n\n\n\n\n\n\nDefine functions to generate and kill variables/expressions for different analyses (liveness, reaching defs, very busy expressions, available expressions)\n\n\n\n\n\nDefine attributes and transfer functions for each analysis type (LIVENESS, VERYBUSY, REACHING, AVAILABLE)\n\n\n\n\n\nLoad BRIL program from input\nRun the specified data flow analysis\n\nFull code: https://github.com/gurusamyanandakuma-r/bril/blob/main/HW/HW3_Rohit/dfa.py\n\n\n\n\n\n\n```{turnt.toml} [envs.LIVENESS] command = “bril2json &lt; {filename} | python3 dfa.py LIVENESS” output.”LIVENESS.out” = “-”\n[envs.VERYBUSY]\ncommand = \"bril2json &lt; {filename} | python3 dfa.py VERYBUSY\"\noutput.\"VERYBUSY.out\" = \"-\"\n\n[envs.REACHING]\ncommand = \"bril2json &lt; {filename} | python3 dfa.py REACHING\"\noutput.\"REACHING.out\" = \"-\"\n\n[envs.AVAILABLE]\ncommand = \"bril2json &lt; {filename} | python3 dfa.py AVAILABLE\"\noutput.\"AVAILABLE.out\" = \"-\"\n#### Example 1: Without branches (one block code)\n##### Input bril:\n\n\n\n\n\n\n```{bril}\n    @main {\n\n        divisor: int = const 7;\n        divident: int = const 42;\n        quotient: int = div divident divisor;\n        product: int = mul quotient divisor;\n        remainder: int = sub divident product;  \n\n        print remainder; \n\n    }\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  ('div', ('divident', 'divisor')), ('mul', ('quotient', 'divisor')), ('sub', ('divident', 'product'))\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: ('divident', 'BLOCK1'), ('divisor', 'BLOCK1'), ('product', 'BLOCK1'), ('quotient', 'BLOCK1'), ('remainder', 'BLOCK1')\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: ('div', ('divident', 'divisor')), ('mul', ('quotient', 'divisor')), ('sub', ('divident', 'product'))\n\n\n\n\n\n\n    @main {\n    x: int = const 3;\n    y: int = const 4;\n    \n    .header:\n        cond: bool = lt x y;   # Check if x &lt; y\n        br cond .then .else;   # Branch based on condition\n\n    .then:\n        result: int = add x y;  # result = x + y\n        jmp .end;\n\n    .else:\n        result: int = sub x y;  # result = x - y\n        jmp .end;\n\n    .end:\n        print result;           # Print the result\n    }\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: x, y\n    header:\n        IN:  x, y\n        OUT: x, y\n    then:\n        IN:  x, y\n        OUT: result\n    else:\n        IN:  x, y\n        OUT: result\n    end:\n        IN:  result\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('lt', ('x', 'y'))\n    header:\n        IN:  ('lt', ('x', 'y'))\n        OUT: NULL\n    then:\n        IN:  ('add', ('x', 'y'))\n        OUT: NULL\n    else:\n        IN:  ('sub', ('x', 'y'))\n        OUT: NULL\n    end:\n        IN:  NULL\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    header:\n        IN:  ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    then:\n        IN:  ('cond', 'header'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('result', 'then'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    else:\n        IN:  ('cond', 'header'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('result', 'else'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    end:\n        IN:  ('cond', 'header'), ('result', 'else'), ('result', 'then'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('result', 'else'), ('result', 'then'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: NULL\n    header:\n        IN:  NULL\n        OUT: ('lt', ('x', 'y'))\n    then:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('add', ('x', 'y')), ('lt', ('x', 'y'))\n    else:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('lt', ('x', 'y')), ('sub', ('x', 'y'))\n    end:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('lt', ('x', 'y'))\n\n\n\n\n\n\nBalancing the forward and backward data flow analysis while managing the worklist efficiently wass tough. Each direction affects the edges and node values differently, which can lead to complicated logic.\n\n\n\n\nDeveloped code that handles liveness, availability, reaching definitions, and very busy expressions using a worklist algorithm. This ensures effective forward and backward analysis by generating and killing sets for each analysis type.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 3"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-10-17-Rohit-HW3.html#data-flow-analysis",
    "href": "blogs/rohit/2024-10-17-Rohit-HW3.html#data-flow-analysis",
    "title": "Homework 3",
    "section": "",
    "text": "Definition: Data Flow Analysis (DFA) is a technique used in compiler optimization to analyze how values flow through program variables during execution.\n\nThe code should remove the instructions that are reassigned without being used.\nIf the value in being used in between the reassigning, then the instruction should be retained.\n\n\n\n\n\n\nFlows in direction of program execution\nPropagates information about variable definitions forward\nInitial state flows from start to end\n\n\n\n\n\nInformation flows from top to bottom\nComputes expressions already evaluated at each point\nPropagates forward through control flow graph\n\n\n\n\n\n\n\n\nInformation flows opposite to program execution\nStarts from variable uses and works backwards\nDetermines if variable value will be needed later\n\n\n\n\n\nFlows from bottom to top\nWorks backwards from expression uses\nDetermines what will definitely be computed later\n\n\n\n\n\n\nForward analyses use information from predecessor nodes\nBackward analyses use information from successor nodes\nDirection affects how we iterate through the control flow graph\nInitialization points differ (entry vs exit nodes)\n\n\n\n\n\n\n\n\nImport necessary modules (sys, json, etc.)\nDefine Analysis named tuple with attributes: forward, init, merge, transfer\n\n\n\n\n\nDefine union function: Merge multiple sets into one\nDefine intersection function: Find common elements among sets\n\n\n\n\n\nDetermine edges based on analysis direction (forward/backward)\nInitialize in_ and out sets for each block\nAdd all blocks to worklist\nWhile worklist is not empty:\n\nPop a block, calculate in_ value by merging predecessor/successor out values\nUpdate out value using transfer function\nIf out value changes, re-add successors/predecessors to worklist\n\n\n\n\n\n\nFormat sets and dictionaries into readable strings\n\n\n\n\n\nFor each function in the BRIL program:\n\nConvert instructions into blocks\nAdd terminators to blocks\nExecute worklist algorithm\nPrint in_ and out values for each block\n\n\n\n\n\n\nDefine functions to generate and kill variables/expressions for different analyses (liveness, reaching defs, very busy expressions, available expressions)\n\n\n\n\n\nDefine attributes and transfer functions for each analysis type (LIVENESS, VERYBUSY, REACHING, AVAILABLE)\n\n\n\n\n\nLoad BRIL program from input\nRun the specified data flow analysis\n\nFull code: https://github.com/gurusamyanandakuma-r/bril/blob/main/HW/HW3_Rohit/dfa.py\n\n\n\n\n\n\n```{turnt.toml} [envs.LIVENESS] command = “bril2json &lt; {filename} | python3 dfa.py LIVENESS” output.”LIVENESS.out” = “-”\n[envs.VERYBUSY]\ncommand = \"bril2json &lt; {filename} | python3 dfa.py VERYBUSY\"\noutput.\"VERYBUSY.out\" = \"-\"\n\n[envs.REACHING]\ncommand = \"bril2json &lt; {filename} | python3 dfa.py REACHING\"\noutput.\"REACHING.out\" = \"-\"\n\n[envs.AVAILABLE]\ncommand = \"bril2json &lt; {filename} | python3 dfa.py AVAILABLE\"\noutput.\"AVAILABLE.out\" = \"-\"\n#### Example 1: Without branches (one block code)\n##### Input bril:\n\n\n\n\n\n\n```{bril}\n    @main {\n\n        divisor: int = const 7;\n        divident: int = const 42;\n        quotient: int = div divident divisor;\n        product: int = mul quotient divisor;\n        remainder: int = sub divident product;  \n\n        print remainder; \n\n    }\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  ('div', ('divident', 'divisor')), ('mul', ('quotient', 'divisor')), ('sub', ('divident', 'product'))\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: ('divident', 'BLOCK1'), ('divisor', 'BLOCK1'), ('product', 'BLOCK1'), ('quotient', 'BLOCK1'), ('remainder', 'BLOCK1')\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: ('div', ('divident', 'divisor')), ('mul', ('quotient', 'divisor')), ('sub', ('divident', 'product'))\n\n\n\n\n\n\n    @main {\n    x: int = const 3;\n    y: int = const 4;\n    \n    .header:\n        cond: bool = lt x y;   # Check if x &lt; y\n        br cond .then .else;   # Branch based on condition\n\n    .then:\n        result: int = add x y;  # result = x + y\n        jmp .end;\n\n    .else:\n        result: int = sub x y;  # result = x - y\n        jmp .end;\n\n    .end:\n        print result;           # Print the result\n    }\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: x, y\n    header:\n        IN:  x, y\n        OUT: x, y\n    then:\n        IN:  x, y\n        OUT: result\n    else:\n        IN:  x, y\n        OUT: result\n    end:\n        IN:  result\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('lt', ('x', 'y'))\n    header:\n        IN:  ('lt', ('x', 'y'))\n        OUT: NULL\n    then:\n        IN:  ('add', ('x', 'y'))\n        OUT: NULL\n    else:\n        IN:  ('sub', ('x', 'y'))\n        OUT: NULL\n    end:\n        IN:  NULL\n        OUT: NULL\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    header:\n        IN:  ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    then:\n        IN:  ('cond', 'header'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('result', 'then'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    else:\n        IN:  ('cond', 'header'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('result', 'else'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n    end:\n        IN:  ('cond', 'header'), ('result', 'else'), ('result', 'then'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n        OUT: ('cond', 'header'), ('result', 'else'), ('result', 'then'), ('x', 'BLOCK1'), ('y', 'BLOCK1')\n\n\n\n    BLOCK1:\n        IN:  NULL\n        OUT: NULL\n    header:\n        IN:  NULL\n        OUT: ('lt', ('x', 'y'))\n    then:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('add', ('x', 'y')), ('lt', ('x', 'y'))\n    else:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('lt', ('x', 'y')), ('sub', ('x', 'y'))\n    end:\n        IN:  ('lt', ('x', 'y'))\n        OUT: ('lt', ('x', 'y'))\n\n\n\n\n\n\nBalancing the forward and backward data flow analysis while managing the worklist efficiently wass tough. Each direction affects the edges and node values differently, which can lead to complicated logic.\n\n\n\n\nDeveloped code that handles liveness, availability, reaching definitions, and very busy expressions using a worklist algorithm. This ensures effective forward and backward analysis by generating and killing sets for each analysis type.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 3"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-20-Rohit-HW1.html",
    "href": "blogs/rohit/2024-09-20-Rohit-HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "A Cyclic Redundancy Check (CRC) is an error-detecting code used in digital networks and storage devices to detect accidental changes to raw data. In embedded systems, CRCs are crucial for ensuring data integrity during communication, verifying data stored in memory, and validating firmware updates. They are popular due to their simplicity, efficiency in binary hardware, and effectiveness in detecting common transmission errors.\n\nIt ensure data integrity in communication protocols like UART, SPI, and I2C by detecting errors caused by noise or interference.\nHow CRC Works:\n\nPolynomial Division: The data block is treated as a large binary number and divided by a fixed polynomial. The remainder of this division is the CRC value.\nAppending CRC: The CRC value is appended to the data before transmission or storage.\nVerification: Upon retrieval, the same polynomial division is performed. If the remainder matches the CRC value, the data is considered intact; otherwise, it indicates corruption\n\nLearn more at: https://en.wikipedia.org/wiki/Cyclic_redundancy_check\n\n\n\n\n\nCRC calculations prominently involve memory allocation, extensively using ptr&lt;int&gt;.\nCRC algorithms typically involve a mix of arithmetic (e.g., addition, subtraction, Multiplication) and bitwise operations (e.g., XOR, shifts).\nThis makes CRC an excellent microbenchmark for evaluating how well your Bril implementation handles these critical operations, which are essential for many real-world applications.\n\n\n\n\n\nBril code for CRC is fully hand typed code of 300+ lines using VS Code, the most useful tool ever was Bril syntax highlighting Extension in VS Code.\nTurnt tool was used to test and save the output file.\nturnt.toml file:\n\n    [envs.test]\n    command = \"bril2json &lt; {filename} | brili -p {args}\"\n    output.out = \"-\"\n    output.prof = \"2\"\n\n\nLearn more at: https://github.com/cucapra/turnt?tab=readme-ov-file\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Initialize Inputs]--&gt; B0[Get CRC Remainder] --&gt; B1[\"Check CRC\"] --&gt; B2[Print Outputs];\n\n\n\n\n\n\n\n\n\nGet Word, Divisor, check_value as an int.\ncheck_value will be 0 if the bits are missing and error.\nAppend Divisor size - 1 zeros to word.\nConvert the int into array, here in bril we can use ptr&lt;int&gt; allocations calling @toPtr function.\nReference to memory allocation in bril: https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/manually-managed-memory/\n\n\n\n\n\nTo divide Word and Divisor we need to do xor in each bit.\nFirst copy first few bits from Word to Word_split having same length as Divisor.\nCall @xorfunction and overwrite the result to first few bits of Word.\nCall @shiftleft function to left shift the Word and decrement word_size.\nRepeat this process until Word_size &lt; Div_size.\nAt the end return Word as a crc_rem to @main.\nConvert crc_rem from ptr&lt;int&gt; to int by calling toNum function.\n\n\n\n\n\nIf: crc_rem == 0 then there is no error in bit and crc_check is true.\nElse: there is a error and crc_check is false.\n\n\n\n\n\nOuputs are bool value crc_check and int value crc_rem.\nWhen check_value is set to 0\n\nThis Indicates that there are error or missing bits.\ncrc_check value will be false\ncheck_rem will give out the correct check_value\nso again replacing 0 from check_rem with check_value and running the code will give us crc_check as true with check_rem = 0 .\n\nFull code: https://github.com/gurusamyanandakuma-r/bril/blob/main/benchmarks/mem/crc_check.bril\n\n\n\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    1011\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 1011;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    100\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 100;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-1-benchmark",
    "href": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-1-benchmark",
    "title": "Homework 1",
    "section": "",
    "text": "A Cyclic Redundancy Check (CRC) is an error-detecting code used in digital networks and storage devices to detect accidental changes to raw data. In embedded systems, CRCs are crucial for ensuring data integrity during communication, verifying data stored in memory, and validating firmware updates. They are popular due to their simplicity, efficiency in binary hardware, and effectiveness in detecting common transmission errors.\n\nIt ensure data integrity in communication protocols like UART, SPI, and I2C by detecting errors caused by noise or interference.\nHow CRC Works:\n\nPolynomial Division: The data block is treated as a large binary number and divided by a fixed polynomial. The remainder of this division is the CRC value.\nAppending CRC: The CRC value is appended to the data before transmission or storage.\nVerification: Upon retrieval, the same polynomial division is performed. If the remainder matches the CRC value, the data is considered intact; otherwise, it indicates corruption\n\nLearn more at: https://en.wikipedia.org/wiki/Cyclic_redundancy_check\n\n\n\n\n\nCRC calculations prominently involve memory allocation, extensively using ptr&lt;int&gt;.\nCRC algorithms typically involve a mix of arithmetic (e.g., addition, subtraction, Multiplication) and bitwise operations (e.g., XOR, shifts).\nThis makes CRC an excellent microbenchmark for evaluating how well your Bril implementation handles these critical operations, which are essential for many real-world applications.\n\n\n\n\n\nBril code for CRC is fully hand typed code of 300+ lines using VS Code, the most useful tool ever was Bril syntax highlighting Extension in VS Code.\nTurnt tool was used to test and save the output file.\nturnt.toml file:\n\n    [envs.test]\n    command = \"bril2json &lt; {filename} | brili -p {args}\"\n    output.out = \"-\"\n    output.prof = \"2\"\n\n\nLearn more at: https://github.com/cucapra/turnt?tab=readme-ov-file\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Initialize Inputs]--&gt; B0[Get CRC Remainder] --&gt; B1[\"Check CRC\"] --&gt; B2[Print Outputs];\n\n\n\n\n\n\n\n\n\nGet Word, Divisor, check_value as an int.\ncheck_value will be 0 if the bits are missing and error.\nAppend Divisor size - 1 zeros to word.\nConvert the int into array, here in bril we can use ptr&lt;int&gt; allocations calling @toPtr function.\nReference to memory allocation in bril: https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/manually-managed-memory/\n\n\n\n\n\nTo divide Word and Divisor we need to do xor in each bit.\nFirst copy first few bits from Word to Word_split having same length as Divisor.\nCall @xorfunction and overwrite the result to first few bits of Word.\nCall @shiftleft function to left shift the Word and decrement word_size.\nRepeat this process until Word_size &lt; Div_size.\nAt the end return Word as a crc_rem to @main.\nConvert crc_rem from ptr&lt;int&gt; to int by calling toNum function.\n\n\n\n\n\nIf: crc_rem == 0 then there is no error in bit and crc_check is true.\nElse: there is a error and crc_check is false.\n\n\n\n\n\nOuputs are bool value crc_check and int value crc_rem.\nWhen check_value is set to 0\n\nThis Indicates that there are error or missing bits.\ncrc_check value will be false\ncheck_rem will give out the correct check_value\nso again replacing 0 from check_rem with check_value and running the code will give us crc_check as true with check_rem = 0 .\n\nFull code: https://github.com/gurusamyanandakuma-r/bril/blob/main/benchmarks/mem/crc_check.bril\n\n\n\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    1011\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\nInput:\n\n    word: int = const 1101101;\n    word_size: int = const 7;\n    divisor: int = const 10101;\n    divisor_size: int = const 5;\n    check_value: int = const 1011;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 1784\n\n\n\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 0;\n\nOutput:\n\n    false\n    100\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061\n\n\n\n\nInput:\n\n    word: int = const 11010011101100;\n    word_size: int = const 14;\n    divisor: int = const 1011;\n    divisor_size: int = const 4;\n    check_value: int = const 100;\n\nOutput:\n\n    true\n    0\n\nTotal Dynamic Instructions:\n\n    total_dyn_inst: 3061",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-2-analysis",
    "href": "blogs/rohit/2024-09-20-Rohit-HW1.html#part-2-analysis",
    "title": "Homework 1",
    "section": "PART 2: Analysis:",
    "text": "PART 2: Analysis:\n\nFinding Number of Functions and its Calls\n\nCode: https://github.com/gurusamyanandakuma-r/bril/blob/main/examples/Count_Function.py\n\n\nInitialize\n\nThis analysis is done in python.\nUsing bril2json converting .bril file to JSON.\nLoading into python file using prog = json.load(sys.stdin).\nJSON heap structure will be loaded as dictionary in python.\n\n\n\nProcess\n\nCounting all functions in bril.\nCounting function calls of a function.\n\n\n\nTest\n\nTurnt.toml file:\n\n    [envs.countFunc]\n    default = false\n    command = \"bril2json &lt; {filename} | python3 hw.py &gt; {base}.txt\"\n\nOutput is stored in .txt file.\n\n\nExample 1: CRC\n\nInput:\n\nfile: https://github.com/gurusamyanandakuma-r/bril/blob/main/benchmarks/mem/crc_check.bril\n\n\n\nOutput:\n```\nNumber of Functions:  11\n------------------------\nFunction Call Counts:\nmain     : 0\nrem      : 1\nn_zeros  : 2\ntoPtr    : 2\nwordSplit: 1\nxor      : 1\nshiftLeft: 1\nprint_ptr: 0\ncrc_rem  : 1\ncrc_check: 1\ntoNum    : 1\n\n\n##### Example 2: Fibonacci\n###### Input: \n- file: &lt;https://github.com/normrubin/bril/blob/main/benchmarks/core/fibonacci.bril&gt;\n\n###### Output:\n    ```\n    Number of Functions:  2\n    ------------------------\n    Function Call Counts:\n    main     : 0\n    Fibonacci: 3\n\n\n\nExample 3: Binary Search\n\nInput:\n\nfile: https://github.com/normrubin/bril/blob/main/benchmarks/mem/binary-search.bril\n\n\n\nOutput:\n    Number of Functions:  4\n    ------------------------\n    Function Call Counts:\n    pack         : 1\n    print_array  : 0\n    binary_search: 3\n    main         : 0",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 1"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-10-18-Rohit-HW4.html",
    "href": "blogs/rohit/2024-10-18-Rohit-HW4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Definition: Dominance analysis is a fundamental concept in compiler optimization that helps us understand control flow relationships between basic blocks in a program. Let’s break down the key components and their implementations.\n\n\n\nA block D dominates block B if every path from the program entry to B must go through D\nProperties:\n\nEntry block dominates all blocks\nEvery block dominates itself\nIf A dominates B and B dominates C, then A dominates C (transitive)\n\nApplications:\n\nUsed in SSA form construction\nHelps identify natural loops\nCritical for many optimizations\n\n\n\n\n\n\nA compact representation of dominance relationships\nProperties:\n\nEach block (except entry) has exactly one immediate dominator\nForms a tree structure where parent dominates all its children\nImmediate dominator is the closest dominator in the path from entry\n\nBenefits:\n\nEfficient dominance queries\nSimplified analysis of nested structures\nQuick ancestor-descendant checks\n\n\n\n\n\n\nThe dominance frontier of block X contains blocks where X’s dominance stops\nKey aspects:\n\nCritical for SSA form construction\nIdentifies where to place φ-functions\nHelps determine variable live ranges\n\nUsage:\n\nControl dependence analysis\nData flow optimization\nLoop optimization\n\n\n\n\n\n\n\n\n\nInitialize with a stack.\nDefine methods for:\n\nReversing the graph.\nTraversing the graph in post-order.\nMerging sets.\nCalculating dominators.\nFinding dominance frontiers.\nBuilding a dominator tree.\n\n\n\n\n\n\nCreate a reversed graph dictionary.\n\n\n\n\n\nPerform post-order traversal on the graph starting from a given node.\n\n\n\n\n\nMerge multiple sets, finding the intersection.\n\n\n\n\n\nReverse the graph.\nTraverse the graph in post-order.\nInitialize dominator sets.\nIteratively update dominator sets until convergence.\n\n\n\n\n\nReverse the dominator sets.\nIdentify and return the dominance frontiers for each block.\n\n\n\n\n\nReverse the dominator sets.\nCreate strict dominator sets.\nCreate double strict dominator sets.\nBuild and return the dominator tree.\n\n\n\n\n\nInitialize DominanceProcessor.\nFor each function in BRIL:\n\nMap blocks and add entry/terminators.\nCalculate dominators.\nBased on analysis type, find frontiers or build tree.\nPrint results in JSON format.\n\n\n\n\n\n\nLoad BRIL from input.\nCall process_dominance with the specified analysis type.\n\n\n\n\n\n\n\n```{turnt.toml} [envs.DOM] command = “bril2json &lt; {filename} | python3 HW4.py DOM” output.”DOM.json” = “-”\n[envs.FRONT]\ncommand = \"bril2json &lt; {filename} | python3 HW4.py FRONT\"\noutput.\"FRONT.json\" = \"-\"\n\n[envs.TREE]\ncommand = \"bril2json &lt; {filename} | python3 HW4.py TREE\"\noutput.\"TREE.json\" = \"-\"\n#### Example 1: Simple Code: Absolute Value\n##### Input bril:\n\n\n\n\n\n\n```{bril}\n    @main(x: int) {\n    zero: int = const 0;\n    is_negative: bool = lt x zero;\n    br is_negative .negative .positive;\n    .negative:\n    result: int = sub zero x;\n    jmp .end;\n    .positive:\n    result: int = id x;\n    .end:\n    print result;\n    }\n\n\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"end\": [\n        \"BLOCK1\",\n        \"end\"\n    ],\n    \"negative\": [\n        \"BLOCK1\",\n        \"negative\"\n    ],\n    \"positive\": [\n        \"BLOCK1\",\n        \"positive\"\n    ]\n    }\n\n\n\n\n{\n  \"BLOCK1\": []\n}\n{\n  \"BLOCK1\": [],\n  \"body\": [\n    \"loop\"\n  ],\n  \"done\": [],\n  \"loop\": [\n    \"loop\"\n  ],\n  \"loop_end\": [\n    \"loop\"\n  ]\n}\n{\n  \"BLOCK1\": [],\n  \"done\": [],\n  \"swap\": [\n    \"done\"\n  ]\n}\n{\n  \"BLOCK1\": [],\n  \"bodyi\": [\n    \"loopi\"\n  ],\n  \"bodyj\": [\n    \"loopj\"\n  ],\n  \"donei\": [],\n  \"donej\": [\n    \"loopi\"\n  ],\n  \"loop_endj\": [\n    \"loopj\"\n  ],\n  \"loopi\": [\n    \"loopi\"\n  ],\n  \"loopi_end\": [\n    \"loopi\"\n  ],\n  \"loopj\": [\n    \"loopi\",\n    \"loopj\"\n  ]\n}\n\n\n\n\n    {\n    \"BLOCK1\": [\n        \"end\",\n        \"negative\",\n        \"positive\"\n    ],\n    \"end\": [],\n    \"negative\": [],\n    \"positive\": []\n    }\n\n\n\n\n\n\n\n        \n    @pack(size: int, n1: int, n2: int, n3: int, n4: int, n5: int) : ptr&lt;int&gt; {\n        one: int = const 1;\n        i: int = const 0;\n        array: ptr&lt;int&gt; = alloc size;\n    # Pack data into array manually. Cannot use loop because of the different var name.     \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n1;\n        i: int = add i one;\n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n2;\n        i: int = add i one;        \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n3;\n        i: int = add i one;        \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n4;\n        i: int = add i one;        \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n5;\n        ret array;\n    }\n\n    @print_array(array: ptr&lt;int&gt;, size: int) {\n        i: int = const 0;\n        one: int = const 1;\n    .loop:\n        cond: bool = lt i size;\n        br cond .body .done;\n    .body:\n        loc: ptr&lt;int&gt; = ptradd array i;\n        val: int = load loc;\n        print val;\n    .loop_end:\n        i: int = add i one;\n        jmp .loop;\n    .done:\n        ret;\n    }\n\n    @swap_cond(array: ptr&lt;int&gt;, j: int) {\n        one: int = const 1;\n        j_add_1: int = add j one;\n        loc: ptr&lt;int&gt; = ptradd array j;\n        loc_next: ptr&lt;int&gt; = ptradd array j_add_1;\n        elem_a: int = load loc;\n        elem_b: int = load loc_next;\n        \n        cond: bool = gt elem_a elem_b;\n        br cond .swap .done;\n    .swap:\n        store loc elem_b;\n        store loc_next elem_a;\n    .done:\n        ret;\n    }\n\n    # ARGS: 5 3 10 1 9 7\n    @main(size: int, n1: int, n2: int, n3: int, n4: int, n5: int) {\n    # Pack the input elements into an array with a starting pointer\n        array: ptr&lt;int&gt; = call @pack size n1 n2 n3 n4 n5;\n\n    # Bubble Sort\n    one: int = const 1;\n    i: int = const 0;\n    j: int = const 0;\n    sizei: int = sub size one;\n    .loopi:\n        condi: bool = lt i sizei;\n        br condi .bodyi .donei;\n    .bodyi:\n        sizej: int = sub size i;\n        sizej: int = sub sizej one;\n    .loopj:\n        condj: bool = lt j sizej;\n        br condj .bodyj .donej;\n    .bodyj:\n        call @swap_cond array j;\n    .loop_endj:\n        j: int = add j one;\n        jmp .loopj;\n    .donej:\n        j: int = const 0;\n    .loopi_end:\n        i: int = add i one;\n        jmp .loopi;\n    .donei:\n\n    # Print array\n        call @print_array array size;\n\n        free array;\n    }\n\n\n\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ]\n    }\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"body\": [\n        \"BLOCK1\",\n        \"body\",\n        \"loop\"\n    ],\n    \"done\": [\n        \"BLOCK1\",\n        \"done\",\n        \"loop\"\n    ],\n    \"loop\": [\n        \"BLOCK1\",\n        \"loop\"\n    ],\n    \"loop_end\": [\n        \"BLOCK1\",\n        \"body\",\n        \"loop\",\n        \"loop_end\"\n    ]\n    }\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"done\": [\n        \"BLOCK1\",\n        \"done\"\n    ],\n    \"swap\": [\n        \"BLOCK1\",\n        \"swap\"\n    ]\n    }\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"bodyi\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"loopi\"\n    ],\n    \"bodyj\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"bodyj\",\n        \"loopi\",\n        \"loopj\"\n    ],\n    \"donei\": [\n        \"BLOCK1\",\n        \"donei\",\n        \"loopi\"\n    ],\n    \"donej\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"donej\",\n        \"loopi\",\n        \"loopj\"\n    ],\n    \"loop_endj\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"bodyj\",\n        \"loop_endj\",\n        \"loopi\",\n        \"loopj\"\n    ],\n    \"loopi\": [\n        \"BLOCK1\",\n        \"loopi\"\n    ],\n    \"loopi_end\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"donej\",\n        \"loopi\",\n        \"loopi_end\",\n        \"loopj\"\n    ],\n    \"loopj\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"loopi\",\n        \"loopj\"\n    ]\n    }\n\n\n\n\n        {\n    \"BLOCK1\": []\n    }\n    {\n    \"BLOCK1\": [],\n    \"body\": [\n        \"loop\"\n    ],\n    \"done\": [],\n    \"loop\": [\n        \"loop\"\n    ],\n    \"loop_end\": [\n        \"loop\"\n    ]\n    }\n    {\n    \"BLOCK1\": [],\n    \"done\": [],\n    \"swap\": [\n        \"done\"\n    ]\n    }\n    {\n    \"BLOCK1\": [],\n    \"bodyi\": [\n        \"loopi\"\n    ],\n    \"bodyj\": [\n        \"loopj\"\n    ],\n    \"donei\": [],\n    \"donej\": [\n        \"loopi\"\n    ],\n    \"loop_endj\": [\n        \"loopj\"\n    ],\n    \"loopi\": [\n        \"loopi\"\n    ],\n    \"loopi_end\": [\n        \"loopi\"\n    ],\n    \"loopj\": [\n        \"loopi\",\n        \"loopj\"\n    ]\n    }\n\n\n\n\n        {\n    \"BLOCK1\": []\n    }\n    {\n    \"BLOCK1\": [\n        \"loop\"\n    ],\n    \"body\": [\n        \"loop_end\"\n    ],\n    \"done\": [],\n    \"loop\": [\n        \"body\",\n        \"done\"\n    ],\n    \"loop_end\": []\n    }\n    {\n    \"BLOCK1\": [\n        \"done\",\n        \"swap\"\n    ],\n    \"done\": [],\n    \"swap\": []\n    }\n    {\n    \"BLOCK1\": [\n        \"loopi\"\n    ],\n    \"bodyi\": [\n        \"loopj\"\n    ],\n    \"bodyj\": [\n        \"loop_endj\"\n    ],\n    \"donei\": [],\n    \"donej\": [\n        \"loopi_end\"\n    ],\n    \"loop_endj\": [],\n    \"loopi\": [\n        \"bodyi\",\n        \"donei\"\n    ],\n    \"loopi_end\": [],\n    \"loopj\": [\n        \"bodyj\",\n        \"donej\"\n    ]\n    }\n\n\n\n\n\n\n\n\n\n\n\nInput: dominators (dictionary), block_A (string), block_B (string)\nOutput: Boolean indicating if block_A dominates block_B\nLogic:\n\nIf block_B exists in dominators dictionary:\n\nCheck if block_A is in the list of dominators for block_B\nReturn True if it is, else return False\n\n\n\n\n\n\n\nLoad the dominator sets from a JSON file ex1.DOM.json\n\nOpen the file and parse JSON data into dominator_data dictionary\n\nDisplay the available blocks\n\nRetrieve keys from dominator_data and store in available_blocks\nPrint each block with its index number\n\nGet user input for block_A and block_B\n\nPrompt user to enter index for block_A and block_B\nConvert user input to integer and adjust for zero-based indexing\nUse these indices to select block_A and block_B from available_blocks\n\nCheck if block_A dominates block_B\n\nCall check_dominance function with dominator_data, block_A, block_B\nPrint result indicating if block_A dominates block_B\n\nExecute main function if the script is run directly\n\n\n\n\n\n\n\n\n    python3 checkDom.py ex1.DOM.json\n\n\n\n\n\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"end\": [\n        \"BLOCK1\",\n        \"end\"\n    ],\n    \"negative\": [\n        \"BLOCK1\",\n        \"negative\"\n    ],\n    \"positive\": [\n        \"BLOCK1\",\n        \"positive\"\n    ]\n    }\n\n\n\n\n    Available blocks:\n    1. BLOCK1\n    2. end\n    3. negative\n    4. positive\n\n    Enter the number for block A: 1\n    Enter the number for block B: 2\n\n    BLOCK1 dominates end\n\n\n\n\n\nThe dominator finding algorithm was complex and slow, and constructing the dominator tree required extensive testing and debugging to ensure accuracy.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 4"
    ]
  },
  {
    "objectID": "blogs/rohit/2024-10-18-Rohit-HW4.html#dominance",
    "href": "blogs/rohit/2024-10-18-Rohit-HW4.html#dominance",
    "title": "Homework 4",
    "section": "",
    "text": "Definition: Dominance analysis is a fundamental concept in compiler optimization that helps us understand control flow relationships between basic blocks in a program. Let’s break down the key components and their implementations.\n\n\n\nA block D dominates block B if every path from the program entry to B must go through D\nProperties:\n\nEntry block dominates all blocks\nEvery block dominates itself\nIf A dominates B and B dominates C, then A dominates C (transitive)\n\nApplications:\n\nUsed in SSA form construction\nHelps identify natural loops\nCritical for many optimizations\n\n\n\n\n\n\nA compact representation of dominance relationships\nProperties:\n\nEach block (except entry) has exactly one immediate dominator\nForms a tree structure where parent dominates all its children\nImmediate dominator is the closest dominator in the path from entry\n\nBenefits:\n\nEfficient dominance queries\nSimplified analysis of nested structures\nQuick ancestor-descendant checks\n\n\n\n\n\n\nThe dominance frontier of block X contains blocks where X’s dominance stops\nKey aspects:\n\nCritical for SSA form construction\nIdentifies where to place φ-functions\nHelps determine variable live ranges\n\nUsage:\n\nControl dependence analysis\nData flow optimization\nLoop optimization\n\n\n\n\n\n\n\n\n\nInitialize with a stack.\nDefine methods for:\n\nReversing the graph.\nTraversing the graph in post-order.\nMerging sets.\nCalculating dominators.\nFinding dominance frontiers.\nBuilding a dominator tree.\n\n\n\n\n\n\nCreate a reversed graph dictionary.\n\n\n\n\n\nPerform post-order traversal on the graph starting from a given node.\n\n\n\n\n\nMerge multiple sets, finding the intersection.\n\n\n\n\n\nReverse the graph.\nTraverse the graph in post-order.\nInitialize dominator sets.\nIteratively update dominator sets until convergence.\n\n\n\n\n\nReverse the dominator sets.\nIdentify and return the dominance frontiers for each block.\n\n\n\n\n\nReverse the dominator sets.\nCreate strict dominator sets.\nCreate double strict dominator sets.\nBuild and return the dominator tree.\n\n\n\n\n\nInitialize DominanceProcessor.\nFor each function in BRIL:\n\nMap blocks and add entry/terminators.\nCalculate dominators.\nBased on analysis type, find frontiers or build tree.\nPrint results in JSON format.\n\n\n\n\n\n\nLoad BRIL from input.\nCall process_dominance with the specified analysis type.\n\n\n\n\n\n\n\n```{turnt.toml} [envs.DOM] command = “bril2json &lt; {filename} | python3 HW4.py DOM” output.”DOM.json” = “-”\n[envs.FRONT]\ncommand = \"bril2json &lt; {filename} | python3 HW4.py FRONT\"\noutput.\"FRONT.json\" = \"-\"\n\n[envs.TREE]\ncommand = \"bril2json &lt; {filename} | python3 HW4.py TREE\"\noutput.\"TREE.json\" = \"-\"\n#### Example 1: Simple Code: Absolute Value\n##### Input bril:\n\n\n\n\n\n\n```{bril}\n    @main(x: int) {\n    zero: int = const 0;\n    is_negative: bool = lt x zero;\n    br is_negative .negative .positive;\n    .negative:\n    result: int = sub zero x;\n    jmp .end;\n    .positive:\n    result: int = id x;\n    .end:\n    print result;\n    }\n\n\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"end\": [\n        \"BLOCK1\",\n        \"end\"\n    ],\n    \"negative\": [\n        \"BLOCK1\",\n        \"negative\"\n    ],\n    \"positive\": [\n        \"BLOCK1\",\n        \"positive\"\n    ]\n    }\n\n\n\n\n{\n  \"BLOCK1\": []\n}\n{\n  \"BLOCK1\": [],\n  \"body\": [\n    \"loop\"\n  ],\n  \"done\": [],\n  \"loop\": [\n    \"loop\"\n  ],\n  \"loop_end\": [\n    \"loop\"\n  ]\n}\n{\n  \"BLOCK1\": [],\n  \"done\": [],\n  \"swap\": [\n    \"done\"\n  ]\n}\n{\n  \"BLOCK1\": [],\n  \"bodyi\": [\n    \"loopi\"\n  ],\n  \"bodyj\": [\n    \"loopj\"\n  ],\n  \"donei\": [],\n  \"donej\": [\n    \"loopi\"\n  ],\n  \"loop_endj\": [\n    \"loopj\"\n  ],\n  \"loopi\": [\n    \"loopi\"\n  ],\n  \"loopi_end\": [\n    \"loopi\"\n  ],\n  \"loopj\": [\n    \"loopi\",\n    \"loopj\"\n  ]\n}\n\n\n\n\n    {\n    \"BLOCK1\": [\n        \"end\",\n        \"negative\",\n        \"positive\"\n    ],\n    \"end\": [],\n    \"negative\": [],\n    \"positive\": []\n    }\n\n\n\n\n\n\n\n        \n    @pack(size: int, n1: int, n2: int, n3: int, n4: int, n5: int) : ptr&lt;int&gt; {\n        one: int = const 1;\n        i: int = const 0;\n        array: ptr&lt;int&gt; = alloc size;\n    # Pack data into array manually. Cannot use loop because of the different var name.     \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n1;\n        i: int = add i one;\n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n2;\n        i: int = add i one;        \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n3;\n        i: int = add i one;        \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n4;\n        i: int = add i one;        \n        loc: ptr&lt;int&gt; = ptradd array i;\n        store loc n5;\n        ret array;\n    }\n\n    @print_array(array: ptr&lt;int&gt;, size: int) {\n        i: int = const 0;\n        one: int = const 1;\n    .loop:\n        cond: bool = lt i size;\n        br cond .body .done;\n    .body:\n        loc: ptr&lt;int&gt; = ptradd array i;\n        val: int = load loc;\n        print val;\n    .loop_end:\n        i: int = add i one;\n        jmp .loop;\n    .done:\n        ret;\n    }\n\n    @swap_cond(array: ptr&lt;int&gt;, j: int) {\n        one: int = const 1;\n        j_add_1: int = add j one;\n        loc: ptr&lt;int&gt; = ptradd array j;\n        loc_next: ptr&lt;int&gt; = ptradd array j_add_1;\n        elem_a: int = load loc;\n        elem_b: int = load loc_next;\n        \n        cond: bool = gt elem_a elem_b;\n        br cond .swap .done;\n    .swap:\n        store loc elem_b;\n        store loc_next elem_a;\n    .done:\n        ret;\n    }\n\n    # ARGS: 5 3 10 1 9 7\n    @main(size: int, n1: int, n2: int, n3: int, n4: int, n5: int) {\n    # Pack the input elements into an array with a starting pointer\n        array: ptr&lt;int&gt; = call @pack size n1 n2 n3 n4 n5;\n\n    # Bubble Sort\n    one: int = const 1;\n    i: int = const 0;\n    j: int = const 0;\n    sizei: int = sub size one;\n    .loopi:\n        condi: bool = lt i sizei;\n        br condi .bodyi .donei;\n    .bodyi:\n        sizej: int = sub size i;\n        sizej: int = sub sizej one;\n    .loopj:\n        condj: bool = lt j sizej;\n        br condj .bodyj .donej;\n    .bodyj:\n        call @swap_cond array j;\n    .loop_endj:\n        j: int = add j one;\n        jmp .loopj;\n    .donej:\n        j: int = const 0;\n    .loopi_end:\n        i: int = add i one;\n        jmp .loopi;\n    .donei:\n\n    # Print array\n        call @print_array array size;\n\n        free array;\n    }\n\n\n\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ]\n    }\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"body\": [\n        \"BLOCK1\",\n        \"body\",\n        \"loop\"\n    ],\n    \"done\": [\n        \"BLOCK1\",\n        \"done\",\n        \"loop\"\n    ],\n    \"loop\": [\n        \"BLOCK1\",\n        \"loop\"\n    ],\n    \"loop_end\": [\n        \"BLOCK1\",\n        \"body\",\n        \"loop\",\n        \"loop_end\"\n    ]\n    }\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"done\": [\n        \"BLOCK1\",\n        \"done\"\n    ],\n    \"swap\": [\n        \"BLOCK1\",\n        \"swap\"\n    ]\n    }\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"bodyi\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"loopi\"\n    ],\n    \"bodyj\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"bodyj\",\n        \"loopi\",\n        \"loopj\"\n    ],\n    \"donei\": [\n        \"BLOCK1\",\n        \"donei\",\n        \"loopi\"\n    ],\n    \"donej\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"donej\",\n        \"loopi\",\n        \"loopj\"\n    ],\n    \"loop_endj\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"bodyj\",\n        \"loop_endj\",\n        \"loopi\",\n        \"loopj\"\n    ],\n    \"loopi\": [\n        \"BLOCK1\",\n        \"loopi\"\n    ],\n    \"loopi_end\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"donej\",\n        \"loopi\",\n        \"loopi_end\",\n        \"loopj\"\n    ],\n    \"loopj\": [\n        \"BLOCK1\",\n        \"bodyi\",\n        \"loopi\",\n        \"loopj\"\n    ]\n    }\n\n\n\n\n        {\n    \"BLOCK1\": []\n    }\n    {\n    \"BLOCK1\": [],\n    \"body\": [\n        \"loop\"\n    ],\n    \"done\": [],\n    \"loop\": [\n        \"loop\"\n    ],\n    \"loop_end\": [\n        \"loop\"\n    ]\n    }\n    {\n    \"BLOCK1\": [],\n    \"done\": [],\n    \"swap\": [\n        \"done\"\n    ]\n    }\n    {\n    \"BLOCK1\": [],\n    \"bodyi\": [\n        \"loopi\"\n    ],\n    \"bodyj\": [\n        \"loopj\"\n    ],\n    \"donei\": [],\n    \"donej\": [\n        \"loopi\"\n    ],\n    \"loop_endj\": [\n        \"loopj\"\n    ],\n    \"loopi\": [\n        \"loopi\"\n    ],\n    \"loopi_end\": [\n        \"loopi\"\n    ],\n    \"loopj\": [\n        \"loopi\",\n        \"loopj\"\n    ]\n    }\n\n\n\n\n        {\n    \"BLOCK1\": []\n    }\n    {\n    \"BLOCK1\": [\n        \"loop\"\n    ],\n    \"body\": [\n        \"loop_end\"\n    ],\n    \"done\": [],\n    \"loop\": [\n        \"body\",\n        \"done\"\n    ],\n    \"loop_end\": []\n    }\n    {\n    \"BLOCK1\": [\n        \"done\",\n        \"swap\"\n    ],\n    \"done\": [],\n    \"swap\": []\n    }\n    {\n    \"BLOCK1\": [\n        \"loopi\"\n    ],\n    \"bodyi\": [\n        \"loopj\"\n    ],\n    \"bodyj\": [\n        \"loop_endj\"\n    ],\n    \"donei\": [],\n    \"donej\": [\n        \"loopi_end\"\n    ],\n    \"loop_endj\": [],\n    \"loopi\": [\n        \"bodyi\",\n        \"donei\"\n    ],\n    \"loopi_end\": [],\n    \"loopj\": [\n        \"bodyj\",\n        \"donej\"\n    ]\n    }\n\n\n\n\n\n\n\n\n\n\n\nInput: dominators (dictionary), block_A (string), block_B (string)\nOutput: Boolean indicating if block_A dominates block_B\nLogic:\n\nIf block_B exists in dominators dictionary:\n\nCheck if block_A is in the list of dominators for block_B\nReturn True if it is, else return False\n\n\n\n\n\n\n\nLoad the dominator sets from a JSON file ex1.DOM.json\n\nOpen the file and parse JSON data into dominator_data dictionary\n\nDisplay the available blocks\n\nRetrieve keys from dominator_data and store in available_blocks\nPrint each block with its index number\n\nGet user input for block_A and block_B\n\nPrompt user to enter index for block_A and block_B\nConvert user input to integer and adjust for zero-based indexing\nUse these indices to select block_A and block_B from available_blocks\n\nCheck if block_A dominates block_B\n\nCall check_dominance function with dominator_data, block_A, block_B\nPrint result indicating if block_A dominates block_B\n\nExecute main function if the script is run directly\n\n\n\n\n\n\n\n\n    python3 checkDom.py ex1.DOM.json\n\n\n\n\n\n    {\n    \"BLOCK1\": [\n        \"BLOCK1\"\n    ],\n    \"end\": [\n        \"BLOCK1\",\n        \"end\"\n    ],\n    \"negative\": [\n        \"BLOCK1\",\n        \"negative\"\n    ],\n    \"positive\": [\n        \"BLOCK1\",\n        \"positive\"\n    ]\n    }\n\n\n\n\n    Available blocks:\n    1. BLOCK1\n    2. end\n    3. negative\n    4. positive\n\n    Enter the number for block A: 1\n    Enter the number for block B: 2\n\n    BLOCK1 dominates end\n\n\n\n\n\nThe dominator finding algorithm was complex and slow, and constructing the dominator tree required extensive testing and debugging to ensure accuracy.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Rohit",
      "Homework 4"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-18-Sharmila-HW04.html",
    "href": "blogs/sharmila/2024-10-18-Sharmila-HW04.html",
    "title": "Compiler Homework 04 - Implementing Dominance Utilities",
    "section": "",
    "text": "In this homework blog, the task involves three main components: finding dominators for a function, constructing the dominance tree, and computing the dominance frontier. This blog post will walk through the implementation process, challenges faced, and testing my implementation.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 04 -  Implementing Dominance Utilities"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-18-Sharmila-HW04.html#implementation-process",
    "href": "blogs/sharmila/2024-10-18-Sharmila-HW04.html#implementation-process",
    "title": "Compiler Homework 04 - Implementing Dominance Utilities",
    "section": "Implementation Process",
    "text": "Implementation Process\n\n1. Finding Dominators\nThe first step was to implement a function to find dominators for a given control flow graph (CFG). I used the iterative algorithm, which involves:\n\nInitializing all nodes as dominators for each node.\nIteratively refining the dominator sets based on the predecessors of each node.\nContinuing until no changes occur in the dominator sets.\n\n\n\n2. Constructing the Dominance Tree\nWith the dominator information in hand, constructing the dominance tree was the next challenge, implemented by:\n\nInverting the dominator relation to get a map of dominated nodes.\nIdentifying the strictly dominated nodes (excluding self-domination).\nBuilding the tree structure by finding the immediate dominator for each node.\n\n\n\n3. Computing the Dominance Frontier\nThe final piece of the puzzle was computing the dominance frontier. Implemented this by:\n\nFinding all successors of dominated blocks for each node.\nIdentifying which of these successors are not strictly dominated by the current node.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 04 -  Implementing Dominance Utilities"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-18-Sharmila-HW04.html#testing",
    "href": "blogs/sharmila/2024-10-18-Sharmila-HW04.html#testing",
    "title": "Compiler Homework 04 - Implementing Dominance Utilities",
    "section": "Testing",
    "text": "Testing\nTo ensure the correctness of the implementation, I tested the code with 2 examples:\n\nExample 1: Sum of Two Numbers\n\n@main {\n a: int = const 10;\n b: int = const 3;\n sum: int = add a b;\n print sum;\n}\nOutput: Dominators:\n{\n  \"Main1\": [\"Main1\"]\n}\nDominance Tree:\n{\n  \"Main1\": []\n}\nDominance Frontier:\n{\n  \"Main1\": []\n}\n\nExample 1: Fibonacci Sequence\n\n@main(n: int) {\n zero: int = const 0;\n one: int = const 1;\n is_base_case: bool = le n one;\n br is_base_case .base_case .recursive_case;\n\n.base_case:\n result: int = id n;\n jmp .end;\n\n.recursive_case:\n n_minus_one: int = sub n one;\n n_minus_two: int = sub n two;\n \n fib_n_minus_one: int = call @fibonacci n_minus_one;\n fib_n_minus_two: int = call @fibonacci n_minus_two;\n \n result: int = add fib_n_minus_one fib_n_minus_two;\n\n.end:\n print result;\n}\n\n@fibonacci(n: int): int {\n zero: int = const 0;\n one: int = const 1;\n is_base_case: bool = le n one;\n br is_base_case .base_case .recursive_case;\n\n.base_case:\n ret n;\n\n.recursive_case:\n n_minus_one: int = sub n one;\n n_minus_two: int = sub n two;\n \n fib_n_minus_one: int = call @fibonacci n_minus_one;\n fib_n_minus_two: int = call @fibonacci n_minus_two;\n \n result: int = add fib_n_minus_one fib_n_minus_two;\n ret result;\n}\nOutput: Dominators:\n{\n  \"Main1\": [\"Main1\"],\n  \"base_case\": [\"Main1\",\"base_case\"],\n  \"end\": [\"Main1\",\"end\"],\n  \"recursive_case\": [\"Main1\",\"recursive_case\"]\n}\nDominance Tree:\n{\n  \"Main1\": [\"base_case\",\"end\",\"recursive_case\"],\n  \"base_case\": [],\n  \"end\": [],\n  \"recursive_case\": []\n}\nDominance Frontier:\n{\n  \"Main1\": [],\n  \"base_case\": [\"end\"],\n  \"end\": [],\n  \"recursive_case\": [\"end\"]\n}\nThe code correctly identifies dominators, constructs accurate dominance trees, and computes the correct dominance frontiers. By these output it is understood that Block A(Main1 block here) dominates the other blocks.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 04 -  Implementing Dominance Utilities"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-18-Sharmila-HW04.html#challenges-faced",
    "href": "blogs/sharmila/2024-10-18-Sharmila-HW04.html#challenges-faced",
    "title": "Compiler Homework 04 - Implementing Dominance Utilities",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nComplexity of the dominator finding algorithm, which is slow for large tree. Additionally, constructing dominator tree was difficult required extra testing and debugging to ensure correctness.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 04 -  Implementing Dominance Utilities"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-15-Sharmila-HW03.html",
    "href": "blogs/sharmila/2024-10-15-Sharmila-HW03.html",
    "title": "Compiler Homework 03 - Data Flow Analysis",
    "section": "",
    "text": "In this homework the task is to implement a data flow analysis. The challenge was to make it generic enough to support multiple types of analysis, such as liveness analysis, reaching definitions, available expressions, and very busy expressions.. In this blog post, I’ll share my experience, the code I developed, and some of the challenges I faced along the way.\n\n\nThe four types of data flow analysis that I implemented in this project:\n\nLiveness Analysis (Backward) Liveness analysis determines which variables are “live” at each point in the program. A variable is considered live if its value may be read in the future before it’s overwritten. This is a backward analysis because it propagates information from the end of the program towards the beginning.\n\nDirection: Backward\nInitial State: Empty set\nMerge Operation: Union\n\nVery Busy Expressions Analysis (Backward) Very Busy Expressions (VBE) analysis identifies expressions that are “very busy” at each program point. An expression is very busy if it will be evaluated again before any of its operands are overwrittern. This is also a backward analysis.\n\nDirection: Backward\nInitial State: Empty set\nMerge Operation: Intersection\n\nReaching Definitions Analysis (Forward) Reaching Definitions analysis determines which definitions of variables may reach each point in the program. A definition reaches a point if there is a path from the definition to the point without any other overwrite or interven of the same variable. This is a forward analysis.\n\nDirection: Forward\nInitial State: Empty set\nMerge Operation: Union\n\nAvailable Expressions Analysis (Forward) Available Expressions analysis determines which expressions are already computed and not modified at each point in the program. An expression is available at a point if it has been computed on every path to that point and none of its operands have been redefined since its last computation. This is a forward analysis.\n\nDirection: Forward\nInitial State: Empty set (or all expressions for some formulations)\nMerge Operation: Intersection\n\n\n\n\n\nI decided to take on the challenge of creating a generic data flow analysis framework. Here’s a overview of the key components of my analysis:\n\nA df_worklist function that implements the worklist algorithm for data flow analysis.\nA run_df function that applies the analysis to each function in the input program.\nSeveral helper functions for set operations and formatting output.\nSpecific analysis implementations for liveness, very busy expressions (VBE), reaching definitions, and available expressions.\n\nThe core of the implementation is the df_worklist function, which can perform both forward and backward analysis based on the configuration provided:\ndef df_worklist(blocks, analysis):\n    # ... (implementation details)\nThis function takes a set of basic blocks and an analysis configuration, and returns the in and out sets for each block.\nThe analysis configuration is defined using a named tuple:\nAnalysis = namedtuple('Analysis', ['forward', 'init', 'merge', 'transfer'])\nThis allows us to easily specify different analyses by providing the appropriate parameters.\n\n\n\nI tested my implementation with two examples to ensure it was working correctly.\n\nsimple.bril: In order to understand that my analysis works or not I took a simple example to test and assured that the code works for all 4 types\n\n    @main {\n    a: int = const 5;\n    b: int = const 10;\n    \n    sum: int = add a b;\n    print sum;\n    }\nAnd the output are:\na. Liveness:\n    b1:\n    in:  ∅\n    out: ∅\n\nb. Very Busy Expression:\n    b1:\n    in:  ('add', ('a', 'b'))\n    out: ∅\nc. Reaching Definition:\n    b1:\n    in:  ∅\n    out: ('a', 'b1'), ('b', 'b1'), ('sum', 'b1')\nd. Available Expression:\n    b1:\n    in:  ∅\n    out: ('add', ('a', 'b'))\n\nAdding Square of Even and Odd numbers: This is another example which has loop and check whether my analysis works or not for this example.\n\n    @main {\n    sum_even: int = const 0;      \n    sum_odd: int = const 0;       \n    i: int = const 1;             \n    limit: int = const 10;        \n    one: int = const 1;           \n    two: int = const 2;           \n\n    .loop:\n    square: int = mul i i;        \n    half: int = div i two;        \n    check: int = mul half two;    \n    is_even: bool = eq check i;   \n    br is_even .even_case .odd_case; \n\n    .even_case:\n    sum_even: int = add sum_even square; \n    jmp .increment;\n\n    .odd_case:\n    sum_odd: int = add sum_odd square;   \n\n    .increment:\n    i: int = add i one;           \n    cond: bool = le i limit;      \n    br cond .loop .exit;          \n\n    .exit:\n    print sum_even;               \n    print sum_odd;                \n    }\nAnd the output are:\na. Liveness:\n        b1:\n        in:  ∅\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        loop:\n        in:  i, limit, one, sum_even, sum_odd, two\n        out: i, limit, one, square, sum_even, sum_odd, two\n        \n        even_case:\n        in:  i, limit, one, square, sum_even, sum_odd, two\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        odd_case:\n        in:  i, limit, one, square, sum_even, sum_odd, two\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        increment:\n        in:  i, limit, one, sum_even, sum_odd, two\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        exit:\n        in:  sum_even, sum_odd\n        out: ∅\n\nb. Very Busy Expression:\n        b1:\n        in:  ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        loop:\n        in:  ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        \n        even_case:\n        in:  ('add', ('i', 'one')), ('add', ('sum_even', 'square')), ('le', ('i', 'limit'))\n        out: ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        \n        odd_case:\n        in:  ('add', ('i', 'one')), ('add', ('sum_odd', 'square')), ('le', ('i', 'limit'))\n        out: ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        \n        increment:\n        in:  ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        out: ∅\n        \n        exit:\n        in:  ∅\n        out: ∅\n   \nc. Reaching Definition:\n        b1:\n        in:  ∅\n        out: ('i', 'b1'), ('limit', 'b1'), ('one', 'b1'), ('sum_even', 'b1'), ('sum_odd', 'b1'), ('two', 'b1')\n\n        loop:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n\n        even_case:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        \n        odd_case:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        \n        increment:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        \n        exit:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n\nd. Available Expression:\n        b1:\n        in:  ∅\n        out: ∅\n        \n        loop:\n        in:  ∅\n        out: ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        even_case:\n        in:  ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('sum_even', 'square')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        odd_case:\n        in:  ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('sum_odd', 'square')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        increment:\n        in:  ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        exit:\n        in:  ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))    \n\n\n\n\nOne of the most significant challenges I encountered was correctly implementing both forward and backward analysis within the same framework. This took a considerable amount of time to debug and get right.\nThe most tricky part was getting the initialization and update of the in_ and out dictionaries correct.\nInitially, I made the mistake of not properly distinguishing between in_ and out for forward and backward analyses, which led to incorrect results. After careful debugging and reexamining the theory behind data flow analysis, I was able to correct this issue.\n\n\n\nImplementing a generic data flow analysis framework was a challenging. It deepened my understanding of how different analyses work. The main steps in this assignment are:\n\nFigure out the thing you want to know at the entry and exit of a block.\nwrite an equation for every block relting to the entry and exit.\nAdd equalities according to edges in the CFGs.\nFinally, solve the system of equations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 03 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#introduction-to-data-flow-analysis-types",
    "href": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#introduction-to-data-flow-analysis-types",
    "title": "Compiler Homework 03 - Data Flow Analysis",
    "section": "",
    "text": "The four types of data flow analysis that I implemented in this project:\n\nLiveness Analysis (Backward) Liveness analysis determines which variables are “live” at each point in the program. A variable is considered live if its value may be read in the future before it’s overwritten. This is a backward analysis because it propagates information from the end of the program towards the beginning.\n\nDirection: Backward\nInitial State: Empty set\nMerge Operation: Union\n\nVery Busy Expressions Analysis (Backward) Very Busy Expressions (VBE) analysis identifies expressions that are “very busy” at each program point. An expression is very busy if it will be evaluated again before any of its operands are overwrittern. This is also a backward analysis.\n\nDirection: Backward\nInitial State: Empty set\nMerge Operation: Intersection\n\nReaching Definitions Analysis (Forward) Reaching Definitions analysis determines which definitions of variables may reach each point in the program. A definition reaches a point if there is a path from the definition to the point without any other overwrite or interven of the same variable. This is a forward analysis.\n\nDirection: Forward\nInitial State: Empty set\nMerge Operation: Union\n\nAvailable Expressions Analysis (Forward) Available Expressions analysis determines which expressions are already computed and not modified at each point in the program. An expression is available at a point if it has been computed on every path to that point and none of its operands have been redefined since its last computation. This is a forward analysis.\n\nDirection: Forward\nInitial State: Empty set (or all expressions for some formulations)\nMerge Operation: Intersection",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 03 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#the-implementation",
    "href": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#the-implementation",
    "title": "Compiler Homework 03 - Data Flow Analysis",
    "section": "",
    "text": "I decided to take on the challenge of creating a generic data flow analysis framework. Here’s a overview of the key components of my analysis:\n\nA df_worklist function that implements the worklist algorithm for data flow analysis.\nA run_df function that applies the analysis to each function in the input program.\nSeveral helper functions for set operations and formatting output.\nSpecific analysis implementations for liveness, very busy expressions (VBE), reaching definitions, and available expressions.\n\nThe core of the implementation is the df_worklist function, which can perform both forward and backward analysis based on the configuration provided:\ndef df_worklist(blocks, analysis):\n    # ... (implementation details)\nThis function takes a set of basic blocks and an analysis configuration, and returns the in and out sets for each block.\nThe analysis configuration is defined using a named tuple:\nAnalysis = namedtuple('Analysis', ['forward', 'init', 'merge', 'transfer'])\nThis allows us to easily specify different analyses by providing the appropriate parameters.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 03 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#testing-the-implementation",
    "href": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#testing-the-implementation",
    "title": "Compiler Homework 03 - Data Flow Analysis",
    "section": "",
    "text": "I tested my implementation with two examples to ensure it was working correctly.\n\nsimple.bril: In order to understand that my analysis works or not I took a simple example to test and assured that the code works for all 4 types\n\n    @main {\n    a: int = const 5;\n    b: int = const 10;\n    \n    sum: int = add a b;\n    print sum;\n    }\nAnd the output are:\na. Liveness:\n    b1:\n    in:  ∅\n    out: ∅\n\nb. Very Busy Expression:\n    b1:\n    in:  ('add', ('a', 'b'))\n    out: ∅\nc. Reaching Definition:\n    b1:\n    in:  ∅\n    out: ('a', 'b1'), ('b', 'b1'), ('sum', 'b1')\nd. Available Expression:\n    b1:\n    in:  ∅\n    out: ('add', ('a', 'b'))\n\nAdding Square of Even and Odd numbers: This is another example which has loop and check whether my analysis works or not for this example.\n\n    @main {\n    sum_even: int = const 0;      \n    sum_odd: int = const 0;       \n    i: int = const 1;             \n    limit: int = const 10;        \n    one: int = const 1;           \n    two: int = const 2;           \n\n    .loop:\n    square: int = mul i i;        \n    half: int = div i two;        \n    check: int = mul half two;    \n    is_even: bool = eq check i;   \n    br is_even .even_case .odd_case; \n\n    .even_case:\n    sum_even: int = add sum_even square; \n    jmp .increment;\n\n    .odd_case:\n    sum_odd: int = add sum_odd square;   \n\n    .increment:\n    i: int = add i one;           \n    cond: bool = le i limit;      \n    br cond .loop .exit;          \n\n    .exit:\n    print sum_even;               \n    print sum_odd;                \n    }\nAnd the output are:\na. Liveness:\n        b1:\n        in:  ∅\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        loop:\n        in:  i, limit, one, sum_even, sum_odd, two\n        out: i, limit, one, square, sum_even, sum_odd, two\n        \n        even_case:\n        in:  i, limit, one, square, sum_even, sum_odd, two\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        odd_case:\n        in:  i, limit, one, square, sum_even, sum_odd, two\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        increment:\n        in:  i, limit, one, sum_even, sum_odd, two\n        out: i, limit, one, sum_even, sum_odd, two\n        \n        exit:\n        in:  sum_even, sum_odd\n        out: ∅\n\nb. Very Busy Expression:\n        b1:\n        in:  ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        loop:\n        in:  ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        \n        even_case:\n        in:  ('add', ('i', 'one')), ('add', ('sum_even', 'square')), ('le', ('i', 'limit'))\n        out: ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        \n        odd_case:\n        in:  ('add', ('i', 'one')), ('add', ('sum_odd', 'square')), ('le', ('i', 'limit'))\n        out: ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        \n        increment:\n        in:  ('add', ('i', 'one')), ('le', ('i', 'limit'))\n        out: ∅\n        \n        exit:\n        in:  ∅\n        out: ∅\n   \nc. Reaching Definition:\n        b1:\n        in:  ∅\n        out: ('i', 'b1'), ('limit', 'b1'), ('one', 'b1'), ('sum_even', 'b1'), ('sum_odd', 'b1'), ('two', 'b1')\n\n        loop:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n\n        even_case:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        \n        odd_case:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        \n        increment:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'b1'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        \n        exit:\n        in:  ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n        out: ('check', 'loop'), ('cond', 'increment'), ('half', 'loop'), ('i', 'increment'), ('is_even', 'loop'), ('limit', 'b1'), ('one', 'b1'), ('square', 'loop'), ('sum_even', 'b1'), ('sum_even', 'even_case'), ('sum_odd', 'b1'), ('sum_odd', 'odd_case'), ('two', 'b1')\n\nd. Available Expression:\n        b1:\n        in:  ∅\n        out: ∅\n        \n        loop:\n        in:  ∅\n        out: ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        even_case:\n        in:  ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('sum_even', 'square')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        odd_case:\n        in:  ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('sum_odd', 'square')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        increment:\n        in:  ('div', ('i', 'two')), ('eq', ('check', 'i')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        \n        exit:\n        in:  ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))\n        out: ('add', ('i', 'one')), ('div', ('i', 'two')), ('eq', ('check', 'i')), ('le', ('i', 'limit')), ('mul', ('half', 'two')), ('mul', ('i', 'i'))",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 03 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#challenges-faced-forward-vs.-backward-analysis",
    "href": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#challenges-faced-forward-vs.-backward-analysis",
    "title": "Compiler Homework 03 - Data Flow Analysis",
    "section": "",
    "text": "One of the most significant challenges I encountered was correctly implementing both forward and backward analysis within the same framework. This took a considerable amount of time to debug and get right.\nThe most tricky part was getting the initialization and update of the in_ and out dictionaries correct.\nInitially, I made the mistake of not properly distinguishing between in_ and out for forward and backward analyses, which led to incorrect results. After careful debugging and reexamining the theory behind data flow analysis, I was able to correct this issue.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 03 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#conclusion",
    "href": "blogs/sharmila/2024-10-15-Sharmila-HW03.html#conclusion",
    "title": "Compiler Homework 03 - Data Flow Analysis",
    "section": "",
    "text": "Implementing a generic data flow analysis framework was a challenging. It deepened my understanding of how different analyses work. The main steps in this assignment are:\n\nFigure out the thing you want to know at the entry and exit of a block.\nwrite an equation for every block relting to the entry and exit.\nAdd equalities according to edges in the CFGs.\nFinally, solve the system of equations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Sharmila",
      "Compiler Homework 03 - Data Flow Analysis"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "I created a Brill benchmark that calculates and prints the sum of prime numbers and composite numbers up to a given input (in this case, 100). The algorithm used here is very similar to the algorithm used in sieve.bril code in the Brill benchmark folder which is designed to find and print all prime numbers up to a specified limit. It emphasizes the identification of primes through boolean flags and modular functions. Our implementation extends the algorithm to calculate the sum of primes and the sum of composites up to a specified limit. It uses an integer array to flag primes and composites and focuses on aggregating values rather than listing them.\n\n\n\nTo give a little explanation about what each part of the code does:\n\n\n@sumOfPrimes: This function calculates the sum of all prime numbers up to n. First, an array nums of size n is allocated, where each index represents whether a number is prime or composite (1 for prime, 0 for composite). Initially, all numbers are marked as prime. Starting from current = 2, the function marks the multiples of each number as composite (0), skipping prime numbers. The outer loop increments current, and the inner loop marks all multiples of current as composite. After marking non-primes, the function iterates over the array from 2 to n and sums the numbers where the value is 1 (they are prime).\n@sumOfComposites: This function calculates the sum of all composite numbers up to n. It works similarly to the sumOfPrimes function but focuses on composite numbers. The main difference is in the summing step: instead of summing primes, the function starts summing from 4 (since 1 is neither prime nor composite, and 2 and 3 are primes) and adds all numbers marked as 0 (composite).\n\n\n\n\nTo test the implementation, I used the following approach:\n\na) I ran the benchmark with different input values, starting with small numbers like 10, 20, and then larger numbers like 100.\nb) I verified the results manually for smaller inputs by calculating the expected sums of primes and composites.\nc) I used the Brill interpreter (brili) to run the benchmark and checked both the output and the number of dynamic instructions executed.\n\nQuantitative results for input 100:\n1060\n3889\n\n\n\nThe most challenging part was handling the inner and outer loops in the Bril format, especially managing control flow with branches (br) and jumps (jmp). In Bril, control flow is more explicit than in higher-level languages, and ensuring proper transitions between loop bodies and loop conditions while avoiding infinite loops or incorrect logic was complex.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "To give a little explanation about what each part of the code does:\n\n\n@sumOfPrimes: This function calculates the sum of all prime numbers up to n. First, an array nums of size n is allocated, where each index represents whether a number is prime or composite (1 for prime, 0 for composite). Initially, all numbers are marked as prime. Starting from current = 2, the function marks the multiples of each number as composite (0), skipping prime numbers. The outer loop increments current, and the inner loop marks all multiples of current as composite. After marking non-primes, the function iterates over the array from 2 to n and sums the numbers where the value is 1 (they are prime).\n@sumOfComposites: This function calculates the sum of all composite numbers up to n. It works similarly to the sumOfPrimes function but focuses on composite numbers. The main difference is in the summing step: instead of summing primes, the function starts summing from 4 (since 1 is neither prime nor composite, and 2 and 3 are primes) and adds all numbers marked as 0 (composite).",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "To test the implementation, I used the following approach:\n\na) I ran the benchmark with different input values, starting with small numbers like 10, 20, and then larger numbers like 100.\nb) I verified the results manually for smaller inputs by calculating the expected sums of primes and composites.\nc) I used the Brill interpreter (brili) to run the benchmark and checked both the output and the number of dynamic instructions executed.\n\nQuantitative results for input 100:\n1060\n3889",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced",
    "title": "Homework1 - Sana",
    "section": "",
    "text": "The most challenging part was handling the inner and outer loops in the Bril format, especially managing control flow with branches (br) and jumps (jmp). In Bril, control flow is more explicit than in higher-level languages, and ensuring proper transitions between loop bodies and loop conditions while avoiding infinite loops or incorrect logic was complex.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#explanation-of-the-code-1",
    "title": "Homework1 - Sana",
    "section": "Explanation of the Code",
    "text": "Explanation of the Code\nThe code first iterates through each function in the program using the outer loop. Inside the function, the inner loop goes through each instruction. For each instruction, it increments the instruction count and checks if the instruction is a jump (br or jmp). If it is, a print instruction is added before the jump.\n\nimport json\nimport copy\n\nbril_json = \"\"\"\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\", \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"br\", \"args\": [\"v2\"], \"labels\": [\"then\", \"else\"] },\n        { \"label\": \"then\" },\n        { \"op\": \"print\", \"args\": [\"v2\"] },\n        { \"op\": \"jmp\", \"labels\": [\"end\"] },\n        { \"label\": \"else\" },\n        { \"op\": \"print\", \"args\": [\"v1\"] },\n        { \"label\": \"end\" },\n        { \"op\": \"ret\" }\n      ]\n    }\n  ]\n}\n\"\"\"\n\nbril_program = json.loads(bril_json)\n\ndef process_bril_program(bril_program):\n    total_instructions = 0\n    for function in bril_program['functions']:\n        new_instrs = []\n        for instruction in function['instrs']:\n            total_instructions += 1\n            \n            # add a print instruction before a jump!\n            if instruction.get('op') in ['br', 'jmp']:\n                print_instr = {\n                    \"op\": \"print\",\n                    \"args\": [\"Jumping\"]\n                }\n                new_instrs.append(print_instr)\n            \n            new_instrs.append(instruction)\n        \n        function['instrs'] = new_instrs\n\n    return bril_program, total_instructions\n\nmodified_program, instruction_count = process_bril_program(bril_program)\n\nprint(\"Total number of instructions:\", instruction_count)\nprint(\"Modified Bril program:\")\nprint(json.dumps(modified_program, indent=2))\n\nTotal number of instructions: 11\nModified Bril program:\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"Jumping\"\n          ]\n        },\n        {\n          \"op\": \"br\",\n          \"args\": [\n            \"v2\"\n          ],\n          \"labels\": [\n            \"then\",\n            \"else\"\n          ]\n        },\n        {\n          \"label\": \"then\"\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"Jumping\"\n          ]\n        },\n        {\n          \"op\": \"jmp\",\n          \"labels\": [\n            \"end\"\n          ]\n        },\n        {\n          \"label\": \"else\"\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v1\"\n          ]\n        },\n        {\n          \"label\": \"end\"\n        },\n        {\n          \"op\": \"ret\"\n        }\n      ]\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested-1",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#how-the-implementation-is-tested-1",
    "title": "Homework1 - Sana",
    "section": "How the Implementation is Tested",
    "text": "How the Implementation is Tested\nTo test the implementation, I created a small Bril program called test.json that contains various types of instructions, including constants, an add operation, a branch instruction (br), a jump instruction (jmp), and print statements. I used this file to verify that the transformation was applied correctly and that the total number of instructions was counted.\nTest Input (test.json):\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\", \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"br\", \"args\": [\"v2\"], \"labels\": [\"then\", \"else\"] },\n        { \"label\": \"then\" },\n        { \"op\": \"print\", \"args\": [\"v2\"] },\n        { \"op\": \"jmp\", \"labels\": [\"end\"] },\n        { \"label\": \"else\" },\n        { \"op\": \"print\", \"args\": [\"v1\"] },\n        { \"label\": \"end\" },\n        { \"op\": \"ret\" }\n      ]\n    }\n  ]\n}\n\nOutput of The program is shown in previous section.\nQuantitative Results: The total number of instructions before the transformation was 11. After transformation, 2 print instructions were added (one before the br and another before the jmp), making the total number of instructions 13. (We can conclude this by counting the instructions in the modified Bril program)",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced-1",
    "href": "blogs/09-20-2024-HW1-SanaTaghipourAnvari.html#challenges-faced-1",
    "title": "Homework1 - Sana",
    "section": "Challenges Faced",
    "text": "Challenges Faced\nThe most challenging part of the task was ensuring that the additional instructions were inserted in the correct place without modifying the logic of the Bril program. The Bril program must still execute in the intended order, and placing the print instructions incorrectly could have changed the control flow. To address this challenge, I carefully looped through the instruction list, checked for br and jmp operations, and inserted the print instructions before each of these jump-related instructions by also maintaining the program’s original flow and semantics.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Homework1 - Sana"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html",
    "title": "Homework 1: Exploring Bril",
    "section": "",
    "text": "For this assignment, I explored the Bril intermediate representation and wrote a new benchmark along with a tool to analyze and transform Bril programs.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#introduction",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#introduction",
    "title": "Homework 1: Exploring Bril",
    "section": "",
    "text": "For this assignment, I explored the Bril intermediate representation and wrote a new benchmark along with a tool to analyze and transform Bril programs.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#detail-design",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#detail-design",
    "title": "Homework 1: Exploring Bril",
    "section": "Detail Design",
    "text": "Detail Design\nThe homework was divided into two main parts. I’ll walk through the details of my implementation, challenges faced, and the testing process.\n\nPart 1: Creating and Running a New Benchmark\nPart 2: Implementing a Bril Program Stub-Analyzer",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#conclusion",
    "href": "blogs/Qucheng/2024-09-20-Qucheng-HW1.html#conclusion",
    "title": "Homework 1: Exploring Bril",
    "section": "Conclusion",
    "text": "Conclusion\nThis assignment provided a comprehensive introduction to Bril and its tooling ecosystem. By creating benchmarks and developing a custom analyzer, I gained insights into compiler design and intermediate representations.\nHardest Part: The most challenging aspect was managing dependencies and environment setup for the Bril toolchain. Careful attention to the makefile and troubleshooting through GitHub Discussions helped overcome these issues.\nTesting and Results: I validated my benchmarks and analyzer using various Bril programs. The tools successfully transformed and analyzed the input programs, demonstrating the utility of Bril in simple code analysis and transformation tasks.\nThis experience has equipped me with practical skills in working with compiler tools and representations, paving the way for more complex analyses in future assignments.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 1: Exploring Bril"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "",
    "text": "This assignment aims to implement two key local optimizations for the Bril intermediate language: Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN). These optimizations enhance the efficiency of Bril programs by removing unnecessary instructions and consolidating equivalent expressions. This report outlines the development process, testing methodology, and analysis of the implemented optimizations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#introduction",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#introduction",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "",
    "text": "This assignment aims to implement two key local optimizations for the Bril intermediate language: Trivial Dead Code Elimination (DCE) and Local Value Numbering (LVN). These optimizations enhance the efficiency of Bril programs by removing unnecessary instructions and consolidating equivalent expressions. This report outlines the development process, testing methodology, and analysis of the implemented optimizations.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#detail-design",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#detail-design",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Detail Design",
    "text": "Detail Design\nCode: For details, check the code repository.\n\nAbstraction Classes\nThe core of the Bril language representation in this project is implemented in the bril_model/_bril_struct.py file. This module provides a structured and object-oriented way to represent Bril programs (BrilScript), functions (BrilFunction), and instructions (BrilInstruction). Each Bril instruction is modeled as a Python object, enabling intuitive manipulation and transformation of the program during optimization.\nThe primary classes include:\nBril Program: Represents the entire Bril program, containing multiple functions.\nBril Function: Encapsulates a sequence of instructions and metadata for a function within the program.\nBril Instruction: Models individual instructions, differentiating between operations (e.g., addition, multiplication) and effectful statements (e.g., print).\nFirst, the BrilInstruction class is the base class for all instructions. Its constructor accepts a dictionary raw and deeply copies its contents into the instance variable _raw. It also initializes a mark dictionary _marks to track whether the instruction has been deleted, modified, or replaced. The constructor also checks whether the key in the raw dictionary is in the allowed key set AVAILABLE_KEYS, and throws NotImplementedError if there is an unrecognized key. The class also defines a series of properties and methods for accessing and modifying various parts of the instruction, such as dest, type, op, args, etc.\nNext are several subclasses inherited from BrilInstruction, which handle different types of instructions. The BrilInstruction_Const class is used to handle constant instructions. It checks whether the opcode is const in the constructor and verifies whether the key in the dictionary is in the allowed set. The BrilInstruction_Label class is used to handle label instructions. It checks whether the label exists in the constructor and verifies the key in the dictionary. The BrilInstruction_ValOp class is used to handle operation instructions with a return value. It checks whether the opcode is in the allowed set and verifies the key in the dictionary in the constructor. The BrilInstruction_EffOp class is used to handle operation instructions without a return value. It performs similar checks and verifications in the constructor.\nThe BrilFunction class is used to represent a Bril function. Its constructor accepts a dictionary raw and extracts the instruction list instrs from it, converting each instruction into a corresponding BrilInstruction subclass instance. It also checks whether the key in the dictionary is in the allowed set. The class also defines some properties and methods for accessing and modifying various parts of the function, such as name, type, args, etc.\nFinally, the BrilScript class is used to represent a Bril script. Its constructor accepts a dictionary raw and extracts the function list functions from it, converting each function into a BrilFunction instance. It also checks whether the key in the dictionary is in the allowed set. The class also defines some properties and methods for accessing and modifying various parts of the script, such as functions, etc.\nTogether, these classes form a framework for processing Bril language instructions and scripts, providing a wealth of properties and methods to access and modify various parts of instructions and scripts.\n\n\nTrivial Dead Code Elimination (DCE)\nThe Trivial-DCE implementation is encapsulated in tdce.py. This script scans through the instructions of a Bril function and removes any instructions whose results are not used before being overwritten. The optimization process involves:\nThe trivial_dce_once function performs a dead code elimination operation. It traverses all instructions in the function, collects all used variables, and marks unused instructions for deletion. Then, it updates the function’s instruction list, deletes the instructions marked for deletion, and returns a Boolean value indicating whether the instruction is deleted.\nThe trivial_dce function is a loop that repeatedly calls the trivial_dce_once function until no more instructions are deleted.\nThe _block_mark_reassign_before_use function deletes instructions that are reassigned before use within a single basic block. It maintains a dictionary to track the most recent unused assignment instructions and deletes old assignment instructions before reassignment is found.\nThe rm_reassign_before_use function traverses all basic blocks of the function, calls the _block_mark_reassign_before_use function to delete instructions that are reassigned before use, and updates the function’s instruction list.\nThe trivial_dce_plus function combines function-level dead code elimination with instruction removal before reassignment until there are no more instructions to remove.\nThis straightforward approach efficiently eliminates redundant calculations, contributing to a cleaner and faster program.\n\n\nLocal Value Numbering (LVN)\nLocal Value Numbering optimization is implemented in lvn.py, LVN assigns unique numbers to distinct computations to detect and eliminate redundant expressions within a single block. Key steps include:\nNumbering Expressions: LVN assigns a unique identifier to each distinct computation. This identifier, or value number, is used to track expressions within a block. If an identical computation is encountered later, the existing value number is reused, eliminating the need to recompute the expression. For example, if the expression a + b is already computed and assigned a value number, any subsequent occurrence of a + b will directly use the same value number instead of recalculating the result.\nSimplification and Substitution: The script replaces redundant operations with precomputed values or previously assigned variables, reducing the number of cpu-intense operations in the block. This is done by looking up the value number table for existing computations and substituting them wherever possible. By minimizing redundant calculations, LVN not only optimizes runtime performance but also simplifies the code.\nConstant Folding: Constant folding is a compile-time optimization technique that evaluates expressions with known constant values. For instance, an expression like const 2 + const 3 is directly replaced with const 5. In the script, a dictionary named FOLDABLE_OPS maps operation names (e.g., add, mul, sub) to their respective lambda functions that perform the computation. When the LVN process encounters an expression with constant arguments, it applies the corresponding function to compute the result immediately. Credit: Bril Official Example\nExpression Tracking and Reuse: An Expr class is defined to uniquely represent computations in terms of operations and their arguments. This allows the LVN process to easily check if a computation has been previously performed and reuse the result if possible. The implementation also handles commutative operations (e.g., add, mul, and, or, eq) by normalizing the order of arguments, ensuring that expressions like a + b and b + a are recognized as identical.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#integration-and-testing",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#integration-and-testing",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Integration and Testing",
    "text": "Integration and Testing\nThe brench tool is used for batch testing both optimizations across a variety of Bril programs. The brench_test_lvn.toml and brench_test_tdce.toml configuration files specify the programs and expected results for LVN and DCE tests, respectively. This ensures that both optimizations work correctly and consistently.\nAs defined in brench_test_lvn.toml, we specifies the path to the Bril benchmark programs to be tested, which are all the *.bril located in the ../bril/benchmarks/core/.\nThe configuration file defines multiple test run pipelines, each of which is defined in the [runs.&lt;name&gt;] section. Each pipeline contains a pipeline field that lists the sequence of commands to be executed.\nThe baseline pipeline is a baseline test without any optimization. It first converts the Bril program to JSON format and then runs the program using the brili interpreter.\nThe hw2p1_s0 pipeline is used to test whether the input and output structures are correct, but it does not perform any optimization. The purpose of this pipeline is to test if the Bril Construction work has no bug in it.\nThe hw2p1_s1 pipeline tests simple dead code elimination optimization. It calls the tdce.py script and passes the tdce parameter to enable function-level dead code elimination.\nThe hw2p1_s2 pipeline tests the instruction removal optimization used before revalue. It calls the tdce.py script and passes the raby argument to enable the rm_reassign_before_use pass optimization.\nThe hw2p1_s3 pipeline combines function-level dead code elimination and instruction removal optimization used before revalue. It calls the tdce.py script and passes the tdce+ argument to enable both optimizations.\nEach pipeline ultimately runs the optimized Bril program using the brili interpreter, passing arguments via the -p {args} option.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#results-and-analysis",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#results-and-analysis",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Results and Analysis",
    "text": "Results and Analysis\nThe optimizations were tested using brench tool, which verifies the correctness and performance of the implemented passes. The tool checks the brili Standard Output (STDOUT) for each test specification to ensure that the optimized programs produce the same results as their unoptimized counterparts. This rigorous testing confirms that the optimization passes do not alter the semantics of the Bril programs.\nThe testing demonstrated significant improvements in reducing the number of executed instructions for each Bril program. Programs with redundant calculations and unused instructions were simplified, leading to a reduced instruction count and faster execution times (based on Instructions Executed reported by brili -p).\nFor example, in the original benchmark check-primes, the program required 8,468 instructions to complete its execution. After applying the hw2p1_s3 optimization pipeline (DCE-only), the number of instructions executed was reduced to 8,419. Furthermore, using the hw2p2_s2 optimization pipeline (LVN+DCE), the total instructions executed dropped significantly to 4,238, representing a reduction to 50.05% of the original execution time. This demonstrates the substantial impact of combining LVN and DCE optimizations on program efficiency.\n\nRaw test log\n❯ brench brench_test_tdce.toml\nbenchmark,run,result\nfact,baseline,229\nfact,hw2p1_s0,229\nfact,hw2p1_s1,228\nfact,hw2p1_s2,229\nfact,hw2p1_s3,228\nquadratic,baseline,785\nquadratic,hw2p1_s0,785\nquadratic,hw2p1_s1,783\nquadratic,hw2p1_s2,785\nquadratic,hw2p1_s3,783\nrecfact,baseline,104\nrecfact,hw2p1_s0,104\nrecfact,hw2p1_s1,103\nrecfact,hw2p1_s2,104\nrecfact,hw2p1_s3,103\npascals-row,baseline,146\npascals-row,hw2p1_s0,146\npascals-row,hw2p1_s1,139\npascals-row,hw2p1_s2,146\npascals-row,hw2p1_s3,139\nloopfact,baseline,116\nloopfact,hw2p1_s0,116\nloopfact,hw2p1_s1,115\nloopfact,hw2p1_s2,116\nloopfact,hw2p1_s3,115\nsum-sq-diff,baseline,3038\nsum-sq-diff,hw2p1_s0,3038\nsum-sq-diff,hw2p1_s1,3036\nsum-sq-diff,hw2p1_s2,3038\nsum-sq-diff,hw2p1_s3,3036\nbirthday,baseline,484\nbirthday,hw2p1_s0,484\nbirthday,hw2p1_s1,483\nbirthday,hw2p1_s2,484\nbirthday,hw2p1_s3,483\nmod_inv,baseline,558\nmod_inv,hw2p1_s0,558\nmod_inv,hw2p1_s1,555\nmod_inv,hw2p1_s2,558\nmod_inv,hw2p1_s3,555\ncheck-primes,baseline,8468\ncheck-primes,hw2p1_s0,8468\ncheck-primes,hw2p1_s1,8419\ncheck-primes,hw2p1_s2,8468\ncheck-primes,hw2p1_s3,8419\nbitwise-ops,baseline,1690\nbitwise-ops,hw2p1_s0,1690\nbitwise-ops,hw2p1_s1,1689\nbitwise-ops,hw2p1_s2,1690\nbitwise-ops,hw2p1_s3,1689\nrelative-primes,baseline,1923\nrelative-primes,hw2p1_s0,1923\nrelative-primes,hw2p1_s1,1914\nrelative-primes,hw2p1_s2,1923\nrelative-primes,hw2p1_s3,1914\neuclid,baseline,563\neuclid,hw2p1_s0,563\neuclid,hw2p1_s1,562\neuclid,hw2p1_s2,563\neuclid,hw2p1_s3,562\nprimes-between,baseline,574100\nprimes-between,hw2p1_s0,574100\nprimes-between,hw2p1_s1,574100\nprimes-between,hw2p1_s2,574100\nprimes-between,hw2p1_s3,574100\nsum-check,baseline,5018\nsum-check,hw2p1_s0,5018\nsum-check,hw2p1_s1,5018\nsum-check,hw2p1_s2,5018\nsum-check,hw2p1_s3,5018\narmstrong,baseline,133\narmstrong,hw2p1_s0,133\narmstrong,hw2p1_s1,130\narmstrong,hw2p1_s2,133\narmstrong,hw2p1_s3,130\n\n❯ brench brench_test_lvn.toml\nbenchmark,run,result\nfact,baseline,229\nfact,hw2p2_s1,229\nfact,hw2p2_s2,167\nis-decreasing,baseline,127\nis-decreasing,hw2p2_s1,127\nis-decreasing,hw2p2_s2,123\nquadratic,baseline,785\nquadratic,hw2p2_s1,785\nquadratic,hw2p2_s2,500\nrecfact,baseline,104\nrecfact,hw2p2_s1,104\nrecfact,hw2p2_s2,64\nfizz-buzz,baseline,3652\nfizz-buzz,hw2p2_s1,3652\nfizz-buzz,hw2p2_s2,2103\npascals-row,baseline,146\npascals-row,hw2p2_s1,146\npascals-row,hw2p2_s2,68\nloopfact,baseline,116\nloopfact,hw2p2_s1,116\nloopfact,hw2p2_s2,78\nreverse,baseline,46\nreverse,hw2p2_s1,46\nreverse,hw2p2_s2,38\nsum-sq-diff,baseline,3038\nsum-sq-diff,hw2p2_s1,3038\nsum-sq-diff,hw2p2_s2,1717\nbirthday,baseline,484\nbirthday,hw2p2_s1,484\nbirthday,hw2p2_s2,278\nmod_inv,baseline,558\nmod_inv,hw2p2_s1,558\nmod_inv,hw2p2_s2,304\ncheck-primes,baseline,8468\ncheck-primes,hw2p2_s1,8468\ncheck-primes,hw2p2_s2,4238\nbitwise-ops,baseline,1690\nbitwise-ops,hw2p2_s1,1690\nbitwise-ops,hw2p2_s2,1689\nrelative-primes,baseline,1923\nrelative-primes,hw2p2_s1,1923\nrelative-primes,hw2p2_s2,1207\neuclid,baseline,563\neuclid,hw2p2_s1,563\neuclid,hw2p2_s2,272\nprimes-between,baseline,574100\nprimes-between,hw2p2_s1,574100\nprimes-between,hw2p2_s2,571439\nperfect,baseline,232\nperfect,hw2p2_s1,232\nperfect,hw2p2_s2,231\nbitshift,baseline,167\nbitshift,hw2p2_s1,167\nbitshift,hw2p2_s2,104\nsum-check,baseline,5018\nsum-check,hw2p2_s1,5018\nsum-check,hw2p2_s2,5018\narmstrong,baseline,133\narmstrong,hw2p2_s1,133\narmstrong,hw2p2_s2,130",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#conclusion",
    "href": "blogs/Qucheng/2024-09-27-Qucheng-HW2.html#conclusion",
    "title": "Homework 2: Optimizing with DCE and LVN",
    "section": "Conclusion",
    "text": "Conclusion\nThe implementation successfully optimizes Bril programs through Trivial Dead Code Elimination and Local Value Numbering. Both techniques were integrated and tested using brench, confirming their effectiveness. Future work could focus on extending these optimizations to handle more complex cases, such as multi-block programs and interprocedural optimizations.\nThis project demonstrates the power of local optimizations in streamlining intermediate representations and serves as a solid foundation for further exploration of compiler optimization techniques.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Qucheng",
      "Homework 2: Optimizing with DCE and LVN"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "I created a program that iterates through an array of values both suming and multiplying the values.\n\n\nthe code was written in text forma ns used a pointer to initialize the array. store and load instructions were used to access the array and .loop with a jmp was used for the iterations\n\n\n\nThe code was tested with different size arrays with the answers check using an external calculator.\n\n\n\nThe main challenge for this was finding the best way to populate the array with values. brili is very simple and using just stores and loads to index into the array gave added complexity.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#about-the-code",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "the code was written in text forma ns used a pointer to initialize the array. store and load instructions were used to access the array and .loop with a jmp was used for the iterations",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#testing",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#testing",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "The code was tested with different size arrays with the answers check using an external calculator.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#challenges",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#challenges",
    "title": "Homework1 - Yashaswini",
    "section": "",
    "text": "The main challenge for this was finding the best way to populate the array with values. brili is very simple and using just stores and loads to index into the array gave added complexity.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#python-tool",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#python-tool",
    "title": "Homework1 - Yashaswini",
    "section": "Python Tool",
    "text": "Python Tool\nThe python tool was run on the a new add.json file based off of my benchmark from part 1\nimport json\n\ndef load_bril_program(filename):\n    \"\"\"Load the Bril program from a JSON file.\"\"\"\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef count_add_instructions(program):\n    \"\"\"Count the number of 'add' instructions in the Bril program.\"\"\"\n    add_count = 0\n    for func in program['functions']:\n        for instr in func['instrs']:\n            if instr.get('op') == 'add':\n                add_count += 1\n    return add_count\n\ndef add_print_before_jumps(program):\n    \"\"\"Insert a 'print' instruction before every 'jmp' instruction.\"\"\"\n    for func in program['functions']:\n        new_instrs = []\n        for instr in func['instrs']:\n            if instr.get('op') == 'jmp':\n                # Add a print instruction before the jump\n                new_instr = {\n                    \"op\": \"print\",\n                    \"args\": [\"jmp\"]\n                }\n                new_instrs.append(new_instr)\n            new_instrs.append(instr)\n        func['instrs'] = new_instrs\n    return program\n\ndef save_bril_program(program, filename):\n    \"\"\"Save the transformed Bril program back to a JSON file.\"\"\"\n    with open(filename, 'w') as file:\n        json.dump(program, file, indent=2)\n\n# Main function to load, transform, and save the Bril program\ndef main():\n    # Load the Bril program from a file\n    bril_program = load_bril_program('add.json')\n\n    # Count the number of 'add' instructions\n    add_count = count_add_instructions(bril_program)\n    print(f\"Number of 'add' instructions: {add_count}\")\n\n    # Add 'print' before 'jmp' instructions\n    transformed_program = add_print_before_jumps(bril_program)\n\n    # Save the transformed Bril program to a file\n    save_bril_program(transformed_program, 'output_add.json')\n\n# Run the main function\nif __name__ == \"__main__\":\n    main()",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#output",
    "href": "blogs/yashaswini/09-20-2024-HW1-YashaswiniMakaram.html#output",
    "title": "Homework1 - Yashaswini",
    "section": "Output",
    "text": "Output\nthe program found 2 add instrucitons and produced and output file shown below\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\n          \"dest\": \"c5\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 5\n        },\n        {\n          \"args\": [\n            \"c5\"\n          ],\n          \"dest\": \"v0\",\n          \"op\": \"alloc\",\n          \"type\": {\n            \"ptr\": \"int\"\n          }\n        },\n        {\n          \"dest\": \"j\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 1\n        },\n        {\n          \"dest\": \"c1\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 1\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c1\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c2\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 2\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c3\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 3\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c4\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 4\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"c5\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 5\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"c2\"\n          ],\n          \"op\": \"store\"\n        },\n        {\n          \"dest\": \"sum\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 0\n        },\n        {\n          \"dest\": \"i\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 0\n        },\n        {\n          \"label\": \"loop\"\n        },\n        {\n          \"args\": [\n            \"i\",\n            \"c5\"\n          ],\n          \"dest\": \"cond\",\n          \"op\": \"lt\",\n          \"type\": \"bool\"\n        },\n        {\n          \"args\": [\n            \"cond\"\n          ],\n          \"labels\": [\n            \"body\",\n            \"end\"\n          ],\n          \"op\": \"br\"\n        },\n        {\n          \"label\": \"body\"\n        },\n        {\n          \"args\": [\n            \"v0\"\n          ],\n          \"dest\": \"current\",\n          \"op\": \"load\",\n          \"type\": \"int\"\n        },\n        {\n          \"args\": [\n            \"sum\",\n            \"current\"\n          ],\n          \"dest\": \"sum\",\n          \"op\": \"add\",\n          \"type\": \"int\"\n        },\n        {\n          \"args\": [\n            \"i\",\n            \"j\"\n          ],\n          \"dest\": \"i\",\n          \"op\": \"add\",\n          \"type\": \"int\"\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"jmp\"\n          ]\n        },\n        {\n          \"labels\": [\n            \"loop\"\n          ],\n          \"op\": \"jmp\"\n        },\n        {\n          \"label\": \"end\"\n        },\n        {\n          \"args\": [\n            \"sum\"\n          ],\n          \"op\": \"print\"\n        },\n        {\n          \"args\": [\n            \"v0\"\n          ],\n          \"op\": \"free\"\n        },\n        {\n          \"op\": \"ret\"\n        }\n      ],\n      \"name\": \"main\"\n    }\n  ]\n}\n##Testing\na good way to otest this is using small scripts where the number of adds is known or can be calculates.\nI could also develop a tool to reverse the addition of prints before jmp and compare the output to the original code using turnt.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework1 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html",
    "title": "Homework4 - Yashaswini",
    "section": "",
    "text": "#Dominator Computation (find_dominators):\n\nThis function initializes all nodes to be dominated by every other node. Then, using an iterative approach, it refines the set of dominators until convergence.\nThe entry node is assumed to be node 0, and it dominates itself.\nThe dominators of each node are found by intersecting the dominator sets of its predecessors and adding the node itself.\n\n#Dominance Tree Construction (construct_dominance_tree):\n\nThis function builds the dominance tree from the dominator sets.\nFor each node, the immediate dominator (idom) is the node with the highest index in its dominator set that isn’t itself. The tree is constructed using these relationships.\n\n#Dominance Frontier Computation (compute_dominance_frontier):\n\nThe dominance frontier of a node is the set of nodes where the node dominates one of their predecessors but does not strictly dominate the node itself.\nThis is computed using the reverse of the CFG and the dominator sets.\n\nimport json\nfrom collections import defaultdict\n\ndef load_bril_program(filename):\n    \"\"\"Load the Bril program from a JSON file.\"\"\"\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef build_cfg(function):\n    \"\"\"Build the Control Flow Graph (CFG) for a given function.\"\"\"\n    instrs = function['instrs']\n    cfg = defaultdict(list)\n    label_map = {}\n\n    # Map labels to instruction indices\n    for i, instr in enumerate(instrs):\n        if 'label' in instr:\n            label_map[instr['label']] = i\n\n    for i, instr in enumerate(instrs):\n        if 'op' in instr and instr['op'] == 'jmp':\n            target = label_map[instr['labels'][0]]\n            cfg[i].append(target)\n        elif 'op' in instr and instr['op'] == 'br':\n            target1 = label_map[instr['labels'][0]]\n            target2 = label_map[instr['labels'][1]]\n            cfg[i].extend([target1, target2])\n        else:\n            # Fall-through case: connect to the next instruction\n            if i + 1 &lt; len(instrs):\n                cfg[i].append(i + 1)\n\n    return cfg\n\ndef reverse_cfg(cfg):\n    \"\"\"Compute the reverse of the CFG.\"\"\"\n    reverse = defaultdict(list)\n    for node, successors in cfg.items():\n        for succ in successors:\n            reverse[succ].append(node)\n    return reverse\n\ndef find_dominators(function):\n    \"\"\"Find the dominators for each node in the function.\"\"\"\n    cfg = build_cfg(function)\n    nodes = set(cfg.keys())\n    entry = min(nodes)#0  # Assuming the entry node is at index 0\n    dom = {node: nodes.copy() for node in nodes}\n    dom[entry] = {entry}\n\n    changed = True\n    while changed:\n        changed = False\n        for node in nodes - {entry}:\n            #new_dom = set.intersection(*(dom[pred] for pred in reverse_cfg(cfg)[node])) | {node}\n            preds = reverse_cfg(cfg)[node]\n            if preds:\n                # Compute intersection only if there are predecessors\n                new_dom = set.intersection(*(dom[pred] for pred in preds)) | {node}\n            else:\n                # If no predecessors, the dominators are just the node itself\n                new_dom = {node}\n            if dom[node] != new_dom:\n                dom[node] = new_dom\n                changed = True\n\n    return dom\n\ndef construct_dominance_tree(dominators):\n    \"\"\"Construct the dominance tree from the dominators.\"\"\"\n    tree = defaultdict(list)\n    for node, dom_set in dominators.items():\n        if node != min(dom_set):\n            idom = max(dom_set - {node})\n            tree[idom].append(node)\n    return tree\n\ndef compute_dominance_frontier(function, dominators):\n    \"\"\"Compute the dominance frontier for each node.\"\"\"\n    cfg = build_cfg(function)\n    df = defaultdict(set)\n\n    for node in cfg:\n        preds = reverse_cfg(cfg)[node]\n        if len(preds) &gt;= 2:\n            for pred in preds:\n                runner = pred\n                while runner not in dominators[node]:\n                    df[runner].add(node)\n                    #runner = max(dominators[runner] - {runner})\n                    if dominators[runner] - {runner}:\n                        runner = max(dominators[runner] - {runner})\n                    else:\n                        break  # If no other dominators, exit the loop\n\n    return df\n\ndef test_dominance_utilities(function):\n    \"\"\"Test the dominance utilities for a given function.\"\"\"\n    print(f\"Testing function: {function['name']}\")\n    dominators = find_dominators(function)\n    print(f\"Dominators: {dominators}\")\n\n    dominance_tree = construct_dominance_tree(dominators)\n    print(f\"Dominance Tree: {dominance_tree}\")\n\n    dominance_frontier = compute_dominance_frontier(function, dominators)\n    print(f\"Dominance Frontier: {dominance_frontier}\")\n\ndef main():\n    # Load the Bril program from a file\n    #bril_program = load_bril_program('input_bril.json')\n    for bril_program in bril_programs:\n    # Run the tests\n        for function in bril_program['functions']:\n            test_dominance_utilities(function)\n\n# Run the main function\nif __name__ == \"__main__\":\n    main()\n\n\n\nI implemented 8 test cases each targeting a different type of CFG. I then manually checked the against the outputs produced by the code. I had to make some changes when the code was unable to handle empty sets but after the output seems to be work correctly\n\n\n\nThe hardest part of this task was understanding ensuring that the algorithm i used could handle various data flow types.\nOnce I was able to get the code to work for both independent branches and nested branches it became much easier.\n\n\n\nHere are the test cases used and the output from the function after running all of the test cases.\n#Simple Linear Sequence A program with a single linear sequence of instructions. No branches or loops.\n{\n  \"functions\": [\n    {\n      \"name\": \"linear\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"a\", \"type\": \"int\", \"value\": 1},\n        {\"op\": \"add\", \"dest\": \"b\", \"type\": \"int\", \"args\": [\"a\", \"a\"]},\n        {\"op\": \"mul\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"b\", \"a\"]},\n        {\"label\": \"exit\"}\n      ]\n    }\n  ]\n}\n\n#Simple Branch - A conditional branch leading to two different paths and joining back together.\n{\n  \"functions\": [\n    {\n      \"name\": \"branch\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"x\", \"type\": \"int\", \"value\": 5},\n        {\"op\": \"const\", \"dest\": \"y\", \"type\": \"int\", \"value\": 10},\n        {\"op\": \"br\", \"args\": [\"x\"], \"labels\": [\"true_branch\", \"false_branch\"]},\n        {\"label\": \"true_branch\"},\n        {\"op\": \"add\", \"dest\": \"z\", \"type\": \"int\", \"args\": [\"x\", \"y\"]},\n        {\"op\": \"jmp\", \"labels\": [\"join\"]},\n        {\"label\": \"false_branch\"},\n        {\"op\": \"sub\", \"dest\": \"z\", \"type\": \"int\", \"args\": [\"y\", \"x\"]},\n        {\"label\": \"join\"},\n        {\"op\": \"mul\", \"dest\": \"w\", \"type\": \"int\", \"args\": [\"z\", \"x\"]}\n      ]\n    }\n  ]\n}\n\n#Loop with Back Edge -A basic loop where a variable is incremented until a condition is met.\n{\n  \"functions\": [\n    {\n      \"name\": \"loop\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"i\", \"type\": \"int\", \"value\": 0},\n        {\"label\": \"loop_start\"},\n        {\"op\": \"lt\", \"dest\": \"cond\", \"type\": \"bool\", \"args\": [\"i\", \"10\"]},\n        {\"op\": \"br\", \"args\": [\"cond\"], \"labels\": [\"body\", \"exit\"]},\n        {\"label\": \"body\"},\n        {\"op\": \"add\", \"dest\": \"i\", \"type\": \"int\", \"args\": [\"i\", \"1\"]},\n        {\"op\": \"jmp\", \"labels\": [\"loop_start\"]},\n        {\"label\": \"exit\"}\n      ]\n    }\n  ]\n}\n#Nested Branches -Two nested conditional branches.\n{\n  \"functions\": [\n    {\n      \"name\": \"nested_branches\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"a\", \"type\": \"int\", \"value\": 1},\n        {\"op\": \"const\", \"dest\": \"b\", \"type\": \"int\", \"value\": 2},\n        {\"op\": \"br\", \"args\": [\"a\"], \"labels\": [\"branch1\", \"merge\"]},\n        {\"label\": \"branch1\"},\n        {\"op\": \"br\", \"args\": [\"b\"], \"labels\": [\"branch2\", \"merge\"]},\n        {\"label\": \"branch2\"},\n        {\"op\": \"mul\", \"dest\": \"x\", \"type\": \"int\", \"args\": [\"a\", \"b\"]},\n        {\"op\": \"jmp\", \"labels\": [\"merge\"]},\n        {\"label\": \"merge\"},\n        {\"op\": \"add\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"a\", \"b\"]}\n      ]\n    }\n  ]\n}\n#Multiple Independent Branches - A program with two independent branches and a join.\n{\n  \"functions\": [\n    {\n      \"name\": \"independent_branches\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"a\", \"type\": \"int\", \"value\": 3},\n        {\"op\": \"const\", \"dest\": \"b\", \"type\": \"int\", \"value\": 6},\n        {\"op\": \"br\", \"args\": [\"a\"], \"labels\": [\"branch1\", \"merge\"]},\n        {\"label\": \"branch1\"},\n        {\"op\": \"add\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"a\", \"b\"]},\n        {\"op\": \"jmp\", \"labels\": [\"merge\"]},\n        {\"label\": \"branch2\"},\n        {\"op\": \"sub\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"b\", \"a\"]},\n        {\"op\": \"jmp\", \"labels\": [\"merge\"]},\n        {\"label\": \"merge\"},\n        {\"op\": \"mul\", \"dest\": \"d\", \"type\": \"int\", \"args\": [\"c\", \"a\"]}\n      ]\n    }\n  ]\n}\n#Simple Two-Way Loop - A loop with a branch that exits early based on a condition.\n{\n  \"functions\": [\n    {\n      \"name\": \"two_way_loop\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"x\", \"type\": \"int\", \"value\": 0},\n        {\"label\": \"loop_start\"},\n        {\"op\": \"lt\", \"dest\": \"cond\", \"type\": \"bool\", \"args\": [\"x\", \"5\"]},\n        {\"op\": \"br\", \"args\": [\"cond\"], \"labels\": [\"loop_body\", \"exit\"]},\n        {\"label\": \"loop_body\"},\n        {\"op\": \"add\", \"dest\": \"x\", \"type\": \"int\", \"args\": [\"x\", \"1\"]},\n        {\"op\": \"jmp\", \"labels\": [\"loop_start\"]},\n        {\"label\": \"exit\"},\n        {\"op\": \"const\", \"dest\": \"y\", \"type\": \"int\", \"value\": 1}\n      ]\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework4 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#about-the-code",
    "title": "Homework4 - Yashaswini",
    "section": "",
    "text": "#Dominator Computation (find_dominators):\n\nThis function initializes all nodes to be dominated by every other node. Then, using an iterative approach, it refines the set of dominators until convergence.\nThe entry node is assumed to be node 0, and it dominates itself.\nThe dominators of each node are found by intersecting the dominator sets of its predecessors and adding the node itself.\n\n#Dominance Tree Construction (construct_dominance_tree):\n\nThis function builds the dominance tree from the dominator sets.\nFor each node, the immediate dominator (idom) is the node with the highest index in its dominator set that isn’t itself. The tree is constructed using these relationships.\n\n#Dominance Frontier Computation (compute_dominance_frontier):\n\nThe dominance frontier of a node is the set of nodes where the node dominates one of their predecessors but does not strictly dominate the node itself.\nThis is computed using the reverse of the CFG and the dominator sets.\n\nimport json\nfrom collections import defaultdict\n\ndef load_bril_program(filename):\n    \"\"\"Load the Bril program from a JSON file.\"\"\"\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef build_cfg(function):\n    \"\"\"Build the Control Flow Graph (CFG) for a given function.\"\"\"\n    instrs = function['instrs']\n    cfg = defaultdict(list)\n    label_map = {}\n\n    # Map labels to instruction indices\n    for i, instr in enumerate(instrs):\n        if 'label' in instr:\n            label_map[instr['label']] = i\n\n    for i, instr in enumerate(instrs):\n        if 'op' in instr and instr['op'] == 'jmp':\n            target = label_map[instr['labels'][0]]\n            cfg[i].append(target)\n        elif 'op' in instr and instr['op'] == 'br':\n            target1 = label_map[instr['labels'][0]]\n            target2 = label_map[instr['labels'][1]]\n            cfg[i].extend([target1, target2])\n        else:\n            # Fall-through case: connect to the next instruction\n            if i + 1 &lt; len(instrs):\n                cfg[i].append(i + 1)\n\n    return cfg\n\ndef reverse_cfg(cfg):\n    \"\"\"Compute the reverse of the CFG.\"\"\"\n    reverse = defaultdict(list)\n    for node, successors in cfg.items():\n        for succ in successors:\n            reverse[succ].append(node)\n    return reverse\n\ndef find_dominators(function):\n    \"\"\"Find the dominators for each node in the function.\"\"\"\n    cfg = build_cfg(function)\n    nodes = set(cfg.keys())\n    entry = min(nodes)#0  # Assuming the entry node is at index 0\n    dom = {node: nodes.copy() for node in nodes}\n    dom[entry] = {entry}\n\n    changed = True\n    while changed:\n        changed = False\n        for node in nodes - {entry}:\n            #new_dom = set.intersection(*(dom[pred] for pred in reverse_cfg(cfg)[node])) | {node}\n            preds = reverse_cfg(cfg)[node]\n            if preds:\n                # Compute intersection only if there are predecessors\n                new_dom = set.intersection(*(dom[pred] for pred in preds)) | {node}\n            else:\n                # If no predecessors, the dominators are just the node itself\n                new_dom = {node}\n            if dom[node] != new_dom:\n                dom[node] = new_dom\n                changed = True\n\n    return dom\n\ndef construct_dominance_tree(dominators):\n    \"\"\"Construct the dominance tree from the dominators.\"\"\"\n    tree = defaultdict(list)\n    for node, dom_set in dominators.items():\n        if node != min(dom_set):\n            idom = max(dom_set - {node})\n            tree[idom].append(node)\n    return tree\n\ndef compute_dominance_frontier(function, dominators):\n    \"\"\"Compute the dominance frontier for each node.\"\"\"\n    cfg = build_cfg(function)\n    df = defaultdict(set)\n\n    for node in cfg:\n        preds = reverse_cfg(cfg)[node]\n        if len(preds) &gt;= 2:\n            for pred in preds:\n                runner = pred\n                while runner not in dominators[node]:\n                    df[runner].add(node)\n                    #runner = max(dominators[runner] - {runner})\n                    if dominators[runner] - {runner}:\n                        runner = max(dominators[runner] - {runner})\n                    else:\n                        break  # If no other dominators, exit the loop\n\n    return df\n\ndef test_dominance_utilities(function):\n    \"\"\"Test the dominance utilities for a given function.\"\"\"\n    print(f\"Testing function: {function['name']}\")\n    dominators = find_dominators(function)\n    print(f\"Dominators: {dominators}\")\n\n    dominance_tree = construct_dominance_tree(dominators)\n    print(f\"Dominance Tree: {dominance_tree}\")\n\n    dominance_frontier = compute_dominance_frontier(function, dominators)\n    print(f\"Dominance Frontier: {dominance_frontier}\")\n\ndef main():\n    # Load the Bril program from a file\n    #bril_program = load_bril_program('input_bril.json')\n    for bril_program in bril_programs:\n    # Run the tests\n        for function in bril_program['functions']:\n            test_dominance_utilities(function)\n\n# Run the main function\nif __name__ == \"__main__\":\n    main()",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework4 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#testing",
    "href": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#testing",
    "title": "Homework4 - Yashaswini",
    "section": "",
    "text": "I implemented 8 test cases each targeting a different type of CFG. I then manually checked the against the outputs produced by the code. I had to make some changes when the code was unable to handle empty sets but after the output seems to be work correctly",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework4 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#challanges",
    "href": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#challanges",
    "title": "Homework4 - Yashaswini",
    "section": "",
    "text": "The hardest part of this task was understanding ensuring that the algorithm i used could handle various data flow types.\nOnce I was able to get the code to work for both independent branches and nested branches it became much easier.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework4 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#test-cases-and-output",
    "href": "blogs/yashaswini/10-18-2024-HW4-YashaswiniMakaram.html#test-cases-and-output",
    "title": "Homework4 - Yashaswini",
    "section": "",
    "text": "Here are the test cases used and the output from the function after running all of the test cases.\n#Simple Linear Sequence A program with a single linear sequence of instructions. No branches or loops.\n{\n  \"functions\": [\n    {\n      \"name\": \"linear\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"a\", \"type\": \"int\", \"value\": 1},\n        {\"op\": \"add\", \"dest\": \"b\", \"type\": \"int\", \"args\": [\"a\", \"a\"]},\n        {\"op\": \"mul\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"b\", \"a\"]},\n        {\"label\": \"exit\"}\n      ]\n    }\n  ]\n}\n\n#Simple Branch - A conditional branch leading to two different paths and joining back together.\n{\n  \"functions\": [\n    {\n      \"name\": \"branch\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"x\", \"type\": \"int\", \"value\": 5},\n        {\"op\": \"const\", \"dest\": \"y\", \"type\": \"int\", \"value\": 10},\n        {\"op\": \"br\", \"args\": [\"x\"], \"labels\": [\"true_branch\", \"false_branch\"]},\n        {\"label\": \"true_branch\"},\n        {\"op\": \"add\", \"dest\": \"z\", \"type\": \"int\", \"args\": [\"x\", \"y\"]},\n        {\"op\": \"jmp\", \"labels\": [\"join\"]},\n        {\"label\": \"false_branch\"},\n        {\"op\": \"sub\", \"dest\": \"z\", \"type\": \"int\", \"args\": [\"y\", \"x\"]},\n        {\"label\": \"join\"},\n        {\"op\": \"mul\", \"dest\": \"w\", \"type\": \"int\", \"args\": [\"z\", \"x\"]}\n      ]\n    }\n  ]\n}\n\n#Loop with Back Edge -A basic loop where a variable is incremented until a condition is met.\n{\n  \"functions\": [\n    {\n      \"name\": \"loop\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"i\", \"type\": \"int\", \"value\": 0},\n        {\"label\": \"loop_start\"},\n        {\"op\": \"lt\", \"dest\": \"cond\", \"type\": \"bool\", \"args\": [\"i\", \"10\"]},\n        {\"op\": \"br\", \"args\": [\"cond\"], \"labels\": [\"body\", \"exit\"]},\n        {\"label\": \"body\"},\n        {\"op\": \"add\", \"dest\": \"i\", \"type\": \"int\", \"args\": [\"i\", \"1\"]},\n        {\"op\": \"jmp\", \"labels\": [\"loop_start\"]},\n        {\"label\": \"exit\"}\n      ]\n    }\n  ]\n}\n#Nested Branches -Two nested conditional branches.\n{\n  \"functions\": [\n    {\n      \"name\": \"nested_branches\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"a\", \"type\": \"int\", \"value\": 1},\n        {\"op\": \"const\", \"dest\": \"b\", \"type\": \"int\", \"value\": 2},\n        {\"op\": \"br\", \"args\": [\"a\"], \"labels\": [\"branch1\", \"merge\"]},\n        {\"label\": \"branch1\"},\n        {\"op\": \"br\", \"args\": [\"b\"], \"labels\": [\"branch2\", \"merge\"]},\n        {\"label\": \"branch2\"},\n        {\"op\": \"mul\", \"dest\": \"x\", \"type\": \"int\", \"args\": [\"a\", \"b\"]},\n        {\"op\": \"jmp\", \"labels\": [\"merge\"]},\n        {\"label\": \"merge\"},\n        {\"op\": \"add\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"a\", \"b\"]}\n      ]\n    }\n  ]\n}\n#Multiple Independent Branches - A program with two independent branches and a join.\n{\n  \"functions\": [\n    {\n      \"name\": \"independent_branches\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"a\", \"type\": \"int\", \"value\": 3},\n        {\"op\": \"const\", \"dest\": \"b\", \"type\": \"int\", \"value\": 6},\n        {\"op\": \"br\", \"args\": [\"a\"], \"labels\": [\"branch1\", \"merge\"]},\n        {\"label\": \"branch1\"},\n        {\"op\": \"add\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"a\", \"b\"]},\n        {\"op\": \"jmp\", \"labels\": [\"merge\"]},\n        {\"label\": \"branch2\"},\n        {\"op\": \"sub\", \"dest\": \"c\", \"type\": \"int\", \"args\": [\"b\", \"a\"]},\n        {\"op\": \"jmp\", \"labels\": [\"merge\"]},\n        {\"label\": \"merge\"},\n        {\"op\": \"mul\", \"dest\": \"d\", \"type\": \"int\", \"args\": [\"c\", \"a\"]}\n      ]\n    }\n  ]\n}\n#Simple Two-Way Loop - A loop with a branch that exits early based on a condition.\n{\n  \"functions\": [\n    {\n      \"name\": \"two_way_loop\",\n      \"instrs\": [\n        {\"label\": \"entry\"},\n        {\"op\": \"const\", \"dest\": \"x\", \"type\": \"int\", \"value\": 0},\n        {\"label\": \"loop_start\"},\n        {\"op\": \"lt\", \"dest\": \"cond\", \"type\": \"bool\", \"args\": [\"x\", \"5\"]},\n        {\"op\": \"br\", \"args\": [\"cond\"], \"labels\": [\"loop_body\", \"exit\"]},\n        {\"label\": \"loop_body\"},\n        {\"op\": \"add\", \"dest\": \"x\", \"type\": \"int\", \"args\": [\"x\", \"1\"]},\n        {\"op\": \"jmp\", \"labels\": [\"loop_start\"]},\n        {\"label\": \"exit\"},\n        {\"op\": \"const\", \"dest\": \"y\", \"type\": \"int\", \"value\": 1}\n      ]\n    }\n  ]\n}",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework4 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html",
    "href": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html",
    "title": "Homework2 - Yashaswini",
    "section": "",
    "text": "starting from the end of the function, the optimzer keeps a record of the variables used.\nif an instruction is assigning value to a variable that is not used later in the function, then it is eliminated\nonce a used variable is defined in the code, it is removed form the list of used varibles. ## Testing:\n\ntest case: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “const”, “type”: “int”, “dest”: “v3”, “value”: 1 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\noutput: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\nAs you can see above, satrting with the last instruction, out is the only variable used. Going backwards the instruction is assigning value to out which is used so this line stays and the inputs, v1 and v2 are added to used variables, and out is removed from used variables. the next instrction up is assigning value to v3, which is not used. there fore this instruction is eliminated and its inputs are not added to used variables.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework2 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code",
    "href": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code",
    "title": "Homework2 - Yashaswini",
    "section": "",
    "text": "starting from the end of the function, the optimzer keeps a record of the variables used.\nif an instruction is assigning value to a variable that is not used later in the function, then it is eliminated\nonce a used variable is defined in the code, it is removed form the list of used varibles. ## Testing:\n\ntest case: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “const”, “type”: “int”, “dest”: “v3”, “value”: 1 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\noutput: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 2 }, { “op”: “add”, “type”: “int”, “dest”: “out”, “args”: [“v1”, “v2”] }, { “op”: “print”, “args”: [“out”] } ] } ] } ’’’\nAs you can see above, satrting with the last instruction, out is the only variable used. Going backwards the instruction is assigning value to out which is used so this line stays and the inputs, v1 and v2 are added to used variables, and out is removed from used variables. the next instrction up is assigning value to v3, which is not used. there fore this instruction is eliminated and its inputs are not added to used variables.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework2 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code-1",
    "href": "blogs/yashaswini/09-27-2024-HW2-YashaswiniMakaram.html#about-the-code-1",
    "title": "Homework2 - Yashaswini",
    "section": "About the Code",
    "text": "About the Code\n\ngiven a block of code the program starts from the top and assigns a vlaue number to each variable and computation.\nif a variable is reasigned it’s value number changes. the value number of a computation is the same only if both the value numbers of the inputs and the operation is the same\nif two instuctions have the same value number, then the instruction is changed by copying the previously computed value.\nall subsiquent instructions that use that variable will check the value table, and choose the earliest variable that has that value\n\n##Testing\ntest case: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 5 }, { “op”: “add”, “type”: “int”, “dest”: “sum1”, “args”: [“v1”, “v2”] }, { “op”: “add”, “type”: “int”, “dest”: “sum2”, “args”: [“v1”, “v2”] }, { “op”: “mul”, “type”: “int”, “dest”: “prod1”, “args”: [“sum1”, “sum2”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum1”, “prod1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum3”, “sum2”] }, { “op”: “print”, “args”: [“sum3”] } ] } ] }\n’’’\noutput:\n’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 5 }, { “op”: “add”, “type”: “int”, “dest”: “sum1”, “args”: [“v1”, “v2”] }, { “op”: “copy”, “type”: “int”, “dest”: “sum2”, “args”: [“sum1”] }, { “op”: “mul”, “type”: “int”, “dest”: “prod1”, “args”: [“sum1”, “sum1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum1”, “prod1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum3”, “sum1”] }, { “op”: “print”, “args”: [“sum3”] } ] } ] }\n’’’ In this case, the local value numbering does not reducte the number of instructions, however it does reduce the number of computations.\nin order to remove the unused instructions, we can now run the dead code elimination.\noutput: ’’’ { “functions”: [ { “name”: “main”, “instrs”: [ { “op”: “const”, “type”: “int”, “dest”: “v1”, “value”: 10 }, { “op”: “const”, “type”: “int”, “dest”: “v2”, “value”: 5 }, { “op”: “add”, “type”: “int”, “dest”: “sum1”, “args”: [“v1”, “v2”] }, { “op”: “mul”, “type”: “int”, “dest”: “prod”, “args”: [“sum1”, “sum1”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum1”, “prod”] }, { “op”: “add”, “type”: “int”, “dest”: “sum3”, “args”: [“sum3”, “sum1”] }, { “op”: “print”, “args”: [“sum3”] } ] } ] }\n’’’\nnow the duplicated instuction is removed as sum2 is never used.",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Yashaswini",
      "Homework2 - Yashaswini"
    ]
  },
  {
    "objectID": "blogs/matin/2024-09-28-HW2.html",
    "href": "blogs/matin/2024-09-28-HW2.html",
    "title": "Homework 2: Trivial Dead Code Elimination and Local Value Numbering Passes",
    "section": "",
    "text": "Part 1: Trivial Dead Code Elimination\nThe first part of homework 2 is implemented under the examples/tdce_matin.py file in my BRIL fork. It consists of two function passes that are run in the following order: 1. A pass which iteratively detects unused variables across the entire function and removes them. 2. A local version of the pass, which removes any re-definitions of a variable.\nThe test folder under examples/test/tdce under my BRIL fork contains the turnt script and test cases to test my TDCE implementation.\n\n\nPart 2: Local Value Numbering\nThe second part of homework 2 is implemented under the examples/lvn_matin.py file in my BRIL fork. It implements the vanilla LVN algorithm with support for renaming re-assigned variables.\nSimilar to TDCE, I updated the test folder under examples/test/lvn in my BRIL fork to run my LVN implementation with the existing test cases. As my implementation does not support constant folding and identity propogation, I had to update the expected result of some of the tests.\n\n\nCorrectness Evidence\nBesides the passing tests, I applied both my passes to the fizzbuzz benchmark in BRIL and found a decrease in the number of instructions executed as well as no change in the output of the benchmark, futher demonstrating the correctness of the implementation:\n\nWithout LVN + TDCE:\n\nbril2json &lt; ../benchmarks/core/fizz-buzz.bril | brili 10 -p\n1\n2\n-2\n4\n-3\n-2\n7\n8\n-2\ntotal_dyn_inst: 332\n\nWith LVN + TDCE:\n\nbril2json &lt; ../benchmarks/core/fizz-buzz.bril | python3 lvn_matin.py |\n python3 tdce_matin.py | brili 10 -p\n1\n2\n-2\n4\n-3\n-2\n7\n8\n-2\ntotal_dyn_inst: 278\n\n\nChallenges\nOverall, I found the hard part being working with BRIL.\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Blogs",
      "Matin",
      "Homework 2: Trivial Dead Code Elimination and Local Value Numbering Passes"
    ]
  }
]